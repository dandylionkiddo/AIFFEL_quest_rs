INFO:tensorflow:Using MirroredStrategy with devices ('/job:localhost/replica:0/task:0/device:GPU:0',)
INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).
INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).
INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).
INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).
INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).
INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).
INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).
INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).
INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).
INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).
Start Simple Baseline training...
Start epoch 1 with learning rate 0.0003
/opt/conda/lib/python3.9/site-packages/tensorflow/python/data/ops/dataset_ops.py:374: UserWarning: To make it possible to preserve tf.data options across serialization boundaries, their implementation has moved to be part of the TensorFlow graph. As a consequence, the options value is in general no longer known at graph construction time. Invoking this method in graph mode retains the legacy behavior of the original implementation, but note that the returned value might not reflect the actual value of the options.
  warnings.warn("To make it possible to preserve tf.data options across "
Start distributed traininng...
Trained batch 1 batch loss 2.60709143 epoch total loss 2.60709143
Trained batch 2 batch loss 2.3636384 epoch total loss 2.48536491
Trained batch 3 batch loss 2.25322723 epoch total loss 2.40798569
Trained batch 4 batch loss 2.14659786 epoch total loss 2.34263873
Trained batch 5 batch loss 2.05998516 epoch total loss 2.28610802
Trained batch 6 batch loss 2.07190681 epoch total loss 2.25040793
Trained batch 7 batch loss 1.95897818 epoch total loss 2.20877504
Trained batch 8 batch loss 2.06533909 epoch total loss 2.19084549
Trained batch 9 batch loss 1.9038173 epoch total loss 2.15895367
Trained batch 10 batch loss 2.02266026 epoch total loss 2.14532423
Trained batch 11 batch loss 2.04864979 epoch total loss 2.13653564
Trained batch 12 batch loss 1.94831634 epoch total loss 2.1208508
Trained batch 13 batch loss 1.81419253 epoch total loss 2.09726167
Trained batch 14 batch loss 1.86013269 epoch total loss 2.0803237
Trained batch 15 batch loss 1.89640343 epoch total loss 2.06806254
Trained batch 16 batch loss 1.73200989 epoch total loss 2.04705906
Trained batch 17 batch loss 1.61538625 epoch total loss 2.02166653
Trained batch 18 batch loss 1.69101596 epoch total loss 2.00329709
Trained batch 19 batch loss 1.82761407 epoch total loss 1.99405062
Trained batch 20 batch loss 1.83056307 epoch total loss 1.98587632
Trained batch 21 batch loss 1.67218757 epoch total loss 1.97093868
Trained batch 22 batch loss 1.64158273 epoch total loss 1.95596802
Trained batch 23 batch loss 1.63588142 epoch total loss 1.94205105
Trained batch 24 batch loss 1.8045969 epoch total loss 1.93632376
Trained batch 25 batch loss 1.76260126 epoch total loss 1.92937481
Trained batch 26 batch loss 1.63691831 epoch total loss 1.91812646
Trained batch 27 batch loss 1.80701423 epoch total loss 1.91401124
Trained batch 28 batch loss 1.75617576 epoch total loss 1.90837419
Trained batch 29 batch loss 1.72180533 epoch total loss 1.90194082
Trained batch 30 batch loss 1.78543472 epoch total loss 1.89805734
Trained batch 31 batch loss 1.72699404 epoch total loss 1.89253914
Trained batch 32 batch loss 1.75402355 epoch total loss 1.88821054
Trained batch 33 batch loss 1.73395801 epoch total loss 1.88353622
Trained batch 34 batch loss 1.74834585 epoch total loss 1.87956
Trained batch 35 batch loss 1.60411608 epoch total loss 1.87169015
Trained batch 36 batch loss 1.60650408 epoch total loss 1.86432397
Trained batch 37 batch loss 1.74339914 epoch total loss 1.86105573
Trained batch 38 batch loss 1.71658647 epoch total loss 1.85725379
Trained batch 39 batch loss 1.66618013 epoch total loss 1.85235465
Trained batch 40 batch loss 1.67265117 epoch total loss 1.84786201
Trained batch 41 batch loss 1.67545748 epoch total loss 1.84365714
Trained batch 42 batch loss 1.72268641 epoch total loss 1.84077692
Trained batch 43 batch loss 1.68487573 epoch total loss 1.83715129
Trained batch 44 batch loss 1.70891643 epoch total loss 1.83423686
Trained batch 45 batch loss 1.69729495 epoch total loss 1.83119369
Trained batch 46 batch loss 1.61638808 epoch total loss 1.82652402
Trained batch 47 batch loss 1.69912767 epoch total loss 1.82381344
Trained batch 48 batch loss 1.64909482 epoch total loss 1.82017338
Trained batch 49 batch loss 1.55029035 epoch total loss 1.81466568
Trained batch 50 batch loss 1.74028349 epoch total loss 1.81317794
Trained batch 51 batch loss 1.64844704 epoch total loss 1.80994785
Trained batch 52 batch loss 1.57874203 epoch total loss 1.8055017
Trained batch 53 batch loss 1.74088573 epoch total loss 1.80428243
Trained batch 54 batch loss 1.76262712 epoch total loss 1.80351102
Trained batch 55 batch loss 1.63896859 epoch total loss 1.80051935
Trained batch 56 batch loss 1.70709181 epoch total loss 1.79885101
Trained batch 57 batch loss 1.61813009 epoch total loss 1.79568052
Trained batch 58 batch loss 1.64686716 epoch total loss 1.79311478
Trained batch 59 batch loss 1.65696573 epoch total loss 1.79080713
Trained batch 60 batch loss 1.6250782 epoch total loss 1.78804505
Trained batch 61 batch loss 1.55347919 epoch total loss 1.78419971
Trained batch 62 batch loss 1.67831874 epoch total loss 1.78249204
Trained batch 63 batch loss 1.57069314 epoch total loss 1.7791301
Trained batch 64 batch loss 1.64541018 epoch total loss 1.77704072
Trained batch 65 batch loss 1.68587494 epoch total loss 1.77563822
Trained batch 66 batch loss 1.38631105 epoch total loss 1.76973927
Trained batch 67 batch loss 1.4839716 epoch total loss 1.76547408
Trained batch 68 batch loss 1.61125124 epoch total loss 1.76320612
Trained batch 69 batch loss 1.66838241 epoch total loss 1.76183188
Trained batch 70 batch loss 1.5118022 epoch total loss 1.75826
Trained batch 71 batch loss 1.65864086 epoch total loss 1.75685692
Trained batch 72 batch loss 1.69271719 epoch total loss 1.75596607
Trained batch 73 batch loss 1.54651451 epoch total loss 1.75309694
Trained batch 74 batch loss 1.51862681 epoch total loss 1.74992847
Trained batch 75 batch loss 1.56445217 epoch total loss 1.74745548
Trained batch 76 batch loss 1.47793269 epoch total loss 1.74390912
Trained batch 77 batch loss 1.47862136 epoch total loss 1.74046385
Trained batch 78 batch loss 1.51139927 epoch total loss 1.73752713
Trained batch 79 batch loss 1.5407114 epoch total loss 1.73503578
Trained batch 80 batch loss 1.32020986 epoch total loss 1.72985041
Trained batch 81 batch loss 1.40646136 epoch total loss 1.72585797
Trained batch 82 batch loss 1.49517858 epoch total loss 1.72304475
Trained batch 83 batch loss 1.43815112 epoch total loss 1.71961236
Trained batch 84 batch loss 1.32324755 epoch total loss 1.7148937
Trained batch 85 batch loss 1.26686478 epoch total loss 1.70962274
Trained batch 86 batch loss 1.29157233 epoch total loss 1.70476162
Trained batch 87 batch loss 1.57695127 epoch total loss 1.70329249
Trained batch 88 batch loss 1.38892317 epoch total loss 1.69972
Trained batch 89 batch loss 1.68779087 epoch total loss 1.69958603
Trained batch 90 batch loss 1.56159198 epoch total loss 1.69805264
Trained batch 91 batch loss 1.55012453 epoch total loss 1.69642711
Trained batch 92 batch loss 1.6295526 epoch total loss 1.6957
Trained batch 93 batch loss 1.50720906 epoch total loss 1.69367325
Trained batch 94 batch loss 1.39336967 epoch total loss 1.69047856
Trained batch 95 batch loss 1.37150109 epoch total loss 1.68712091
Trained batch 96 batch loss 1.65279961 epoch total loss 1.68676341
Trained batch 97 batch loss 1.69048834 epoch total loss 1.68680191
Trained batch 98 batch loss 1.68129575 epoch total loss 1.68674564
Trained batch 99 batch loss 1.68348694 epoch total loss 1.68671274
Trained batch 100 batch loss 1.44400454 epoch total loss 1.68428564
Trained batch 101 batch loss 1.43836343 epoch total loss 1.68185079
Trained batch 102 batch loss 1.46027136 epoch total loss 1.67967832
Trained batch 103 batch loss 1.49069715 epoch total loss 1.67784357
Trained batch 104 batch loss 1.59015322 epoch total loss 1.67700028
Trained batch 105 batch loss 1.72660244 epoch total loss 1.67747283
Trained batch 106 batch loss 1.77863991 epoch total loss 1.67842722
Trained batch 107 batch loss 1.63564134 epoch total loss 1.67802727
Trained batch 108 batch loss 1.55296743 epoch total loss 1.67686927
Trained batch 109 batch loss 1.64917302 epoch total loss 1.67661512
Trained batch 110 batch loss 1.52292907 epoch total loss 1.67521811
Trained batch 111 batch loss 1.63682723 epoch total loss 1.67487216
Trained batch 112 batch loss 1.58326387 epoch total loss 1.67405427
Trained batch 113 batch loss 1.64356565 epoch total loss 1.67378449
Trained batch 114 batch loss 1.57084477 epoch total loss 1.6728816
Trained batch 115 batch loss 1.56167889 epoch total loss 1.67191458
Trained batch 116 batch loss 1.55316591 epoch total loss 1.67089081
Trained batch 117 batch loss 1.59474063 epoch total loss 1.67023993
Trained batch 118 batch loss 1.56004667 epoch total loss 1.66930604
Trained batch 119 batch loss 1.53045499 epoch total loss 1.66813934
Trained batch 120 batch loss 1.50088906 epoch total loss 1.66674554
Trained batch 121 batch loss 1.68892193 epoch total loss 1.66692877
Trained batch 122 batch loss 1.73748255 epoch total loss 1.66750705
Trained batch 123 batch loss 1.65543282 epoch total loss 1.66740894
Trained batch 124 batch loss 1.66970336 epoch total loss 1.66742742
Trained batch 125 batch loss 1.41676617 epoch total loss 1.66542208
Trained batch 126 batch loss 1.6666069 epoch total loss 1.6654315
Trained batch 127 batch loss 1.44044805 epoch total loss 1.66366
Trained batch 128 batch loss 1.50841737 epoch total loss 1.66244721
Trained batch 129 batch loss 1.69038343 epoch total loss 1.66266382
Trained batch 130 batch loss 1.66647422 epoch total loss 1.66269302
Trained batch 131 batch loss 1.69355226 epoch total loss 1.6629287
Trained batch 132 batch loss 1.58145463 epoch total loss 1.66231143
Trained batch 133 batch loss 1.35052919 epoch total loss 1.65996718
Trained batch 134 batch loss 1.33438492 epoch total loss 1.65753746
Trained batch 135 batch loss 1.29957676 epoch total loss 1.65488589
Trained batch 136 batch loss 1.42880285 epoch total loss 1.65322351
Trained batch 137 batch loss 1.34390342 epoch total loss 1.65096569
Trained batch 138 batch loss 1.4767108 epoch total loss 1.64970303
Trained batch 139 batch loss 1.27141833 epoch total loss 1.6469816
Trained batch 140 batch loss 1.2733134 epoch total loss 1.6443125
Trained batch 141 batch loss 1.43895757 epoch total loss 1.64285612
Trained batch 142 batch loss 1.27386904 epoch total loss 1.6402576
Trained batch 143 batch loss 1.20194888 epoch total loss 1.63719249
Trained batch 144 batch loss 1.24908221 epoch total loss 1.63449728
Trained batch 145 batch loss 1.61187041 epoch total loss 1.63434136
Trained batch 146 batch loss 1.71218669 epoch total loss 1.63487458
Trained batch 147 batch loss 1.66714334 epoch total loss 1.63509405
Trained batch 148 batch loss 1.54778409 epoch total loss 1.6345042
Trained batch 149 batch loss 1.64252806 epoch total loss 1.63455808
Trained batch 150 batch loss 1.47600746 epoch total loss 1.63350105
Trained batch 151 batch loss 1.26137304 epoch total loss 1.63103664
Trained batch 152 batch loss 1.41878486 epoch total loss 1.62964022
Trained batch 153 batch loss 1.5965898 epoch total loss 1.6294241
Trained batch 154 batch loss 1.67703629 epoch total loss 1.62973332
Trained batch 155 batch loss 1.75020134 epoch total loss 1.63051045
Trained batch 156 batch loss 1.6852082 epoch total loss 1.63086116
Trained batch 157 batch loss 1.70956087 epoch total loss 1.63136244
Trained batch 158 batch loss 1.52598524 epoch total loss 1.63069534
Trained batch 159 batch loss 1.57513571 epoch total loss 1.63034594
Trained batch 160 batch loss 1.584059 epoch total loss 1.63005662
Trained batch 161 batch loss 1.51684189 epoch total loss 1.6293534
Trained batch 162 batch loss 1.43594694 epoch total loss 1.62815952
Trained batch 163 batch loss 1.60272622 epoch total loss 1.62800348
Trained batch 164 batch loss 1.42764497 epoch total loss 1.6267817
Trained batch 165 batch loss 1.37950206 epoch total loss 1.62528312
Trained batch 166 batch loss 1.36849761 epoch total loss 1.62373626
Trained batch 167 batch loss 1.10211921 epoch total loss 1.62061274
Trained batch 168 batch loss 1.54789078 epoch total loss 1.62017989
Trained batch 169 batch loss 1.38392758 epoch total loss 1.61878204
Trained batch 170 batch loss 1.71448028 epoch total loss 1.61934495
Trained batch 171 batch loss 1.61407781 epoch total loss 1.61931407
Trained batch 172 batch loss 1.55945849 epoch total loss 1.61896598
Trained batch 173 batch loss 1.59069669 epoch total loss 1.61880267
Trained batch 174 batch loss 1.66030645 epoch total loss 1.6190412
Trained batch 175 batch loss 1.61188912 epoch total loss 1.6190002
Trained batch 176 batch loss 1.5050863 epoch total loss 1.61835301
Trained batch 177 batch loss 1.60232639 epoch total loss 1.61826253
Trained batch 178 batch loss 1.6736877 epoch total loss 1.61857378
Trained batch 179 batch loss 1.59053802 epoch total loss 1.61841726
Trained batch 180 batch loss 1.48643565 epoch total loss 1.61768413
Trained batch 181 batch loss 1.59179521 epoch total loss 1.61754107
Trained batch 182 batch loss 1.60334206 epoch total loss 1.61746299
Trained batch 183 batch loss 1.64974236 epoch total loss 1.61763942
Trained batch 184 batch loss 1.60116196 epoch total loss 1.6175499
Trained batch 185 batch loss 1.66933107 epoch total loss 1.6178298
Trained batch 186 batch loss 1.61892462 epoch total loss 1.61783576
Trained batch 187 batch loss 1.47446084 epoch total loss 1.61706901
Trained batch 188 batch loss 1.53080845 epoch total loss 1.61661029
Trained batch 189 batch loss 1.50488544 epoch total loss 1.61601913
Trained batch 190 batch loss 1.58954883 epoch total loss 1.61587977
Trained batch 191 batch loss 1.6877954 epoch total loss 1.61625636
Trained batch 192 batch loss 1.87500536 epoch total loss 1.6176039
Trained batch 193 batch loss 1.76391351 epoch total loss 1.61836207
Trained batch 194 batch loss 1.80031323 epoch total loss 1.6193
Trained batch 195 batch loss 1.76169658 epoch total loss 1.62003016
Trained batch 196 batch loss 1.61058724 epoch total loss 1.619982
Trained batch 197 batch loss 1.56737661 epoch total loss 1.61971509
Trained batch 198 batch loss 1.61149693 epoch total loss 1.61967361
Trained batch 199 batch loss 1.56638122 epoch total loss 1.61940575
Trained batch 200 batch loss 1.62176991 epoch total loss 1.61941755
Trained batch 201 batch loss 1.15637052 epoch total loss 1.61711383
Trained batch 202 batch loss 1.47279429 epoch total loss 1.61639953
Trained batch 203 batch loss 1.58963871 epoch total loss 1.61626756
Trained batch 204 batch loss 1.46216154 epoch total loss 1.61551213
Trained batch 205 batch loss 1.4876883 epoch total loss 1.61488867
Trained batch 206 batch loss 1.43939281 epoch total loss 1.6140368
Trained batch 207 batch loss 1.3852644 epoch total loss 1.61293161
Trained batch 208 batch loss 1.52910686 epoch total loss 1.61252856
Trained batch 209 batch loss 1.46789646 epoch total loss 1.61183655
Trained batch 210 batch loss 1.18723869 epoch total loss 1.60981464
Trained batch 211 batch loss 1.29590702 epoch total loss 1.60832679
Trained batch 212 batch loss 1.21300578 epoch total loss 1.60646212
Trained batch 213 batch loss 1.19762111 epoch total loss 1.60454273
Trained batch 214 batch loss 1.16682673 epoch total loss 1.60249746
Trained batch 215 batch loss 1.28824282 epoch total loss 1.60103571
Trained batch 216 batch loss 1.38000381 epoch total loss 1.60001242
Trained batch 217 batch loss 1.51481581 epoch total loss 1.59961975
Trained batch 218 batch loss 1.51190329 epoch total loss 1.59921741
Trained batch 219 batch loss 1.58640397 epoch total loss 1.59915888
Trained batch 220 batch loss 1.59308767 epoch total loss 1.59913123
Trained batch 221 batch loss 1.56589031 epoch total loss 1.59898078
Trained batch 222 batch loss 1.22379768 epoch total loss 1.59729075
Trained batch 223 batch loss 1.14434123 epoch total loss 1.59525955
Trained batch 224 batch loss 0.955358505 epoch total loss 1.59240282
Trained batch 225 batch loss 1.17603111 epoch total loss 1.59055233
Trained batch 226 batch loss 1.20511949 epoch total loss 1.5888468
Trained batch 227 batch loss 1.20042324 epoch total loss 1.58713567
Trained batch 228 batch loss 1.18817854 epoch total loss 1.5853858
Trained batch 229 batch loss 1.19245577 epoch total loss 1.5836699
Trained batch 230 batch loss 1.16929245 epoch total loss 1.58186817
Trained batch 231 batch loss 1.1818378 epoch total loss 1.58013642
Trained batch 232 batch loss 1.22866595 epoch total loss 1.57862139
Trained batch 233 batch loss 1.26425874 epoch total loss 1.57727218
Trained batch 234 batch loss 1.29930758 epoch total loss 1.57608438
Trained batch 235 batch loss 1.24309 epoch total loss 1.57466745
Trained batch 236 batch loss 1.55147433 epoch total loss 1.57456923
Trained batch 237 batch loss 1.25656819 epoch total loss 1.57322741
Trained batch 238 batch loss 1.28029847 epoch total loss 1.57199657
Trained batch 239 batch loss 1.41480684 epoch total loss 1.57133889
Trained batch 240 batch loss 1.50721788 epoch total loss 1.57107174
Trained batch 241 batch loss 1.52369511 epoch total loss 1.57087517
Trained batch 242 batch loss 1.55589271 epoch total loss 1.57081318
Trained batch 243 batch loss 1.55924606 epoch total loss 1.5707655
Trained batch 244 batch loss 1.48669887 epoch total loss 1.57042098
Trained batch 245 batch loss 1.57074058 epoch total loss 1.57042229
Trained batch 246 batch loss 1.58165717 epoch total loss 1.57046795
Trained batch 247 batch loss 1.7101475 epoch total loss 1.57103348
Trained batch 248 batch loss 1.62784421 epoch total loss 1.57126248
Trained batch 249 batch loss 1.62506962 epoch total loss 1.57147849
Trained batch 250 batch loss 1.63734889 epoch total loss 1.57174206
Trained batch 251 batch loss 1.63325512 epoch total loss 1.57198715
Trained batch 252 batch loss 1.64699209 epoch total loss 1.57228494
Trained batch 253 batch loss 1.72998226 epoch total loss 1.57290816
Trained batch 254 batch loss 1.68922675 epoch total loss 1.57336617
Trained batch 255 batch loss 1.64966989 epoch total loss 1.57366538
Trained batch 256 batch loss 1.63196874 epoch total loss 1.57389307
Trained batch 257 batch loss 1.58131874 epoch total loss 1.57392204
Trained batch 258 batch loss 1.59131455 epoch total loss 1.57398939
Trained batch 259 batch loss 1.61034203 epoch total loss 1.57412982
Trained batch 260 batch loss 1.59337306 epoch total loss 1.57420385
Trained batch 261 batch loss 1.57184875 epoch total loss 1.57419479
Trained batch 262 batch loss 1.46284342 epoch total loss 1.57376969
Trained batch 263 batch loss 1.59351158 epoch total loss 1.57384479
Trained batch 264 batch loss 1.51651 epoch total loss 1.57362759
Trained batch 265 batch loss 1.55707145 epoch total loss 1.57356513
Trained batch 266 batch loss 1.55237186 epoch total loss 1.57348537
Trained batch 267 batch loss 1.40024221 epoch total loss 1.57283652
Trained batch 268 batch loss 1.45125329 epoch total loss 1.57238293
Trained batch 269 batch loss 1.2449826 epoch total loss 1.5711658
Trained batch 270 batch loss 1.63155937 epoch total loss 1.57138956
Trained batch 271 batch loss 1.50383973 epoch total loss 1.57114029
Trained batch 272 batch loss 1.5563314 epoch total loss 1.57108593
Trained batch 273 batch loss 1.54177582 epoch total loss 1.57097852
Trained batch 274 batch loss 1.50528944 epoch total loss 1.57073879
Trained batch 275 batch loss 1.4900887 epoch total loss 1.57044542
Trained batch 276 batch loss 1.53141046 epoch total loss 1.57030404
Trained batch 277 batch loss 1.57308316 epoch total loss 1.57031405
Trained batch 278 batch loss 1.67435241 epoch total loss 1.57068825
Trained batch 279 batch loss 1.52917 epoch total loss 1.57053947
Trained batch 280 batch loss 1.56452501 epoch total loss 1.5705179
Trained batch 281 batch loss 1.53028417 epoch total loss 1.57037473
Trained batch 282 batch loss 1.53472352 epoch total loss 1.57024837
Trained batch 283 batch loss 1.5099498 epoch total loss 1.57003522
Trained batch 284 batch loss 1.54378784 epoch total loss 1.56994283
Trained batch 285 batch loss 1.5188117 epoch total loss 1.56976342
Trained batch 286 batch loss 1.52142227 epoch total loss 1.56959438
Trained batch 287 batch loss 1.46858072 epoch total loss 1.56924236
Trained batch 288 batch loss 1.57846904 epoch total loss 1.56927443
Trained batch 289 batch loss 1.51366854 epoch total loss 1.56908202
Trained batch 290 batch loss 1.47163928 epoch total loss 1.56874597
Trained batch 291 batch loss 1.58867979 epoch total loss 1.56881452
Trained batch 292 batch loss 1.62546027 epoch total loss 1.56900847
Trained batch 293 batch loss 1.30623245 epoch total loss 1.56811166
Trained batch 294 batch loss 1.39752126 epoch total loss 1.56753147
Trained batch 295 batch loss 1.29475069 epoch total loss 1.56660676
Trained batch 296 batch loss 1.46153736 epoch total loss 1.56625175
Trained batch 297 batch loss 1.31527019 epoch total loss 1.5654068
Trained batch 298 batch loss 1.50111091 epoch total loss 1.56519103
Trained batch 299 batch loss 1.51323938 epoch total loss 1.56501722
Trained batch 300 batch loss 1.4441452 epoch total loss 1.56461442
Trained batch 301 batch loss 1.52183282 epoch total loss 1.5644722
Trained batch 302 batch loss 1.55338216 epoch total loss 1.56443548
Trained batch 303 batch loss 1.62411642 epoch total loss 1.56463242
Trained batch 304 batch loss 1.37890875 epoch total loss 1.56402147
Trained batch 305 batch loss 1.54753947 epoch total loss 1.56396747
Trained batch 306 batch loss 1.48575974 epoch total loss 1.56371188
Trained batch 307 batch loss 1.46355343 epoch total loss 1.56338561
Trained batch 308 batch loss 1.41358221 epoch total loss 1.56289923
Trained batch 309 batch loss 1.53845251 epoch total loss 1.56282008
Trained batch 310 batch loss 1.55127478 epoch total loss 1.56278288
Trained batch 311 batch loss 1.44042325 epoch total loss 1.56238937
Trained batch 312 batch loss 1.53807688 epoch total loss 1.56231153
Trained batch 313 batch loss 1.51066506 epoch total loss 1.56214643
Trained batch 314 batch loss 1.22732365 epoch total loss 1.5610801
Trained batch 315 batch loss 1.01544714 epoch total loss 1.55934799
Trained batch 316 batch loss 1.1349647 epoch total loss 1.55800498
Trained batch 317 batch loss 1.32651591 epoch total loss 1.5572747
Trained batch 318 batch loss 1.42703605 epoch total loss 1.55686522
Trained batch 319 batch loss 1.46476531 epoch total loss 1.55657649
Trained batch 320 batch loss 1.44205511 epoch total loss 1.5562185
Trained batch 321 batch loss 1.50936568 epoch total loss 1.55607259
Trained batch 322 batch loss 1.46402121 epoch total loss 1.55578673
Trained batch 323 batch loss 1.45158553 epoch total loss 1.55546415
Trained batch 324 batch loss 1.44406438 epoch total loss 1.55512035
Trained batch 325 batch loss 1.53032565 epoch total loss 1.55504405
Trained batch 326 batch loss 1.58990622 epoch total loss 1.55515099
Trained batch 327 batch loss 1.59982157 epoch total loss 1.5552876
Trained batch 328 batch loss 1.57779622 epoch total loss 1.55535614
Trained batch 329 batch loss 1.55475378 epoch total loss 1.55535436
Trained batch 330 batch loss 1.60976887 epoch total loss 1.55551922
Trained batch 331 batch loss 1.53142548 epoch total loss 1.55544651
Trained batch 332 batch loss 1.69233859 epoch total loss 1.55585873
Trained batch 333 batch loss 1.59952557 epoch total loss 1.55599
Trained batch 334 batch loss 1.58279288 epoch total loss 1.55607009
Trained batch 335 batch loss 1.52090764 epoch total loss 1.55596519
Trained batch 336 batch loss 1.5590719 epoch total loss 1.55597448
Trained batch 337 batch loss 1.53427207 epoch total loss 1.55591023
Trained batch 338 batch loss 1.50958514 epoch total loss 1.55577314
Trained batch 339 batch loss 1.57026172 epoch total loss 1.55581582
Trained batch 340 batch loss 1.586905 epoch total loss 1.55590725
Trained batch 341 batch loss 1.36614156 epoch total loss 1.55535078
Trained batch 342 batch loss 1.34117854 epoch total loss 1.55472457
Trained batch 343 batch loss 1.36553109 epoch total loss 1.55417311
Trained batch 344 batch loss 1.29345262 epoch total loss 1.55341518
Trained batch 345 batch loss 1.43660402 epoch total loss 1.55307651
Trained batch 346 batch loss 1.23763752 epoch total loss 1.55216479
Trained batch 347 batch loss 1.26879358 epoch total loss 1.55134821
Trained batch 348 batch loss 1.30260873 epoch total loss 1.55063343
Trained batch 349 batch loss 1.30468905 epoch total loss 1.54992867
Trained batch 350 batch loss 1.56510055 epoch total loss 1.54997206
Trained batch 351 batch loss 1.4511981 epoch total loss 1.5496906
Trained batch 352 batch loss 1.55193067 epoch total loss 1.54969704
Trained batch 353 batch loss 1.56921434 epoch total loss 1.54975235
Trained batch 354 batch loss 1.47376621 epoch total loss 1.54953766
Trained batch 355 batch loss 1.52042222 epoch total loss 1.54945564
Trained batch 356 batch loss 1.51964235 epoch total loss 1.54937196
Trained batch 357 batch loss 1.57094324 epoch total loss 1.54943228
Trained batch 358 batch loss 1.53467774 epoch total loss 1.54939103
Trained batch 359 batch loss 1.59103167 epoch total loss 1.54950702
Trained batch 360 batch loss 1.44999659 epoch total loss 1.54923058
Trained batch 361 batch loss 1.51829422 epoch total loss 1.54914498
Trained batch 362 batch loss 1.66934943 epoch total loss 1.5494771
Trained batch 363 batch loss 1.1675297 epoch total loss 1.54842496
Trained batch 364 batch loss 1.60123491 epoch total loss 1.54857
Trained batch 365 batch loss 1.51143336 epoch total loss 1.54846823
Trained batch 366 batch loss 1.38061523 epoch total loss 1.54800963
Trained batch 367 batch loss 1.27542615 epoch total loss 1.54726696
Trained batch 368 batch loss 1.23060536 epoch total loss 1.54640651
Trained batch 369 batch loss 1.20093083 epoch total loss 1.54547024
Trained batch 370 batch loss 1.28131962 epoch total loss 1.54475629
Trained batch 371 batch loss 1.20300865 epoch total loss 1.54383504
Trained batch 372 batch loss 1.33604479 epoch total loss 1.54327655
Trained batch 373 batch loss 1.39713407 epoch total loss 1.54288483
Trained batch 374 batch loss 1.40691781 epoch total loss 1.54252124
Trained batch 375 batch loss 1.61802745 epoch total loss 1.5427227
Trained batch 376 batch loss 1.59383559 epoch total loss 1.54285848
Trained batch 377 batch loss 1.70607257 epoch total loss 1.54329145
Trained batch 378 batch loss 1.62309539 epoch total loss 1.54350257
Trained batch 379 batch loss 1.58192456 epoch total loss 1.5436039
Trained batch 380 batch loss 1.68120575 epoch total loss 1.54396605
Trained batch 381 batch loss 1.59693456 epoch total loss 1.54410505
Trained batch 382 batch loss 1.62022901 epoch total loss 1.54430437
Trained batch 383 batch loss 1.5628469 epoch total loss 1.54435277
Trained batch 384 batch loss 1.56623554 epoch total loss 1.54440975
Trained batch 385 batch loss 1.6897893 epoch total loss 1.54478741
Trained batch 386 batch loss 1.58086205 epoch total loss 1.54488087
Trained batch 387 batch loss 1.60761774 epoch total loss 1.54504299
Trained batch 388 batch loss 1.52800214 epoch total loss 1.54499912
Trained batch 389 batch loss 1.70307672 epoch total loss 1.54540551
Trained batch 390 batch loss 1.56198454 epoch total loss 1.54544806
Trained batch 391 batch loss 1.57606041 epoch total loss 1.54552627
Trained batch 392 batch loss 1.69929409 epoch total loss 1.54591846
Trained batch 393 batch loss 1.6767664 epoch total loss 1.54625142
Trained batch 394 batch loss 1.50618279 epoch total loss 1.54614973
Trained batch 395 batch loss 1.53004181 epoch total loss 1.54610884
Trained batch 396 batch loss 1.57572043 epoch total loss 1.54618371
Trained batch 397 batch loss 1.51199102 epoch total loss 1.54609752
Trained batch 398 batch loss 1.55133522 epoch total loss 1.54611063
Trained batch 399 batch loss 1.59933901 epoch total loss 1.54624414
Trained batch 400 batch loss 1.56940937 epoch total loss 1.54630208
Trained batch 401 batch loss 1.51038301 epoch total loss 1.54621243
Trained batch 402 batch loss 1.54631841 epoch total loss 1.54621267
Trained batch 403 batch loss 1.56729853 epoch total loss 1.54626513
Trained batch 404 batch loss 1.61016202 epoch total loss 1.54642332
Trained batch 405 batch loss 1.48604083 epoch total loss 1.54627419
Trained batch 406 batch loss 1.60626268 epoch total loss 1.54642189
Trained batch 407 batch loss 1.34167981 epoch total loss 1.54591882
Trained batch 408 batch loss 1.48484182 epoch total loss 1.54576921
Trained batch 409 batch loss 1.47126341 epoch total loss 1.54558694
Trained batch 410 batch loss 1.44859838 epoch total loss 1.54535043
Trained batch 411 batch loss 1.54940116 epoch total loss 1.54536021
Trained batch 412 batch loss 1.52518249 epoch total loss 1.54531133
Trained batch 413 batch loss 1.3929925 epoch total loss 1.54494262
Trained batch 414 batch loss 1.70250595 epoch total loss 1.54532313
Trained batch 415 batch loss 1.68898392 epoch total loss 1.54566932
Trained batch 416 batch loss 1.42398143 epoch total loss 1.5453769
Trained batch 417 batch loss 1.3944205 epoch total loss 1.54501486
Trained batch 418 batch loss 1.41882515 epoch total loss 1.5447129
Trained batch 419 batch loss 1.520082 epoch total loss 1.54465413
Trained batch 420 batch loss 1.4961189 epoch total loss 1.5445385
Trained batch 421 batch loss 1.56388545 epoch total loss 1.54458451
Trained batch 422 batch loss 1.5899477 epoch total loss 1.54469204
Trained batch 423 batch loss 1.45809102 epoch total loss 1.54448724
Trained batch 424 batch loss 1.50678551 epoch total loss 1.54439831
Trained batch 425 batch loss 1.50795949 epoch total loss 1.54431248
Trained batch 426 batch loss 1.51717365 epoch total loss 1.54424882
Trained batch 427 batch loss 1.5179615 epoch total loss 1.54418719
Trained batch 428 batch loss 1.41110086 epoch total loss 1.54387617
Trained batch 429 batch loss 1.37515378 epoch total loss 1.5434829
Trained batch 430 batch loss 1.56871414 epoch total loss 1.54354167
Trained batch 431 batch loss 1.51660466 epoch total loss 1.54347908
Trained batch 432 batch loss 1.54824257 epoch total loss 1.54349
Trained batch 433 batch loss 1.5675931 epoch total loss 1.54354572
Trained batch 434 batch loss 1.32114196 epoch total loss 1.54303324
Trained batch 435 batch loss 1.53021133 epoch total loss 1.5430038
Trained batch 436 batch loss 1.63128591 epoch total loss 1.54320633
Trained batch 437 batch loss 1.55438209 epoch total loss 1.54323184
Trained batch 438 batch loss 1.45119429 epoch total loss 1.54302168
Trained batch 439 batch loss 1.59147882 epoch total loss 1.54313207
Trained batch 440 batch loss 1.57073212 epoch total loss 1.54319489
Trained batch 441 batch loss 1.50459099 epoch total loss 1.54310727
Trained batch 442 batch loss 1.53330898 epoch total loss 1.54308522
Trained batch 443 batch loss 1.47699153 epoch total loss 1.54293597
Trained batch 444 batch loss 1.37332892 epoch total loss 1.54255402
Trained batch 445 batch loss 1.40729368 epoch total loss 1.54225
Trained batch 446 batch loss 1.4555124 epoch total loss 1.54205561
Trained batch 447 batch loss 1.40322208 epoch total loss 1.54174495
Trained batch 448 batch loss 1.39144158 epoch total loss 1.54140937
Trained batch 449 batch loss 1.28292584 epoch total loss 1.54083359
Trained batch 450 batch loss 1.22686458 epoch total loss 1.54013586
Trained batch 451 batch loss 1.42614639 epoch total loss 1.53988314
Trained batch 452 batch loss 1.45875406 epoch total loss 1.53970361
Trained batch 453 batch loss 1.48832476 epoch total loss 1.53959024
Trained batch 454 batch loss 1.45729399 epoch total loss 1.53940892
Trained batch 455 batch loss 1.4456594 epoch total loss 1.53920293
Trained batch 456 batch loss 1.48885894 epoch total loss 1.53909254
Trained batch 457 batch loss 1.48698723 epoch total loss 1.53897846
Trained batch 458 batch loss 1.40016699 epoch total loss 1.53867531
Trained batch 459 batch loss 1.46120465 epoch total loss 1.53850651
Trained batch 460 batch loss 1.4163264 epoch total loss 1.53824091
Trained batch 461 batch loss 1.47403193 epoch total loss 1.53810167
Trained batch 462 batch loss 1.43749332 epoch total loss 1.537884
Trained batch 463 batch loss 1.32498527 epoch total loss 1.53742421
Trained batch 464 batch loss 1.3241396 epoch total loss 1.53696454
Trained batch 465 batch loss 1.31041551 epoch total loss 1.53647733
Trained batch 466 batch loss 1.36568499 epoch total loss 1.53611076
Trained batch 467 batch loss 1.59560919 epoch total loss 1.53623819
Trained batch 468 batch loss 1.46444702 epoch total loss 1.53608477
Trained batch 469 batch loss 1.64267707 epoch total loss 1.5363121
Trained batch 470 batch loss 1.63910341 epoch total loss 1.53653085
Trained batch 471 batch loss 1.55152965 epoch total loss 1.53656268
Trained batch 472 batch loss 1.52168179 epoch total loss 1.53653109
Trained batch 473 batch loss 1.44944859 epoch total loss 1.53634703
Trained batch 474 batch loss 1.09815717 epoch total loss 1.53542256
Trained batch 475 batch loss 1.40680933 epoch total loss 1.53515172
Trained batch 476 batch loss 1.45516264 epoch total loss 1.53498363
Trained batch 477 batch loss 1.43055558 epoch total loss 1.53476465
Trained batch 478 batch loss 1.48791456 epoch total loss 1.53466666
Trained batch 479 batch loss 1.66048467 epoch total loss 1.53492928
Trained batch 480 batch loss 1.58123481 epoch total loss 1.53502584
Trained batch 481 batch loss 1.53636718 epoch total loss 1.53502858
Trained batch 482 batch loss 1.5568614 epoch total loss 1.535074
Trained batch 483 batch loss 1.3653307 epoch total loss 1.53472257
Trained batch 484 batch loss 1.50217867 epoch total loss 1.53465533
Trained batch 485 batch loss 1.52246666 epoch total loss 1.53463018
Trained batch 486 batch loss 1.61690509 epoch total loss 1.53479946
Trained batch 487 batch loss 1.62270069 epoch total loss 1.53497994
Trained batch 488 batch loss 1.58536172 epoch total loss 1.53508317
Trained batch 489 batch loss 1.54029393 epoch total loss 1.53509378
Trained batch 490 batch loss 1.68854284 epoch total loss 1.53540695
Trained batch 491 batch loss 1.83514404 epoch total loss 1.53601742
Trained batch 492 batch loss 1.5564549 epoch total loss 1.53605902
Trained batch 493 batch loss 1.71054459 epoch total loss 1.53641295
Trained batch 494 batch loss 1.60270262 epoch total loss 1.53654718
Trained batch 495 batch loss 1.37396038 epoch total loss 1.53621876
Trained batch 496 batch loss 1.61555767 epoch total loss 1.53637862
Trained batch 497 batch loss 1.53190506 epoch total loss 1.53636968
Trained batch 498 batch loss 1.56448054 epoch total loss 1.53642607
Trained batch 499 batch loss 1.38370752 epoch total loss 1.53612
Trained batch 500 batch loss 1.26820433 epoch total loss 1.53558421
Trained batch 501 batch loss 1.31535542 epoch total loss 1.53514469
Trained batch 502 batch loss 1.14269364 epoch total loss 1.53436291
Trained batch 503 batch loss 1.35644221 epoch total loss 1.53400922
Trained batch 504 batch loss 1.31208444 epoch total loss 1.53356886
Trained batch 505 batch loss 1.14731836 epoch total loss 1.53280401
Trained batch 506 batch loss 1.06533492 epoch total loss 1.53188014
Trained batch 507 batch loss 1.43043232 epoch total loss 1.53168
Trained batch 508 batch loss 1.65609789 epoch total loss 1.53192496
Trained batch 509 batch loss 1.57342327 epoch total loss 1.5320065
Trained batch 510 batch loss 1.59972382 epoch total loss 1.5321393
Trained batch 511 batch loss 1.62338161 epoch total loss 1.53231776
Trained batch 512 batch loss 1.57973897 epoch total loss 1.53241038
Trained batch 513 batch loss 1.63101411 epoch total loss 1.53260267
Trained batch 514 batch loss 1.68847144 epoch total loss 1.53290594
Trained batch 515 batch loss 1.37646616 epoch total loss 1.53260219
Trained batch 516 batch loss 1.64132428 epoch total loss 1.53281283
Trained batch 517 batch loss 1.44289362 epoch total loss 1.53263879
Trained batch 518 batch loss 1.55704188 epoch total loss 1.532686
Trained batch 519 batch loss 1.45807457 epoch total loss 1.53254223
Trained batch 520 batch loss 1.51079607 epoch total loss 1.53250039
Trained batch 521 batch loss 1.57324612 epoch total loss 1.53257859
Trained batch 522 batch loss 1.57487559 epoch total loss 1.53265965
Trained batch 523 batch loss 1.5252459 epoch total loss 1.53264546
Trained batch 524 batch loss 1.51980352 epoch total loss 1.53262091
Trained batch 525 batch loss 1.5897603 epoch total loss 1.53272986
Trained batch 526 batch loss 1.64415956 epoch total loss 1.5329417
Trained batch 527 batch loss 1.68569887 epoch total loss 1.5332315
Trained batch 528 batch loss 1.68810129 epoch total loss 1.53352487
Trained batch 529 batch loss 1.64867592 epoch total loss 1.53374255
Trained batch 530 batch loss 1.57307422 epoch total loss 1.5338167
Trained batch 531 batch loss 1.5406208 epoch total loss 1.53382957
Trained batch 532 batch loss 1.49579382 epoch total loss 1.53375804
Trained batch 533 batch loss 1.60788083 epoch total loss 1.53389716
Trained batch 534 batch loss 1.5307399 epoch total loss 1.53389132
Trained batch 535 batch loss 1.54049921 epoch total loss 1.53390372
Trained batch 536 batch loss 1.39036584 epoch total loss 1.53363597
Trained batch 537 batch loss 1.2553302 epoch total loss 1.53311765
Trained batch 538 batch loss 1.17552757 epoch total loss 1.53245306
Trained batch 539 batch loss 1.30917883 epoch total loss 1.53203881
Trained batch 540 batch loss 1.72389007 epoch total loss 1.53239405
Trained batch 541 batch loss 1.57128382 epoch total loss 1.53246593
Trained batch 542 batch loss 1.5408417 epoch total loss 1.53248143
Trained batch 543 batch loss 1.36643052 epoch total loss 1.53217566
Trained batch 544 batch loss 1.31108129 epoch total loss 1.53176928
Trained batch 545 batch loss 1.51002383 epoch total loss 1.53172934
Trained batch 546 batch loss 1.55596352 epoch total loss 1.53177369
Trained batch 547 batch loss 1.54650021 epoch total loss 1.53180063
Trained batch 548 batch loss 1.55157876 epoch total loss 1.53183675
Trained batch 549 batch loss 1.36486816 epoch total loss 1.53153265
Trained batch 550 batch loss 1.36213732 epoch total loss 1.53122461
Trained batch 551 batch loss 1.51200056 epoch total loss 1.5311898
Trained batch 552 batch loss 1.59108126 epoch total loss 1.53129816
Trained batch 553 batch loss 1.48549807 epoch total loss 1.53121531
Trained batch 554 batch loss 1.44477618 epoch total loss 1.53105927
Trained batch 555 batch loss 1.36898792 epoch total loss 1.5307672
Trained batch 556 batch loss 1.35961914 epoch total loss 1.5304594
Trained batch 557 batch loss 1.44483709 epoch total loss 1.53030562
Trained batch 558 batch loss 1.64494944 epoch total loss 1.53051114
Trained batch 559 batch loss 1.6268754 epoch total loss 1.53068352
Trained batch 560 batch loss 1.49215066 epoch total loss 1.53061473
Trained batch 561 batch loss 1.62293804 epoch total loss 1.53077924
Trained batch 562 batch loss 1.58963633 epoch total loss 1.53088403
Trained batch 563 batch loss 1.10333312 epoch total loss 1.53012455
Trained batch 564 batch loss 1.40420127 epoch total loss 1.52990127
Trained batch 565 batch loss 1.28214371 epoch total loss 1.52946281
Trained batch 566 batch loss 1.36833227 epoch total loss 1.52917814
Trained batch 567 batch loss 1.21938109 epoch total loss 1.52863169
Trained batch 568 batch loss 1.59524274 epoch total loss 1.52874899
Trained batch 569 batch loss 1.48428106 epoch total loss 1.52867079
Trained batch 570 batch loss 1.48801398 epoch total loss 1.5285995
Trained batch 571 batch loss 1.52066755 epoch total loss 1.52858567
Trained batch 572 batch loss 1.72445989 epoch total loss 1.52892816
Trained batch 573 batch loss 1.46781945 epoch total loss 1.52882147
Trained batch 574 batch loss 1.516559 epoch total loss 1.52880013
Trained batch 575 batch loss 1.48489285 epoch total loss 1.52872372
Trained batch 576 batch loss 1.41086817 epoch total loss 1.52851915
Trained batch 577 batch loss 1.45023251 epoch total loss 1.52838349
Trained batch 578 batch loss 1.46812415 epoch total loss 1.52827919
Trained batch 579 batch loss 1.43072796 epoch total loss 1.52811074
Trained batch 580 batch loss 1.42282665 epoch total loss 1.52792931
Trained batch 581 batch loss 1.41828346 epoch total loss 1.52774048
Trained batch 582 batch loss 1.51457453 epoch total loss 1.52771795
Trained batch 583 batch loss 1.5476675 epoch total loss 1.52775216
Trained batch 584 batch loss 1.48244643 epoch total loss 1.52767456
Trained batch 585 batch loss 1.47124755 epoch total loss 1.52757812
Trained batch 586 batch loss 1.49716747 epoch total loss 1.52752626
Trained batch 587 batch loss 1.4759984 epoch total loss 1.52743852
Trained batch 588 batch loss 1.39426279 epoch total loss 1.52721202
Trained batch 589 batch loss 1.41091406 epoch total loss 1.52701449
Trained batch 590 batch loss 1.44984174 epoch total loss 1.52688372
Trained batch 591 batch loss 1.3868196 epoch total loss 1.52664673
Trained batch 592 batch loss 1.36218023 epoch total loss 1.52636898
Trained batch 593 batch loss 1.33975434 epoch total loss 1.52605426
Trained batch 594 batch loss 1.32478774 epoch total loss 1.52571547
Trained batch 595 batch loss 1.48064899 epoch total loss 1.52563965
Trained batch 596 batch loss 1.46233201 epoch total loss 1.52553344
Trained batch 597 batch loss 1.34967434 epoch total loss 1.52523887
Trained batch 598 batch loss 1.32548892 epoch total loss 1.52490485
Trained batch 599 batch loss 1.36209559 epoch total loss 1.52463317
Trained batch 600 batch loss 1.376297 epoch total loss 1.52438593
Trained batch 601 batch loss 1.3425281 epoch total loss 1.52408326
Trained batch 602 batch loss 1.37689114 epoch total loss 1.52383876
Trained batch 603 batch loss 1.36442828 epoch total loss 1.52357447
Trained batch 604 batch loss 1.58612084 epoch total loss 1.52367795
Trained batch 605 batch loss 1.51279163 epoch total loss 1.52366006
Trained batch 606 batch loss 1.54257751 epoch total loss 1.5236913
Trained batch 607 batch loss 1.49358845 epoch total loss 1.52364171
Trained batch 608 batch loss 1.50036263 epoch total loss 1.52360344
Trained batch 609 batch loss 1.37819493 epoch total loss 1.52336466
Trained batch 610 batch loss 1.56890225 epoch total loss 1.52343929
Trained batch 611 batch loss 1.29564977 epoch total loss 1.52306652
Trained batch 612 batch loss 1.42358744 epoch total loss 1.52290392
Trained batch 613 batch loss 1.42814088 epoch total loss 1.52274942
Trained batch 614 batch loss 1.16282487 epoch total loss 1.52216327
Trained batch 615 batch loss 1.46407366 epoch total loss 1.52206874
Trained batch 616 batch loss 1.5003233 epoch total loss 1.52203345
Trained batch 617 batch loss 1.40816736 epoch total loss 1.5218488
Trained batch 618 batch loss 1.51631117 epoch total loss 1.52183986
Trained batch 619 batch loss 1.50987291 epoch total loss 1.52182055
Trained batch 620 batch loss 1.49888563 epoch total loss 1.52178359
Trained batch 621 batch loss 1.5623759 epoch total loss 1.52184892
Trained batch 622 batch loss 1.39522386 epoch total loss 1.52164531
Trained batch 623 batch loss 1.48052359 epoch total loss 1.52157927
Trained batch 624 batch loss 1.34491956 epoch total loss 1.52129614
Trained batch 625 batch loss 1.46789408 epoch total loss 1.52121079
Trained batch 626 batch loss 1.5142622 epoch total loss 1.5211997
Trained batch 627 batch loss 1.51321113 epoch total loss 1.52118695
Trained batch 628 batch loss 1.49735034 epoch total loss 1.52114892
Trained batch 629 batch loss 1.47300041 epoch total loss 1.52107251
Trained batch 630 batch loss 1.4235301 epoch total loss 1.52091765
Trained batch 631 batch loss 1.38866973 epoch total loss 1.52070808
Trained batch 632 batch loss 1.53886783 epoch total loss 1.52073681
Trained batch 633 batch loss 1.15627623 epoch total loss 1.52016103
Trained batch 634 batch loss 1.34907508 epoch total loss 1.51989114
Trained batch 635 batch loss 1.28800046 epoch total loss 1.519526
Trained batch 636 batch loss 1.31549335 epoch total loss 1.51920521
Trained batch 637 batch loss 1.49604511 epoch total loss 1.51916873
Trained batch 638 batch loss 1.4280808 epoch total loss 1.51902604
Trained batch 639 batch loss 1.42611372 epoch total loss 1.51888061
Trained batch 640 batch loss 1.45544362 epoch total loss 1.51878142
Trained batch 641 batch loss 1.47599113 epoch total loss 1.51871479
Trained batch 642 batch loss 1.28391 epoch total loss 1.51834905
Trained batch 643 batch loss 1.37163973 epoch total loss 1.51812088
Trained batch 644 batch loss 1.29137409 epoch total loss 1.51776886
Trained batch 645 batch loss 1.26963973 epoch total loss 1.51738417
Trained batch 646 batch loss 1.23566341 epoch total loss 1.51694798
Trained batch 647 batch loss 1.22807229 epoch total loss 1.51650155
Trained batch 648 batch loss 1.38824439 epoch total loss 1.51630366
Trained batch 649 batch loss 1.3370347 epoch total loss 1.51602745
Trained batch 650 batch loss 1.25808716 epoch total loss 1.5156306
Trained batch 651 batch loss 1.46315765 epoch total loss 1.51555
Trained batch 652 batch loss 1.40336 epoch total loss 1.515378
Trained batch 653 batch loss 1.50351977 epoch total loss 1.51535988
Trained batch 654 batch loss 1.2776655 epoch total loss 1.51499641
Trained batch 655 batch loss 1.31348705 epoch total loss 1.51468873
Trained batch 656 batch loss 1.30794811 epoch total loss 1.51437354
Trained batch 657 batch loss 1.2877667 epoch total loss 1.51402867
Trained batch 658 batch loss 1.41654706 epoch total loss 1.51388049
Trained batch 659 batch loss 1.49603796 epoch total loss 1.51385343
Trained batch 660 batch loss 1.43577623 epoch total loss 1.51373518
Trained batch 661 batch loss 1.28432083 epoch total loss 1.51338804
Trained batch 662 batch loss 1.3488431 epoch total loss 1.51313949
Trained batch 663 batch loss 1.22773242 epoch total loss 1.5127089
Trained batch 664 batch loss 1.22795808 epoch total loss 1.51228011
Trained batch 665 batch loss 1.02681577 epoch total loss 1.51155007
Trained batch 666 batch loss 1.54726052 epoch total loss 1.51160359
Trained batch 667 batch loss 1.41557145 epoch total loss 1.51145971
Trained batch 668 batch loss 1.25055349 epoch total loss 1.51106906
Trained batch 669 batch loss 1.55613589 epoch total loss 1.51113653
Trained batch 670 batch loss 1.38053393 epoch total loss 1.51094162
Trained batch 671 batch loss 1.50028777 epoch total loss 1.51092577
Trained batch 672 batch loss 1.42810822 epoch total loss 1.51080251
Trained batch 673 batch loss 1.3835299 epoch total loss 1.51061344
Trained batch 674 batch loss 1.28188396 epoch total loss 1.51027405
Trained batch 675 batch loss 1.51100469 epoch total loss 1.51027501
Trained batch 676 batch loss 1.17666101 epoch total loss 1.50978148
Trained batch 677 batch loss 1.2753545 epoch total loss 1.50943518
Trained batch 678 batch loss 1.37970209 epoch total loss 1.50924385
Trained batch 679 batch loss 1.59491611 epoch total loss 1.50937009
Trained batch 680 batch loss 1.54097307 epoch total loss 1.5094167
Trained batch 681 batch loss 1.59673643 epoch total loss 1.50954473
Trained batch 682 batch loss 1.37459421 epoch total loss 1.50934696
Trained batch 683 batch loss 1.52736616 epoch total loss 1.50937331
Trained batch 684 batch loss 1.49869335 epoch total loss 1.50935769
Trained batch 685 batch loss 1.5110755 epoch total loss 1.50936019
Trained batch 686 batch loss 1.54771924 epoch total loss 1.5094161
Trained batch 687 batch loss 1.50470269 epoch total loss 1.50940931
Trained batch 688 batch loss 1.46373308 epoch total loss 1.50934303
Trained batch 689 batch loss 1.45944333 epoch total loss 1.50927067
Trained batch 690 batch loss 1.4448669 epoch total loss 1.50917721
Trained batch 691 batch loss 1.41569757 epoch total loss 1.50904191
Trained batch 692 batch loss 1.40578055 epoch total loss 1.50889266
Trained batch 693 batch loss 1.24743295 epoch total loss 1.50851536
Trained batch 694 batch loss 1.54864097 epoch total loss 1.50857306
Trained batch 695 batch loss 1.4424715 epoch total loss 1.50847805
Trained batch 696 batch loss 1.39527774 epoch total loss 1.50831532
Trained batch 697 batch loss 1.61149824 epoch total loss 1.50846326
Trained batch 698 batch loss 1.55047131 epoch total loss 1.50852346
Trained batch 699 batch loss 1.49283612 epoch total loss 1.50850093
Trained batch 700 batch loss 1.15553021 epoch total loss 1.50799668
Trained batch 701 batch loss 1.40479517 epoch total loss 1.50784945
Trained batch 702 batch loss 1.48707616 epoch total loss 1.50781977
Trained batch 703 batch loss 1.41964734 epoch total loss 1.50769448
Trained batch 704 batch loss 1.52652788 epoch total loss 1.50772107
Trained batch 705 batch loss 1.39221776 epoch total loss 1.50755727
Trained batch 706 batch loss 1.30227196 epoch total loss 1.50726652
Trained batch 707 batch loss 1.50098681 epoch total loss 1.50725758
Trained batch 708 batch loss 1.47264874 epoch total loss 1.5072087
Trained batch 709 batch loss 1.4701674 epoch total loss 1.50715649
Trained batch 710 batch loss 1.54583073 epoch total loss 1.50721097
Trained batch 711 batch loss 1.34018707 epoch total loss 1.50697601
Trained batch 712 batch loss 1.10208225 epoch total loss 1.50640726
Trained batch 713 batch loss 1.2656281 epoch total loss 1.50606966
Trained batch 714 batch loss 1.2245841 epoch total loss 1.50567544
Trained batch 715 batch loss 1.24269128 epoch total loss 1.50530756
Trained batch 716 batch loss 1.39509082 epoch total loss 1.50515378
Trained batch 717 batch loss 1.39995253 epoch total loss 1.50500691
Trained batch 718 batch loss 1.48391533 epoch total loss 1.50497746
Trained batch 719 batch loss 1.27488279 epoch total loss 1.50465751
Trained batch 720 batch loss 1.44270027 epoch total loss 1.50457156
Trained batch 721 batch loss 1.42802668 epoch total loss 1.50446534
Trained batch 722 batch loss 1.45121682 epoch total loss 1.50439143
Trained batch 723 batch loss 1.45701945 epoch total loss 1.50432599
Trained batch 724 batch loss 1.30405021 epoch total loss 1.50404942
Trained batch 725 batch loss 1.41204858 epoch total loss 1.50392258
Trained batch 726 batch loss 1.40381622 epoch total loss 1.50378466
Trained batch 727 batch loss 1.49546897 epoch total loss 1.50377321
Trained batch 728 batch loss 1.4350692 epoch total loss 1.50367892
Trained batch 729 batch loss 1.39894092 epoch total loss 1.50353515
Trained batch 730 batch loss 1.3179574 epoch total loss 1.503281
Trained batch 731 batch loss 1.36345243 epoch total loss 1.50308967
Trained batch 732 batch loss 1.31604874 epoch total loss 1.50283408
Trained batch 733 batch loss 1.24821043 epoch total loss 1.50248671
Trained batch 734 batch loss 1.26201344 epoch total loss 1.502159
Trained batch 735 batch loss 1.36184466 epoch total loss 1.50196803
Trained batch 736 batch loss 1.23043406 epoch total loss 1.50159919
Trained batch 737 batch loss 1.35552204 epoch total loss 1.50140095
Trained batch 738 batch loss 1.44360149 epoch total loss 1.50132263
Trained batch 739 batch loss 1.2304697 epoch total loss 1.50095606
Trained batch 740 batch loss 1.38358068 epoch total loss 1.50079739
Trained batch 741 batch loss 1.41999078 epoch total loss 1.50068843
Trained batch 742 batch loss 1.43526769 epoch total loss 1.50060034
Trained batch 743 batch loss 1.5212822 epoch total loss 1.50062811
Trained batch 744 batch loss 1.53340399 epoch total loss 1.50067222
Trained batch 745 batch loss 1.35225701 epoch total loss 1.50047302
Trained batch 746 batch loss 1.25789714 epoch total loss 1.50014794
Trained batch 747 batch loss 1.24015808 epoch total loss 1.49979985
Trained batch 748 batch loss 1.26856947 epoch total loss 1.49949062
Trained batch 749 batch loss 1.3563838 epoch total loss 1.49929953
Trained batch 750 batch loss 1.33535731 epoch total loss 1.4990809
Trained batch 751 batch loss 1.32490873 epoch total loss 1.49884903
Trained batch 752 batch loss 1.51933253 epoch total loss 1.49887621
Trained batch 753 batch loss 1.3187449 epoch total loss 1.49863696
Trained batch 754 batch loss 1.26992559 epoch total loss 1.49833357
Trained batch 755 batch loss 1.39042687 epoch total loss 1.49819064
Trained batch 756 batch loss 1.50238478 epoch total loss 1.49819624
Trained batch 757 batch loss 1.43195438 epoch total loss 1.49810874
Trained batch 758 batch loss 1.43369019 epoch total loss 1.49802387
Trained batch 759 batch loss 1.35272837 epoch total loss 1.49783254
Trained batch 760 batch loss 1.30079198 epoch total loss 1.49757326
Trained batch 761 batch loss 1.44809222 epoch total loss 1.49750817
Trained batch 762 batch loss 1.64314699 epoch total loss 1.49769938
Trained batch 763 batch loss 1.57617545 epoch total loss 1.49780226
Trained batch 764 batch loss 1.69791102 epoch total loss 1.49806416
Trained batch 765 batch loss 1.59713364 epoch total loss 1.49819362
Trained batch 766 batch loss 1.47924709 epoch total loss 1.49816895
Trained batch 767 batch loss 1.63455057 epoch total loss 1.49834669
Trained batch 768 batch loss 1.40945685 epoch total loss 1.49823093
Trained batch 769 batch loss 1.48361921 epoch total loss 1.49821198
Trained batch 770 batch loss 1.61533594 epoch total loss 1.49836409
Trained batch 771 batch loss 1.5951556 epoch total loss 1.49848974
Trained batch 772 batch loss 1.45175147 epoch total loss 1.49842918
Trained batch 773 batch loss 1.48342133 epoch total loss 1.49840975
Trained batch 774 batch loss 1.31297016 epoch total loss 1.49817026
Trained batch 775 batch loss 1.51966059 epoch total loss 1.49819791
Trained batch 776 batch loss 1.4553535 epoch total loss 1.49814272
Trained batch 777 batch loss 1.45148873 epoch total loss 1.49808264
Trained batch 778 batch loss 1.55373788 epoch total loss 1.49815416
Trained batch 779 batch loss 1.50498545 epoch total loss 1.49816298
Trained batch 780 batch loss 1.21297359 epoch total loss 1.49779737
Trained batch 781 batch loss 1.09688711 epoch total loss 1.49728417
Trained batch 782 batch loss 1.40538716 epoch total loss 1.49716663
Trained batch 783 batch loss 1.34221816 epoch total loss 1.49696863
Trained batch 784 batch loss 1.43294954 epoch total loss 1.49688709
Trained batch 785 batch loss 1.46740866 epoch total loss 1.49684954
Trained batch 786 batch loss 1.44185495 epoch total loss 1.49677956
Trained batch 787 batch loss 1.42334199 epoch total loss 1.49668622
Trained batch 788 batch loss 1.41317546 epoch total loss 1.49658036
Trained batch 789 batch loss 1.40154719 epoch total loss 1.49645984
Trained batch 790 batch loss 1.3206321 epoch total loss 1.49623728
Trained batch 791 batch loss 1.32135105 epoch total loss 1.49601626
Trained batch 792 batch loss 1.2931459 epoch total loss 1.49576008
Trained batch 793 batch loss 1.29298353 epoch total loss 1.49550438
Trained batch 794 batch loss 1.26094079 epoch total loss 1.49520898
Trained batch 795 batch loss 1.44997883 epoch total loss 1.495152
Trained batch 796 batch loss 1.41167772 epoch total loss 1.49504709
Trained batch 797 batch loss 1.59973168 epoch total loss 1.49517846
Trained batch 798 batch loss 1.46390152 epoch total loss 1.49513924
Trained batch 799 batch loss 1.56900334 epoch total loss 1.49523163
Trained batch 800 batch loss 1.43874776 epoch total loss 1.49516094
Trained batch 801 batch loss 1.54991889 epoch total loss 1.49522936
Trained batch 802 batch loss 1.39602363 epoch total loss 1.49510562
Trained batch 803 batch loss 1.47902286 epoch total loss 1.4950856
Trained batch 804 batch loss 1.41032124 epoch total loss 1.4949801
Trained batch 805 batch loss 1.56760228 epoch total loss 1.49507034
Trained batch 806 batch loss 1.51352465 epoch total loss 1.49509323
Trained batch 807 batch loss 1.39034033 epoch total loss 1.49496353
Trained batch 808 batch loss 1.38937378 epoch total loss 1.49483287
Trained batch 809 batch loss 1.46708894 epoch total loss 1.49479854
Trained batch 810 batch loss 1.46467853 epoch total loss 1.49476135
Trained batch 811 batch loss 1.46247816 epoch total loss 1.49472165
Trained batch 812 batch loss 1.46702647 epoch total loss 1.49468756
Trained batch 813 batch loss 1.35968542 epoch total loss 1.4945215
Trained batch 814 batch loss 1.40014029 epoch total loss 1.49440563
Trained batch 815 batch loss 1.31484902 epoch total loss 1.49418521
Trained batch 816 batch loss 1.4199264 epoch total loss 1.49409425
Trained batch 817 batch loss 1.31750667 epoch total loss 1.49387813
Trained batch 818 batch loss 1.56362283 epoch total loss 1.49396336
Trained batch 819 batch loss 1.41647887 epoch total loss 1.49386871
Trained batch 820 batch loss 1.49600768 epoch total loss 1.49387133
Trained batch 821 batch loss 1.48325396 epoch total loss 1.49385846
Trained batch 822 batch loss 1.50963926 epoch total loss 1.49387765
Trained batch 823 batch loss 1.58929813 epoch total loss 1.49399364
Trained batch 824 batch loss 1.63171506 epoch total loss 1.49416077
Trained batch 825 batch loss 1.48069084 epoch total loss 1.49414444
Trained batch 826 batch loss 1.34031212 epoch total loss 1.49395823
Trained batch 827 batch loss 1.37712145 epoch total loss 1.49381697
Trained batch 828 batch loss 1.29739642 epoch total loss 1.49357963
Trained batch 829 batch loss 1.29669893 epoch total loss 1.49334228
Trained batch 830 batch loss 1.44289327 epoch total loss 1.49328148
Trained batch 831 batch loss 1.45451713 epoch total loss 1.49323475
Trained batch 832 batch loss 1.36798573 epoch total loss 1.49308419
Trained batch 833 batch loss 1.25901449 epoch total loss 1.49280322
Trained batch 834 batch loss 1.52403975 epoch total loss 1.49284077
Trained batch 835 batch loss 1.43184364 epoch total loss 1.49276769
Trained batch 836 batch loss 1.399827 epoch total loss 1.49265647
Trained batch 837 batch loss 1.47701383 epoch total loss 1.49263787
Trained batch 838 batch loss 1.44329977 epoch total loss 1.4925791
Trained batch 839 batch loss 1.44866788 epoch total loss 1.49252665
Trained batch 840 batch loss 1.41010427 epoch total loss 1.49242854
Trained batch 841 batch loss 1.20836985 epoch total loss 1.49209082
Trained batch 842 batch loss 1.0152595 epoch total loss 1.49152458
Trained batch 843 batch loss 1.17823648 epoch total loss 1.49115288
Trained batch 844 batch loss 1.41208816 epoch total loss 1.49105918
Trained batch 845 batch loss 1.41055357 epoch total loss 1.49096394
Trained batch 846 batch loss 1.21788073 epoch total loss 1.49064112
Trained batch 847 batch loss 1.44772708 epoch total loss 1.49059045
Trained batch 848 batch loss 1.49349129 epoch total loss 1.49059391
Trained batch 849 batch loss 1.44355512 epoch total loss 1.4905386
Trained batch 850 batch loss 1.48400033 epoch total loss 1.49053097
Trained batch 851 batch loss 1.41256893 epoch total loss 1.49043941
Trained batch 852 batch loss 1.59079993 epoch total loss 1.49055719
Trained batch 853 batch loss 1.43729663 epoch total loss 1.49049473
Trained batch 854 batch loss 1.40150118 epoch total loss 1.49039042
Trained batch 855 batch loss 1.49701881 epoch total loss 1.49039829
Trained batch 856 batch loss 1.3769027 epoch total loss 1.49026573
Trained batch 857 batch loss 1.49655151 epoch total loss 1.49027312
Trained batch 858 batch loss 1.37970221 epoch total loss 1.49014437
Trained batch 859 batch loss 1.46462655 epoch total loss 1.49011457
Trained batch 860 batch loss 1.27838147 epoch total loss 1.4898684
Trained batch 861 batch loss 1.3364203 epoch total loss 1.48969018
Trained batch 862 batch loss 1.26043 epoch total loss 1.48942423
Trained batch 863 batch loss 1.30978298 epoch total loss 1.48921609
Trained batch 864 batch loss 1.21042681 epoch total loss 1.48889339
Trained batch 865 batch loss 1.31470728 epoch total loss 1.48869205
Trained batch 866 batch loss 1.40178108 epoch total loss 1.48859167
Trained batch 867 batch loss 1.2349081 epoch total loss 1.48829901
Trained batch 868 batch loss 1.41109514 epoch total loss 1.48821008
Trained batch 869 batch loss 1.47325134 epoch total loss 1.48819292
Trained batch 870 batch loss 1.43420696 epoch total loss 1.48813081
Trained batch 871 batch loss 1.54119432 epoch total loss 1.48819172
Trained batch 872 batch loss 1.46409333 epoch total loss 1.48816407
Trained batch 873 batch loss 1.4144423 epoch total loss 1.48807967
Trained batch 874 batch loss 1.42556572 epoch total loss 1.48800802
Trained batch 875 batch loss 1.41756988 epoch total loss 1.48792756
Trained batch 876 batch loss 1.37460423 epoch total loss 1.48779821
Trained batch 877 batch loss 1.45894229 epoch total loss 1.48776543
Trained batch 878 batch loss 1.47832716 epoch total loss 1.48775458
Trained batch 879 batch loss 1.45531559 epoch total loss 1.48771775
Trained batch 880 batch loss 1.33361959 epoch total loss 1.48754263
Trained batch 881 batch loss 1.24322248 epoch total loss 1.48726523
Trained batch 882 batch loss 1.11731839 epoch total loss 1.48684573
Trained batch 883 batch loss 1.41257024 epoch total loss 1.48676169
Trained batch 884 batch loss 1.13337469 epoch total loss 1.48636198
Trained batch 885 batch loss 1.12731242 epoch total loss 1.48595631
Trained batch 886 batch loss 1.13126123 epoch total loss 1.48555589
Trained batch 887 batch loss 1.14115238 epoch total loss 1.4851675
Trained batch 888 batch loss 1.21339369 epoch total loss 1.48486149
Trained batch 889 batch loss 1.2767241 epoch total loss 1.48462737
Trained batch 890 batch loss 1.53960299 epoch total loss 1.48468912
Trained batch 891 batch loss 1.44495118 epoch total loss 1.48464453
Trained batch 892 batch loss 1.39188027 epoch total loss 1.48454046
Trained batch 893 batch loss 1.48266196 epoch total loss 1.48453832
Trained batch 894 batch loss 1.14414716 epoch total loss 1.48415768
Trained batch 895 batch loss 1.31973243 epoch total loss 1.48397386
Trained batch 896 batch loss 1.43731952 epoch total loss 1.48392189
Trained batch 897 batch loss 1.27415514 epoch total loss 1.483688
Trained batch 898 batch loss 1.62377405 epoch total loss 1.48384404
Trained batch 899 batch loss 1.60088515 epoch total loss 1.48397422
Trained batch 900 batch loss 1.37735605 epoch total loss 1.48385561
Trained batch 901 batch loss 1.41833317 epoch total loss 1.48378289
Trained batch 902 batch loss 1.36132789 epoch total loss 1.48364723
Trained batch 903 batch loss 1.37089777 epoch total loss 1.4835223
Trained batch 904 batch loss 1.48991072 epoch total loss 1.48352933
Trained batch 905 batch loss 1.51755834 epoch total loss 1.48356688
Trained batch 906 batch loss 1.45649207 epoch total loss 1.48353708
Trained batch 907 batch loss 1.4214654 epoch total loss 1.48346865
Trained batch 908 batch loss 1.359936 epoch total loss 1.48333275
Trained batch 909 batch loss 1.23651826 epoch total loss 1.48306119
Trained batch 910 batch loss 1.30754828 epoch total loss 1.48286831
Trained batch 911 batch loss 1.37184405 epoch total loss 1.48274636
Trained batch 912 batch loss 1.47436452 epoch total loss 1.48273718
Trained batch 913 batch loss 1.48436 epoch total loss 1.48273897
Trained batch 914 batch loss 1.6022 epoch total loss 1.48286974
Trained batch 915 batch loss 1.53602898 epoch total loss 1.4829278
Trained batch 916 batch loss 1.45742309 epoch total loss 1.4828999
Trained batch 917 batch loss 1.47336769 epoch total loss 1.48288953
Trained batch 918 batch loss 1.40261078 epoch total loss 1.48280203
Trained batch 919 batch loss 1.39172912 epoch total loss 1.48270297
Trained batch 920 batch loss 1.3853792 epoch total loss 1.48259711
Trained batch 921 batch loss 1.50875735 epoch total loss 1.4826256
Trained batch 922 batch loss 1.43194366 epoch total loss 1.48257053
Trained batch 923 batch loss 1.41476047 epoch total loss 1.4824971
Trained batch 924 batch loss 1.41305459 epoch total loss 1.48242199
Trained batch 925 batch loss 1.35837555 epoch total loss 1.48228788
Trained batch 926 batch loss 1.33141303 epoch total loss 1.48212504
Trained batch 927 batch loss 1.3224206 epoch total loss 1.48195267
Trained batch 928 batch loss 1.39287269 epoch total loss 1.48185658
Trained batch 929 batch loss 1.39003277 epoch total loss 1.48175776
Trained batch 930 batch loss 1.40176117 epoch total loss 1.48167169
Trained batch 931 batch loss 1.27305079 epoch total loss 1.4814477
Trained batch 932 batch loss 1.45099878 epoch total loss 1.48141503
Trained batch 933 batch loss 1.237535 epoch total loss 1.48115373
Trained batch 934 batch loss 1.32448292 epoch total loss 1.48098588
Trained batch 935 batch loss 1.51785064 epoch total loss 1.48102534
Trained batch 936 batch loss 1.38443458 epoch total loss 1.4809221
Trained batch 937 batch loss 1.29433227 epoch total loss 1.4807229
Trained batch 938 batch loss 1.22925615 epoch total loss 1.4804548
Trained batch 939 batch loss 1.20856607 epoch total loss 1.48016536
Trained batch 940 batch loss 1.22832799 epoch total loss 1.47989738
Trained batch 941 batch loss 1.36600542 epoch total loss 1.47977626
Trained batch 942 batch loss 1.24977458 epoch total loss 1.47953212
Trained batch 943 batch loss 1.28385043 epoch total loss 1.47932458
Trained batch 944 batch loss 1.41091943 epoch total loss 1.4792521
Trained batch 945 batch loss 1.71509171 epoch total loss 1.47950161
Trained batch 946 batch loss 1.41838312 epoch total loss 1.47943699
Trained batch 947 batch loss 1.42940664 epoch total loss 1.47938418
Trained batch 948 batch loss 1.22122598 epoch total loss 1.47911179
Trained batch 949 batch loss 1.30143595 epoch total loss 1.47892451
Trained batch 950 batch loss 1.48737168 epoch total loss 1.47893345
Trained batch 951 batch loss 1.25558889 epoch total loss 1.47869861
Trained batch 952 batch loss 1.30049253 epoch total loss 1.47851157
Trained batch 953 batch loss 1.32352912 epoch total loss 1.47834885
Trained batch 954 batch loss 1.17321813 epoch total loss 1.47802901
Trained batch 955 batch loss 1.44556212 epoch total loss 1.47799504
Trained batch 956 batch loss 1.37669897 epoch total loss 1.47788906
Trained batch 957 batch loss 1.11559677 epoch total loss 1.47751045
Trained batch 958 batch loss 1.36903644 epoch total loss 1.4773972
Trained batch 959 batch loss 1.4028213 epoch total loss 1.47731948
Trained batch 960 batch loss 1.36449766 epoch total loss 1.47720194
Trained batch 961 batch loss 1.33334565 epoch total loss 1.47705233
Trained batch 962 batch loss 1.31414497 epoch total loss 1.47688293
Trained batch 963 batch loss 1.51685011 epoch total loss 1.47692442
Trained batch 964 batch loss 1.29548633 epoch total loss 1.47673619
Trained batch 965 batch loss 1.45362413 epoch total loss 1.47671223
Trained batch 966 batch loss 1.45564759 epoch total loss 1.47669053
Trained batch 967 batch loss 1.52823913 epoch total loss 1.47674382
Trained batch 968 batch loss 1.41772246 epoch total loss 1.47668278
Trained batch 969 batch loss 1.35735154 epoch total loss 1.47655964
Trained batch 970 batch loss 1.37660944 epoch total loss 1.47645652
Trained batch 971 batch loss 1.45609009 epoch total loss 1.47643554
Trained batch 972 batch loss 1.24236608 epoch total loss 1.47619462
Trained batch 973 batch loss 1.33977723 epoch total loss 1.47605443
Trained batch 974 batch loss 1.3807385 epoch total loss 1.47595656
Trained batch 975 batch loss 1.29827964 epoch total loss 1.47577441
Trained batch 976 batch loss 1.3591373 epoch total loss 1.47565484
Trained batch 977 batch loss 1.50346518 epoch total loss 1.47568321
Trained batch 978 batch loss 1.39110851 epoch total loss 1.47559679
Trained batch 979 batch loss 1.35248542 epoch total loss 1.47547114
Trained batch 980 batch loss 1.20876908 epoch total loss 1.47519898
Trained batch 981 batch loss 1.34169936 epoch total loss 1.47506285
Trained batch 982 batch loss 1.24456334 epoch total loss 1.474828
Trained batch 983 batch loss 1.41665471 epoch total loss 1.47476888
Trained batch 984 batch loss 1.43171585 epoch total loss 1.47472513
Trained batch 985 batch loss 1.35252333 epoch total loss 1.47460103
Trained batch 986 batch loss 1.35051346 epoch total loss 1.47447515
Trained batch 987 batch loss 1.43118072 epoch total loss 1.47443128
Trained batch 988 batch loss 1.49578524 epoch total loss 1.47445285
Trained batch 989 batch loss 1.45240068 epoch total loss 1.47443056
Trained batch 990 batch loss 1.45937204 epoch total loss 1.4744153
Trained batch 991 batch loss 1.30498195 epoch total loss 1.47424424
Trained batch 992 batch loss 1.48286772 epoch total loss 1.47425306
Trained batch 993 batch loss 1.42191112 epoch total loss 1.47420025
Trained batch 994 batch loss 1.37547231 epoch total loss 1.47410095
Trained batch 995 batch loss 1.44211054 epoch total loss 1.47406888
Trained batch 996 batch loss 1.48957586 epoch total loss 1.4740845
Trained batch 997 batch loss 1.43327522 epoch total loss 1.47404349
Trained batch 998 batch loss 1.49123073 epoch total loss 1.47406065
Trained batch 999 batch loss 1.27162218 epoch total loss 1.473858
Trained batch 1000 batch loss 1.28777421 epoch total loss 1.47367191
Trained batch 1001 batch loss 1.25300348 epoch total loss 1.4734515
Trained batch 1002 batch loss 1.3903296 epoch total loss 1.47336853
Trained batch 1003 batch loss 1.296538 epoch total loss 1.47319221
Trained batch 1004 batch loss 1.16719294 epoch total loss 1.47288752
Trained batch 1005 batch loss 1.26402628 epoch total loss 1.47267973
Trained batch 1006 batch loss 1.37017834 epoch total loss 1.47257781
Trained batch 1007 batch loss 1.36304331 epoch total loss 1.47246909
Trained batch 1008 batch loss 1.33742833 epoch total loss 1.4723351
Trained batch 1009 batch loss 1.51818562 epoch total loss 1.47238052
Trained batch 1010 batch loss 1.44398844 epoch total loss 1.47235239
Trained batch 1011 batch loss 1.55257773 epoch total loss 1.47243178
Trained batch 1012 batch loss 1.54700506 epoch total loss 1.47250545
Trained batch 1013 batch loss 1.38784719 epoch total loss 1.47242188
Trained batch 1014 batch loss 1.53474593 epoch total loss 1.4724834
Trained batch 1015 batch loss 1.51783371 epoch total loss 1.4725281
Trained batch 1016 batch loss 1.45611811 epoch total loss 1.47251201
Trained batch 1017 batch loss 1.38126922 epoch total loss 1.47242224
Trained batch 1018 batch loss 1.34065449 epoch total loss 1.47229278
Trained batch 1019 batch loss 1.50618601 epoch total loss 1.47232604
Trained batch 1020 batch loss 1.21012545 epoch total loss 1.47206903
Trained batch 1021 batch loss 1.55301559 epoch total loss 1.4721483
Trained batch 1022 batch loss 1.37902761 epoch total loss 1.4720571
Trained batch 1023 batch loss 1.45068896 epoch total loss 1.47203624
Trained batch 1024 batch loss 1.51634884 epoch total loss 1.47207952
Trained batch 1025 batch loss 1.45243335 epoch total loss 1.47206032
Trained batch 1026 batch loss 1.47537565 epoch total loss 1.47206354
Trained batch 1027 batch loss 1.46781433 epoch total loss 1.47205937
Trained batch 1028 batch loss 1.547122 epoch total loss 1.47213233
Trained batch 1029 batch loss 1.49453211 epoch total loss 1.47215414
Trained batch 1030 batch loss 1.43664098 epoch total loss 1.47211957
Trained batch 1031 batch loss 1.34657788 epoch total loss 1.47199786
Trained batch 1032 batch loss 1.4783138 epoch total loss 1.47200394
Trained batch 1033 batch loss 1.37269664 epoch total loss 1.47190773
Trained batch 1034 batch loss 1.51018012 epoch total loss 1.47194469
Trained batch 1035 batch loss 1.39771616 epoch total loss 1.47187304
Trained batch 1036 batch loss 1.38455439 epoch total loss 1.47178864
Trained batch 1037 batch loss 1.41215932 epoch total loss 1.47173119
Trained batch 1038 batch loss 1.3500036 epoch total loss 1.47161388
Trained batch 1039 batch loss 1.30319035 epoch total loss 1.47145176
Trained batch 1040 batch loss 1.41084576 epoch total loss 1.47139359
Trained batch 1041 batch loss 1.42409348 epoch total loss 1.47134805
Trained batch 1042 batch loss 1.5255332 epoch total loss 1.4714
Trained batch 1043 batch loss 1.67941952 epoch total loss 1.47159946
Trained batch 1044 batch loss 1.74894309 epoch total loss 1.47186518
Trained batch 1045 batch loss 1.54799354 epoch total loss 1.47193801
Trained batch 1046 batch loss 1.79870903 epoch total loss 1.47225034
Trained batch 1047 batch loss 1.68135679 epoch total loss 1.47245014
Trained batch 1048 batch loss 1.57896197 epoch total loss 1.47255182
Trained batch 1049 batch loss 1.63733697 epoch total loss 1.47270882
Trained batch 1050 batch loss 1.52218604 epoch total loss 1.47275603
Trained batch 1051 batch loss 1.55831099 epoch total loss 1.47283745
Trained batch 1052 batch loss 1.33205616 epoch total loss 1.47270358
Trained batch 1053 batch loss 1.37798846 epoch total loss 1.47261357
Trained batch 1054 batch loss 1.20494139 epoch total loss 1.47235966
Trained batch 1055 batch loss 1.24922729 epoch total loss 1.47214818
Trained batch 1056 batch loss 1.46139216 epoch total loss 1.47213805
Trained batch 1057 batch loss 1.39834797 epoch total loss 1.47206819
Trained batch 1058 batch loss 1.4115181 epoch total loss 1.47201097
Trained batch 1059 batch loss 1.50440788 epoch total loss 1.47204149
Trained batch 1060 batch loss 1.35283804 epoch total loss 1.47192895
Trained batch 1061 batch loss 1.30745447 epoch total loss 1.47177398
Trained batch 1062 batch loss 1.19412553 epoch total loss 1.47151256
Trained batch 1063 batch loss 1.37500644 epoch total loss 1.47142172
Trained batch 1064 batch loss 1.418437 epoch total loss 1.47137201
Trained batch 1065 batch loss 1.41373158 epoch total loss 1.47131789
Trained batch 1066 batch loss 1.44762325 epoch total loss 1.4712956
Trained batch 1067 batch loss 1.29326463 epoch total loss 1.4711287
Trained batch 1068 batch loss 1.34854686 epoch total loss 1.4710139
Trained batch 1069 batch loss 1.48606241 epoch total loss 1.47102797
Trained batch 1070 batch loss 1.52438378 epoch total loss 1.47107792
Trained batch 1071 batch loss 1.28580141 epoch total loss 1.47090483
Trained batch 1072 batch loss 1.27424717 epoch total loss 1.47072148
Trained batch 1073 batch loss 1.32944608 epoch total loss 1.47058976
Trained batch 1074 batch loss 1.43849874 epoch total loss 1.47056
Trained batch 1075 batch loss 1.32988811 epoch total loss 1.47042906
Trained batch 1076 batch loss 1.46165442 epoch total loss 1.47042084
Trained batch 1077 batch loss 1.41767979 epoch total loss 1.47037196
Trained batch 1078 batch loss 1.46848977 epoch total loss 1.47037017
Trained batch 1079 batch loss 1.25503123 epoch total loss 1.47017062
Trained batch 1080 batch loss 1.5670253 epoch total loss 1.47026026
Trained batch 1081 batch loss 1.43972945 epoch total loss 1.47023201
Trained batch 1082 batch loss 1.47791553 epoch total loss 1.47023904
Trained batch 1083 batch loss 1.60419011 epoch total loss 1.47036278
Trained batch 1084 batch loss 1.5890584 epoch total loss 1.47047234
Trained batch 1085 batch loss 1.48620653 epoch total loss 1.47048688
Trained batch 1086 batch loss 1.39584363 epoch total loss 1.47041821
Trained batch 1087 batch loss 1.50732088 epoch total loss 1.47045219
Trained batch 1088 batch loss 1.57499933 epoch total loss 1.47054815
Trained batch 1089 batch loss 1.59796166 epoch total loss 1.47066522
Trained batch 1090 batch loss 1.60345268 epoch total loss 1.47078705
Trained batch 1091 batch loss 1.43657172 epoch total loss 1.47075558
Trained batch 1092 batch loss 1.39407849 epoch total loss 1.47068536
Trained batch 1093 batch loss 1.33340168 epoch total loss 1.47055972
Trained batch 1094 batch loss 1.37250972 epoch total loss 1.47047019
Trained batch 1095 batch loss 1.36739564 epoch total loss 1.47037601
Trained batch 1096 batch loss 1.46782982 epoch total loss 1.47037363
Trained batch 1097 batch loss 1.40237021 epoch total loss 1.47031164
Trained batch 1098 batch loss 1.35855627 epoch total loss 1.47020984
Trained batch 1099 batch loss 1.28948045 epoch total loss 1.47004533
Trained batch 1100 batch loss 1.14910293 epoch total loss 1.4697535
Trained batch 1101 batch loss 1.32573581 epoch total loss 1.46962273
Trained batch 1102 batch loss 1.37406874 epoch total loss 1.46953595
Trained batch 1103 batch loss 1.42310846 epoch total loss 1.46949387
Trained batch 1104 batch loss 1.46370125 epoch total loss 1.46948862
Trained batch 1105 batch loss 1.25212252 epoch total loss 1.46929181
Trained batch 1106 batch loss 1.43097 epoch total loss 1.46925724
Trained batch 1107 batch loss 1.39976752 epoch total loss 1.46919453
Trained batch 1108 batch loss 1.38571119 epoch total loss 1.46911919
Trained batch 1109 batch loss 1.36681521 epoch total loss 1.46902692
Trained batch 1110 batch loss 1.4934051 epoch total loss 1.46904886
Trained batch 1111 batch loss 1.45203924 epoch total loss 1.4690336
Trained batch 1112 batch loss 1.38821244 epoch total loss 1.46896088
Trained batch 1113 batch loss 1.20352066 epoch total loss 1.46872234
Trained batch 1114 batch loss 1.21039 epoch total loss 1.46849048
Trained batch 1115 batch loss 1.28142905 epoch total loss 1.46832275
Trained batch 1116 batch loss 1.34181237 epoch total loss 1.46820927
Trained batch 1117 batch loss 1.21694434 epoch total loss 1.46798432
Trained batch 1118 batch loss 1.3495698 epoch total loss 1.46787846
Trained batch 1119 batch loss 1.35791647 epoch total loss 1.46778023
Trained batch 1120 batch loss 1.34512305 epoch total loss 1.46767068
Trained batch 1121 batch loss 1.37919402 epoch total loss 1.46759164
Trained batch 1122 batch loss 1.39794195 epoch total loss 1.46752965
Trained batch 1123 batch loss 1.13663292 epoch total loss 1.46723497
Trained batch 1124 batch loss 1.17261267 epoch total loss 1.46697283
Trained batch 1125 batch loss 1.41618967 epoch total loss 1.46692765
Trained batch 1126 batch loss 1.23366737 epoch total loss 1.46672046
Trained batch 1127 batch loss 1.31397653 epoch total loss 1.46658492
Trained batch 1128 batch loss 1.57439244 epoch total loss 1.46668041
Trained batch 1129 batch loss 1.50740886 epoch total loss 1.46671653
Trained batch 1130 batch loss 1.31811142 epoch total loss 1.46658504
Trained batch 1131 batch loss 1.48038816 epoch total loss 1.4665972
Trained batch 1132 batch loss 1.55277729 epoch total loss 1.46667325
Trained batch 1133 batch loss 1.50670552 epoch total loss 1.46670866
Trained batch 1134 batch loss 1.41413331 epoch total loss 1.46666229
Trained batch 1135 batch loss 1.1801244 epoch total loss 1.46640992
Trained batch 1136 batch loss 1.39510345 epoch total loss 1.46634722
Trained batch 1137 batch loss 1.2693032 epoch total loss 1.46617389
Trained batch 1138 batch loss 1.62208343 epoch total loss 1.46631086
Trained batch 1139 batch loss 1.4396863 epoch total loss 1.46628749
Trained batch 1140 batch loss 1.36902499 epoch total loss 1.46620214
Trained batch 1141 batch loss 1.38003337 epoch total loss 1.46612656
Trained batch 1142 batch loss 1.29559267 epoch total loss 1.46597719
Trained batch 1143 batch loss 1.50534725 epoch total loss 1.46601164
Trained batch 1144 batch loss 1.34626532 epoch total loss 1.4659071
Trained batch 1145 batch loss 1.399827 epoch total loss 1.46584928
Trained batch 1146 batch loss 1.37409544 epoch total loss 1.46576929
Trained batch 1147 batch loss 1.41941094 epoch total loss 1.46572888
Trained batch 1148 batch loss 1.51974249 epoch total loss 1.46577597
Trained batch 1149 batch loss 1.450037 epoch total loss 1.46576226
Trained batch 1150 batch loss 1.52458429 epoch total loss 1.4658134
Trained batch 1151 batch loss 1.51907063 epoch total loss 1.46585965
Trained batch 1152 batch loss 1.40106785 epoch total loss 1.4658035
Trained batch 1153 batch loss 1.41590846 epoch total loss 1.46576023
Trained batch 1154 batch loss 1.38551879 epoch total loss 1.46569061
Trained batch 1155 batch loss 1.36041403 epoch total loss 1.46559954
Trained batch 1156 batch loss 1.26498 epoch total loss 1.46542597
Trained batch 1157 batch loss 1.42293763 epoch total loss 1.46538937
Trained batch 1158 batch loss 1.40178454 epoch total loss 1.4653343
Trained batch 1159 batch loss 1.29149127 epoch total loss 1.46518433
Trained batch 1160 batch loss 1.4087255 epoch total loss 1.46513569
Trained batch 1161 batch loss 1.3163054 epoch total loss 1.46500742
Trained batch 1162 batch loss 1.09648335 epoch total loss 1.46469033
Trained batch 1163 batch loss 1.33824551 epoch total loss 1.46458161
Trained batch 1164 batch loss 1.2460413 epoch total loss 1.46439385
Trained batch 1165 batch loss 1.10014415 epoch total loss 1.46408117
Trained batch 1166 batch loss 1.1896162 epoch total loss 1.46384573
Trained batch 1167 batch loss 1.18816948 epoch total loss 1.46360946
Trained batch 1168 batch loss 1.30518055 epoch total loss 1.4634738
Trained batch 1169 batch loss 1.0754391 epoch total loss 1.46314192
Trained batch 1170 batch loss 1.13647032 epoch total loss 1.46286261
Trained batch 1171 batch loss 1.30706918 epoch total loss 1.46272969
Trained batch 1172 batch loss 1.15554261 epoch total loss 1.46246755
Trained batch 1173 batch loss 1.28215444 epoch total loss 1.46231377
Trained batch 1174 batch loss 1.29909778 epoch total loss 1.46217477
Trained batch 1175 batch loss 1.39908791 epoch total loss 1.46212101
Trained batch 1176 batch loss 1.22182059 epoch total loss 1.46191669
Trained batch 1177 batch loss 1.34300315 epoch total loss 1.4618156
Trained batch 1178 batch loss 1.10681033 epoch total loss 1.46151423
Trained batch 1179 batch loss 1.12756395 epoch total loss 1.46123099
Trained batch 1180 batch loss 1.14060402 epoch total loss 1.46095932
Trained batch 1181 batch loss 1.02489233 epoch total loss 1.46059012
Trained batch 1182 batch loss 1.03372049 epoch total loss 1.46022892
Trained batch 1183 batch loss 1.06040156 epoch total loss 1.45989096
Trained batch 1184 batch loss 1.04322457 epoch total loss 1.45953906
Trained batch 1185 batch loss 0.990639448 epoch total loss 1.45914328
Trained batch 1186 batch loss 1.07866848 epoch total loss 1.45882249
Trained batch 1187 batch loss 1.08957529 epoch total loss 1.45851147
Trained batch 1188 batch loss 1.14659882 epoch total loss 1.45824885
Trained batch 1189 batch loss 1.06313848 epoch total loss 1.4579165
Trained batch 1190 batch loss 1.08034408 epoch total loss 1.45759928
Trained batch 1191 batch loss 0.910885274 epoch total loss 1.45714021
Trained batch 1192 batch loss 1.0451839 epoch total loss 1.45679462
Trained batch 1193 batch loss 0.866366088 epoch total loss 1.45629966
Trained batch 1194 batch loss 1.15594435 epoch total loss 1.45604801
Trained batch 1195 batch loss 1.72960722 epoch total loss 1.45627701
Trained batch 1196 batch loss 1.64702916 epoch total loss 1.4564364
Trained batch 1197 batch loss 1.49021912 epoch total loss 1.45646465
Trained batch 1198 batch loss 1.5228858 epoch total loss 1.45652008
Trained batch 1199 batch loss 1.4275316 epoch total loss 1.45649588
Trained batch 1200 batch loss 1.51942527 epoch total loss 1.45654821
Trained batch 1201 batch loss 1.3910284 epoch total loss 1.45649362
Trained batch 1202 batch loss 1.35326695 epoch total loss 1.45640779
Trained batch 1203 batch loss 1.38664556 epoch total loss 1.45634973
Trained batch 1204 batch loss 1.47386694 epoch total loss 1.45636427
Trained batch 1205 batch loss 1.33919311 epoch total loss 1.45626712
Trained batch 1206 batch loss 1.32057548 epoch total loss 1.45615458
Trained batch 1207 batch loss 1.34054089 epoch total loss 1.45605886
Trained batch 1208 batch loss 1.528687 epoch total loss 1.45611894
Trained batch 1209 batch loss 1.24020231 epoch total loss 1.45594037
Trained batch 1210 batch loss 1.23274624 epoch total loss 1.45575595
Trained batch 1211 batch loss 1.16447115 epoch total loss 1.45551538
Trained batch 1212 batch loss 1.29198313 epoch total loss 1.45538044
Trained batch 1213 batch loss 1.44134212 epoch total loss 1.45536888
Trained batch 1214 batch loss 1.44382226 epoch total loss 1.45535934
Trained batch 1215 batch loss 1.1829145 epoch total loss 1.45513511
Trained batch 1216 batch loss 1.12738824 epoch total loss 1.45486557
Trained batch 1217 batch loss 1.12059367 epoch total loss 1.45459092
Trained batch 1218 batch loss 1.32271528 epoch total loss 1.45448267
Trained batch 1219 batch loss 1.18479133 epoch total loss 1.45426154
Trained batch 1220 batch loss 0.945262909 epoch total loss 1.45384431
Trained batch 1221 batch loss 1.01489174 epoch total loss 1.45348477
Trained batch 1222 batch loss 1.21800339 epoch total loss 1.45329213
Trained batch 1223 batch loss 1.55279243 epoch total loss 1.45337343
Trained batch 1224 batch loss 1.37460291 epoch total loss 1.45330906
Trained batch 1225 batch loss 1.41427183 epoch total loss 1.45327723
Trained batch 1226 batch loss 1.54554844 epoch total loss 1.45335257
Trained batch 1227 batch loss 1.55811846 epoch total loss 1.45343792
Trained batch 1228 batch loss 1.54134536 epoch total loss 1.45350945
Trained batch 1229 batch loss 1.52692294 epoch total loss 1.45356929
Trained batch 1230 batch loss 1.42355394 epoch total loss 1.45354486
Trained batch 1231 batch loss 1.44130492 epoch total loss 1.45353496
Trained batch 1232 batch loss 1.39162135 epoch total loss 1.45348465
Trained batch 1233 batch loss 1.34991741 epoch total loss 1.45340073
Trained batch 1234 batch loss 1.38642955 epoch total loss 1.45334649
Trained batch 1235 batch loss 1.54362798 epoch total loss 1.45341957
Trained batch 1236 batch loss 1.39091599 epoch total loss 1.4533689
Trained batch 1237 batch loss 1.36382937 epoch total loss 1.45329654
Trained batch 1238 batch loss 1.44182467 epoch total loss 1.45328724
Trained batch 1239 batch loss 1.44002151 epoch total loss 1.45327652
Trained batch 1240 batch loss 1.45908177 epoch total loss 1.45328128
Trained batch 1241 batch loss 1.43837357 epoch total loss 1.45326924
Trained batch 1242 batch loss 1.61228204 epoch total loss 1.45339727
Trained batch 1243 batch loss 1.65858841 epoch total loss 1.45356226
Trained batch 1244 batch loss 1.43867087 epoch total loss 1.45355034
Trained batch 1245 batch loss 1.34959102 epoch total loss 1.45346689
Trained batch 1246 batch loss 1.59730768 epoch total loss 1.45358229
Trained batch 1247 batch loss 1.49498534 epoch total loss 1.45361555
Trained batch 1248 batch loss 1.43750858 epoch total loss 1.45360267
Trained batch 1249 batch loss 1.37985432 epoch total loss 1.45354354
Trained batch 1250 batch loss 1.31985331 epoch total loss 1.45343661
Trained batch 1251 batch loss 1.35844159 epoch total loss 1.45336068
Trained batch 1252 batch loss 1.58273864 epoch total loss 1.45346403
Trained batch 1253 batch loss 1.3328619 epoch total loss 1.45336783
Trained batch 1254 batch loss 1.56169617 epoch total loss 1.45345414
Trained batch 1255 batch loss 1.46898711 epoch total loss 1.45346653
Trained batch 1256 batch loss 1.45067859 epoch total loss 1.45346427
Trained batch 1257 batch loss 1.60168469 epoch total loss 1.45358217
Trained batch 1258 batch loss 1.64392221 epoch total loss 1.45373356
Trained batch 1259 batch loss 1.50157797 epoch total loss 1.45377147
Trained batch 1260 batch loss 1.40561509 epoch total loss 1.45373333
Trained batch 1261 batch loss 1.37897301 epoch total loss 1.45367408
Trained batch 1262 batch loss 1.36032665 epoch total loss 1.45360017
Trained batch 1263 batch loss 1.44001389 epoch total loss 1.45358944
Trained batch 1264 batch loss 1.29906034 epoch total loss 1.45346713
Trained batch 1265 batch loss 1.40732539 epoch total loss 1.45343065
Trained batch 1266 batch loss 1.27626348 epoch total loss 1.4532907
Trained batch 1267 batch loss 1.36702764 epoch total loss 1.45322275
Trained batch 1268 batch loss 1.27508307 epoch total loss 1.4530822
Trained batch 1269 batch loss 1.38760674 epoch total loss 1.45303059
Trained batch 1270 batch loss 1.42251968 epoch total loss 1.45300651
Trained batch 1271 batch loss 1.20796227 epoch total loss 1.45281374
Trained batch 1272 batch loss 1.20577669 epoch total loss 1.45261955
Trained batch 1273 batch loss 1.05091023 epoch total loss 1.45230401
Trained batch 1274 batch loss 1.14331746 epoch total loss 1.45206141
Trained batch 1275 batch loss 1.04457235 epoch total loss 1.45174181
Trained batch 1276 batch loss 1.10358036 epoch total loss 1.45146906
Trained batch 1277 batch loss 1.24686992 epoch total loss 1.45130873
Trained batch 1278 batch loss 1.30107045 epoch total loss 1.45119119
Trained batch 1279 batch loss 1.26474118 epoch total loss 1.45104539
Trained batch 1280 batch loss 1.4402802 epoch total loss 1.45103705
Trained batch 1281 batch loss 1.22299361 epoch total loss 1.45085907
Trained batch 1282 batch loss 1.54709601 epoch total loss 1.45093417
Trained batch 1283 batch loss 1.43884325 epoch total loss 1.45092463
Trained batch 1284 batch loss 1.51220345 epoch total loss 1.45097244
Trained batch 1285 batch loss 1.49104357 epoch total loss 1.45100367
Trained batch 1286 batch loss 1.25879121 epoch total loss 1.45085418
Trained batch 1287 batch loss 1.47874188 epoch total loss 1.45087588
Trained batch 1288 batch loss 1.41453183 epoch total loss 1.45084763
Trained batch 1289 batch loss 1.15775228 epoch total loss 1.45062029
Trained batch 1290 batch loss 1.36249685 epoch total loss 1.45055199
Trained batch 1291 batch loss 1.48116326 epoch total loss 1.45057571
Trained batch 1292 batch loss 1.29981482 epoch total loss 1.450459
Trained batch 1293 batch loss 1.43704867 epoch total loss 1.45044863
Trained batch 1294 batch loss 1.60543251 epoch total loss 1.45056844
Trained batch 1295 batch loss 1.5367198 epoch total loss 1.45063496
Trained batch 1296 batch loss 1.38192379 epoch total loss 1.45058191
Trained batch 1297 batch loss 1.46122813 epoch total loss 1.45059013
Trained batch 1298 batch loss 1.35914588 epoch total loss 1.45051968
Trained batch 1299 batch loss 1.32061911 epoch total loss 1.45041966
Trained batch 1300 batch loss 1.39611065 epoch total loss 1.45037794
Trained batch 1301 batch loss 1.25099719 epoch total loss 1.45022464
Trained batch 1302 batch loss 1.2891984 epoch total loss 1.45010102
Trained batch 1303 batch loss 1.29952919 epoch total loss 1.4499855
Trained batch 1304 batch loss 1.00007534 epoch total loss 1.44964051
Trained batch 1305 batch loss 1.11357415 epoch total loss 1.4493829
Trained batch 1306 batch loss 1.27219129 epoch total loss 1.44924724
Trained batch 1307 batch loss 1.31464696 epoch total loss 1.44914436
Trained batch 1308 batch loss 1.40300131 epoch total loss 1.44910896
Trained batch 1309 batch loss 1.41831648 epoch total loss 1.44908547
Trained batch 1310 batch loss 1.63780332 epoch total loss 1.4492296
Trained batch 1311 batch loss 1.72805822 epoch total loss 1.44944227
Trained batch 1312 batch loss 1.65022874 epoch total loss 1.44959533
Trained batch 1313 batch loss 1.35241485 epoch total loss 1.4495213
Trained batch 1314 batch loss 1.59801483 epoch total loss 1.44963431
Trained batch 1315 batch loss 1.47196889 epoch total loss 1.44965124
Trained batch 1316 batch loss 1.41186237 epoch total loss 1.44962251
Trained batch 1317 batch loss 1.45992517 epoch total loss 1.44963038
Trained batch 1318 batch loss 1.50009215 epoch total loss 1.44966865
Trained batch 1319 batch loss 1.52727842 epoch total loss 1.44972754
Trained batch 1320 batch loss 1.47643697 epoch total loss 1.44974768
Trained batch 1321 batch loss 1.45693421 epoch total loss 1.44975317
Trained batch 1322 batch loss 1.3494041 epoch total loss 1.44967723
Trained batch 1323 batch loss 1.45182204 epoch total loss 1.44967878
Trained batch 1324 batch loss 1.45645332 epoch total loss 1.4496839
Trained batch 1325 batch loss 1.46245706 epoch total loss 1.44969344
Trained batch 1326 batch loss 1.61741161 epoch total loss 1.44982
Trained batch 1327 batch loss 1.423805 epoch total loss 1.44980037
Trained batch 1328 batch loss 1.50300205 epoch total loss 1.44984055
Trained batch 1329 batch loss 1.51908243 epoch total loss 1.44989252
Trained batch 1330 batch loss 1.33619356 epoch total loss 1.44980705
Trained batch 1331 batch loss 1.47527754 epoch total loss 1.44982612
Trained batch 1332 batch loss 1.43762684 epoch total loss 1.44981706
Trained batch 1333 batch loss 1.20689261 epoch total loss 1.44963479
Trained batch 1334 batch loss 1.24056482 epoch total loss 1.44947803
Trained batch 1335 batch loss 1.30470586 epoch total loss 1.44936967
Trained batch 1336 batch loss 1.12638235 epoch total loss 1.44912779
Trained batch 1337 batch loss 1.24362254 epoch total loss 1.44897413
Trained batch 1338 batch loss 1.17051542 epoch total loss 1.44876599
Trained batch 1339 batch loss 1.45703208 epoch total loss 1.44877219
Trained batch 1340 batch loss 1.37719047 epoch total loss 1.44871879
Trained batch 1341 batch loss 1.41449869 epoch total loss 1.44869328
Trained batch 1342 batch loss 1.42669773 epoch total loss 1.44867694
Trained batch 1343 batch loss 1.41034198 epoch total loss 1.44864845
Trained batch 1344 batch loss 1.53053927 epoch total loss 1.44870937
Trained batch 1345 batch loss 1.43546963 epoch total loss 1.44869947
Trained batch 1346 batch loss 1.44300723 epoch total loss 1.4486953
Trained batch 1347 batch loss 1.14966476 epoch total loss 1.44847333
Trained batch 1348 batch loss 1.25376129 epoch total loss 1.44832885
Trained batch 1349 batch loss 1.24602008 epoch total loss 1.44817889
Trained batch 1350 batch loss 1.3938365 epoch total loss 1.44813859
Trained batch 1351 batch loss 1.32178354 epoch total loss 1.44804502
Trained batch 1352 batch loss 1.33474255 epoch total loss 1.44796121
Trained batch 1353 batch loss 1.59768069 epoch total loss 1.44807184
Trained batch 1354 batch loss 1.56319523 epoch total loss 1.44815695
Trained batch 1355 batch loss 1.4914273 epoch total loss 1.4481889
Trained batch 1356 batch loss 1.47685289 epoch total loss 1.44821
Trained batch 1357 batch loss 1.5369153 epoch total loss 1.44827533
Trained batch 1358 batch loss 1.36281288 epoch total loss 1.44821239
Trained batch 1359 batch loss 1.25993073 epoch total loss 1.44807374
Trained batch 1360 batch loss 1.21022654 epoch total loss 1.44789886
Trained batch 1361 batch loss 1.3014493 epoch total loss 1.44779122
Trained batch 1362 batch loss 1.42001688 epoch total loss 1.44777083
Trained batch 1363 batch loss 1.62818 epoch total loss 1.44790316
Trained batch 1364 batch loss 1.36514425 epoch total loss 1.44784248
Trained batch 1365 batch loss 1.41423833 epoch total loss 1.4478178
Trained batch 1366 batch loss 1.41454077 epoch total loss 1.44779348
Trained batch 1367 batch loss 1.31882787 epoch total loss 1.44769919
Trained batch 1368 batch loss 1.54798806 epoch total loss 1.4477725
Trained batch 1369 batch loss 1.45178926 epoch total loss 1.44777536
Trained batch 1370 batch loss 1.43198979 epoch total loss 1.44776392
Trained batch 1371 batch loss 1.56717086 epoch total loss 1.44785094
Trained batch 1372 batch loss 1.60799444 epoch total loss 1.44796765
Trained batch 1373 batch loss 1.54673576 epoch total loss 1.44803965
Trained batch 1374 batch loss 1.54918909 epoch total loss 1.44811332
Trained batch 1375 batch loss 1.46288705 epoch total loss 1.44812405
Trained batch 1376 batch loss 1.35327697 epoch total loss 1.44805515
Trained batch 1377 batch loss 1.40927291 epoch total loss 1.4480269
Trained batch 1378 batch loss 1.38224792 epoch total loss 1.44797921
Trained batch 1379 batch loss 1.55414402 epoch total loss 1.44805622
Trained batch 1380 batch loss 1.52437556 epoch total loss 1.44811153
Trained batch 1381 batch loss 1.55534494 epoch total loss 1.44818914
Trained batch 1382 batch loss 1.60481095 epoch total loss 1.44830251
Trained batch 1383 batch loss 1.50388324 epoch total loss 1.44834268
Trained batch 1384 batch loss 1.40204549 epoch total loss 1.4483093
Trained batch 1385 batch loss 1.43523431 epoch total loss 1.44829988
Trained batch 1386 batch loss 1.48193812 epoch total loss 1.44832408
Trained batch 1387 batch loss 1.42720079 epoch total loss 1.44830894
Trained batch 1388 batch loss 1.54355383 epoch total loss 1.44837749
Trained batch 1389 batch loss 1.32144237 epoch total loss 1.44828618
Trained batch 1390 batch loss 1.56511116 epoch total loss 1.4483701
Trained batch 1391 batch loss 1.31501162 epoch total loss 1.44827425
Trained batch 1392 batch loss 1.38101673 epoch total loss 1.44822598
Trained batch 1393 batch loss 1.5261054 epoch total loss 1.44828188
Trained batch 1394 batch loss 1.30279517 epoch total loss 1.44817746
Trained batch 1395 batch loss 1.10740054 epoch total loss 1.4479332
Trained batch 1396 batch loss 1.51686597 epoch total loss 1.44798255
Trained batch 1397 batch loss 1.47439456 epoch total loss 1.4480015
Trained batch 1398 batch loss 1.13288927 epoch total loss 1.44777608
Trained batch 1399 batch loss 1.31556916 epoch total loss 1.44768155
Trained batch 1400 batch loss 1.34537768 epoch total loss 1.44760847
Trained batch 1401 batch loss 1.1935401 epoch total loss 1.44742703
Trained batch 1402 batch loss 1.20621526 epoch total loss 1.44725502
Trained batch 1403 batch loss 1.02774692 epoch total loss 1.44695592
Trained batch 1404 batch loss 1.26433277 epoch total loss 1.44682586
Trained batch 1405 batch loss 1.2321322 epoch total loss 1.44667304
Trained batch 1406 batch loss 1.03086185 epoch total loss 1.4463774
Trained batch 1407 batch loss 1.19173503 epoch total loss 1.44619644
Trained batch 1408 batch loss 1.17188585 epoch total loss 1.44600153
Trained batch 1409 batch loss 1.26174581 epoch total loss 1.44587076
Trained batch 1410 batch loss 1.09962332 epoch total loss 1.44562519
Trained batch 1411 batch loss 1.17078257 epoch total loss 1.4454304
Trained batch 1412 batch loss 1.55193329 epoch total loss 1.44550586
Trained batch 1413 batch loss 1.97112155 epoch total loss 1.44587779
Trained batch 1414 batch loss 1.88459325 epoch total loss 1.44618809
Trained batch 1415 batch loss 1.85574675 epoch total loss 1.44647753
Trained batch 1416 batch loss 1.66990089 epoch total loss 1.44663525
Trained batch 1417 batch loss 1.24276054 epoch total loss 1.44649136
Trained batch 1418 batch loss 1.59902287 epoch total loss 1.44659901
Trained batch 1419 batch loss 1.30111456 epoch total loss 1.44649637
Trained batch 1420 batch loss 1.34741211 epoch total loss 1.44642663
Trained batch 1421 batch loss 1.42233741 epoch total loss 1.4464097
Trained batch 1422 batch loss 1.42123783 epoch total loss 1.44639194
Trained batch 1423 batch loss 1.37349856 epoch total loss 1.44634068
Trained batch 1424 batch loss 1.36153555 epoch total loss 1.44628119
Trained batch 1425 batch loss 1.34175611 epoch total loss 1.44620788
Trained batch 1426 batch loss 1.40822589 epoch total loss 1.44618118
Trained batch 1427 batch loss 1.26073599 epoch total loss 1.44605124
Trained batch 1428 batch loss 1.43369031 epoch total loss 1.44604254
Trained batch 1429 batch loss 1.41547322 epoch total loss 1.4460212
Trained batch 1430 batch loss 1.54163408 epoch total loss 1.44608808
Trained batch 1431 batch loss 1.35257053 epoch total loss 1.44602275
Trained batch 1432 batch loss 1.52184331 epoch total loss 1.44607556
Trained batch 1433 batch loss 1.28126168 epoch total loss 1.44596064
Trained batch 1434 batch loss 1.21663773 epoch total loss 1.44580066
Trained batch 1435 batch loss 1.22786224 epoch total loss 1.44564867
Trained batch 1436 batch loss 1.39792979 epoch total loss 1.44561541
Trained batch 1437 batch loss 1.39806235 epoch total loss 1.44558227
Trained batch 1438 batch loss 1.46270049 epoch total loss 1.44559419
Trained batch 1439 batch loss 1.36357379 epoch total loss 1.44553709
Trained batch 1440 batch loss 1.12947488 epoch total loss 1.44531763
Trained batch 1441 batch loss 1.41501212 epoch total loss 1.44529653
Trained batch 1442 batch loss 1.3963654 epoch total loss 1.44526267
Trained batch 1443 batch loss 1.26913261 epoch total loss 1.4451406
Trained batch 1444 batch loss 1.44748271 epoch total loss 1.44514227
Trained batch 1445 batch loss 1.40126562 epoch total loss 1.44511199
Trained batch 1446 batch loss 1.33616567 epoch total loss 1.44503665
Trained batch 1447 batch loss 1.34237337 epoch total loss 1.4449656
Trained batch 1448 batch loss 1.60514879 epoch total loss 1.44507623
Trained batch 1449 batch loss 1.295524 epoch total loss 1.44497299
Trained batch 1450 batch loss 1.26778591 epoch total loss 1.4448508
Trained batch 1451 batch loss 1.37633586 epoch total loss 1.44480348
Trained batch 1452 batch loss 1.29455829 epoch total loss 1.44470012
Trained batch 1453 batch loss 1.51677597 epoch total loss 1.44474983
Trained batch 1454 batch loss 1.3943547 epoch total loss 1.44471502
Trained batch 1455 batch loss 1.25421119 epoch total loss 1.44458413
Trained batch 1456 batch loss 1.38185024 epoch total loss 1.44454098
Trained batch 1457 batch loss 1.31667209 epoch total loss 1.44445324
Trained batch 1458 batch loss 1.39125454 epoch total loss 1.44441676
Trained batch 1459 batch loss 1.34487474 epoch total loss 1.44434869
Trained batch 1460 batch loss 1.50021887 epoch total loss 1.44438696
Trained batch 1461 batch loss 1.44122994 epoch total loss 1.44438469
Trained batch 1462 batch loss 1.29939902 epoch total loss 1.44428551
Trained batch 1463 batch loss 1.0751555 epoch total loss 1.44403327
Trained batch 1464 batch loss 1.28822732 epoch total loss 1.44392681
Trained batch 1465 batch loss 1.23887575 epoch total loss 1.44378686
Trained batch 1466 batch loss 1.34756422 epoch total loss 1.44372129
Trained batch 1467 batch loss 1.28091681 epoch total loss 1.44361031
Trained batch 1468 batch loss 1.36279416 epoch total loss 1.44355524
Trained batch 1469 batch loss 1.43672824 epoch total loss 1.44355071
Trained batch 1470 batch loss 1.24561036 epoch total loss 1.443416
Trained batch 1471 batch loss 1.31344628 epoch total loss 1.44332767
Trained batch 1472 batch loss 1.30298948 epoch total loss 1.4432323
Trained batch 1473 batch loss 1.3872931 epoch total loss 1.44319427
Trained batch 1474 batch loss 1.36969328 epoch total loss 1.44314444
Trained batch 1475 batch loss 1.24495173 epoch total loss 1.44301
Trained batch 1476 batch loss 1.31161976 epoch total loss 1.44292092
Trained batch 1477 batch loss 1.17830396 epoch total loss 1.44274163
Trained batch 1478 batch loss 1.29586053 epoch total loss 1.44264233
Trained batch 1479 batch loss 1.42169809 epoch total loss 1.44262815
Trained batch 1480 batch loss 1.30495954 epoch total loss 1.44253504
Trained batch 1481 batch loss 1.30662394 epoch total loss 1.44244337
Trained batch 1482 batch loss 1.63616836 epoch total loss 1.44257402
Trained batch 1483 batch loss 1.38080013 epoch total loss 1.44253242
Trained batch 1484 batch loss 1.53286719 epoch total loss 1.44259334
Trained batch 1485 batch loss 1.46145403 epoch total loss 1.44260609
Trained batch 1486 batch loss 1.637501 epoch total loss 1.44273722
Trained batch 1487 batch loss 1.39161515 epoch total loss 1.44270277
Trained batch 1488 batch loss 1.51905942 epoch total loss 1.44275415
Trained batch 1489 batch loss 1.62283564 epoch total loss 1.44287503
Trained batch 1490 batch loss 1.56510985 epoch total loss 1.44295716
Trained batch 1491 batch loss 1.74503326 epoch total loss 1.44315982
Trained batch 1492 batch loss 1.73298693 epoch total loss 1.44335401
Trained batch 1493 batch loss 1.64787436 epoch total loss 1.44349098
Trained batch 1494 batch loss 1.59239602 epoch total loss 1.44359064
Trained batch 1495 batch loss 1.51372528 epoch total loss 1.44363749
Trained batch 1496 batch loss 1.4715265 epoch total loss 1.44365609
Trained batch 1497 batch loss 1.46376491 epoch total loss 1.44366956
Trained batch 1498 batch loss 1.37976027 epoch total loss 1.44362688
Trained batch 1499 batch loss 1.49155211 epoch total loss 1.44365871
Trained batch 1500 batch loss 1.48086035 epoch total loss 1.44368362
Trained batch 1501 batch loss 1.48924959 epoch total loss 1.4437139
Trained batch 1502 batch loss 1.45828283 epoch total loss 1.44372368
Trained batch 1503 batch loss 1.41103113 epoch total loss 1.44370198
Trained batch 1504 batch loss 1.2574842 epoch total loss 1.44357824
Trained batch 1505 batch loss 1.52458382 epoch total loss 1.44363213
Trained batch 1506 batch loss 1.36184764 epoch total loss 1.44357777
Trained batch 1507 batch loss 1.5801065 epoch total loss 1.44366837
Trained batch 1508 batch loss 1.46589422 epoch total loss 1.44368303
Trained batch 1509 batch loss 1.39157498 epoch total loss 1.44364846
Trained batch 1510 batch loss 1.11006987 epoch total loss 1.44342756
Trained batch 1511 batch loss 1.27588308 epoch total loss 1.4433167
Trained batch 1512 batch loss 1.27883315 epoch total loss 1.44320786
Trained batch 1513 batch loss 1.24102664 epoch total loss 1.44307423
Trained batch 1514 batch loss 1.16914022 epoch total loss 1.44289339
Trained batch 1515 batch loss 1.23335028 epoch total loss 1.4427551
Trained batch 1516 batch loss 1.42495918 epoch total loss 1.44274342
Trained batch 1517 batch loss 1.48521316 epoch total loss 1.44277132
Trained batch 1518 batch loss 1.43289793 epoch total loss 1.44276476
Trained batch 1519 batch loss 1.44704247 epoch total loss 1.44276762
Trained batch 1520 batch loss 1.48054075 epoch total loss 1.44279242
Trained batch 1521 batch loss 1.3589865 epoch total loss 1.44273722
Trained batch 1522 batch loss 1.5256052 epoch total loss 1.4427917
Trained batch 1523 batch loss 1.62271881 epoch total loss 1.44290984
Trained batch 1524 batch loss 1.41787267 epoch total loss 1.44289351
Trained batch 1525 batch loss 1.55899346 epoch total loss 1.44296968
Trained batch 1526 batch loss 1.57889247 epoch total loss 1.44305873
Trained batch 1527 batch loss 1.30856562 epoch total loss 1.44297075
Trained batch 1528 batch loss 1.33260226 epoch total loss 1.44289839
Trained batch 1529 batch loss 1.25613642 epoch total loss 1.4427762
Trained batch 1530 batch loss 1.42984772 epoch total loss 1.44276786
Trained batch 1531 batch loss 1.32379115 epoch total loss 1.44269013
Trained batch 1532 batch loss 1.29351616 epoch total loss 1.44259274
Trained batch 1533 batch loss 1.346174 epoch total loss 1.4425298
Trained batch 1534 batch loss 1.31976628 epoch total loss 1.44244981
Trained batch 1535 batch loss 1.36911392 epoch total loss 1.44240201
Trained batch 1536 batch loss 1.19410443 epoch total loss 1.44224036
Trained batch 1537 batch loss 1.12533784 epoch total loss 1.44203413
Trained batch 1538 batch loss 1.24082685 epoch total loss 1.44190323
Trained batch 1539 batch loss 1.30358028 epoch total loss 1.44181335
Trained batch 1540 batch loss 1.21976566 epoch total loss 1.44166911
Trained batch 1541 batch loss 1.27038717 epoch total loss 1.441558
Trained batch 1542 batch loss 1.25517094 epoch total loss 1.44143713
Trained batch 1543 batch loss 1.09930766 epoch total loss 1.4412154
Trained batch 1544 batch loss 1.22837269 epoch total loss 1.44107747
Trained batch 1545 batch loss 1.25091457 epoch total loss 1.44095445
Trained batch 1546 batch loss 1.24202931 epoch total loss 1.4408257
Trained batch 1547 batch loss 1.28745461 epoch total loss 1.44072652
Trained batch 1548 batch loss 1.23602366 epoch total loss 1.44059432
Trained batch 1549 batch loss 1.3399626 epoch total loss 1.44052935
Trained batch 1550 batch loss 1.17921829 epoch total loss 1.44036067
Trained batch 1551 batch loss 1.29829097 epoch total loss 1.44026911
Trained batch 1552 batch loss 1.21746159 epoch total loss 1.44012558
Trained batch 1553 batch loss 1.18661237 epoch total loss 1.43996227
Trained batch 1554 batch loss 1.13158655 epoch total loss 1.4397639
Trained batch 1555 batch loss 1.12816942 epoch total loss 1.43956351
Trained batch 1556 batch loss 1.24202442 epoch total loss 1.43943644
Trained batch 1557 batch loss 1.21851015 epoch total loss 1.43929458
Trained batch 1558 batch loss 1.36066771 epoch total loss 1.43924403
Trained batch 1559 batch loss 1.34946537 epoch total loss 1.43918645
Trained batch 1560 batch loss 1.25548124 epoch total loss 1.43906856
Trained batch 1561 batch loss 1.35297775 epoch total loss 1.43901348
Trained batch 1562 batch loss 1.54078746 epoch total loss 1.43907869
Trained batch 1563 batch loss 1.67110431 epoch total loss 1.4392271
Trained batch 1564 batch loss 1.4488368 epoch total loss 1.43923318
Trained batch 1565 batch loss 1.50397623 epoch total loss 1.43927455
Trained batch 1566 batch loss 1.02849245 epoch total loss 1.43901229
Trained batch 1567 batch loss 1.07395816 epoch total loss 1.43877923
Trained batch 1568 batch loss 1.18267941 epoch total loss 1.43861592
Trained batch 1569 batch loss 1.35354924 epoch total loss 1.43856168
Trained batch 1570 batch loss 1.42616272 epoch total loss 1.43855381
Trained batch 1571 batch loss 1.65763879 epoch total loss 1.4386934
Trained batch 1572 batch loss 1.41221952 epoch total loss 1.43867648
Trained batch 1573 batch loss 1.45465112 epoch total loss 1.43868661
Trained batch 1574 batch loss 1.36189973 epoch total loss 1.43863773
Trained batch 1575 batch loss 1.37426043 epoch total loss 1.43859684
Trained batch 1576 batch loss 1.3366344 epoch total loss 1.43853223
Trained batch 1577 batch loss 1.35686028 epoch total loss 1.43848038
Trained batch 1578 batch loss 1.4868865 epoch total loss 1.43851101
Trained batch 1579 batch loss 1.39832282 epoch total loss 1.43848574
Trained batch 1580 batch loss 1.5244801 epoch total loss 1.4385401
Trained batch 1581 batch loss 1.57253718 epoch total loss 1.43862486
Trained batch 1582 batch loss 1.51901913 epoch total loss 1.43867564
Trained batch 1583 batch loss 1.5279038 epoch total loss 1.43873191
Trained batch 1584 batch loss 1.5771451 epoch total loss 1.43881929
Trained batch 1585 batch loss 1.59798932 epoch total loss 1.43891966
Trained batch 1586 batch loss 1.59420383 epoch total loss 1.43901765
Trained batch 1587 batch loss 1.47199607 epoch total loss 1.4390384
Trained batch 1588 batch loss 1.45549917 epoch total loss 1.43904877
Trained batch 1589 batch loss 1.54664278 epoch total loss 1.43911648
Trained batch 1590 batch loss 1.22002983 epoch total loss 1.43897867
Trained batch 1591 batch loss 1.29286838 epoch total loss 1.43888688
Trained batch 1592 batch loss 1.36546803 epoch total loss 1.43884075
Trained batch 1593 batch loss 1.12485099 epoch total loss 1.43864357
Trained batch 1594 batch loss 1.4217751 epoch total loss 1.43863308
Trained batch 1595 batch loss 1.41093564 epoch total loss 1.43861568
Trained batch 1596 batch loss 1.30281866 epoch total loss 1.43853056
Trained batch 1597 batch loss 1.37356579 epoch total loss 1.43848991
Trained batch 1598 batch loss 1.43048835 epoch total loss 1.43848479
Trained batch 1599 batch loss 1.29848361 epoch total loss 1.43839729
Trained batch 1600 batch loss 1.21801817 epoch total loss 1.4382596
Trained batch 1601 batch loss 1.23658419 epoch total loss 1.4381336
Trained batch 1602 batch loss 1.34075832 epoch total loss 1.43807292
Trained batch 1603 batch loss 1.51741374 epoch total loss 1.43812227
Trained batch 1604 batch loss 1.60021281 epoch total loss 1.43822324
Trained batch 1605 batch loss 1.38547099 epoch total loss 1.43819046
Trained batch 1606 batch loss 1.50228763 epoch total loss 1.43823028
Trained batch 1607 batch loss 1.4557662 epoch total loss 1.43824124
Trained batch 1608 batch loss 1.45008457 epoch total loss 1.43824863
Trained batch 1609 batch loss 1.42047799 epoch total loss 1.43823755
Trained batch 1610 batch loss 1.45277488 epoch total loss 1.43824673
Trained batch 1611 batch loss 1.51229668 epoch total loss 1.43829262
Trained batch 1612 batch loss 1.277771 epoch total loss 1.43819308
Trained batch 1613 batch loss 1.55554223 epoch total loss 1.43826592
Trained batch 1614 batch loss 1.51110268 epoch total loss 1.43831098
Trained batch 1615 batch loss 1.43084 epoch total loss 1.43830633
Trained batch 1616 batch loss 1.53233647 epoch total loss 1.43836451
Trained batch 1617 batch loss 1.47100127 epoch total loss 1.43838465
Trained batch 1618 batch loss 1.50452256 epoch total loss 1.43842554
Trained batch 1619 batch loss 1.58408916 epoch total loss 1.43851542
Trained batch 1620 batch loss 1.47320807 epoch total loss 1.43853688
Trained batch 1621 batch loss 1.54618526 epoch total loss 1.43860328
Trained batch 1622 batch loss 1.50707209 epoch total loss 1.43864548
Trained batch 1623 batch loss 1.47736073 epoch total loss 1.4386692
Trained batch 1624 batch loss 1.5150094 epoch total loss 1.43871617
Trained batch 1625 batch loss 1.63724184 epoch total loss 1.43883836
Trained batch 1626 batch loss 1.47924197 epoch total loss 1.43886316
Trained batch 1627 batch loss 1.45494771 epoch total loss 1.43887305
Trained batch 1628 batch loss 1.46679449 epoch total loss 1.43889022
Trained batch 1629 batch loss 1.48978341 epoch total loss 1.43892133
Trained batch 1630 batch loss 1.59392607 epoch total loss 1.43901646
Trained batch 1631 batch loss 1.44040143 epoch total loss 1.43901742
Trained batch 1632 batch loss 1.43861628 epoch total loss 1.43901718
Trained batch 1633 batch loss 1.63555443 epoch total loss 1.43913758
Trained batch 1634 batch loss 1.5105772 epoch total loss 1.43918121
Trained batch 1635 batch loss 1.40295625 epoch total loss 1.43915915
Trained batch 1636 batch loss 1.45213878 epoch total loss 1.43916702
Trained batch 1637 batch loss 1.43533301 epoch total loss 1.43916464
Trained batch 1638 batch loss 1.49146962 epoch total loss 1.43919659
Trained batch 1639 batch loss 1.38092256 epoch total loss 1.43916106
Trained batch 1640 batch loss 1.39802206 epoch total loss 1.43913591
Trained batch 1641 batch loss 1.37433553 epoch total loss 1.43909633
Trained batch 1642 batch loss 1.45422363 epoch total loss 1.43910551
Trained batch 1643 batch loss 1.46993184 epoch total loss 1.43912423
Trained batch 1644 batch loss 1.37073398 epoch total loss 1.43908274
Trained batch 1645 batch loss 1.39361989 epoch total loss 1.43905509
Trained batch 1646 batch loss 1.4424938 epoch total loss 1.43905711
Trained batch 1647 batch loss 1.41702247 epoch total loss 1.43904376
Trained batch 1648 batch loss 1.50282907 epoch total loss 1.4390825
Trained batch 1649 batch loss 1.1758604 epoch total loss 1.43892276
Trained batch 1650 batch loss 1.2181282 epoch total loss 1.43878889
Trained batch 1651 batch loss 1.36709952 epoch total loss 1.4387455
Trained batch 1652 batch loss 1.28171098 epoch total loss 1.43865049
Trained batch 1653 batch loss 1.47402036 epoch total loss 1.43867195
Trained batch 1654 batch loss 1.50961947 epoch total loss 1.43871474
Trained batch 1655 batch loss 1.35602617 epoch total loss 1.43866479
Trained batch 1656 batch loss 1.39474845 epoch total loss 1.43863833
Trained batch 1657 batch loss 1.50009441 epoch total loss 1.43867528
Trained batch 1658 batch loss 1.70443594 epoch total loss 1.4388355
Trained batch 1659 batch loss 1.51404405 epoch total loss 1.43888092
Trained batch 1660 batch loss 1.51143241 epoch total loss 1.43892467
Trained batch 1661 batch loss 1.37680697 epoch total loss 1.43888724
Trained batch 1662 batch loss 1.33083069 epoch total loss 1.43882215
Trained batch 1663 batch loss 1.18804884 epoch total loss 1.43867135
Trained batch 1664 batch loss 1.34708226 epoch total loss 1.43861639
Trained batch 1665 batch loss 1.15526652 epoch total loss 1.43844616
Trained batch 1666 batch loss 1.30086899 epoch total loss 1.43836355
Trained batch 1667 batch loss 1.49095249 epoch total loss 1.43839514
Trained batch 1668 batch loss 1.42244911 epoch total loss 1.43838549
Trained batch 1669 batch loss 1.43881392 epoch total loss 1.43838573
Trained batch 1670 batch loss 1.41749 epoch total loss 1.43837321
Trained batch 1671 batch loss 1.37344503 epoch total loss 1.43833435
Trained batch 1672 batch loss 1.42323422 epoch total loss 1.43832541
Trained batch 1673 batch loss 1.30702603 epoch total loss 1.43824697
Trained batch 1674 batch loss 1.45797074 epoch total loss 1.43825877
Trained batch 1675 batch loss 1.48330522 epoch total loss 1.43828583
Trained batch 1676 batch loss 1.40757716 epoch total loss 1.43826735
Trained batch 1677 batch loss 1.32606137 epoch total loss 1.43820059
Trained batch 1678 batch loss 1.39526558 epoch total loss 1.43817496
Trained batch 1679 batch loss 1.46756 epoch total loss 1.43819249
Trained batch 1680 batch loss 1.29125631 epoch total loss 1.43810499
Trained batch 1681 batch loss 1.46495986 epoch total loss 1.43812084
Trained batch 1682 batch loss 1.43105316 epoch total loss 1.43811679
Trained batch 1683 batch loss 1.48359323 epoch total loss 1.43814373
Trained batch 1684 batch loss 1.5363996 epoch total loss 1.43820214
Trained batch 1685 batch loss 1.58287644 epoch total loss 1.43828797
Trained batch 1686 batch loss 1.45659149 epoch total loss 1.4382987
Trained batch 1687 batch loss 1.42689419 epoch total loss 1.43829203
Trained batch 1688 batch loss 1.49205554 epoch total loss 1.43832386
Trained batch 1689 batch loss 1.50183094 epoch total loss 1.43836141
Trained batch 1690 batch loss 1.23878801 epoch total loss 1.43824327
Trained batch 1691 batch loss 1.1552484 epoch total loss 1.4380759
Trained batch 1692 batch loss 1.15374053 epoch total loss 1.43790793
Trained batch 1693 batch loss 1.11654592 epoch total loss 1.43771803
Trained batch 1694 batch loss 1.10104477 epoch total loss 1.43751931
Trained batch 1695 batch loss 1.43995142 epoch total loss 1.43752074
Trained batch 1696 batch loss 1.59407461 epoch total loss 1.43761301
Trained batch 1697 batch loss 1.49444091 epoch total loss 1.43764651
Trained batch 1698 batch loss 1.435027 epoch total loss 1.43764496
Trained batch 1699 batch loss 1.51108813 epoch total loss 1.43768811
Trained batch 1700 batch loss 1.40719676 epoch total loss 1.43767023
Trained batch 1701 batch loss 1.43898869 epoch total loss 1.43767095
Trained batch 1702 batch loss 1.08912206 epoch total loss 1.43746614
Trained batch 1703 batch loss 1.37062168 epoch total loss 1.43742692
Trained batch 1704 batch loss 1.45205379 epoch total loss 1.43743551
Trained batch 1705 batch loss 1.34959018 epoch total loss 1.43738401
Trained batch 1706 batch loss 1.49010444 epoch total loss 1.43741488
Trained batch 1707 batch loss 1.49488378 epoch total loss 1.4374485
Trained batch 1708 batch loss 1.31183398 epoch total loss 1.43737495
Trained batch 1709 batch loss 1.30507183 epoch total loss 1.43729758
Trained batch 1710 batch loss 1.30323625 epoch total loss 1.43721914
Trained batch 1711 batch loss 1.37253928 epoch total loss 1.43718135
Trained batch 1712 batch loss 1.40297532 epoch total loss 1.43716145
Trained batch 1713 batch loss 1.39473295 epoch total loss 1.43713677
Trained batch 1714 batch loss 1.40158558 epoch total loss 1.43711603
Trained batch 1715 batch loss 1.34155858 epoch total loss 1.43706024
Trained batch 1716 batch loss 1.29909158 epoch total loss 1.43697989
Trained batch 1717 batch loss 1.17260027 epoch total loss 1.43682587
Trained batch 1718 batch loss 1.38806581 epoch total loss 1.43679762
Trained batch 1719 batch loss 1.63853073 epoch total loss 1.4369148
Trained batch 1720 batch loss 1.23265934 epoch total loss 1.43679607
Trained batch 1721 batch loss 1.39780092 epoch total loss 1.43677342
Trained batch 1722 batch loss 1.28417242 epoch total loss 1.43668473
Trained batch 1723 batch loss 1.07610226 epoch total loss 1.43647552
Trained batch 1724 batch loss 1.24666953 epoch total loss 1.43636537
Trained batch 1725 batch loss 1.56234145 epoch total loss 1.43643832
Trained batch 1726 batch loss 1.58932734 epoch total loss 1.43652701
Trained batch 1727 batch loss 1.4900012 epoch total loss 1.43655789
Trained batch 1728 batch loss 1.47444224 epoch total loss 1.43657982
Trained batch 1729 batch loss 1.18630075 epoch total loss 1.4364351
Trained batch 1730 batch loss 1.38524878 epoch total loss 1.43640542
Trained batch 1731 batch loss 1.36431074 epoch total loss 1.43636382
Trained batch 1732 batch loss 1.38178611 epoch total loss 1.43633235
Trained batch 1733 batch loss 1.47147405 epoch total loss 1.43635261
Trained batch 1734 batch loss 1.11210704 epoch total loss 1.43616557
Trained batch 1735 batch loss 1.27949762 epoch total loss 1.43607521
Trained batch 1736 batch loss 1.10133266 epoch total loss 1.43588245
Trained batch 1737 batch loss 1.29128563 epoch total loss 1.43579912
Trained batch 1738 batch loss 1.13547206 epoch total loss 1.43562639
Trained batch 1739 batch loss 0.961442351 epoch total loss 1.43535376
Trained batch 1740 batch loss 1.27048969 epoch total loss 1.43525898
Trained batch 1741 batch loss 1.33746028 epoch total loss 1.43520272
Trained batch 1742 batch loss 1.41073072 epoch total loss 1.43518865
Trained batch 1743 batch loss 1.51899791 epoch total loss 1.43523681
Trained batch 1744 batch loss 1.43883061 epoch total loss 1.43523872
Trained batch 1745 batch loss 1.63171279 epoch total loss 1.43535125
Trained batch 1746 batch loss 1.69856346 epoch total loss 1.43550193
Trained batch 1747 batch loss 1.58816028 epoch total loss 1.43558931
Trained batch 1748 batch loss 1.69216108 epoch total loss 1.43573618
Trained batch 1749 batch loss 1.38387263 epoch total loss 1.43570638
Trained batch 1750 batch loss 1.2225 epoch total loss 1.43558455
Trained batch 1751 batch loss 1.30017066 epoch total loss 1.43550718
Trained batch 1752 batch loss 1.23390245 epoch total loss 1.43539202
Trained batch 1753 batch loss 1.35264182 epoch total loss 1.43534482
Trained batch 1754 batch loss 1.27319789 epoch total loss 1.43525231
Trained batch 1755 batch loss 1.20855975 epoch total loss 1.43512309
Trained batch 1756 batch loss 1.19002128 epoch total loss 1.43498349
Trained batch 1757 batch loss 1.26144576 epoch total loss 1.43488479
Trained batch 1758 batch loss 1.23425126 epoch total loss 1.43477058
Trained batch 1759 batch loss 1.35778892 epoch total loss 1.43472683
Trained batch 1760 batch loss 1.27067459 epoch total loss 1.43463373
Trained batch 1761 batch loss 1.24655378 epoch total loss 1.43452692
Trained batch 1762 batch loss 1.36217713 epoch total loss 1.43448579
Trained batch 1763 batch loss 1.39749515 epoch total loss 1.43446481
Trained batch 1764 batch loss 1.37814021 epoch total loss 1.43443286
Trained batch 1765 batch loss 1.34075975 epoch total loss 1.43437982
Trained batch 1766 batch loss 1.35786414 epoch total loss 1.43433654
Trained batch 1767 batch loss 1.31390607 epoch total loss 1.43426847
Trained batch 1768 batch loss 1.47501135 epoch total loss 1.43429148
Trained batch 1769 batch loss 1.61372507 epoch total loss 1.43439293
Trained batch 1770 batch loss 1.58841729 epoch total loss 1.43448
Trained batch 1771 batch loss 1.74503326 epoch total loss 1.43465543
Trained batch 1772 batch loss 1.18384 epoch total loss 1.43451381
Trained batch 1773 batch loss 1.28265023 epoch total loss 1.43442822
Trained batch 1774 batch loss 1.24088347 epoch total loss 1.43431914
Trained batch 1775 batch loss 1.36264336 epoch total loss 1.43427873
Trained batch 1776 batch loss 1.66816676 epoch total loss 1.43441045
Trained batch 1777 batch loss 1.25156546 epoch total loss 1.43430746
Trained batch 1778 batch loss 1.29837132 epoch total loss 1.43423104
Trained batch 1779 batch loss 1.40513158 epoch total loss 1.43421459
Trained batch 1780 batch loss 1.31011224 epoch total loss 1.43414485
Trained batch 1781 batch loss 1.34014082 epoch total loss 1.43409204
Trained batch 1782 batch loss 1.30778813 epoch total loss 1.43402123
Trained batch 1783 batch loss 1.34250903 epoch total loss 1.43396986
Trained batch 1784 batch loss 1.3521229 epoch total loss 1.43392396
Trained batch 1785 batch loss 1.29462266 epoch total loss 1.433846
Trained batch 1786 batch loss 1.38374865 epoch total loss 1.43381798
Trained batch 1787 batch loss 1.43367362 epoch total loss 1.43381786
Trained batch 1788 batch loss 1.24685597 epoch total loss 1.4337132
Trained batch 1789 batch loss 1.13688338 epoch total loss 1.43354738
Trained batch 1790 batch loss 1.35468781 epoch total loss 1.43350327
Trained batch 1791 batch loss 1.33531952 epoch total loss 1.43344843
Trained batch 1792 batch loss 1.51992702 epoch total loss 1.43349671
Trained batch 1793 batch loss 1.4803822 epoch total loss 1.43352294
Trained batch 1794 batch loss 1.55437589 epoch total loss 1.43359029
Trained batch 1795 batch loss 1.33274567 epoch total loss 1.43353415
Trained batch 1796 batch loss 1.400424 epoch total loss 1.43351567
Trained batch 1797 batch loss 1.49893486 epoch total loss 1.43355215
Trained batch 1798 batch loss 1.41635895 epoch total loss 1.43354261
Trained batch 1799 batch loss 1.51221538 epoch total loss 1.43358624
Trained batch 1800 batch loss 1.53743386 epoch total loss 1.43364394
Trained batch 1801 batch loss 1.58552313 epoch total loss 1.43372822
Trained batch 1802 batch loss 1.35684443 epoch total loss 1.43368566
Trained batch 1803 batch loss 1.4861064 epoch total loss 1.43371463
Trained batch 1804 batch loss 1.50301445 epoch total loss 1.43375301
Trained batch 1805 batch loss 1.4010632 epoch total loss 1.43373501
Trained batch 1806 batch loss 1.31279969 epoch total loss 1.43366802
Trained batch 1807 batch loss 1.46338797 epoch total loss 1.43368435
Trained batch 1808 batch loss 1.22454023 epoch total loss 1.43356872
Trained batch 1809 batch loss 0.969615936 epoch total loss 1.43331242
Trained batch 1810 batch loss 1.256639 epoch total loss 1.43321478
Trained batch 1811 batch loss 1.29610133 epoch total loss 1.43313909
Trained batch 1812 batch loss 1.40568066 epoch total loss 1.43312395
Trained batch 1813 batch loss 1.29800653 epoch total loss 1.43304944
Trained batch 1814 batch loss 1.07619143 epoch total loss 1.43285275
Trained batch 1815 batch loss 1.37677753 epoch total loss 1.43282175
Trained batch 1816 batch loss 1.17781663 epoch total loss 1.43268132
Trained batch 1817 batch loss 1.17852473 epoch total loss 1.43254137
Trained batch 1818 batch loss 1.39591467 epoch total loss 1.43252134
Trained batch 1819 batch loss 1.2569 epoch total loss 1.43242466
Trained batch 1820 batch loss 1.33887362 epoch total loss 1.43237329
Trained batch 1821 batch loss 1.56756139 epoch total loss 1.43244755
Trained batch 1822 batch loss 1.45058537 epoch total loss 1.43245757
Trained batch 1823 batch loss 1.47939348 epoch total loss 1.43248343
Trained batch 1824 batch loss 1.34614801 epoch total loss 1.43243611
Trained batch 1825 batch loss 1.25944448 epoch total loss 1.43234134
Trained batch 1826 batch loss 1.39024663 epoch total loss 1.43231821
Trained batch 1827 batch loss 1.59886813 epoch total loss 1.43240941
Trained batch 1828 batch loss 1.45959091 epoch total loss 1.43242419
Trained batch 1829 batch loss 1.22198653 epoch total loss 1.43230915
Trained batch 1830 batch loss 1.36716938 epoch total loss 1.43227351
Trained batch 1831 batch loss 1.12169957 epoch total loss 1.43210387
Trained batch 1832 batch loss 1.09681153 epoch total loss 1.43192089
Trained batch 1833 batch loss 1.06124783 epoch total loss 1.43171871
Trained batch 1834 batch loss 1.08437216 epoch total loss 1.43152928
Trained batch 1835 batch loss 1.02624381 epoch total loss 1.43130839
Trained batch 1836 batch loss 1.08867311 epoch total loss 1.43112171
Trained batch 1837 batch loss 1.11833143 epoch total loss 1.43095148
Trained batch 1838 batch loss 1.15527821 epoch total loss 1.43080151
Trained batch 1839 batch loss 1.11927664 epoch total loss 1.43063223
Trained batch 1840 batch loss 1.05570829 epoch total loss 1.43042839
Trained batch 1841 batch loss 1.05803895 epoch total loss 1.43022621
Trained batch 1842 batch loss 1.20508647 epoch total loss 1.4301039
Trained batch 1843 batch loss 1.19311512 epoch total loss 1.42997539
Trained batch 1844 batch loss 1.22526562 epoch total loss 1.42986441
Trained batch 1845 batch loss 1.50563014 epoch total loss 1.42990541
Trained batch 1846 batch loss 1.4679848 epoch total loss 1.42992604
Trained batch 1847 batch loss 1.46130431 epoch total loss 1.42994308
Trained batch 1848 batch loss 1.33734202 epoch total loss 1.42989302
Trained batch 1849 batch loss 1.35572147 epoch total loss 1.42985296
Trained batch 1850 batch loss 1.45418715 epoch total loss 1.42986608
Trained batch 1851 batch loss 1.43804264 epoch total loss 1.42987049
Trained batch 1852 batch loss 1.43402743 epoch total loss 1.42987275
Trained batch 1853 batch loss 1.57216406 epoch total loss 1.42994952
Trained batch 1854 batch loss 1.57369637 epoch total loss 1.43002713
Trained batch 1855 batch loss 1.46252263 epoch total loss 1.43004453
Trained batch 1856 batch loss 1.37097549 epoch total loss 1.43001282
Trained batch 1857 batch loss 1.51143861 epoch total loss 1.43005669
Trained batch 1858 batch loss 1.48348248 epoch total loss 1.43008542
Trained batch 1859 batch loss 1.34070969 epoch total loss 1.43003738
Trained batch 1860 batch loss 1.20158577 epoch total loss 1.42991459
Trained batch 1861 batch loss 1.31327605 epoch total loss 1.42985189
Trained batch 1862 batch loss 1.25860178 epoch total loss 1.42975986
Trained batch 1863 batch loss 1.23012507 epoch total loss 1.42965281
Trained batch 1864 batch loss 1.60310137 epoch total loss 1.42974579
Trained batch 1865 batch loss 1.24800909 epoch total loss 1.4296484
Trained batch 1866 batch loss 1.28613806 epoch total loss 1.42957139
Trained batch 1867 batch loss 1.1078701 epoch total loss 1.42939913
Trained batch 1868 batch loss 1.09980941 epoch total loss 1.4292227
Trained batch 1869 batch loss 1.53626943 epoch total loss 1.42928
Trained batch 1870 batch loss 1.57314551 epoch total loss 1.42935705
Trained batch 1871 batch loss 1.63169694 epoch total loss 1.42946517
Trained batch 1872 batch loss 1.33563137 epoch total loss 1.42941511
Trained batch 1873 batch loss 1.57839012 epoch total loss 1.42949462
Trained batch 1874 batch loss 1.23702872 epoch total loss 1.42939186
Trained batch 1875 batch loss 1.39752114 epoch total loss 1.42937481
Trained batch 1876 batch loss 1.25411046 epoch total loss 1.42928147
Trained batch 1877 batch loss 1.50127816 epoch total loss 1.42931974
Trained batch 1878 batch loss 1.4479022 epoch total loss 1.42932975
Trained batch 1879 batch loss 1.51153469 epoch total loss 1.4293735
Trained batch 1880 batch loss 1.49052584 epoch total loss 1.42940593
Trained batch 1881 batch loss 1.27891898 epoch total loss 1.42932594
Trained batch 1882 batch loss 1.35326314 epoch total loss 1.42928553
Trained batch 1883 batch loss 1.31238854 epoch total loss 1.42922342
Trained batch 1884 batch loss 1.350945 epoch total loss 1.42918181
Trained batch 1885 batch loss 1.38182807 epoch total loss 1.42915678
Trained batch 1886 batch loss 1.48200846 epoch total loss 1.42918468
Trained batch 1887 batch loss 1.58772016 epoch total loss 1.42926872
Trained batch 1888 batch loss 1.58612919 epoch total loss 1.42935181
Trained batch 1889 batch loss 1.56770301 epoch total loss 1.429425
Trained batch 1890 batch loss 1.62173438 epoch total loss 1.42952681
Trained batch 1891 batch loss 1.47450697 epoch total loss 1.42955065
Trained batch 1892 batch loss 1.4012351 epoch total loss 1.42953563
Trained batch 1893 batch loss 1.21272075 epoch total loss 1.42942107
Trained batch 1894 batch loss 1.19281 epoch total loss 1.42929614
Trained batch 1895 batch loss 1.25724864 epoch total loss 1.42920542
Trained batch 1896 batch loss 1.56035733 epoch total loss 1.42927456
Trained batch 1897 batch loss 1.35645199 epoch total loss 1.42923617
Trained batch 1898 batch loss 1.37253451 epoch total loss 1.42920625
Trained batch 1899 batch loss 1.38399303 epoch total loss 1.42918253
Trained batch 1900 batch loss 1.44130182 epoch total loss 1.42918897
Trained batch 1901 batch loss 1.34146643 epoch total loss 1.42914283
Trained batch 1902 batch loss 1.19285381 epoch total loss 1.42901862
Trained batch 1903 batch loss 1.15265274 epoch total loss 1.4288733
Trained batch 1904 batch loss 1.12471509 epoch total loss 1.42871368
Trained batch 1905 batch loss 1.17377424 epoch total loss 1.42857981
Trained batch 1906 batch loss 1.15499496 epoch total loss 1.42843628
Trained batch 1907 batch loss 1.12896919 epoch total loss 1.42827928
Trained batch 1908 batch loss 1.29532552 epoch total loss 1.42820966
Trained batch 1909 batch loss 1.26815414 epoch total loss 1.42812574
Trained batch 1910 batch loss 1.28304815 epoch total loss 1.42804968
Trained batch 1911 batch loss 1.24931192 epoch total loss 1.4279561
Trained batch 1912 batch loss 1.3188374 epoch total loss 1.42789912
Trained batch 1913 batch loss 1.27035034 epoch total loss 1.42781675
Trained batch 1914 batch loss 1.30060315 epoch total loss 1.42775023
Trained batch 1915 batch loss 1.31480312 epoch total loss 1.4276911
Trained batch 1916 batch loss 1.29326856 epoch total loss 1.42762101
Trained batch 1917 batch loss 1.24173331 epoch total loss 1.42752397
Trained batch 1918 batch loss 1.20276451 epoch total loss 1.42740691
Trained batch 1919 batch loss 1.28952587 epoch total loss 1.42733502
Trained batch 1920 batch loss 1.29927683 epoch total loss 1.42726839
Trained batch 1921 batch loss 1.29813182 epoch total loss 1.42720115
Trained batch 1922 batch loss 1.29410696 epoch total loss 1.42713189
Trained batch 1923 batch loss 1.17123461 epoch total loss 1.42699873
Trained batch 1924 batch loss 1.4639523 epoch total loss 1.42701793
Trained batch 1925 batch loss 1.49895251 epoch total loss 1.42705536
Trained batch 1926 batch loss 1.57256937 epoch total loss 1.42713082
Trained batch 1927 batch loss 1.33944917 epoch total loss 1.42708528
Trained batch 1928 batch loss 1.31541336 epoch total loss 1.42702746
Trained batch 1929 batch loss 1.23718929 epoch total loss 1.426929
Trained batch 1930 batch loss 1.343297 epoch total loss 1.42688572
Trained batch 1931 batch loss 1.58361685 epoch total loss 1.42696679
Trained batch 1932 batch loss 1.42807293 epoch total loss 1.42696738
Trained batch 1933 batch loss 1.50902843 epoch total loss 1.42700982
Trained batch 1934 batch loss 1.426687 epoch total loss 1.4270097
Trained batch 1935 batch loss 1.35357845 epoch total loss 1.42697167
Trained batch 1936 batch loss 1.17522216 epoch total loss 1.42684162
Trained batch 1937 batch loss 1.29063535 epoch total loss 1.42677128
Trained batch 1938 batch loss 1.41598856 epoch total loss 1.4267658
Trained batch 1939 batch loss 1.26030612 epoch total loss 1.42667985
Trained batch 1940 batch loss 1.35569859 epoch total loss 1.42664325
Trained batch 1941 batch loss 1.20720601 epoch total loss 1.42653024
Trained batch 1942 batch loss 1.09365392 epoch total loss 1.42635894
Trained batch 1943 batch loss 0.966899514 epoch total loss 1.42612243
Trained batch 1944 batch loss 1.10610747 epoch total loss 1.4259578
Trained batch 1945 batch loss 1.33220148 epoch total loss 1.42590964
Trained batch 1946 batch loss 1.23180532 epoch total loss 1.42580986
Trained batch 1947 batch loss 1.42021441 epoch total loss 1.425807
Trained batch 1948 batch loss 0.961017609 epoch total loss 1.42556834
Trained batch 1949 batch loss 1.42722368 epoch total loss 1.42556918
Trained batch 1950 batch loss 1.47072673 epoch total loss 1.4255923
Trained batch 1951 batch loss 1.28531814 epoch total loss 1.42552042
Trained batch 1952 batch loss 1.1841414 epoch total loss 1.4253968
Trained batch 1953 batch loss 1.37808943 epoch total loss 1.4253726
Trained batch 1954 batch loss 1.34352946 epoch total loss 1.42533076
Trained batch 1955 batch loss 1.3633039 epoch total loss 1.42529893
Trained batch 1956 batch loss 1.32777166 epoch total loss 1.4252491
Trained batch 1957 batch loss 1.31074536 epoch total loss 1.42519069
Trained batch 1958 batch loss 1.57742417 epoch total loss 1.42526841
Trained batch 1959 batch loss 1.1160084 epoch total loss 1.42511046
Trained batch 1960 batch loss 1.55759633 epoch total loss 1.42517817
Trained batch 1961 batch loss 1.49929643 epoch total loss 1.42521596
Trained batch 1962 batch loss 1.45428538 epoch total loss 1.42523074
Trained batch 1963 batch loss 1.34490728 epoch total loss 1.42518985
Trained batch 1964 batch loss 1.40004802 epoch total loss 1.4251771
Trained batch 1965 batch loss 1.41114914 epoch total loss 1.42517
Trained batch 1966 batch loss 1.45324326 epoch total loss 1.42518413
Trained batch 1967 batch loss 1.46511519 epoch total loss 1.42520452
Trained batch 1968 batch loss 1.42652011 epoch total loss 1.42520511
Trained batch 1969 batch loss 1.28219581 epoch total loss 1.42513251
Trained batch 1970 batch loss 1.30936241 epoch total loss 1.42507374
Trained batch 1971 batch loss 1.37274921 epoch total loss 1.42504716
Trained batch 1972 batch loss 1.46075296 epoch total loss 1.42506528
Trained batch 1973 batch loss 1.21614754 epoch total loss 1.42495942
Trained batch 1974 batch loss 1.36739099 epoch total loss 1.42493021
Trained batch 1975 batch loss 1.33019757 epoch total loss 1.42488217
Trained batch 1976 batch loss 1.51138949 epoch total loss 1.42492604
Trained batch 1977 batch loss 1.43843007 epoch total loss 1.42493284
Trained batch 1978 batch loss 1.21218085 epoch total loss 1.42482531
Trained batch 1979 batch loss 1.32790589 epoch total loss 1.42477632
Trained batch 1980 batch loss 1.27433336 epoch total loss 1.42470038
Trained batch 1981 batch loss 1.32505667 epoch total loss 1.42465007
Trained batch 1982 batch loss 1.20744157 epoch total loss 1.42454052
Trained batch 1983 batch loss 1.42280197 epoch total loss 1.42453957
Trained batch 1984 batch loss 1.4184804 epoch total loss 1.42453659
Trained batch 1985 batch loss 1.25036168 epoch total loss 1.42444873
Trained batch 1986 batch loss 1.2471863 epoch total loss 1.42435944
Trained batch 1987 batch loss 1.19587231 epoch total loss 1.4242444
Trained batch 1988 batch loss 1.46135199 epoch total loss 1.42426312
Trained batch 1989 batch loss 1.29199648 epoch total loss 1.4241966
Trained batch 1990 batch loss 1.18944156 epoch total loss 1.4240787
Trained batch 1991 batch loss 1.39364088 epoch total loss 1.42406332
Trained batch 1992 batch loss 1.38828814 epoch total loss 1.42404532
Trained batch 1993 batch loss 1.37743056 epoch total loss 1.42402196
Trained batch 1994 batch loss 1.36071324 epoch total loss 1.42399013
Trained batch 1995 batch loss 1.59545541 epoch total loss 1.42407608
Trained batch 1996 batch loss 1.41854692 epoch total loss 1.42407322
Trained batch 1997 batch loss 1.42669487 epoch total loss 1.42407453
Trained batch 1998 batch loss 1.47050357 epoch total loss 1.42409778
Trained batch 1999 batch loss 1.36026716 epoch total loss 1.42406595
Trained batch 2000 batch loss 1.2008338 epoch total loss 1.42395437
Trained batch 2001 batch loss 1.4904263 epoch total loss 1.42398763
Trained batch 2002 batch loss 1.30610847 epoch total loss 1.42392874
Trained batch 2003 batch loss 1.33477736 epoch total loss 1.42388415
Trained batch 2004 batch loss 1.37213671 epoch total loss 1.42385828
Trained batch 2005 batch loss 1.44632435 epoch total loss 1.42386949
Trained batch 2006 batch loss 1.17359173 epoch total loss 1.4237448
Trained batch 2007 batch loss 1.23716271 epoch total loss 1.4236517
Trained batch 2008 batch loss 1.25313687 epoch total loss 1.42356682
Trained batch 2009 batch loss 1.21822429 epoch total loss 1.42346466
Trained batch 2010 batch loss 1.41209805 epoch total loss 1.42345905
Trained batch 2011 batch loss 1.28766012 epoch total loss 1.42339146
Trained batch 2012 batch loss 1.19542634 epoch total loss 1.42327809
Trained batch 2013 batch loss 1.41565967 epoch total loss 1.4232744
Trained batch 2014 batch loss 1.24271894 epoch total loss 1.42318463
Trained batch 2015 batch loss 1.19800174 epoch total loss 1.42307293
Trained batch 2016 batch loss 1.25201464 epoch total loss 1.42298806
Trained batch 2017 batch loss 1.12900758 epoch total loss 1.42284226
Trained batch 2018 batch loss 1.08520365 epoch total loss 1.42267489
Trained batch 2019 batch loss 1.19845653 epoch total loss 1.42256391
Trained batch 2020 batch loss 1.21927869 epoch total loss 1.42246318
Trained batch 2021 batch loss 1.27796721 epoch total loss 1.42239177
Trained batch 2022 batch loss 1.1616652 epoch total loss 1.42226279
Trained batch 2023 batch loss 1.32494807 epoch total loss 1.42221475
Trained batch 2024 batch loss 1.33516026 epoch total loss 1.42217171
Trained batch 2025 batch loss 1.22081089 epoch total loss 1.42207229
Trained batch 2026 batch loss 1.09556806 epoch total loss 1.421911
Trained batch 2027 batch loss 1.33027852 epoch total loss 1.42186582
Trained batch 2028 batch loss 1.28130639 epoch total loss 1.42179656
Trained batch 2029 batch loss 1.14291978 epoch total loss 1.42165899
Trained batch 2030 batch loss 1.14437914 epoch total loss 1.42152238
Trained batch 2031 batch loss 1.2944541 epoch total loss 1.42145979
Trained batch 2032 batch loss 1.29153073 epoch total loss 1.4213959
Trained batch 2033 batch loss 1.34376621 epoch total loss 1.42135763
Trained batch 2034 batch loss 1.24663401 epoch total loss 1.42127168
Trained batch 2035 batch loss 1.18296707 epoch total loss 1.42115462
Trained batch 2036 batch loss 1.190871 epoch total loss 1.42104149
Trained batch 2037 batch loss 1.12499142 epoch total loss 1.42089617
Trained batch 2038 batch loss 1.22808814 epoch total loss 1.42080152
Trained batch 2039 batch loss 1.24424815 epoch total loss 1.42071486
Trained batch 2040 batch loss 1.37287474 epoch total loss 1.42069137
Trained batch 2041 batch loss 1.41061115 epoch total loss 1.42068648
Trained batch 2042 batch loss 1.18142772 epoch total loss 1.4205693
Trained batch 2043 batch loss 1.14897501 epoch total loss 1.42043638
Trained batch 2044 batch loss 1.12095642 epoch total loss 1.42028975
Trained batch 2045 batch loss 1.39498806 epoch total loss 1.42027736
Trained batch 2046 batch loss 1.31748724 epoch total loss 1.42022717
Trained batch 2047 batch loss 1.23756289 epoch total loss 1.42013788
Trained batch 2048 batch loss 1.42485273 epoch total loss 1.42014015
Trained batch 2049 batch loss 1.20271277 epoch total loss 1.42003405
Trained batch 2050 batch loss 1.26963043 epoch total loss 1.41996062
Trained batch 2051 batch loss 1.55431163 epoch total loss 1.42002606
Trained batch 2052 batch loss 1.55185604 epoch total loss 1.4200902
Trained batch 2053 batch loss 1.60435808 epoch total loss 1.42018
Trained batch 2054 batch loss 1.19107723 epoch total loss 1.42006838
Trained batch 2055 batch loss 1.42159057 epoch total loss 1.42006922
Trained batch 2056 batch loss 1.28324127 epoch total loss 1.42000258
Trained batch 2057 batch loss 1.14402103 epoch total loss 1.41986847
Trained batch 2058 batch loss 1.11539221 epoch total loss 1.41972053
Trained batch 2059 batch loss 1.37327266 epoch total loss 1.419698
Trained batch 2060 batch loss 1.19542384 epoch total loss 1.41958904
Trained batch 2061 batch loss 1.39637899 epoch total loss 1.41957784
Trained batch 2062 batch loss 1.4918611 epoch total loss 1.419613
Trained batch 2063 batch loss 1.43611169 epoch total loss 1.41962087
Trained batch 2064 batch loss 1.11523128 epoch total loss 1.41947341
Trained batch 2065 batch loss 1.43387437 epoch total loss 1.41948044
Trained batch 2066 batch loss 1.38361907 epoch total loss 1.41946304
Trained batch 2067 batch loss 1.48549271 epoch total loss 1.41949499
Trained batch 2068 batch loss 1.14304137 epoch total loss 1.41936135
Trained batch 2069 batch loss 1.35677624 epoch total loss 1.41933107
Trained batch 2070 batch loss 1.20894504 epoch total loss 1.41922939
Trained batch 2071 batch loss 1.3552047 epoch total loss 1.41919851
Trained batch 2072 batch loss 1.33277023 epoch total loss 1.41915679
Trained batch 2073 batch loss 1.2861042 epoch total loss 1.41909266
Trained batch 2074 batch loss 1.4121542 epoch total loss 1.41908932
Trained batch 2075 batch loss 1.39514494 epoch total loss 1.41907775
Trained batch 2076 batch loss 1.27054286 epoch total loss 1.41900623
Trained batch 2077 batch loss 1.54105246 epoch total loss 1.419065
Trained batch 2078 batch loss 1.57641554 epoch total loss 1.4191407
Trained batch 2079 batch loss 1.46748257 epoch total loss 1.41916394
Trained batch 2080 batch loss 1.36003518 epoch total loss 1.41913557
Trained batch 2081 batch loss 1.27483082 epoch total loss 1.41906631
Trained batch 2082 batch loss 1.49325871 epoch total loss 1.41910183
Trained batch 2083 batch loss 1.3315804 epoch total loss 1.41905987
Trained batch 2084 batch loss 1.21968091 epoch total loss 1.41896415
Trained batch 2085 batch loss 1.36876106 epoch total loss 1.41894007
Trained batch 2086 batch loss 1.23894775 epoch total loss 1.41885376
Trained batch 2087 batch loss 1.31477082 epoch total loss 1.41880393
Trained batch 2088 batch loss 1.3208456 epoch total loss 1.41875696
Trained batch 2089 batch loss 1.29194021 epoch total loss 1.41869628
Trained batch 2090 batch loss 1.21980107 epoch total loss 1.41860104
Trained batch 2091 batch loss 1.17850852 epoch total loss 1.41848624
Trained batch 2092 batch loss 1.29453611 epoch total loss 1.41842687
Trained batch 2093 batch loss 1.165115 epoch total loss 1.41830587
Trained batch 2094 batch loss 1.37245655 epoch total loss 1.41828406
Trained batch 2095 batch loss 1.34769046 epoch total loss 1.41825032
Trained batch 2096 batch loss 1.26516891 epoch total loss 1.41817725
Trained batch 2097 batch loss 1.36866045 epoch total loss 1.41815364
Trained batch 2098 batch loss 1.28645682 epoch total loss 1.41809082
Trained batch 2099 batch loss 1.25864673 epoch total loss 1.41801476
Trained batch 2100 batch loss 1.40943098 epoch total loss 1.41801071
Trained batch 2101 batch loss 1.15958762 epoch total loss 1.41788781
Trained batch 2102 batch loss 1.28504157 epoch total loss 1.41782463
Trained batch 2103 batch loss 1.21649039 epoch total loss 1.4177289
Trained batch 2104 batch loss 1.22297251 epoch total loss 1.41763628
Trained batch 2105 batch loss 1.37972319 epoch total loss 1.41761827
Trained batch 2106 batch loss 1.4971199 epoch total loss 1.41765594
Trained batch 2107 batch loss 1.344769 epoch total loss 1.41762137
Trained batch 2108 batch loss 1.43133974 epoch total loss 1.41762793
Trained batch 2109 batch loss 1.43926382 epoch total loss 1.41763818
Trained batch 2110 batch loss 1.32424903 epoch total loss 1.41759384
Trained batch 2111 batch loss 1.5383426 epoch total loss 1.41765106
Trained batch 2112 batch loss 1.42029357 epoch total loss 1.41765237
Trained batch 2113 batch loss 1.37484407 epoch total loss 1.4176321
Trained batch 2114 batch loss 1.32717848 epoch total loss 1.41758931
Trained batch 2115 batch loss 1.41915298 epoch total loss 1.41759
Trained batch 2116 batch loss 1.38842416 epoch total loss 1.41757619
Trained batch 2117 batch loss 1.40848553 epoch total loss 1.4175719
Trained batch 2118 batch loss 1.48103952 epoch total loss 1.41760182
Trained batch 2119 batch loss 1.40568984 epoch total loss 1.41759622
Trained batch 2120 batch loss 1.36455965 epoch total loss 1.41757119
Trained batch 2121 batch loss 1.29468238 epoch total loss 1.41751325
Trained batch 2122 batch loss 1.31970537 epoch total loss 1.41746724
Trained batch 2123 batch loss 1.32135987 epoch total loss 1.41742194
Trained batch 2124 batch loss 1.31044698 epoch total loss 1.41737163
Trained batch 2125 batch loss 1.33918214 epoch total loss 1.41733479
Trained batch 2126 batch loss 1.30959678 epoch total loss 1.41728413
Trained batch 2127 batch loss 1.37818623 epoch total loss 1.41726565
Trained batch 2128 batch loss 1.38450062 epoch total loss 1.41725028
Trained batch 2129 batch loss 1.40973687 epoch total loss 1.41724682
Trained batch 2130 batch loss 0.982733548 epoch total loss 1.41704273
Trained batch 2131 batch loss 1.11126614 epoch total loss 1.41689932
Trained batch 2132 batch loss 1.17184472 epoch total loss 1.41678441
Trained batch 2133 batch loss 1.09198272 epoch total loss 1.41663206
Trained batch 2134 batch loss 1.19891918 epoch total loss 1.41653013
Trained batch 2135 batch loss 1.30351591 epoch total loss 1.4164772
Trained batch 2136 batch loss 1.20942688 epoch total loss 1.41638029
Trained batch 2137 batch loss 1.13846326 epoch total loss 1.41625011
Trained batch 2138 batch loss 1.25181341 epoch total loss 1.41617322
Trained batch 2139 batch loss 1.49628615 epoch total loss 1.41621065
Trained batch 2140 batch loss 1.23833108 epoch total loss 1.41612756
Trained batch 2141 batch loss 1.28730774 epoch total loss 1.41606736
Trained batch 2142 batch loss 1.22494686 epoch total loss 1.41597807
Trained batch 2143 batch loss 1.5488 epoch total loss 1.41604006
Trained batch 2144 batch loss 1.3060205 epoch total loss 1.4159888
Trained batch 2145 batch loss 1.49097848 epoch total loss 1.41602373
Trained batch 2146 batch loss 1.60971427 epoch total loss 1.41611397
Trained batch 2147 batch loss 1.46134889 epoch total loss 1.41613507
Trained batch 2148 batch loss 1.41908157 epoch total loss 1.4161365
Trained batch 2149 batch loss 1.3221451 epoch total loss 1.41609275
Trained batch 2150 batch loss 1.06327176 epoch total loss 1.4159286
Trained batch 2151 batch loss 1.42941856 epoch total loss 1.41593492
Trained batch 2152 batch loss 1.25449371 epoch total loss 1.41585982
Trained batch 2153 batch loss 1.19515765 epoch total loss 1.4157573
Trained batch 2154 batch loss 1.32760763 epoch total loss 1.41571641
Trained batch 2155 batch loss 1.22835088 epoch total loss 1.41562939
Trained batch 2156 batch loss 1.36503243 epoch total loss 1.4156059
Trained batch 2157 batch loss 1.20114827 epoch total loss 1.41550648
Trained batch 2158 batch loss 1.30652177 epoch total loss 1.41545606
Trained batch 2159 batch loss 1.2909745 epoch total loss 1.41539848
Trained batch 2160 batch loss 1.39906549 epoch total loss 1.41539097
Trained batch 2161 batch loss 1.40583587 epoch total loss 1.41538644
Trained batch 2162 batch loss 1.33482122 epoch total loss 1.41534913
Trained batch 2163 batch loss 1.40891039 epoch total loss 1.41534615
Trained batch 2164 batch loss 1.4001025 epoch total loss 1.41533911
Trained batch 2165 batch loss 1.14178658 epoch total loss 1.41521287
Trained batch 2166 batch loss 1.04695582 epoch total loss 1.41504276
Trained batch 2167 batch loss 0.945046663 epoch total loss 1.41482592
Trained batch 2168 batch loss 1.19281232 epoch total loss 1.41472352
Trained batch 2169 batch loss 1.2831037 epoch total loss 1.41466284
Trained batch 2170 batch loss 1.2380712 epoch total loss 1.41458154
Trained batch 2171 batch loss 1.51836991 epoch total loss 1.41462922
Trained batch 2172 batch loss 1.47617269 epoch total loss 1.41465759
Trained batch 2173 batch loss 1.52041721 epoch total loss 1.41470623
Trained batch 2174 batch loss 1.35629857 epoch total loss 1.41467941
Trained batch 2175 batch loss 1.40777946 epoch total loss 1.41467619
Trained batch 2176 batch loss 1.22502053 epoch total loss 1.41458905
Trained batch 2177 batch loss 1.18912125 epoch total loss 1.41448545
Trained batch 2178 batch loss 1.14363384 epoch total loss 1.41436112
Trained batch 2179 batch loss 1.28317308 epoch total loss 1.41430092
Trained batch 2180 batch loss 1.29885864 epoch total loss 1.41424799
Trained batch 2181 batch loss 1.21330667 epoch total loss 1.41415584
Trained batch 2182 batch loss 1.32429552 epoch total loss 1.41411459
Trained batch 2183 batch loss 1.32579374 epoch total loss 1.41407418
Trained batch 2184 batch loss 1.38780022 epoch total loss 1.41406202
Trained batch 2185 batch loss 1.30133557 epoch total loss 1.41401041
Trained batch 2186 batch loss 1.28933203 epoch total loss 1.41395342
Trained batch 2187 batch loss 1.45967329 epoch total loss 1.41397429
Trained batch 2188 batch loss 1.31774795 epoch total loss 1.4139303
Trained batch 2189 batch loss 1.42775083 epoch total loss 1.41393661
Trained batch 2190 batch loss 1.30657959 epoch total loss 1.41388762
Trained batch 2191 batch loss 1.23046947 epoch total loss 1.41380382
Trained batch 2192 batch loss 1.31054986 epoch total loss 1.41375673
Trained batch 2193 batch loss 1.34972548 epoch total loss 1.41372752
Trained batch 2194 batch loss 1.44544101 epoch total loss 1.41374207
Trained batch 2195 batch loss 1.40568018 epoch total loss 1.41373837
Trained batch 2196 batch loss 1.20755243 epoch total loss 1.41364443
Trained batch 2197 batch loss 1.2849561 epoch total loss 1.4135859
Trained batch 2198 batch loss 1.43697953 epoch total loss 1.41359651
Trained batch 2199 batch loss 1.23934734 epoch total loss 1.41351724
Trained batch 2200 batch loss 1.23139262 epoch total loss 1.41343451
Trained batch 2201 batch loss 1.32354903 epoch total loss 1.41339362
Trained batch 2202 batch loss 1.43881392 epoch total loss 1.41340518
Trained batch 2203 batch loss 1.47272098 epoch total loss 1.413432
Trained batch 2204 batch loss 1.48215413 epoch total loss 1.41346323
Trained batch 2205 batch loss 1.4888835 epoch total loss 1.41349733
Trained batch 2206 batch loss 1.38669181 epoch total loss 1.41348529
Trained batch 2207 batch loss 1.39619112 epoch total loss 1.41347742
Trained batch 2208 batch loss 1.27392101 epoch total loss 1.41341424
Trained batch 2209 batch loss 1.50263488 epoch total loss 1.41345465
Trained batch 2210 batch loss 1.57738853 epoch total loss 1.4135288
Trained batch 2211 batch loss 1.53861952 epoch total loss 1.41358542
Trained batch 2212 batch loss 1.34121418 epoch total loss 1.41355264
Trained batch 2213 batch loss 1.41547298 epoch total loss 1.4135536
Trained batch 2214 batch loss 1.28149867 epoch total loss 1.41349399
Trained batch 2215 batch loss 1.38832176 epoch total loss 1.41348267
Trained batch 2216 batch loss 1.43605721 epoch total loss 1.4134928
Trained batch 2217 batch loss 1.31290185 epoch total loss 1.4134475
Trained batch 2218 batch loss 1.23140836 epoch total loss 1.41336536
Trained batch 2219 batch loss 1.52194357 epoch total loss 1.41341436
Trained batch 2220 batch loss 1.28398561 epoch total loss 1.41335607
Trained batch 2221 batch loss 1.43255138 epoch total loss 1.41336465
Trained batch 2222 batch loss 1.12799621 epoch total loss 1.41323626
Trained batch 2223 batch loss 1.19426298 epoch total loss 1.41313779
Trained batch 2224 batch loss 1.26312184 epoch total loss 1.41307032
Trained batch 2225 batch loss 1.1377039 epoch total loss 1.41294658
Trained batch 2226 batch loss 1.20199275 epoch total loss 1.41285181
Trained batch 2227 batch loss 1.47763109 epoch total loss 1.41288078
Trained batch 2228 batch loss 1.2832613 epoch total loss 1.4128226
Trained batch 2229 batch loss 1.50569773 epoch total loss 1.41286421
Trained batch 2230 batch loss 1.2492553 epoch total loss 1.41279089
Trained batch 2231 batch loss 1.20191336 epoch total loss 1.41269636
Trained batch 2232 batch loss 1.2615751 epoch total loss 1.41262865
Trained batch 2233 batch loss 1.37065876 epoch total loss 1.41260982
Trained batch 2234 batch loss 1.29488051 epoch total loss 1.41255713
Trained batch 2235 batch loss 1.28917634 epoch total loss 1.41250181
Trained batch 2236 batch loss 1.31855 epoch total loss 1.41245985
Trained batch 2237 batch loss 1.38915074 epoch total loss 1.41244948
Trained batch 2238 batch loss 1.08571911 epoch total loss 1.41230345
Trained batch 2239 batch loss 1.27067208 epoch total loss 1.41224027
Trained batch 2240 batch loss 1.46230352 epoch total loss 1.41226256
Trained batch 2241 batch loss 1.33403099 epoch total loss 1.41222763
Trained batch 2242 batch loss 1.17810178 epoch total loss 1.41212332
Trained batch 2243 batch loss 1.41116786 epoch total loss 1.41212285
Trained batch 2244 batch loss 1.40851855 epoch total loss 1.41212118
Trained batch 2245 batch loss 1.31524682 epoch total loss 1.41207802
Trained batch 2246 batch loss 1.33295202 epoch total loss 1.41204286
Trained batch 2247 batch loss 1.21575975 epoch total loss 1.41195548
Trained batch 2248 batch loss 1.35110819 epoch total loss 1.41192842
Trained batch 2249 batch loss 1.34732723 epoch total loss 1.41189981
Trained batch 2250 batch loss 1.29314482 epoch total loss 1.411847
Trained batch 2251 batch loss 1.31655145 epoch total loss 1.41180468
Trained batch 2252 batch loss 1.22637212 epoch total loss 1.4117223
Trained batch 2253 batch loss 1.24559116 epoch total loss 1.41164863
Trained batch 2254 batch loss 1.36493647 epoch total loss 1.41162789
Trained batch 2255 batch loss 1.27345896 epoch total loss 1.41156662
Trained batch 2256 batch loss 1.46967554 epoch total loss 1.41159236
Trained batch 2257 batch loss 1.38771963 epoch total loss 1.41158187
Trained batch 2258 batch loss 1.48896921 epoch total loss 1.41161609
Trained batch 2259 batch loss 1.53701615 epoch total loss 1.41167164
Trained batch 2260 batch loss 1.58924937 epoch total loss 1.41175032
Trained batch 2261 batch loss 1.42354107 epoch total loss 1.41175556
Trained batch 2262 batch loss 1.46575737 epoch total loss 1.4117794
Trained batch 2263 batch loss 1.27927649 epoch total loss 1.41172087
Trained batch 2264 batch loss 1.16242599 epoch total loss 1.41161072
Trained batch 2265 batch loss 1.44436514 epoch total loss 1.41162515
Trained batch 2266 batch loss 1.35740376 epoch total loss 1.41160131
Trained batch 2267 batch loss 1.46627712 epoch total loss 1.41162539
Trained batch 2268 batch loss 1.5313046 epoch total loss 1.41167819
Trained batch 2269 batch loss 1.26078296 epoch total loss 1.41161168
Trained batch 2270 batch loss 1.10880053 epoch total loss 1.41147828
Trained batch 2271 batch loss 1.03080261 epoch total loss 1.41131067
Trained batch 2272 batch loss 1.10532141 epoch total loss 1.41117585
Trained batch 2273 batch loss 1.29910254 epoch total loss 1.41112661
Trained batch 2274 batch loss 1.09945989 epoch total loss 1.41098952
Trained batch 2275 batch loss 1.37214398 epoch total loss 1.41097236
Trained batch 2276 batch loss 1.32743835 epoch total loss 1.41093564
Trained batch 2277 batch loss 1.30574846 epoch total loss 1.41088939
Trained batch 2278 batch loss 1.37530541 epoch total loss 1.41087377
Trained batch 2279 batch loss 1.3136301 epoch total loss 1.41083109
Trained batch 2280 batch loss 1.30099416 epoch total loss 1.41078293
Trained batch 2281 batch loss 1.35693121 epoch total loss 1.41075933
Trained batch 2282 batch loss 1.3263731 epoch total loss 1.41072237
Trained batch 2283 batch loss 1.27903104 epoch total loss 1.4106648
Trained batch 2284 batch loss 1.12373543 epoch total loss 1.41053915
Trained batch 2285 batch loss 1.1315639 epoch total loss 1.41041708
Trained batch 2286 batch loss 1.16980827 epoch total loss 1.41031182
Trained batch 2287 batch loss 1.13754511 epoch total loss 1.41019249
Trained batch 2288 batch loss 1.12333393 epoch total loss 1.4100672
Trained batch 2289 batch loss 1.06610131 epoch total loss 1.40991688
Trained batch 2290 batch loss 1.19363809 epoch total loss 1.40982246
Trained batch 2291 batch loss 1.04519486 epoch total loss 1.40966332
Trained batch 2292 batch loss 1.07867646 epoch total loss 1.40951884
Trained batch 2293 batch loss 0.922967076 epoch total loss 1.40930665
Trained batch 2294 batch loss 1.08503568 epoch total loss 1.40916526
Trained batch 2295 batch loss 1.41926324 epoch total loss 1.40916955
Trained batch 2296 batch loss 1.02630925 epoch total loss 1.4090029
Trained batch 2297 batch loss 1.31725955 epoch total loss 1.40896285
Trained batch 2298 batch loss 1.28572035 epoch total loss 1.4089092
Trained batch 2299 batch loss 1.31628823 epoch total loss 1.40886891
Trained batch 2300 batch loss 1.30199695 epoch total loss 1.40882254
Trained batch 2301 batch loss 1.36890244 epoch total loss 1.40880513
Trained batch 2302 batch loss 1.12959898 epoch total loss 1.4086839
Trained batch 2303 batch loss 1.07836819 epoch total loss 1.40854049
Trained batch 2304 batch loss 0.962164521 epoch total loss 1.40834665
Trained batch 2305 batch loss 1.24452877 epoch total loss 1.40827572
Trained batch 2306 batch loss 1.06960702 epoch total loss 1.40812886
Trained batch 2307 batch loss 1.23555803 epoch total loss 1.40805399
Trained batch 2308 batch loss 1.14686012 epoch total loss 1.40794086
Trained batch 2309 batch loss 1.33924675 epoch total loss 1.40791118
Trained batch 2310 batch loss 1.26716447 epoch total loss 1.40785027
Trained batch 2311 batch loss 1.43874955 epoch total loss 1.40786362
Trained batch 2312 batch loss 1.22449195 epoch total loss 1.40778434
Trained batch 2313 batch loss 1.21823728 epoch total loss 1.40770245
Trained batch 2314 batch loss 1.18883348 epoch total loss 1.40760779
Trained batch 2315 batch loss 1.45856 epoch total loss 1.40762973
Trained batch 2316 batch loss 1.35714817 epoch total loss 1.40760791
Trained batch 2317 batch loss 1.36991191 epoch total loss 1.4075917
Trained batch 2318 batch loss 1.34216857 epoch total loss 1.40756345
Trained batch 2319 batch loss 1.31133735 epoch total loss 1.40752196
Trained batch 2320 batch loss 1.41934395 epoch total loss 1.40752709
Trained batch 2321 batch loss 1.1118505 epoch total loss 1.40739965
Trained batch 2322 batch loss 1.23256874 epoch total loss 1.40732443
Trained batch 2323 batch loss 1.10742962 epoch total loss 1.40719533
Trained batch 2324 batch loss 1.35841262 epoch total loss 1.40717435
Trained batch 2325 batch loss 1.1991508 epoch total loss 1.40708494
Trained batch 2326 batch loss 1.04279733 epoch total loss 1.4069283
Trained batch 2327 batch loss 1.09083223 epoch total loss 1.4067924
Trained batch 2328 batch loss 1.42220592 epoch total loss 1.40679896
Trained batch 2329 batch loss 1.41861534 epoch total loss 1.40680408
Trained batch 2330 batch loss 1.26949072 epoch total loss 1.4067452
Trained batch 2331 batch loss 1.42000639 epoch total loss 1.4067508
Trained batch 2332 batch loss 1.50881886 epoch total loss 1.40679455
Trained batch 2333 batch loss 1.32290196 epoch total loss 1.40675867
Trained batch 2334 batch loss 1.51070845 epoch total loss 1.40680325
Trained batch 2335 batch loss 1.28603768 epoch total loss 1.40675151
Trained batch 2336 batch loss 1.36844957 epoch total loss 1.40673518
Trained batch 2337 batch loss 1.40653729 epoch total loss 1.40673506
Trained batch 2338 batch loss 1.28778315 epoch total loss 1.40668416
Trained batch 2339 batch loss 1.40215206 epoch total loss 1.40668225
Trained batch 2340 batch loss 1.42851973 epoch total loss 1.40669155
Trained batch 2341 batch loss 1.33354151 epoch total loss 1.40666032
Trained batch 2342 batch loss 1.32846737 epoch total loss 1.40662682
Trained batch 2343 batch loss 1.19746757 epoch total loss 1.40653753
Trained batch 2344 batch loss 1.34349608 epoch total loss 1.40651071
Trained batch 2345 batch loss 1.43919277 epoch total loss 1.40652466
Trained batch 2346 batch loss 1.47215199 epoch total loss 1.40655267
Trained batch 2347 batch loss 1.10303617 epoch total loss 1.40642333
Trained batch 2348 batch loss 1.16238701 epoch total loss 1.40631938
Trained batch 2349 batch loss 1.26258481 epoch total loss 1.40625823
Trained batch 2350 batch loss 1.26265252 epoch total loss 1.40619707
Trained batch 2351 batch loss 1.2186811 epoch total loss 1.40611744
Trained batch 2352 batch loss 1.30909514 epoch total loss 1.40607607
Trained batch 2353 batch loss 1.39933944 epoch total loss 1.40607333
Trained batch 2354 batch loss 1.54056525 epoch total loss 1.40613043
Trained batch 2355 batch loss 1.39748788 epoch total loss 1.40612674
Trained batch 2356 batch loss 1.26658511 epoch total loss 1.40606749
Trained batch 2357 batch loss 1.50375867 epoch total loss 1.40610898
Trained batch 2358 batch loss 1.22158265 epoch total loss 1.40603065
Trained batch 2359 batch loss 1.20953691 epoch total loss 1.40594733
Trained batch 2360 batch loss 0.96742475 epoch total loss 1.4057616
Trained batch 2361 batch loss 1.37731457 epoch total loss 1.40574956
Trained batch 2362 batch loss 1.40208316 epoch total loss 1.40574801
Trained batch 2363 batch loss 1.13086307 epoch total loss 1.40563166
Trained batch 2364 batch loss 1.37675261 epoch total loss 1.40561938
Trained batch 2365 batch loss 1.37921643 epoch total loss 1.40560818
Trained batch 2366 batch loss 1.24009109 epoch total loss 1.4055382
Trained batch 2367 batch loss 1.32560432 epoch total loss 1.40550447
Trained batch 2368 batch loss 1.41330814 epoch total loss 1.4055078
Trained batch 2369 batch loss 1.17115974 epoch total loss 1.40540886
Trained batch 2370 batch loss 1.34583616 epoch total loss 1.40538371
Trained batch 2371 batch loss 1.21184444 epoch total loss 1.40530217
Trained batch 2372 batch loss 1.50165021 epoch total loss 1.40534282
Trained batch 2373 batch loss 1.43135262 epoch total loss 1.40535378
Trained batch 2374 batch loss 1.43404293 epoch total loss 1.40536594
Trained batch 2375 batch loss 1.34723496 epoch total loss 1.40534139
Trained batch 2376 batch loss 1.56347895 epoch total loss 1.40540791
Trained batch 2377 batch loss 1.57676983 epoch total loss 1.40548
Trained batch 2378 batch loss 1.45538914 epoch total loss 1.40550089
Trained batch 2379 batch loss 1.14127672 epoch total loss 1.4053899
Trained batch 2380 batch loss 1.00778079 epoch total loss 1.40522289
Trained batch 2381 batch loss 0.997962058 epoch total loss 1.40505183
Trained batch 2382 batch loss 0.98689878 epoch total loss 1.40487623
Trained batch 2383 batch loss 1.20370317 epoch total loss 1.40479183
Trained batch 2384 batch loss 1.0096941 epoch total loss 1.40462613
Trained batch 2385 batch loss 1.04305935 epoch total loss 1.4044745
Trained batch 2386 batch loss 0.892218649 epoch total loss 1.4042598
Trained batch 2387 batch loss 1.08716083 epoch total loss 1.404127
Trained batch 2388 batch loss 1.29588699 epoch total loss 1.4040817
Trained batch 2389 batch loss 1.45201874 epoch total loss 1.40410173
Trained batch 2390 batch loss 1.34530962 epoch total loss 1.40407705
Trained batch 2391 batch loss 0.94361341 epoch total loss 1.40388441
Trained batch 2392 batch loss 1.34828508 epoch total loss 1.40386128
Trained batch 2393 batch loss 1.42229319 epoch total loss 1.40386903
Trained batch 2394 batch loss 1.26186323 epoch total loss 1.40380967
Trained batch 2395 batch loss 1.20955932 epoch total loss 1.4037286
Trained batch 2396 batch loss 1.20563483 epoch total loss 1.40364587
Trained batch 2397 batch loss 1.17278957 epoch total loss 1.40354955
Trained batch 2398 batch loss 1.19199061 epoch total loss 1.40346134
Trained batch 2399 batch loss 1.2450006 epoch total loss 1.4033953
Trained batch 2400 batch loss 1.10678065 epoch total loss 1.40327168
Trained batch 2401 batch loss 1.3551861 epoch total loss 1.40325165
Trained batch 2402 batch loss 1.23397183 epoch total loss 1.4031812
Trained batch 2403 batch loss 1.31847894 epoch total loss 1.40314591
Trained batch 2404 batch loss 1.44939566 epoch total loss 1.4031651
Trained batch 2405 batch loss 1.40597343 epoch total loss 1.40316629
Trained batch 2406 batch loss 1.3035655 epoch total loss 1.40312493
Trained batch 2407 batch loss 1.29957926 epoch total loss 1.40308189
Trained batch 2408 batch loss 1.1906358 epoch total loss 1.40299368
Trained batch 2409 batch loss 1.4248544 epoch total loss 1.40300274
Trained batch 2410 batch loss 1.35551262 epoch total loss 1.40298295
Trained batch 2411 batch loss 1.29813063 epoch total loss 1.40293944
Trained batch 2412 batch loss 1.41591144 epoch total loss 1.40294492
Trained batch 2413 batch loss 1.51699555 epoch total loss 1.40299225
Trained batch 2414 batch loss 1.52642596 epoch total loss 1.40304327
Trained batch 2415 batch loss 1.21340537 epoch total loss 1.40296471
Trained batch 2416 batch loss 1.27479219 epoch total loss 1.40291178
Trained batch 2417 batch loss 1.29332435 epoch total loss 1.40286636
Trained batch 2418 batch loss 1.38524318 epoch total loss 1.40285909
Trained batch 2419 batch loss 1.26236773 epoch total loss 1.40280104
Trained batch 2420 batch loss 1.30695 epoch total loss 1.40276146
Trained batch 2421 batch loss 1.64473534 epoch total loss 1.40286136
Trained batch 2422 batch loss 1.52552855 epoch total loss 1.40291202
Trained batch 2423 batch loss 1.59642315 epoch total loss 1.40299189
Trained batch 2424 batch loss 1.62844992 epoch total loss 1.40308499
Trained batch 2425 batch loss 1.57043362 epoch total loss 1.4031539
Trained batch 2426 batch loss 1.4251579 epoch total loss 1.40316296
Trained batch 2427 batch loss 1.52849972 epoch total loss 1.40321457
Trained batch 2428 batch loss 1.58812451 epoch total loss 1.40329075
Trained batch 2429 batch loss 1.46493745 epoch total loss 1.40331614
Trained batch 2430 batch loss 1.38067889 epoch total loss 1.40330672
Trained batch 2431 batch loss 1.33380532 epoch total loss 1.40327811
Trained batch 2432 batch loss 1.22466207 epoch total loss 1.40320468
Trained batch 2433 batch loss 1.28442693 epoch total loss 1.4031558
Trained batch 2434 batch loss 1.42137825 epoch total loss 1.40316331
Trained batch 2435 batch loss 1.26360905 epoch total loss 1.40310609
Trained batch 2436 batch loss 1.29629374 epoch total loss 1.40306222
Trained batch 2437 batch loss 1.42857873 epoch total loss 1.40307271
Trained batch 2438 batch loss 1.1940279 epoch total loss 1.402987
Trained batch 2439 batch loss 1.24109232 epoch total loss 1.4029206
Trained batch 2440 batch loss 1.10611892 epoch total loss 1.40279901
Trained batch 2441 batch loss 1.20155454 epoch total loss 1.40271664
Trained batch 2442 batch loss 1.37372077 epoch total loss 1.40270472
Trained batch 2443 batch loss 1.45836246 epoch total loss 1.40272748
Trained batch 2444 batch loss 1.43591571 epoch total loss 1.40274107
Trained batch 2445 batch loss 1.43330264 epoch total loss 1.40275359
Trained batch 2446 batch loss 1.45216441 epoch total loss 1.40277386
Trained batch 2447 batch loss 1.16131306 epoch total loss 1.40267515
Trained batch 2448 batch loss 1.44635689 epoch total loss 1.40269303
Trained batch 2449 batch loss 1.29828286 epoch total loss 1.40265036
Trained batch 2450 batch loss 1.07207537 epoch total loss 1.40251541
Trained batch 2451 batch loss 1.21795309 epoch total loss 1.40244019
Trained batch 2452 batch loss 1.23573148 epoch total loss 1.40237224
Trained batch 2453 batch loss 1.42258537 epoch total loss 1.40238047
Trained batch 2454 batch loss 1.19715452 epoch total loss 1.4022969
Trained batch 2455 batch loss 1.17303753 epoch total loss 1.40220356
Trained batch 2456 batch loss 1.21336913 epoch total loss 1.40212667
Trained batch 2457 batch loss 1.16967344 epoch total loss 1.40203202
Trained batch 2458 batch loss 1.33372653 epoch total loss 1.40200424
Trained batch 2459 batch loss 1.21870387 epoch total loss 1.40192974
Trained batch 2460 batch loss 1.32283592 epoch total loss 1.40189755
Trained batch 2461 batch loss 1.34932792 epoch total loss 1.40187621
Trained batch 2462 batch loss 1.41229284 epoch total loss 1.4018805
Trained batch 2463 batch loss 1.38926816 epoch total loss 1.40187526
Trained batch 2464 batch loss 1.30427754 epoch total loss 1.40183568
Trained batch 2465 batch loss 1.09870267 epoch total loss 1.40171266
Trained batch 2466 batch loss 1.31178486 epoch total loss 1.40167618
Trained batch 2467 batch loss 1.41449988 epoch total loss 1.40168142
Trained batch 2468 batch loss 1.30790687 epoch total loss 1.4016434
Trained batch 2469 batch loss 1.53872073 epoch total loss 1.40169895
Trained batch 2470 batch loss 1.5820694 epoch total loss 1.4017719
Trained batch 2471 batch loss 1.42276096 epoch total loss 1.40178049
Trained batch 2472 batch loss 1.39496017 epoch total loss 1.40177774
Trained batch 2473 batch loss 1.45875669 epoch total loss 1.40180075
Trained batch 2474 batch loss 1.28972316 epoch total loss 1.40175545
Trained batch 2475 batch loss 1.3840034 epoch total loss 1.4017483
Trained batch 2476 batch loss 1.27764428 epoch total loss 1.40169823
Trained batch 2477 batch loss 1.13045669 epoch total loss 1.40158868
Trained batch 2478 batch loss 1.15438294 epoch total loss 1.4014889
Trained batch 2479 batch loss 1.18574643 epoch total loss 1.40140188
Trained batch 2480 batch loss 1.14744854 epoch total loss 1.40129948
Trained batch 2481 batch loss 1.30778384 epoch total loss 1.40126181
Trained batch 2482 batch loss 1.36824846 epoch total loss 1.40124846
Trained batch 2483 batch loss 1.37398601 epoch total loss 1.40123749
Trained batch 2484 batch loss 1.46250463 epoch total loss 1.40126216
Trained batch 2485 batch loss 1.41207433 epoch total loss 1.40126646
Trained batch 2486 batch loss 1.29470897 epoch total loss 1.40122366
Trained batch 2487 batch loss 1.29255283 epoch total loss 1.40117991
Trained batch 2488 batch loss 1.3932941 epoch total loss 1.40117669
Trained batch 2489 batch loss 1.39836025 epoch total loss 1.40117562
Trained batch 2490 batch loss 1.30023 epoch total loss 1.40113509
Trained batch 2491 batch loss 1.25188637 epoch total loss 1.40107524
Trained batch 2492 batch loss 1.30974913 epoch total loss 1.40103865
Trained batch 2493 batch loss 1.36908376 epoch total loss 1.40102577
Trained batch 2494 batch loss 1.40362322 epoch total loss 1.40102684
Trained batch 2495 batch loss 1.34047222 epoch total loss 1.40100265
Trained batch 2496 batch loss 1.4425199 epoch total loss 1.40101922
Trained batch 2497 batch loss 1.39544582 epoch total loss 1.40101707
Trained batch 2498 batch loss 1.37981081 epoch total loss 1.40100861
Trained batch 2499 batch loss 1.36571622 epoch total loss 1.40099454
Trained batch 2500 batch loss 1.18315375 epoch total loss 1.40090728
Trained batch 2501 batch loss 1.21620548 epoch total loss 1.40083349
Trained batch 2502 batch loss 1.08635139 epoch total loss 1.40070784
Trained batch 2503 batch loss 1.23141432 epoch total loss 1.40064025
Trained batch 2504 batch loss 1.25590217 epoch total loss 1.40058243
Trained batch 2505 batch loss 1.22239399 epoch total loss 1.40051126
Trained batch 2506 batch loss 1.29366302 epoch total loss 1.40046871
Trained batch 2507 batch loss 1.17137218 epoch total loss 1.40037727
Trained batch 2508 batch loss 1.14706254 epoch total loss 1.4002763
Trained batch 2509 batch loss 1.22646976 epoch total loss 1.40020704
Trained batch 2510 batch loss 1.39108181 epoch total loss 1.40020335
Trained batch 2511 batch loss 1.25628281 epoch total loss 1.40014613
Trained batch 2512 batch loss 1.47173429 epoch total loss 1.40017462
Trained batch 2513 batch loss 1.28795862 epoch total loss 1.40012991
Trained batch 2514 batch loss 1.03959632 epoch total loss 1.39998639
Trained batch 2515 batch loss 1.07650018 epoch total loss 1.39985776
Trained batch 2516 batch loss 1.24059153 epoch total loss 1.39979446
Trained batch 2517 batch loss 1.2716018 epoch total loss 1.39974344
Trained batch 2518 batch loss 1.29433262 epoch total loss 1.3997016
Trained batch 2519 batch loss 1.30675185 epoch total loss 1.39966464
Trained batch 2520 batch loss 1.36352015 epoch total loss 1.39965034
Trained batch 2521 batch loss 1.37772858 epoch total loss 1.39964163
Trained batch 2522 batch loss 1.41176367 epoch total loss 1.39964652
Trained batch 2523 batch loss 1.30573833 epoch total loss 1.39960921
Trained batch 2524 batch loss 1.34931159 epoch total loss 1.3995893
Trained batch 2525 batch loss 1.26962614 epoch total loss 1.3995378
Trained batch 2526 batch loss 1.35739088 epoch total loss 1.39952111
Trained batch 2527 batch loss 1.32710505 epoch total loss 1.3994925
Trained batch 2528 batch loss 1.24792767 epoch total loss 1.39943266
Trained batch 2529 batch loss 1.28929031 epoch total loss 1.39938903
Trained batch 2530 batch loss 1.13894272 epoch total loss 1.39928615
Trained batch 2531 batch loss 1.24581861 epoch total loss 1.39922547
Trained batch 2532 batch loss 1.16669607 epoch total loss 1.39913368
Trained batch 2533 batch loss 1.25554562 epoch total loss 1.39907706
Trained batch 2534 batch loss 1.17752564 epoch total loss 1.39898956
Trained batch 2535 batch loss 1.07585156 epoch total loss 1.39886212
Trained batch 2536 batch loss 1.16141772 epoch total loss 1.39876842
Trained batch 2537 batch loss 1.15750849 epoch total loss 1.39867342
Trained batch 2538 batch loss 1.19641018 epoch total loss 1.39859366
Trained batch 2539 batch loss 1.19952071 epoch total loss 1.39851522
Trained batch 2540 batch loss 1.19201875 epoch total loss 1.39843392
Trained batch 2541 batch loss 1.17199624 epoch total loss 1.39834476
Trained batch 2542 batch loss 1.42149925 epoch total loss 1.39835382
Trained batch 2543 batch loss 1.51283097 epoch total loss 1.39839888
Trained batch 2544 batch loss 1.32204914 epoch total loss 1.39836884
Trained batch 2545 batch loss 1.28900385 epoch total loss 1.39832592
Trained batch 2546 batch loss 1.3005445 epoch total loss 1.39828753
Trained batch 2547 batch loss 1.43601334 epoch total loss 1.39830232
Trained batch 2548 batch loss 1.27981722 epoch total loss 1.39825583
Trained batch 2549 batch loss 1.40153408 epoch total loss 1.39825714
Trained batch 2550 batch loss 1.57358682 epoch total loss 1.39832592
Trained batch 2551 batch loss 1.44471526 epoch total loss 1.39834404
Trained batch 2552 batch loss 1.55446815 epoch total loss 1.39840531
Trained batch 2553 batch loss 1.72297716 epoch total loss 1.39853239
Trained batch 2554 batch loss 1.67699671 epoch total loss 1.39864135
Trained batch 2555 batch loss 1.51298738 epoch total loss 1.39868617
Trained batch 2556 batch loss 1.47452784 epoch total loss 1.39871585
Trained batch 2557 batch loss 1.55809796 epoch total loss 1.3987782
Trained batch 2558 batch loss 1.37417006 epoch total loss 1.39876854
Trained batch 2559 batch loss 1.43264568 epoch total loss 1.39878178
Trained batch 2560 batch loss 1.43135035 epoch total loss 1.39879453
Trained batch 2561 batch loss 1.28823614 epoch total loss 1.39875138
Trained batch 2562 batch loss 1.34815454 epoch total loss 1.39873171
Trained batch 2563 batch loss 1.44997346 epoch total loss 1.39875162
Trained batch 2564 batch loss 1.37635636 epoch total loss 1.39874291
Trained batch 2565 batch loss 1.31101751 epoch total loss 1.39870882
Trained batch 2566 batch loss 1.45498252 epoch total loss 1.39873075
Trained batch 2567 batch loss 1.40043378 epoch total loss 1.39873135
Trained batch 2568 batch loss 1.22550702 epoch total loss 1.398664
Trained batch 2569 batch loss 1.32573915 epoch total loss 1.39863551
Trained batch 2570 batch loss 1.29100204 epoch total loss 1.39859366
Trained batch 2571 batch loss 1.19454122 epoch total loss 1.39851427
Trained batch 2572 batch loss 1.21986556 epoch total loss 1.39844489
Trained batch 2573 batch loss 1.18347502 epoch total loss 1.39836144
Trained batch 2574 batch loss 1.19006431 epoch total loss 1.3982805
Trained batch 2575 batch loss 1.27935898 epoch total loss 1.39823437
Trained batch 2576 batch loss 1.36647916 epoch total loss 1.39822197
Trained batch 2577 batch loss 1.39053512 epoch total loss 1.39821899
Trained batch 2578 batch loss 1.13661385 epoch total loss 1.39811754
Trained batch 2579 batch loss 1.36696959 epoch total loss 1.3981055
Trained batch 2580 batch loss 1.48552132 epoch total loss 1.39813948
Trained batch 2581 batch loss 1.50174844 epoch total loss 1.39817953
Trained batch 2582 batch loss 1.30235696 epoch total loss 1.39814234
Trained batch 2583 batch loss 1.3336978 epoch total loss 1.39811742
Trained batch 2584 batch loss 1.29238582 epoch total loss 1.39807653
Trained batch 2585 batch loss 1.28043509 epoch total loss 1.39803112
Trained batch 2586 batch loss 1.42408562 epoch total loss 1.39804113
Trained batch 2587 batch loss 1.30211687 epoch total loss 1.39800406
Trained batch 2588 batch loss 1.28738642 epoch total loss 1.39796126
Trained batch 2589 batch loss 1.26761079 epoch total loss 1.39791095
Trained batch 2590 batch loss 1.43856716 epoch total loss 1.39792657
Trained batch 2591 batch loss 1.31002247 epoch total loss 1.39789271
Trained batch 2592 batch loss 1.42942 epoch total loss 1.39790487
Trained batch 2593 batch loss 1.32844031 epoch total loss 1.39787805
Trained batch 2594 batch loss 1.22424126 epoch total loss 1.39781106
Trained batch 2595 batch loss 1.30409348 epoch total loss 1.39777493
Trained batch 2596 batch loss 1.29780459 epoch total loss 1.39773643
Trained batch 2597 batch loss 1.39027607 epoch total loss 1.39773369
Trained batch 2598 batch loss 1.26504362 epoch total loss 1.39768267
Trained batch 2599 batch loss 1.28764582 epoch total loss 1.39764023
Trained batch 2600 batch loss 1.3118602 epoch total loss 1.39760721
Trained batch 2601 batch loss 1.17320323 epoch total loss 1.3975209
Trained batch 2602 batch loss 1.38864207 epoch total loss 1.39751756
Trained batch 2603 batch loss 1.43157196 epoch total loss 1.39753067
Trained batch 2604 batch loss 1.56245363 epoch total loss 1.39759398
Trained batch 2605 batch loss 1.65543163 epoch total loss 1.39769304
Trained batch 2606 batch loss 1.37117767 epoch total loss 1.39768279
Trained batch 2607 batch loss 1.42734206 epoch total loss 1.39769411
Trained batch 2608 batch loss 1.16280258 epoch total loss 1.39760411
Trained batch 2609 batch loss 1.32157493 epoch total loss 1.3975749
Trained batch 2610 batch loss 1.26383412 epoch total loss 1.39752376
Trained batch 2611 batch loss 1.23666239 epoch total loss 1.39746201
Trained batch 2612 batch loss 1.2050761 epoch total loss 1.39738846
Trained batch 2613 batch loss 1.44255471 epoch total loss 1.39740574
Trained batch 2614 batch loss 1.31669307 epoch total loss 1.39737487
Trained batch 2615 batch loss 1.43786812 epoch total loss 1.39739037
Trained batch 2616 batch loss 1.36062121 epoch total loss 1.3973763
Trained batch 2617 batch loss 1.10704577 epoch total loss 1.39726532
Trained batch 2618 batch loss 1.64515746 epoch total loss 1.39736009
Trained batch 2619 batch loss 1.24892342 epoch total loss 1.39730334
Trained batch 2620 batch loss 1.2580409 epoch total loss 1.39725029
Trained batch 2621 batch loss 1.26902521 epoch total loss 1.3972013
Trained batch 2622 batch loss 1.18476415 epoch total loss 1.39712036
Trained batch 2623 batch loss 1.32979965 epoch total loss 1.39709473
Trained batch 2624 batch loss 1.05243349 epoch total loss 1.39696336
Trained batch 2625 batch loss 1.14664483 epoch total loss 1.39686799
Trained batch 2626 batch loss 1.27119458 epoch total loss 1.39682019
Trained batch 2627 batch loss 1.00369573 epoch total loss 1.39667058
Trained batch 2628 batch loss 1.26755428 epoch total loss 1.39662135
Trained batch 2629 batch loss 1.30796671 epoch total loss 1.39658761
Trained batch 2630 batch loss 1.34957683 epoch total loss 1.39656973
Trained batch 2631 batch loss 1.33261776 epoch total loss 1.39654541
Trained batch 2632 batch loss 1.34558642 epoch total loss 1.3965261
Trained batch 2633 batch loss 1.1667732 epoch total loss 1.39643884
Trained batch 2634 batch loss 1.34531713 epoch total loss 1.39641941
Trained batch 2635 batch loss 1.25268853 epoch total loss 1.39636481
Trained batch 2636 batch loss 1.36887765 epoch total loss 1.39635444
Trained batch 2637 batch loss 1.419101 epoch total loss 1.39636314
Trained batch 2638 batch loss 1.21270275 epoch total loss 1.3962934
Trained batch 2639 batch loss 1.28116632 epoch total loss 1.39624989
Trained batch 2640 batch loss 1.45327508 epoch total loss 1.39627147
Trained batch 2641 batch loss 1.32344198 epoch total loss 1.39624393
Trained batch 2642 batch loss 1.0983814 epoch total loss 1.39613116
Trained batch 2643 batch loss 1.10715246 epoch total loss 1.39602184
Trained batch 2644 batch loss 1.29458666 epoch total loss 1.39598358
Trained batch 2645 batch loss 1.2606976 epoch total loss 1.39593244
Trained batch 2646 batch loss 1.40343297 epoch total loss 1.39593518
Trained batch 2647 batch loss 1.41686702 epoch total loss 1.39594305
Trained batch 2648 batch loss 1.2749052 epoch total loss 1.39589739
Trained batch 2649 batch loss 1.30613708 epoch total loss 1.39586341
Trained batch 2650 batch loss 1.43331468 epoch total loss 1.3958776
Trained batch 2651 batch loss 1.31475902 epoch total loss 1.39584696
Trained batch 2652 batch loss 1.16802311 epoch total loss 1.39576101
Trained batch 2653 batch loss 1.23206139 epoch total loss 1.39569938
Trained batch 2654 batch loss 1.20898235 epoch total loss 1.39562905
Trained batch 2655 batch loss 1.12549686 epoch total loss 1.39552736
Trained batch 2656 batch loss 1.19501376 epoch total loss 1.39545178
Trained batch 2657 batch loss 1.12101352 epoch total loss 1.39534855
Trained batch 2658 batch loss 1.3422637 epoch total loss 1.39532864
Trained batch 2659 batch loss 1.30379772 epoch total loss 1.39529419
Trained batch 2660 batch loss 1.3375771 epoch total loss 1.39527249
Trained batch 2661 batch loss 1.34655762 epoch total loss 1.39525425
Trained batch 2662 batch loss 1.38907099 epoch total loss 1.39525199
Trained batch 2663 batch loss 1.5833391 epoch total loss 1.39532256
Trained batch 2664 batch loss 1.48316503 epoch total loss 1.39535546
Trained batch 2665 batch loss 1.3733325 epoch total loss 1.39534724
Trained batch 2666 batch loss 1.28597188 epoch total loss 1.39530611
Trained batch 2667 batch loss 1.32188535 epoch total loss 1.39527857
Trained batch 2668 batch loss 1.31240308 epoch total loss 1.39524758
Trained batch 2669 batch loss 1.31045485 epoch total loss 1.39521587
Trained batch 2670 batch loss 1.31509197 epoch total loss 1.39518583
Trained batch 2671 batch loss 1.33767509 epoch total loss 1.39516437
Trained batch 2672 batch loss 1.35743225 epoch total loss 1.39515018
Trained batch 2673 batch loss 1.47014308 epoch total loss 1.39517832
Trained batch 2674 batch loss 1.34701824 epoch total loss 1.3951602
Trained batch 2675 batch loss 1.39169955 epoch total loss 1.39515889
Trained batch 2676 batch loss 1.34898973 epoch total loss 1.3951416
Trained batch 2677 batch loss 1.19061947 epoch total loss 1.39506519
Trained batch 2678 batch loss 1.23002243 epoch total loss 1.39500356
Trained batch 2679 batch loss 1.24763584 epoch total loss 1.39494848
Trained batch 2680 batch loss 1.04106605 epoch total loss 1.39481652
Trained batch 2681 batch loss 0.915714681 epoch total loss 1.39463782
Trained batch 2682 batch loss 1.20636892 epoch total loss 1.39456761
Trained batch 2683 batch loss 1.11114907 epoch total loss 1.39446187
Trained batch 2684 batch loss 1.53705084 epoch total loss 1.39451504
Trained batch 2685 batch loss 1.40880036 epoch total loss 1.39452028
Trained batch 2686 batch loss 1.53581309 epoch total loss 1.39457297
Trained batch 2687 batch loss 1.55062723 epoch total loss 1.39463103
Trained batch 2688 batch loss 1.55444348 epoch total loss 1.39469051
Trained batch 2689 batch loss 1.39896452 epoch total loss 1.39469206
Trained batch 2690 batch loss 1.37297928 epoch total loss 1.39468396
Trained batch 2691 batch loss 1.35431528 epoch total loss 1.39466894
Trained batch 2692 batch loss 1.11133099 epoch total loss 1.39456367
Trained batch 2693 batch loss 1.26400149 epoch total loss 1.39451516
Trained batch 2694 batch loss 1.33857191 epoch total loss 1.39449441
Trained batch 2695 batch loss 1.42711425 epoch total loss 1.39450657
Trained batch 2696 batch loss 1.22937751 epoch total loss 1.3944453
Trained batch 2697 batch loss 1.21142352 epoch total loss 1.39437747
Trained batch 2698 batch loss 1.12641096 epoch total loss 1.39427817
Trained batch 2699 batch loss 1.35036731 epoch total loss 1.39426184
Trained batch 2700 batch loss 1.31900704 epoch total loss 1.39423406
Trained batch 2701 batch loss 1.33883595 epoch total loss 1.39421356
Trained batch 2702 batch loss 1.082829 epoch total loss 1.39409828
Trained batch 2703 batch loss 1.22760487 epoch total loss 1.39403665
Trained batch 2704 batch loss 1.32410049 epoch total loss 1.39401078
Trained batch 2705 batch loss 1.20946419 epoch total loss 1.39394259
Trained batch 2706 batch loss 1.34060574 epoch total loss 1.39392292
Trained batch 2707 batch loss 1.3024025 epoch total loss 1.39388907
Trained batch 2708 batch loss 1.15115273 epoch total loss 1.39379942
Trained batch 2709 batch loss 1.23248386 epoch total loss 1.39373994
Trained batch 2710 batch loss 1.2472192 epoch total loss 1.39368582
Trained batch 2711 batch loss 1.17482841 epoch total loss 1.39360511
Trained batch 2712 batch loss 1.28191924 epoch total loss 1.39356399
Trained batch 2713 batch loss 1.3025347 epoch total loss 1.39353037
Trained batch 2714 batch loss 1.39123571 epoch total loss 1.39352953
Trained batch 2715 batch loss 1.44394696 epoch total loss 1.39354813
Trained batch 2716 batch loss 1.37251818 epoch total loss 1.39354038
Trained batch 2717 batch loss 1.22829866 epoch total loss 1.39347959
Trained batch 2718 batch loss 1.17486286 epoch total loss 1.39339912
Trained batch 2719 batch loss 1.25186133 epoch total loss 1.39334714
Trained batch 2720 batch loss 1.14039898 epoch total loss 1.39325404
Trained batch 2721 batch loss 1.05744171 epoch total loss 1.39313066
Trained batch 2722 batch loss 1.20625699 epoch total loss 1.393062
Trained batch 2723 batch loss 1.10833681 epoch total loss 1.39295745
Trained batch 2724 batch loss 1.27535975 epoch total loss 1.3929143
Trained batch 2725 batch loss 1.16910338 epoch total loss 1.39283216
Trained batch 2726 batch loss 1.04241705 epoch total loss 1.39270365
Trained batch 2727 batch loss 1.13297617 epoch total loss 1.39260852
Trained batch 2728 batch loss 0.953895 epoch total loss 1.39244759
Trained batch 2729 batch loss 0.88713181 epoch total loss 1.39226246
Trained batch 2730 batch loss 1.01484191 epoch total loss 1.3921243
Trained batch 2731 batch loss 0.868604839 epoch total loss 1.39193261
Trained batch 2732 batch loss 1.05215192 epoch total loss 1.39180827
Trained batch 2733 batch loss 1.39541829 epoch total loss 1.39180958
Trained batch 2734 batch loss 1.52843595 epoch total loss 1.39185953
Trained batch 2735 batch loss 1.36599696 epoch total loss 1.39185011
Trained batch 2736 batch loss 1.40787363 epoch total loss 1.39185596
Trained batch 2737 batch loss 1.52233553 epoch total loss 1.39190364
Trained batch 2738 batch loss 1.59082735 epoch total loss 1.39197624
Trained batch 2739 batch loss 1.31957769 epoch total loss 1.39194977
Trained batch 2740 batch loss 1.28960478 epoch total loss 1.39191246
Trained batch 2741 batch loss 1.22198224 epoch total loss 1.39185047
Trained batch 2742 batch loss 1.38129497 epoch total loss 1.39184654
Trained batch 2743 batch loss 1.3144933 epoch total loss 1.3918184
Trained batch 2744 batch loss 1.46557593 epoch total loss 1.39184523
Trained batch 2745 batch loss 1.20097148 epoch total loss 1.39177573
Trained batch 2746 batch loss 1.22469592 epoch total loss 1.39171481
Trained batch 2747 batch loss 1.36324739 epoch total loss 1.39170444
Trained batch 2748 batch loss 1.35168314 epoch total loss 1.3916899
Trained batch 2749 batch loss 1.21807718 epoch total loss 1.39162672
Trained batch 2750 batch loss 1.33985662 epoch total loss 1.39160788
Trained batch 2751 batch loss 1.33308768 epoch total loss 1.39158654
Trained batch 2752 batch loss 1.32734787 epoch total loss 1.3915633
Trained batch 2753 batch loss 1.20495892 epoch total loss 1.39149547
Trained batch 2754 batch loss 1.29693401 epoch total loss 1.39146113
Trained batch 2755 batch loss 1.19687653 epoch total loss 1.39139044
Trained batch 2756 batch loss 1.17714357 epoch total loss 1.39131272
Trained batch 2757 batch loss 1.12063169 epoch total loss 1.39121461
Trained batch 2758 batch loss 1.05869341 epoch total loss 1.39109397
Trained batch 2759 batch loss 1.08915591 epoch total loss 1.39098454
Trained batch 2760 batch loss 1.22632217 epoch total loss 1.39092481
Trained batch 2761 batch loss 1.21032465 epoch total loss 1.39085937
Trained batch 2762 batch loss 1.18091679 epoch total loss 1.39078343
Trained batch 2763 batch loss 1.22363222 epoch total loss 1.39072287
Trained batch 2764 batch loss 1.29716551 epoch total loss 1.39068902
Trained batch 2765 batch loss 1.20356536 epoch total loss 1.39062142
Trained batch 2766 batch loss 1.42063522 epoch total loss 1.39063227
Trained batch 2767 batch loss 1.11049843 epoch total loss 1.39053106
Trained batch 2768 batch loss 1.1917038 epoch total loss 1.39045918
Trained batch 2769 batch loss 1.50972486 epoch total loss 1.39050221
Trained batch 2770 batch loss 1.25127578 epoch total loss 1.39045203
Trained batch 2771 batch loss 1.29120743 epoch total loss 1.39041615
Trained batch 2772 batch loss 1.11449456 epoch total loss 1.39031661
Trained batch 2773 batch loss 1.42706728 epoch total loss 1.39032984
Trained batch 2774 batch loss 1.2444756 epoch total loss 1.39027727
Trained batch 2775 batch loss 1.35454202 epoch total loss 1.39026439
Trained batch 2776 batch loss 1.23125529 epoch total loss 1.39020705
Trained batch 2777 batch loss 1.31262016 epoch total loss 1.39017904
Trained batch 2778 batch loss 1.48505378 epoch total loss 1.39021325
Trained batch 2779 batch loss 1.51183915 epoch total loss 1.390257
Trained batch 2780 batch loss 1.18401742 epoch total loss 1.39018285
Trained batch 2781 batch loss 1.21096468 epoch total loss 1.39011836
Trained batch 2782 batch loss 1.32442069 epoch total loss 1.39009476
Trained batch 2783 batch loss 1.3796792 epoch total loss 1.39009106
Trained batch 2784 batch loss 1.47423184 epoch total loss 1.39012122
Trained batch 2785 batch loss 1.34899569 epoch total loss 1.39010644
Trained batch 2786 batch loss 1.3506881 epoch total loss 1.39009225
Trained batch 2787 batch loss 1.62996519 epoch total loss 1.3901782
Trained batch 2788 batch loss 1.47410727 epoch total loss 1.39020836
Trained batch 2789 batch loss 1.6628499 epoch total loss 1.39030612
Trained batch 2790 batch loss 1.20210326 epoch total loss 1.39023864
Trained batch 2791 batch loss 1.45882583 epoch total loss 1.3902632
Trained batch 2792 batch loss 1.41477489 epoch total loss 1.39027202
Trained batch 2793 batch loss 1.4056139 epoch total loss 1.3902775
Trained batch 2794 batch loss 1.29712915 epoch total loss 1.39024413
Trained batch 2795 batch loss 1.3241601 epoch total loss 1.39022052
Trained batch 2796 batch loss 1.28401279 epoch total loss 1.3901825
Trained batch 2797 batch loss 1.44937134 epoch total loss 1.39020371
Trained batch 2798 batch loss 1.48842216 epoch total loss 1.39023876
Trained batch 2799 batch loss 1.48010933 epoch total loss 1.39027095
Trained batch 2800 batch loss 1.54304552 epoch total loss 1.39032555
Trained batch 2801 batch loss 1.42254066 epoch total loss 1.39033699
Trained batch 2802 batch loss 1.28131044 epoch total loss 1.39029813
Trained batch 2803 batch loss 1.29255009 epoch total loss 1.3902632
Trained batch 2804 batch loss 1.27502775 epoch total loss 1.39022219
Trained batch 2805 batch loss 1.36030853 epoch total loss 1.39021146
Trained batch 2806 batch loss 1.32613492 epoch total loss 1.39018869
Trained batch 2807 batch loss 1.12272143 epoch total loss 1.39009345
Trained batch 2808 batch loss 1.31117094 epoch total loss 1.39006531
Trained batch 2809 batch loss 1.22267628 epoch total loss 1.39000571
Trained batch 2810 batch loss 1.35196829 epoch total loss 1.38999224
Trained batch 2811 batch loss 1.22355485 epoch total loss 1.38993311
Trained batch 2812 batch loss 1.37373567 epoch total loss 1.38992727
Trained batch 2813 batch loss 1.36135244 epoch total loss 1.38991714
Trained batch 2814 batch loss 1.46346426 epoch total loss 1.38994324
Trained batch 2815 batch loss 1.44253576 epoch total loss 1.38996196
Trained batch 2816 batch loss 1.51949823 epoch total loss 1.39000797
Trained batch 2817 batch loss 1.71612573 epoch total loss 1.39012372
Trained batch 2818 batch loss 1.48130071 epoch total loss 1.39015603
Trained batch 2819 batch loss 1.52677763 epoch total loss 1.39020455
Trained batch 2820 batch loss 1.52779722 epoch total loss 1.39025331
Trained batch 2821 batch loss 1.36748052 epoch total loss 1.3902452
Trained batch 2822 batch loss 1.45038545 epoch total loss 1.39026654
Trained batch 2823 batch loss 1.23894095 epoch total loss 1.39021301
Trained batch 2824 batch loss 1.29596424 epoch total loss 1.39017963
Trained batch 2825 batch loss 1.2941637 epoch total loss 1.39014566
Trained batch 2826 batch loss 1.25084054 epoch total loss 1.39009631
Trained batch 2827 batch loss 1.31770849 epoch total loss 1.39007068
Trained batch 2828 batch loss 1.29697084 epoch total loss 1.39003766
Trained batch 2829 batch loss 1.20381367 epoch total loss 1.38997185
Trained batch 2830 batch loss 1.20448351 epoch total loss 1.38990641
Trained batch 2831 batch loss 1.47243667 epoch total loss 1.38993549
Trained batch 2832 batch loss 1.51678109 epoch total loss 1.38998032
Trained batch 2833 batch loss 1.43697608 epoch total loss 1.38999689
Trained batch 2834 batch loss 1.38161147 epoch total loss 1.38999403
Trained batch 2835 batch loss 1.39858735 epoch total loss 1.38999701
Trained batch 2836 batch loss 1.44057846 epoch total loss 1.39001489
Trained batch 2837 batch loss 1.26151812 epoch total loss 1.38996959
Trained batch 2838 batch loss 1.03497553 epoch total loss 1.38984454
Trained batch 2839 batch loss 1.37452161 epoch total loss 1.38983905
Trained batch 2840 batch loss 1.30527747 epoch total loss 1.38980925
Trained batch 2841 batch loss 1.38059294 epoch total loss 1.38980603
Trained batch 2842 batch loss 1.46050334 epoch total loss 1.38983095
Trained batch 2843 batch loss 1.65661883 epoch total loss 1.38992476
Trained batch 2844 batch loss 1.41510427 epoch total loss 1.38993359
Trained batch 2845 batch loss 1.4057492 epoch total loss 1.38993919
Trained batch 2846 batch loss 1.41176367 epoch total loss 1.38994694
Trained batch 2847 batch loss 1.37731814 epoch total loss 1.38994241
Trained batch 2848 batch loss 1.43723822 epoch total loss 1.38995898
Trained batch 2849 batch loss 1.56899869 epoch total loss 1.39002192
Trained batch 2850 batch loss 1.48123085 epoch total loss 1.39005387
Trained batch 2851 batch loss 1.30735135 epoch total loss 1.3900249
Trained batch 2852 batch loss 1.22222614 epoch total loss 1.38996601
Trained batch 2853 batch loss 1.59369016 epoch total loss 1.39003742
Trained batch 2854 batch loss 1.37804306 epoch total loss 1.39003325
Trained batch 2855 batch loss 1.04056382 epoch total loss 1.38991082
Trained batch 2856 batch loss 1.24478424 epoch total loss 1.38986
Trained batch 2857 batch loss 1.03558135 epoch total loss 1.38973606
Trained batch 2858 batch loss 1.16542852 epoch total loss 1.38965762
Trained batch 2859 batch loss 1.10513806 epoch total loss 1.38955808
Trained batch 2860 batch loss 1.27723241 epoch total loss 1.38951886
Trained batch 2861 batch loss 1.1531496 epoch total loss 1.38943624
Trained batch 2862 batch loss 1.1251477 epoch total loss 1.38934386
Trained batch 2863 batch loss 1.20463359 epoch total loss 1.38927937
Trained batch 2864 batch loss 1.32244468 epoch total loss 1.389256
Trained batch 2865 batch loss 1.27972662 epoch total loss 1.38921785
Trained batch 2866 batch loss 1.36105824 epoch total loss 1.38920808
Trained batch 2867 batch loss 1.30679464 epoch total loss 1.38917935
Trained batch 2868 batch loss 1.31272411 epoch total loss 1.38915265
Trained batch 2869 batch loss 1.36055493 epoch total loss 1.38914275
Trained batch 2870 batch loss 1.34088767 epoch total loss 1.38912582
Trained batch 2871 batch loss 1.31540358 epoch total loss 1.38910019
Trained batch 2872 batch loss 1.38854289 epoch total loss 1.3891
Trained batch 2873 batch loss 1.51258302 epoch total loss 1.38914299
Trained batch 2874 batch loss 1.36469734 epoch total loss 1.38913453
Trained batch 2875 batch loss 1.27391481 epoch total loss 1.38909447
Trained batch 2876 batch loss 1.40233803 epoch total loss 1.389099
Trained batch 2877 batch loss 1.23575878 epoch total loss 1.38904572
Trained batch 2878 batch loss 1.29885066 epoch total loss 1.38901436
Trained batch 2879 batch loss 1.23738694 epoch total loss 1.38896167
Trained batch 2880 batch loss 1.2244699 epoch total loss 1.38890457
Trained batch 2881 batch loss 1.26042664 epoch total loss 1.38886
Trained batch 2882 batch loss 1.23229599 epoch total loss 1.38880563
Trained batch 2883 batch loss 1.19803619 epoch total loss 1.38873947
Trained batch 2884 batch loss 1.28824222 epoch total loss 1.38870466
Trained batch 2885 batch loss 1.42103934 epoch total loss 1.38871586
Trained batch 2886 batch loss 1.35979033 epoch total loss 1.38870585
Trained batch 2887 batch loss 1.28788209 epoch total loss 1.38867092
Trained batch 2888 batch loss 1.22709882 epoch total loss 1.38861501
Trained batch 2889 batch loss 1.24474525 epoch total loss 1.38856518
Trained batch 2890 batch loss 1.22768784 epoch total loss 1.38850951
Trained batch 2891 batch loss 1.18929505 epoch total loss 1.38844061
Trained batch 2892 batch loss 1.10913479 epoch total loss 1.38834405
Trained batch 2893 batch loss 1.06558585 epoch total loss 1.38823247
Trained batch 2894 batch loss 1.1383121 epoch total loss 1.38814616
Trained batch 2895 batch loss 1.37940598 epoch total loss 1.38814306
Trained batch 2896 batch loss 1.35299587 epoch total loss 1.38813102
Trained batch 2897 batch loss 1.46060252 epoch total loss 1.38815606
Trained batch 2898 batch loss 1.47777534 epoch total loss 1.38818693
Trained batch 2899 batch loss 1.366552 epoch total loss 1.38817942
Trained batch 2900 batch loss 1.24053717 epoch total loss 1.38812852
Trained batch 2901 batch loss 1.13404799 epoch total loss 1.3880409
Trained batch 2902 batch loss 1.28487265 epoch total loss 1.38800538
Trained batch 2903 batch loss 1.38880014 epoch total loss 1.38800573
Trained batch 2904 batch loss 1.01184464 epoch total loss 1.38787627
Trained batch 2905 batch loss 1.21574616 epoch total loss 1.38781703
Trained batch 2906 batch loss 1.13040686 epoch total loss 1.38772845
Trained batch 2907 batch loss 1.41799247 epoch total loss 1.38773882
Trained batch 2908 batch loss 1.45307279 epoch total loss 1.38776135
Trained batch 2909 batch loss 1.21722269 epoch total loss 1.3877027
Trained batch 2910 batch loss 1.32156444 epoch total loss 1.38767993
Trained batch 2911 batch loss 1.22632182 epoch total loss 1.3876245
Trained batch 2912 batch loss 1.31961179 epoch total loss 1.38760114
Trained batch 2913 batch loss 1.14171195 epoch total loss 1.38751674
Trained batch 2914 batch loss 1.31644797 epoch total loss 1.3874923
Trained batch 2915 batch loss 1.23748493 epoch total loss 1.38744092
Trained batch 2916 batch loss 1.23687065 epoch total loss 1.38738918
Trained batch 2917 batch loss 1.11583185 epoch total loss 1.38729608
Trained batch 2918 batch loss 1.24160647 epoch total loss 1.38724613
Trained batch 2919 batch loss 1.21740818 epoch total loss 1.38718808
Trained batch 2920 batch loss 1.34824014 epoch total loss 1.38717473
Trained batch 2921 batch loss 1.32328606 epoch total loss 1.38715279
Trained batch 2922 batch loss 1.22772837 epoch total loss 1.38709819
Trained batch 2923 batch loss 1.04886341 epoch total loss 1.38698256
Trained batch 2924 batch loss 1.50225079 epoch total loss 1.3870219
Trained batch 2925 batch loss 1.31756496 epoch total loss 1.38699818
Trained batch 2926 batch loss 1.26665401 epoch total loss 1.38695705
Trained batch 2927 batch loss 1.19676828 epoch total loss 1.38689208
Trained batch 2928 batch loss 1.3222549 epoch total loss 1.38687
Trained batch 2929 batch loss 1.31159878 epoch total loss 1.38684428
Trained batch 2930 batch loss 1.19482422 epoch total loss 1.38677871
Trained batch 2931 batch loss 1.10629463 epoch total loss 1.38668299
Trained batch 2932 batch loss 1.19118071 epoch total loss 1.38661635
Trained batch 2933 batch loss 1.35454702 epoch total loss 1.38660538
Trained batch 2934 batch loss 1.17504013 epoch total loss 1.38653326
Trained batch 2935 batch loss 1.37181783 epoch total loss 1.38652825
Trained batch 2936 batch loss 1.18681061 epoch total loss 1.38646019
Trained batch 2937 batch loss 1.3977865 epoch total loss 1.386464
Trained batch 2938 batch loss 1.2810849 epoch total loss 1.38642812
Trained batch 2939 batch loss 1.21765435 epoch total loss 1.38637078
Trained batch 2940 batch loss 1.23782063 epoch total loss 1.38632023
Trained batch 2941 batch loss 1.10067713 epoch total loss 1.38622308
Trained batch 2942 batch loss 1.26933694 epoch total loss 1.38618338
Trained batch 2943 batch loss 1.4626931 epoch total loss 1.38620937
Trained batch 2944 batch loss 1.39000487 epoch total loss 1.38621056
Trained batch 2945 batch loss 1.28973269 epoch total loss 1.38617778
Trained batch 2946 batch loss 1.40229869 epoch total loss 1.38618326
Trained batch 2947 batch loss 1.30122578 epoch total loss 1.38615453
Trained batch 2948 batch loss 1.34650528 epoch total loss 1.38614106
Trained batch 2949 batch loss 1.49095726 epoch total loss 1.38617659
Trained batch 2950 batch loss 1.11289561 epoch total loss 1.38608396
Trained batch 2951 batch loss 1.36650264 epoch total loss 1.38607728
Trained batch 2952 batch loss 1.27954614 epoch total loss 1.38604116
Trained batch 2953 batch loss 1.34169936 epoch total loss 1.38602614
Trained batch 2954 batch loss 1.23438835 epoch total loss 1.38597488
Trained batch 2955 batch loss 1.22591507 epoch total loss 1.38592064
Trained batch 2956 batch loss 1.4818933 epoch total loss 1.38595307
Trained batch 2957 batch loss 1.26626325 epoch total loss 1.38591266
Trained batch 2958 batch loss 1.32339025 epoch total loss 1.38589144
Trained batch 2959 batch loss 1.25928831 epoch total loss 1.38584864
Trained batch 2960 batch loss 1.32019472 epoch total loss 1.38582647
Trained batch 2961 batch loss 1.43064344 epoch total loss 1.38584161
Trained batch 2962 batch loss 1.45686281 epoch total loss 1.38586569
Trained batch 2963 batch loss 1.4279536 epoch total loss 1.38587976
Trained batch 2964 batch loss 1.30980611 epoch total loss 1.38585401
Trained batch 2965 batch loss 1.26149154 epoch total loss 1.38581216
Trained batch 2966 batch loss 1.24098372 epoch total loss 1.38576341
Trained batch 2967 batch loss 1.35215902 epoch total loss 1.38575208
Trained batch 2968 batch loss 1.1647594 epoch total loss 1.38567758
Trained batch 2969 batch loss 1.38870525 epoch total loss 1.38567853
Trained batch 2970 batch loss 1.35866284 epoch total loss 1.38566947
Trained batch 2971 batch loss 1.15038276 epoch total loss 1.38559031
Trained batch 2972 batch loss 1.16510153 epoch total loss 1.38551617
Trained batch 2973 batch loss 1.33395195 epoch total loss 1.38549876
Trained batch 2974 batch loss 1.43870139 epoch total loss 1.38551664
Trained batch 2975 batch loss 1.42702866 epoch total loss 1.38553059
Trained batch 2976 batch loss 1.49259806 epoch total loss 1.38556659
Trained batch 2977 batch loss 1.38206911 epoch total loss 1.3855654
Trained batch 2978 batch loss 1.24529326 epoch total loss 1.38551819
Trained batch 2979 batch loss 1.26327133 epoch total loss 1.38547719
Trained batch 2980 batch loss 1.3811183 epoch total loss 1.38547575
Trained batch 2981 batch loss 1.31265783 epoch total loss 1.38545132
Trained batch 2982 batch loss 1.21913099 epoch total loss 1.38539553
Trained batch 2983 batch loss 1.36082911 epoch total loss 1.3853873
Trained batch 2984 batch loss 1.31932616 epoch total loss 1.38536513
Trained batch 2985 batch loss 1.41722393 epoch total loss 1.38537574
Trained batch 2986 batch loss 1.35179889 epoch total loss 1.38536441
Trained batch 2987 batch loss 1.17728758 epoch total loss 1.3852948
Trained batch 2988 batch loss 1.30378723 epoch total loss 1.3852675
Trained batch 2989 batch loss 1.21845317 epoch total loss 1.38521159
Trained batch 2990 batch loss 1.12071609 epoch total loss 1.38512313
Trained batch 2991 batch loss 1.27226603 epoch total loss 1.38508546
Trained batch 2992 batch loss 1.18114233 epoch total loss 1.38501728
Trained batch 2993 batch loss 1.26308572 epoch total loss 1.38497663
Trained batch 2994 batch loss 1.40888619 epoch total loss 1.38498449
Trained batch 2995 batch loss 1.28776133 epoch total loss 1.38495195
Trained batch 2996 batch loss 1.40580046 epoch total loss 1.38495886
Trained batch 2997 batch loss 1.53622484 epoch total loss 1.38500941
Trained batch 2998 batch loss 1.43877792 epoch total loss 1.38502741
Trained batch 2999 batch loss 1.57369268 epoch total loss 1.38509023
Trained batch 3000 batch loss 1.53057027 epoch total loss 1.38513887
Trained batch 3001 batch loss 1.26555443 epoch total loss 1.38509905
Trained batch 3002 batch loss 1.30774045 epoch total loss 1.38507318
Trained batch 3003 batch loss 1.39746594 epoch total loss 1.38507736
Trained batch 3004 batch loss 1.36087275 epoch total loss 1.38506925
Trained batch 3005 batch loss 1.22776508 epoch total loss 1.3850168
Trained batch 3006 batch loss 1.34769332 epoch total loss 1.3850044
Trained batch 3007 batch loss 1.22685289 epoch total loss 1.38495183
Trained batch 3008 batch loss 1.36022091 epoch total loss 1.38494372
Trained batch 3009 batch loss 1.34571636 epoch total loss 1.38493061
Trained batch 3010 batch loss 1.37005973 epoch total loss 1.38492572
Trained batch 3011 batch loss 1.17708445 epoch total loss 1.38485682
Trained batch 3012 batch loss 1.15569949 epoch total loss 1.38478065
Trained batch 3013 batch loss 1.14516807 epoch total loss 1.38470113
Trained batch 3014 batch loss 1.0494566 epoch total loss 1.38458979
Trained batch 3015 batch loss 1.05751419 epoch total loss 1.38448143
Trained batch 3016 batch loss 1.1118722 epoch total loss 1.38439095
Trained batch 3017 batch loss 1.04539895 epoch total loss 1.38427866
Trained batch 3018 batch loss 1.11796916 epoch total loss 1.38419044
Trained batch 3019 batch loss 1.13350463 epoch total loss 1.38410735
Trained batch 3020 batch loss 1.30421078 epoch total loss 1.38408089
Trained batch 3021 batch loss 1.3115561 epoch total loss 1.38405693
Trained batch 3022 batch loss 1.19830346 epoch total loss 1.38399541
Trained batch 3023 batch loss 1.18859673 epoch total loss 1.38393068
Trained batch 3024 batch loss 1.47980845 epoch total loss 1.38396251
Trained batch 3025 batch loss 1.33676124 epoch total loss 1.3839469
Trained batch 3026 batch loss 0.976279497 epoch total loss 1.38381219
Trained batch 3027 batch loss 1.18561816 epoch total loss 1.38374662
Trained batch 3028 batch loss 1.38127387 epoch total loss 1.38374579
Trained batch 3029 batch loss 1.61983395 epoch total loss 1.38382375
Trained batch 3030 batch loss 1.44252825 epoch total loss 1.38384306
Trained batch 3031 batch loss 1.38783693 epoch total loss 1.38384438
Trained batch 3032 batch loss 1.51083326 epoch total loss 1.38388622
Trained batch 3033 batch loss 1.26529312 epoch total loss 1.383847
Trained batch 3034 batch loss 1.29259598 epoch total loss 1.38381696
Trained batch 3035 batch loss 1.48770213 epoch total loss 1.38385117
Trained batch 3036 batch loss 1.32715392 epoch total loss 1.38383245
Trained batch 3037 batch loss 1.22264338 epoch total loss 1.38377941
Trained batch 3038 batch loss 1.43871307 epoch total loss 1.38379741
Trained batch 3039 batch loss 1.23488832 epoch total loss 1.38374841
Trained batch 3040 batch loss 1.29272842 epoch total loss 1.38371861
Trained batch 3041 batch loss 1.38144231 epoch total loss 1.38371778
Trained batch 3042 batch loss 1.19815779 epoch total loss 1.38365674
Trained batch 3043 batch loss 1.21058941 epoch total loss 1.38359988
Trained batch 3044 batch loss 1.30868351 epoch total loss 1.3835752
Trained batch 3045 batch loss 1.15263343 epoch total loss 1.3834995
Trained batch 3046 batch loss 1.24480653 epoch total loss 1.38345385
Trained batch 3047 batch loss 1.16540742 epoch total loss 1.38338232
Trained batch 3048 batch loss 1.17103541 epoch total loss 1.38331258
Trained batch 3049 batch loss 1.33362329 epoch total loss 1.38329625
Trained batch 3050 batch loss 1.10873914 epoch total loss 1.38320637
Trained batch 3051 batch loss 1.28772581 epoch total loss 1.38317502
Trained batch 3052 batch loss 1.28499055 epoch total loss 1.38314283
Trained batch 3053 batch loss 1.18926859 epoch total loss 1.38307941
Trained batch 3054 batch loss 1.11798584 epoch total loss 1.38299274
Trained batch 3055 batch loss 1.27198339 epoch total loss 1.38295639
Trained batch 3056 batch loss 1.31054819 epoch total loss 1.38293266
Trained batch 3057 batch loss 1.3328557 epoch total loss 1.38291633
Trained batch 3058 batch loss 1.17243266 epoch total loss 1.38284743
Trained batch 3059 batch loss 1.18809867 epoch total loss 1.38278377
Trained batch 3060 batch loss 1.1070559 epoch total loss 1.38269365
Trained batch 3061 batch loss 1.18185842 epoch total loss 1.38262796
Trained batch 3062 batch loss 1.05538034 epoch total loss 1.38252103
Trained batch 3063 batch loss 1.22483706 epoch total loss 1.38246942
Trained batch 3064 batch loss 1.19305253 epoch total loss 1.38240755
Trained batch 3065 batch loss 1.37066483 epoch total loss 1.38240373
Trained batch 3066 batch loss 1.25649214 epoch total loss 1.3823626
Trained batch 3067 batch loss 1.20446324 epoch total loss 1.38230467
Trained batch 3068 batch loss 1.30488658 epoch total loss 1.3822794
Trained batch 3069 batch loss 1.35719204 epoch total loss 1.38227129
Trained batch 3070 batch loss 1.27219 epoch total loss 1.38223529
Trained batch 3071 batch loss 1.20899928 epoch total loss 1.3821789
Trained batch 3072 batch loss 1.21956134 epoch total loss 1.38212597
Trained batch 3073 batch loss 1.33418179 epoch total loss 1.38211036
Trained batch 3074 batch loss 1.07558417 epoch total loss 1.3820107
Trained batch 3075 batch loss 1.17587125 epoch total loss 1.38194358
Trained batch 3076 batch loss 1.22105408 epoch total loss 1.38189137
Trained batch 3077 batch loss 1.11650741 epoch total loss 1.38180518
Trained batch 3078 batch loss 1.21671247 epoch total loss 1.38175154
Trained batch 3079 batch loss 1.19696224 epoch total loss 1.38169146
Trained batch 3080 batch loss 1.0841701 epoch total loss 1.38159478
Trained batch 3081 batch loss 1.33420706 epoch total loss 1.3815794
Trained batch 3082 batch loss 1.22815299 epoch total loss 1.38152957
Trained batch 3083 batch loss 1.39347935 epoch total loss 1.38153338
Trained batch 3084 batch loss 1.12300587 epoch total loss 1.38144958
Trained batch 3085 batch loss 1.18322563 epoch total loss 1.38138533
Trained batch 3086 batch loss 1.27371025 epoch total loss 1.38135052
Trained batch 3087 batch loss 1.05632663 epoch total loss 1.38124514
Trained batch 3088 batch loss 1.10422814 epoch total loss 1.38115537
Trained batch 3089 batch loss 1.44356048 epoch total loss 1.38117552
Trained batch 3090 batch loss 1.50534499 epoch total loss 1.38121569
Trained batch 3091 batch loss 1.51711702 epoch total loss 1.38125968
Trained batch 3092 batch loss 1.53585625 epoch total loss 1.38130963
Trained batch 3093 batch loss 1.60957336 epoch total loss 1.3813833
Trained batch 3094 batch loss 1.57114983 epoch total loss 1.38144469
Trained batch 3095 batch loss 1.42804813 epoch total loss 1.38145983
Trained batch 3096 batch loss 1.45092237 epoch total loss 1.38148224
Trained batch 3097 batch loss 1.35922766 epoch total loss 1.38147509
Trained batch 3098 batch loss 1.48692584 epoch total loss 1.38150907
Trained batch 3099 batch loss 1.20576334 epoch total loss 1.38145232
Trained batch 3100 batch loss 1.1376009 epoch total loss 1.38137364
Trained batch 3101 batch loss 1.46671319 epoch total loss 1.38140118
Trained batch 3102 batch loss 1.38840389 epoch total loss 1.38140333
Trained batch 3103 batch loss 1.44595265 epoch total loss 1.38142419
Trained batch 3104 batch loss 1.55503988 epoch total loss 1.3814801
Trained batch 3105 batch loss 1.71764779 epoch total loss 1.38158846
Trained batch 3106 batch loss 1.33213758 epoch total loss 1.38157248
Trained batch 3107 batch loss 1.49534082 epoch total loss 1.38160896
Trained batch 3108 batch loss 1.49465585 epoch total loss 1.38164532
Trained batch 3109 batch loss 1.40588331 epoch total loss 1.38165307
Trained batch 3110 batch loss 1.4434557 epoch total loss 1.38167298
Trained batch 3111 batch loss 1.3675189 epoch total loss 1.38166845
Trained batch 3112 batch loss 1.34691024 epoch total loss 1.38165724
Trained batch 3113 batch loss 1.39068925 epoch total loss 1.3816601
Trained batch 3114 batch loss 1.38295579 epoch total loss 1.38166046
Trained batch 3115 batch loss 1.35911727 epoch total loss 1.38165319
Trained batch 3116 batch loss 1.40886962 epoch total loss 1.38166189
Trained batch 3117 batch loss 1.45646465 epoch total loss 1.38168585
Trained batch 3118 batch loss 1.39212346 epoch total loss 1.38168919
Trained batch 3119 batch loss 1.12071157 epoch total loss 1.38160551
Trained batch 3120 batch loss 1.26811552 epoch total loss 1.38156915
Trained batch 3121 batch loss 1.15344369 epoch total loss 1.38149595
Trained batch 3122 batch loss 1.16917384 epoch total loss 1.38142788
Trained batch 3123 batch loss 1.23475766 epoch total loss 1.38138092
Trained batch 3124 batch loss 1.41856742 epoch total loss 1.38139284
Trained batch 3125 batch loss 1.15135884 epoch total loss 1.38131917
Trained batch 3126 batch loss 1.28849614 epoch total loss 1.3812896
Trained batch 3127 batch loss 1.28713751 epoch total loss 1.38125944
Trained batch 3128 batch loss 1.24570501 epoch total loss 1.38121605
Trained batch 3129 batch loss 1.27359164 epoch total loss 1.3811816
Trained batch 3130 batch loss 1.3671453 epoch total loss 1.38117719
Trained batch 3131 batch loss 1.16606474 epoch total loss 1.3811084
Trained batch 3132 batch loss 1.06680059 epoch total loss 1.38100815
Trained batch 3133 batch loss 1.11905074 epoch total loss 1.38092446
Trained batch 3134 batch loss 1.1501317 epoch total loss 1.38085079
Trained batch 3135 batch loss 1.08109558 epoch total loss 1.38075519
Trained batch 3136 batch loss 0.99898535 epoch total loss 1.38063347
Trained batch 3137 batch loss 1.14699852 epoch total loss 1.38055897
Trained batch 3138 batch loss 1.11957717 epoch total loss 1.38047576
Trained batch 3139 batch loss 1.04354322 epoch total loss 1.38036847
Trained batch 3140 batch loss 1.08822715 epoch total loss 1.38027549
Trained batch 3141 batch loss 1.34357715 epoch total loss 1.38026381
Trained batch 3142 batch loss 1.12571502 epoch total loss 1.38018274
Trained batch 3143 batch loss 1.41284227 epoch total loss 1.38019323
Trained batch 3144 batch loss 1.42969227 epoch total loss 1.38020897
Trained batch 3145 batch loss 1.28444731 epoch total loss 1.38017857
Trained batch 3146 batch loss 1.22915399 epoch total loss 1.38013053
Trained batch 3147 batch loss 0.986044645 epoch total loss 1.38000524
Trained batch 3148 batch loss 1.28786862 epoch total loss 1.37997603
Trained batch 3149 batch loss 1.41636181 epoch total loss 1.3799876
Trained batch 3150 batch loss 1.36086619 epoch total loss 1.37998152
Trained batch 3151 batch loss 1.29826784 epoch total loss 1.37995565
Trained batch 3152 batch loss 1.18581641 epoch total loss 1.37989414
Trained batch 3153 batch loss 1.29788601 epoch total loss 1.37986815
Trained batch 3154 batch loss 1.44408274 epoch total loss 1.37988842
Trained batch 3155 batch loss 1.25088167 epoch total loss 1.37984753
Trained batch 3156 batch loss 1.10425186 epoch total loss 1.37976027
Trained batch 3157 batch loss 1.49391937 epoch total loss 1.3797965
Trained batch 3158 batch loss 1.45457828 epoch total loss 1.37982023
Trained batch 3159 batch loss 1.41299224 epoch total loss 1.37983072
Trained batch 3160 batch loss 1.59337604 epoch total loss 1.37989831
Trained batch 3161 batch loss 1.4670558 epoch total loss 1.37992597
Trained batch 3162 batch loss 1.2889483 epoch total loss 1.37989712
Trained batch 3163 batch loss 1.1365726 epoch total loss 1.37982035
Trained batch 3164 batch loss 1.19020677 epoch total loss 1.37976038
Trained batch 3165 batch loss 1.28009331 epoch total loss 1.37972903
Trained batch 3166 batch loss 1.37484574 epoch total loss 1.37972748
Trained batch 3167 batch loss 1.31279325 epoch total loss 1.37970638
Trained batch 3168 batch loss 1.36359334 epoch total loss 1.37970138
Trained batch 3169 batch loss 1.2465663 epoch total loss 1.37965941
Trained batch 3170 batch loss 1.1552527 epoch total loss 1.3795886
Trained batch 3171 batch loss 1.20499408 epoch total loss 1.37953353
Trained batch 3172 batch loss 1.29073024 epoch total loss 1.37950552
Trained batch 3173 batch loss 1.32960868 epoch total loss 1.37948978
Trained batch 3174 batch loss 1.23872948 epoch total loss 1.37944543
Trained batch 3175 batch loss 1.31061363 epoch total loss 1.37942374
Trained batch 3176 batch loss 1.28656745 epoch total loss 1.37939453
Trained batch 3177 batch loss 1.25007987 epoch total loss 1.37935376
Trained batch 3178 batch loss 1.37071157 epoch total loss 1.37935102
Trained batch 3179 batch loss 1.44103432 epoch total loss 1.37937045
Trained batch 3180 batch loss 1.40421343 epoch total loss 1.3793782
Trained batch 3181 batch loss 1.2721442 epoch total loss 1.37934446
Trained batch 3182 batch loss 1.25787687 epoch total loss 1.37930632
Trained batch 3183 batch loss 0.88835144 epoch total loss 1.37915206
Trained batch 3184 batch loss 1.08514285 epoch total loss 1.37905955
Trained batch 3185 batch loss 0.890134513 epoch total loss 1.37890613
Trained batch 3186 batch loss 0.90450412 epoch total loss 1.37875712
Trained batch 3187 batch loss 0.938559055 epoch total loss 1.37861896
Trained batch 3188 batch loss 0.991856813 epoch total loss 1.3784976
Trained batch 3189 batch loss 0.856977403 epoch total loss 1.37833405
Trained batch 3190 batch loss 0.89403224 epoch total loss 1.37818229
Trained batch 3191 batch loss 1.00921333 epoch total loss 1.37806666
Trained batch 3192 batch loss 1.18123949 epoch total loss 1.37800491
Trained batch 3193 batch loss 1.27967763 epoch total loss 1.37797415
Trained batch 3194 batch loss 1.32505858 epoch total loss 1.3779577
Trained batch 3195 batch loss 1.36873007 epoch total loss 1.37795472
Trained batch 3196 batch loss 1.47372413 epoch total loss 1.37798464
Trained batch 3197 batch loss 1.44707632 epoch total loss 1.37800634
Trained batch 3198 batch loss 1.44171667 epoch total loss 1.37802637
Trained batch 3199 batch loss 1.46137261 epoch total loss 1.37805235
Trained batch 3200 batch loss 1.49115622 epoch total loss 1.37808776
Trained batch 3201 batch loss 1.43656945 epoch total loss 1.378106
Trained batch 3202 batch loss 1.49352 epoch total loss 1.37814212
Trained batch 3203 batch loss 1.51558185 epoch total loss 1.37818503
Trained batch 3204 batch loss 1.51423621 epoch total loss 1.37822747
Trained batch 3205 batch loss 1.3702631 epoch total loss 1.37822497
Trained batch 3206 batch loss 1.5010972 epoch total loss 1.37826324
Trained batch 3207 batch loss 1.4731642 epoch total loss 1.3782928
Trained batch 3208 batch loss 1.45578599 epoch total loss 1.37831688
Trained batch 3209 batch loss 1.4315418 epoch total loss 1.37833357
Trained batch 3210 batch loss 1.37544084 epoch total loss 1.37833261
Trained batch 3211 batch loss 1.30795074 epoch total loss 1.3783108
Trained batch 3212 batch loss 1.29847217 epoch total loss 1.37828588
Trained batch 3213 batch loss 1.26097679 epoch total loss 1.37824929
Trained batch 3214 batch loss 1.34469032 epoch total loss 1.3782388
Trained batch 3215 batch loss 1.30449271 epoch total loss 1.37821603
Trained batch 3216 batch loss 1.41309261 epoch total loss 1.37822676
Trained batch 3217 batch loss 1.34285414 epoch total loss 1.37821579
Trained batch 3218 batch loss 1.47612131 epoch total loss 1.37824619
Trained batch 3219 batch loss 1.4037466 epoch total loss 1.37825418
Trained batch 3220 batch loss 1.61532235 epoch total loss 1.37832773
Trained batch 3221 batch loss 1.16926813 epoch total loss 1.37826288
Trained batch 3222 batch loss 1.362113 epoch total loss 1.37825799
Trained batch 3223 batch loss 1.31747448 epoch total loss 1.37823904
Trained batch 3224 batch loss 1.32425046 epoch total loss 1.37822235
Trained batch 3225 batch loss 1.51085758 epoch total loss 1.37826335
Trained batch 3226 batch loss 1.34430099 epoch total loss 1.37825286
Trained batch 3227 batch loss 1.47315133 epoch total loss 1.37828219
Trained batch 3228 batch loss 1.6178906 epoch total loss 1.37835646
Trained batch 3229 batch loss 1.40552115 epoch total loss 1.37836492
Trained batch 3230 batch loss 1.50199401 epoch total loss 1.37840319
Trained batch 3231 batch loss 1.48923683 epoch total loss 1.37843752
Trained batch 3232 batch loss 1.33520544 epoch total loss 1.37842417
Trained batch 3233 batch loss 1.43158877 epoch total loss 1.37844062
Trained batch 3234 batch loss 1.44223237 epoch total loss 1.37846041
Trained batch 3235 batch loss 1.50089049 epoch total loss 1.37849832
Trained batch 3236 batch loss 1.72694588 epoch total loss 1.37860596
Trained batch 3237 batch loss 1.63654613 epoch total loss 1.37868571
Trained batch 3238 batch loss 1.5811317 epoch total loss 1.37874818
Trained batch 3239 batch loss 1.45648074 epoch total loss 1.37877226
Trained batch 3240 batch loss 1.29735565 epoch total loss 1.37874711
Trained batch 3241 batch loss 1.21112514 epoch total loss 1.37869537
Trained batch 3242 batch loss 1.05056453 epoch total loss 1.37859416
Trained batch 3243 batch loss 1.24952865 epoch total loss 1.37855434
Trained batch 3244 batch loss 1.07510877 epoch total loss 1.37846088
Trained batch 3245 batch loss 0.985600471 epoch total loss 1.37833989
Trained batch 3246 batch loss 1.08647168 epoch total loss 1.37825
Trained batch 3247 batch loss 1.27621794 epoch total loss 1.37821853
Trained batch 3248 batch loss 1.4459722 epoch total loss 1.37823939
Trained batch 3249 batch loss 1.3006413 epoch total loss 1.37821555
Trained batch 3250 batch loss 1.27081048 epoch total loss 1.37818253
Trained batch 3251 batch loss 1.42754495 epoch total loss 1.37819779
Trained batch 3252 batch loss 1.30387771 epoch total loss 1.3781749
Trained batch 3253 batch loss 1.30892909 epoch total loss 1.37815368
Trained batch 3254 batch loss 1.33595824 epoch total loss 1.37814069
Trained batch 3255 batch loss 1.28525662 epoch total loss 1.37811208
Trained batch 3256 batch loss 1.05816734 epoch total loss 1.37801385
Trained batch 3257 batch loss 1.2404182 epoch total loss 1.37797153
Trained batch 3258 batch loss 1.17802095 epoch total loss 1.37791026
Trained batch 3259 batch loss 1.12381697 epoch total loss 1.37783229
Trained batch 3260 batch loss 1.19772279 epoch total loss 1.3777771
Trained batch 3261 batch loss 1.17000854 epoch total loss 1.37771332
Trained batch 3262 batch loss 1.30730581 epoch total loss 1.37769163
Trained batch 3263 batch loss 1.09084988 epoch total loss 1.37760377
Trained batch 3264 batch loss 1.25857449 epoch total loss 1.37756741
Trained batch 3265 batch loss 1.2500627 epoch total loss 1.37752831
Trained batch 3266 batch loss 1.04476428 epoch total loss 1.37742651
Trained batch 3267 batch loss 1.20745289 epoch total loss 1.37737441
Trained batch 3268 batch loss 1.11026144 epoch total loss 1.37729275
Trained batch 3269 batch loss 1.36449301 epoch total loss 1.3772887
Trained batch 3270 batch loss 1.09838915 epoch total loss 1.37720358
Trained batch 3271 batch loss 1.27015924 epoch total loss 1.3771708
Trained batch 3272 batch loss 1.07839203 epoch total loss 1.37707949
Trained batch 3273 batch loss 1.00273108 epoch total loss 1.37696517
Trained batch 3274 batch loss 1.13280821 epoch total loss 1.37689066
Trained batch 3275 batch loss 1.09658754 epoch total loss 1.37680507
Trained batch 3276 batch loss 1.05325961 epoch total loss 1.37670624
Trained batch 3277 batch loss 1.12011266 epoch total loss 1.37662804
Trained batch 3278 batch loss 1.13003254 epoch total loss 1.3765527
Trained batch 3279 batch loss 1.1413635 epoch total loss 1.37648106
Trained batch 3280 batch loss 1.08251286 epoch total loss 1.37639141
Trained batch 3281 batch loss 1.27706182 epoch total loss 1.37636113
Trained batch 3282 batch loss 1.36596203 epoch total loss 1.37635791
Trained batch 3283 batch loss 1.34591484 epoch total loss 1.3763485
Trained batch 3284 batch loss 1.19870436 epoch total loss 1.37629449
Trained batch 3285 batch loss 1.38431621 epoch total loss 1.37629688
Trained batch 3286 batch loss 1.50269485 epoch total loss 1.37633538
Trained batch 3287 batch loss 1.29223573 epoch total loss 1.37630975
Trained batch 3288 batch loss 1.15759993 epoch total loss 1.37624323
Trained batch 3289 batch loss 1.13821745 epoch total loss 1.37617087
Trained batch 3290 batch loss 1.15344882 epoch total loss 1.37610316
Trained batch 3291 batch loss 1.10146093 epoch total loss 1.37601972
Trained batch 3292 batch loss 1.21963382 epoch total loss 1.37597227
Trained batch 3293 batch loss 1.10258353 epoch total loss 1.37588918
Trained batch 3294 batch loss 1.28296876 epoch total loss 1.37586105
Trained batch 3295 batch loss 1.2348938 epoch total loss 1.37581825
Trained batch 3296 batch loss 1.04798746 epoch total loss 1.37571883
Trained batch 3297 batch loss 1.24999619 epoch total loss 1.37568069
Trained batch 3298 batch loss 1.53286469 epoch total loss 1.37572825
Trained batch 3299 batch loss 1.37260187 epoch total loss 1.3757273
Trained batch 3300 batch loss 1.40739155 epoch total loss 1.37573683
Trained batch 3301 batch loss 1.49936414 epoch total loss 1.37577438
Trained batch 3302 batch loss 1.33470345 epoch total loss 1.37576187
Trained batch 3303 batch loss 1.39204836 epoch total loss 1.37576675
Trained batch 3304 batch loss 1.02440977 epoch total loss 1.37566042
Trained batch 3305 batch loss 1.18109822 epoch total loss 1.37560165
Trained batch 3306 batch loss 1.34803438 epoch total loss 1.3755933
Trained batch 3307 batch loss 1.49056828 epoch total loss 1.37562811
Trained batch 3308 batch loss 1.24305546 epoch total loss 1.37558806
Trained batch 3309 batch loss 1.39280748 epoch total loss 1.37559319
Trained batch 3310 batch loss 1.33241081 epoch total loss 1.37558019
Trained batch 3311 batch loss 1.22132409 epoch total loss 1.37553358
Trained batch 3312 batch loss 1.49026644 epoch total loss 1.37556815
Trained batch 3313 batch loss 1.442168 epoch total loss 1.3755883
Trained batch 3314 batch loss 1.24944818 epoch total loss 1.37555027
Trained batch 3315 batch loss 1.30212545 epoch total loss 1.37552822
Trained batch 3316 batch loss 1.39713418 epoch total loss 1.37553465
Trained batch 3317 batch loss 1.49676025 epoch total loss 1.37557113
Trained batch 3318 batch loss 1.19419599 epoch total loss 1.37551653
Trained batch 3319 batch loss 1.32215619 epoch total loss 1.37550044
Trained batch 3320 batch loss 1.26360989 epoch total loss 1.37546682
Trained batch 3321 batch loss 1.34669697 epoch total loss 1.37545812
Trained batch 3322 batch loss 1.30868602 epoch total loss 1.37543797
Trained batch 3323 batch loss 1.22353911 epoch total loss 1.37539232
Trained batch 3324 batch loss 1.27535009 epoch total loss 1.37536228
Trained batch 3325 batch loss 1.24785542 epoch total loss 1.37532401
Trained batch 3326 batch loss 1.20216584 epoch total loss 1.37527192
Trained batch 3327 batch loss 1.32053971 epoch total loss 1.37525535
Trained batch 3328 batch loss 1.38168263 epoch total loss 1.37525737
Trained batch 3329 batch loss 1.34514689 epoch total loss 1.37524831
Trained batch 3330 batch loss 1.24161208 epoch total loss 1.37520826
Trained batch 3331 batch loss 1.28501761 epoch total loss 1.3751812
Trained batch 3332 batch loss 1.26298165 epoch total loss 1.37514758
Trained batch 3333 batch loss 1.17187309 epoch total loss 1.37508655
Trained batch 3334 batch loss 1.14403319 epoch total loss 1.37501729
Trained batch 3335 batch loss 1.20952725 epoch total loss 1.37496769
Trained batch 3336 batch loss 1.2717371 epoch total loss 1.37493682
Trained batch 3337 batch loss 1.35187232 epoch total loss 1.3749299
Trained batch 3338 batch loss 1.29094076 epoch total loss 1.37490475
Trained batch 3339 batch loss 1.3301326 epoch total loss 1.3748914
Trained batch 3340 batch loss 1.4328146 epoch total loss 1.37490869
Trained batch 3341 batch loss 1.60353422 epoch total loss 1.37497711
Trained batch 3342 batch loss 1.47713399 epoch total loss 1.37500763
Trained batch 3343 batch loss 1.47009563 epoch total loss 1.37503612
Trained batch 3344 batch loss 1.4143244 epoch total loss 1.37504792
Trained batch 3345 batch loss 1.26711297 epoch total loss 1.37501562
Trained batch 3346 batch loss 1.56436241 epoch total loss 1.37507224
Trained batch 3347 batch loss 1.56915808 epoch total loss 1.3751303
Trained batch 3348 batch loss 1.19556141 epoch total loss 1.37507677
Trained batch 3349 batch loss 1.45031309 epoch total loss 1.37509918
Trained batch 3350 batch loss 1.26931834 epoch total loss 1.37506759
Trained batch 3351 batch loss 1.29793632 epoch total loss 1.37504458
Trained batch 3352 batch loss 1.37536263 epoch total loss 1.3750447
Trained batch 3353 batch loss 1.32855296 epoch total loss 1.37503088
Trained batch 3354 batch loss 1.41609323 epoch total loss 1.37504303
Trained batch 3355 batch loss 1.35298467 epoch total loss 1.37503648
Trained batch 3356 batch loss 1.38887954 epoch total loss 1.37504065
Trained batch 3357 batch loss 1.3302052 epoch total loss 1.37502718
Trained batch 3358 batch loss 1.38661814 epoch total loss 1.37503064
Trained batch 3359 batch loss 1.22986877 epoch total loss 1.37498748
Trained batch 3360 batch loss 1.4777925 epoch total loss 1.37501812
Trained batch 3361 batch loss 1.3959341 epoch total loss 1.37502444
Trained batch 3362 batch loss 1.24349928 epoch total loss 1.37498534
Trained batch 3363 batch loss 1.47216439 epoch total loss 1.37501419
Trained batch 3364 batch loss 1.39805031 epoch total loss 1.3750211
Trained batch 3365 batch loss 1.09154963 epoch total loss 1.3749367
Trained batch 3366 batch loss 1.31976414 epoch total loss 1.37492037
Trained batch 3367 batch loss 1.10412741 epoch total loss 1.3748399
Trained batch 3368 batch loss 1.32455444 epoch total loss 1.374825
Trained batch 3369 batch loss 1.39201593 epoch total loss 1.37483013
Trained batch 3370 batch loss 1.18853331 epoch total loss 1.37477481
Trained batch 3371 batch loss 1.26504779 epoch total loss 1.37474227
Trained batch 3372 batch loss 1.19710767 epoch total loss 1.3746897
Trained batch 3373 batch loss 1.43411827 epoch total loss 1.37470734
Trained batch 3374 batch loss 1.24600649 epoch total loss 1.37466919
Trained batch 3375 batch loss 1.26584601 epoch total loss 1.37463689
Trained batch 3376 batch loss 1.41218615 epoch total loss 1.37464797
Trained batch 3377 batch loss 1.08227563 epoch total loss 1.37456143
Trained batch 3378 batch loss 1.11116624 epoch total loss 1.37448359
Trained batch 3379 batch loss 1.19046187 epoch total loss 1.37442911
Trained batch 3380 batch loss 1.22177708 epoch total loss 1.37438393
Trained batch 3381 batch loss 1.20068145 epoch total loss 1.37433255
Trained batch 3382 batch loss 1.36073017 epoch total loss 1.37432849
Trained batch 3383 batch loss 1.41174817 epoch total loss 1.37433958
Trained batch 3384 batch loss 1.23026466 epoch total loss 1.37429702
Trained batch 3385 batch loss 1.27250957 epoch total loss 1.37426698
Trained batch 3386 batch loss 1.29427099 epoch total loss 1.37424338
Trained batch 3387 batch loss 1.51892185 epoch total loss 1.37428606
Trained batch 3388 batch loss 1.44722176 epoch total loss 1.37430763
Trained batch 3389 batch loss 1.27378345 epoch total loss 1.37427807
Trained batch 3390 batch loss 1.33078122 epoch total loss 1.37426507
Trained batch 3391 batch loss 1.36034608 epoch total loss 1.37426102
Trained batch 3392 batch loss 1.30200362 epoch total loss 1.3742398
Trained batch 3393 batch loss 1.18377352 epoch total loss 1.37418365
Trained batch 3394 batch loss 1.35771966 epoch total loss 1.37417877
Trained batch 3395 batch loss 1.32994568 epoch total loss 1.37416577
Trained batch 3396 batch loss 1.29785323 epoch total loss 1.37414336
Trained batch 3397 batch loss 1.26651573 epoch total loss 1.37411165
Trained batch 3398 batch loss 1.03034902 epoch total loss 1.37401056
Trained batch 3399 batch loss 1.32010913 epoch total loss 1.37399471
Trained batch 3400 batch loss 1.23513079 epoch total loss 1.37395394
Trained batch 3401 batch loss 1.07470012 epoch total loss 1.37386596
Trained batch 3402 batch loss 1.29688048 epoch total loss 1.37384331
Trained batch 3403 batch loss 1.26148105 epoch total loss 1.37381041
Trained batch 3404 batch loss 1.2573514 epoch total loss 1.3737762
Trained batch 3405 batch loss 1.19396281 epoch total loss 1.37372327
Trained batch 3406 batch loss 1.37320793 epoch total loss 1.37372315
Trained batch 3407 batch loss 1.32411218 epoch total loss 1.37370861
Trained batch 3408 batch loss 1.3237114 epoch total loss 1.37369394
Trained batch 3409 batch loss 1.28538013 epoch total loss 1.37366796
Trained batch 3410 batch loss 1.23902762 epoch total loss 1.3736285
Trained batch 3411 batch loss 1.46758413 epoch total loss 1.37365615
Trained batch 3412 batch loss 1.26106131 epoch total loss 1.37362313
Trained batch 3413 batch loss 1.26104105 epoch total loss 1.37359023
Trained batch 3414 batch loss 1.24654448 epoch total loss 1.37355304
Trained batch 3415 batch loss 1.36013353 epoch total loss 1.37354922
Trained batch 3416 batch loss 1.33486497 epoch total loss 1.3735379
Trained batch 3417 batch loss 1.06313109 epoch total loss 1.37344694
Trained batch 3418 batch loss 1.32478189 epoch total loss 1.37343276
Trained batch 3419 batch loss 1.34531569 epoch total loss 1.37342453
Trained batch 3420 batch loss 1.33771241 epoch total loss 1.37341404
Trained batch 3421 batch loss 1.36593568 epoch total loss 1.37341189
Trained batch 3422 batch loss 1.28755689 epoch total loss 1.37338674
Trained batch 3423 batch loss 1.33596349 epoch total loss 1.37337577
Trained batch 3424 batch loss 1.40174341 epoch total loss 1.37338412
Trained batch 3425 batch loss 1.43968892 epoch total loss 1.37340343
Trained batch 3426 batch loss 1.42244828 epoch total loss 1.37341774
Trained batch 3427 batch loss 1.40888238 epoch total loss 1.37342799
Trained batch 3428 batch loss 1.42480659 epoch total loss 1.37344301
Trained batch 3429 batch loss 1.54186141 epoch total loss 1.37349212
Trained batch 3430 batch loss 1.31980848 epoch total loss 1.37347651
Trained batch 3431 batch loss 1.30263543 epoch total loss 1.37345588
Trained batch 3432 batch loss 1.26326823 epoch total loss 1.37342381
Trained batch 3433 batch loss 1.47801626 epoch total loss 1.37345421
Trained batch 3434 batch loss 1.3926506 epoch total loss 1.37345982
Trained batch 3435 batch loss 1.52272654 epoch total loss 1.37350333
Trained batch 3436 batch loss 1.43407297 epoch total loss 1.37352097
Trained batch 3437 batch loss 1.36193395 epoch total loss 1.37351751
Trained batch 3438 batch loss 1.47406507 epoch total loss 1.37354684
Trained batch 3439 batch loss 1.35063696 epoch total loss 1.37354016
Trained batch 3440 batch loss 1.42184043 epoch total loss 1.37355423
Trained batch 3441 batch loss 1.68632615 epoch total loss 1.37364519
Trained batch 3442 batch loss 1.51741827 epoch total loss 1.37368691
Trained batch 3443 batch loss 1.32999802 epoch total loss 1.37367427
Trained batch 3444 batch loss 1.08330083 epoch total loss 1.37359
Trained batch 3445 batch loss 1.15745938 epoch total loss 1.37352717
Trained batch 3446 batch loss 1.14709377 epoch total loss 1.37346148
Trained batch 3447 batch loss 1.31055617 epoch total loss 1.37344325
Trained batch 3448 batch loss 1.28559089 epoch total loss 1.37341774
Trained batch 3449 batch loss 1.21285462 epoch total loss 1.37337124
Trained batch 3450 batch loss 1.26275337 epoch total loss 1.37333918
Trained batch 3451 batch loss 1.30780017 epoch total loss 1.3733201
Trained batch 3452 batch loss 1.41104281 epoch total loss 1.37333107
Trained batch 3453 batch loss 1.20636606 epoch total loss 1.37328279
Trained batch 3454 batch loss 1.2288506 epoch total loss 1.37324095
Trained batch 3455 batch loss 1.30907571 epoch total loss 1.37322235
Trained batch 3456 batch loss 1.21963537 epoch total loss 1.37317801
Trained batch 3457 batch loss 1.24247348 epoch total loss 1.37314022
Trained batch 3458 batch loss 1.09094763 epoch total loss 1.37305856
Trained batch 3459 batch loss 1.10549283 epoch total loss 1.37298119
Trained batch 3460 batch loss 1.15335011 epoch total loss 1.37291777
Trained batch 3461 batch loss 1.08311701 epoch total loss 1.37283397
Trained batch 3462 batch loss 1.27255917 epoch total loss 1.372805
Trained batch 3463 batch loss 1.20436978 epoch total loss 1.37275636
Trained batch 3464 batch loss 1.09407353 epoch total loss 1.37267601
Trained batch 3465 batch loss 1.25783503 epoch total loss 1.37264287
Trained batch 3466 batch loss 1.45334399 epoch total loss 1.37266612
Trained batch 3467 batch loss 1.23429739 epoch total loss 1.37262619
Trained batch 3468 batch loss 1.13902974 epoch total loss 1.37255883
Trained batch 3469 batch loss 1.3914485 epoch total loss 1.37256432
Trained batch 3470 batch loss 1.31799459 epoch total loss 1.37254858
Trained batch 3471 batch loss 1.32204676 epoch total loss 1.37253416
Trained batch 3472 batch loss 1.03886199 epoch total loss 1.37243807
Trained batch 3473 batch loss 1.3858124 epoch total loss 1.37244189
Trained batch 3474 batch loss 1.50973153 epoch total loss 1.37248147
Trained batch 3475 batch loss 1.45678163 epoch total loss 1.37250566
Trained batch 3476 batch loss 1.37769365 epoch total loss 1.37250721
Trained batch 3477 batch loss 1.19619751 epoch total loss 1.37245655
Trained batch 3478 batch loss 1.13273478 epoch total loss 1.37238765
Trained batch 3479 batch loss 1.0187484 epoch total loss 1.37228584
Trained batch 3480 batch loss 1.08587992 epoch total loss 1.37220359
Trained batch 3481 batch loss 1.39459729 epoch total loss 1.37221
Trained batch 3482 batch loss 1.4388485 epoch total loss 1.37222922
Trained batch 3483 batch loss 1.26789713 epoch total loss 1.3721993
Trained batch 3484 batch loss 1.25631249 epoch total loss 1.37216604
Trained batch 3485 batch loss 1.30976033 epoch total loss 1.37214804
Trained batch 3486 batch loss 1.32701135 epoch total loss 1.37213516
Trained batch 3487 batch loss 1.39886153 epoch total loss 1.37214279
Trained batch 3488 batch loss 1.66146052 epoch total loss 1.37222588
Trained batch 3489 batch loss 1.24720824 epoch total loss 1.37219
Trained batch 3490 batch loss 1.16916752 epoch total loss 1.37213171
Trained batch 3491 batch loss 1.05694568 epoch total loss 1.37204146
Trained batch 3492 batch loss 0.993556142 epoch total loss 1.3719331
Trained batch 3493 batch loss 0.991052568 epoch total loss 1.37182415
Trained batch 3494 batch loss 1.09618402 epoch total loss 1.37174523
Trained batch 3495 batch loss 1.36801958 epoch total loss 1.37174428
Trained batch 3496 batch loss 1.34138751 epoch total loss 1.37173557
Trained batch 3497 batch loss 1.47323656 epoch total loss 1.37176454
Trained batch 3498 batch loss 1.44837177 epoch total loss 1.37178636
Trained batch 3499 batch loss 1.41509223 epoch total loss 1.37179875
Trained batch 3500 batch loss 1.44298553 epoch total loss 1.37181902
Trained batch 3501 batch loss 1.50868964 epoch total loss 1.37185824
Trained batch 3502 batch loss 1.51544499 epoch total loss 1.37189925
Trained batch 3503 batch loss 1.37612045 epoch total loss 1.37190044
Trained batch 3504 batch loss 1.38780272 epoch total loss 1.37190485
Trained batch 3505 batch loss 1.45399034 epoch total loss 1.37192833
Trained batch 3506 batch loss 1.32674265 epoch total loss 1.37191546
Trained batch 3507 batch loss 1.20959759 epoch total loss 1.37186909
Trained batch 3508 batch loss 1.26533163 epoch total loss 1.37183869
Trained batch 3509 batch loss 1.24882174 epoch total loss 1.37180364
Trained batch 3510 batch loss 1.1354779 epoch total loss 1.37173629
Trained batch 3511 batch loss 1.16270399 epoch total loss 1.37167668
Trained batch 3512 batch loss 1.09254122 epoch total loss 1.37159729
Trained batch 3513 batch loss 1.25972009 epoch total loss 1.37156546
Trained batch 3514 batch loss 1.08642626 epoch total loss 1.3714844
Trained batch 3515 batch loss 1.10170197 epoch total loss 1.37140751
Trained batch 3516 batch loss 1.16219473 epoch total loss 1.37134802
Trained batch 3517 batch loss 1.12494278 epoch total loss 1.37127793
Trained batch 3518 batch loss 1.25517344 epoch total loss 1.37124503
Trained batch 3519 batch loss 1.23883152 epoch total loss 1.37120736
Trained batch 3520 batch loss 1.18570876 epoch total loss 1.37115467
Trained batch 3521 batch loss 1.16057587 epoch total loss 1.37109482
Trained batch 3522 batch loss 1.13673007 epoch total loss 1.3710283
Trained batch 3523 batch loss 0.974639297 epoch total loss 1.37091577
Trained batch 3524 batch loss 1.13353896 epoch total loss 1.37084842
Trained batch 3525 batch loss 1.14645767 epoch total loss 1.37078476
Trained batch 3526 batch loss 1.1059916 epoch total loss 1.37070966
Trained batch 3527 batch loss 1.19703925 epoch total loss 1.37066042
Trained batch 3528 batch loss 1.10904706 epoch total loss 1.37058628
Trained batch 3529 batch loss 1.13684416 epoch total loss 1.37052
Trained batch 3530 batch loss 1.03866613 epoch total loss 1.37042594
Trained batch 3531 batch loss 1.26908588 epoch total loss 1.37039721
Trained batch 3532 batch loss 1.23764873 epoch total loss 1.37035966
Trained batch 3533 batch loss 1.33391571 epoch total loss 1.37034941
Trained batch 3534 batch loss 1.06083703 epoch total loss 1.37026191
Trained batch 3535 batch loss 1.27904773 epoch total loss 1.37023592
Trained batch 3536 batch loss 1.24430442 epoch total loss 1.37020028
Trained batch 3537 batch loss 1.27390981 epoch total loss 1.3701731
Trained batch 3538 batch loss 1.31703544 epoch total loss 1.37015808
Trained batch 3539 batch loss 1.35808563 epoch total loss 1.37015462
Trained batch 3540 batch loss 1.2096045 epoch total loss 1.3701092
Trained batch 3541 batch loss 1.33624744 epoch total loss 1.37009966
Trained batch 3542 batch loss 1.30454087 epoch total loss 1.37008119
Trained batch 3543 batch loss 1.23044038 epoch total loss 1.37004185
Trained batch 3544 batch loss 1.30597472 epoch total loss 1.37002373
Trained batch 3545 batch loss 1.34351969 epoch total loss 1.37001634
Trained batch 3546 batch loss 1.51545179 epoch total loss 1.37005746
Trained batch 3547 batch loss 1.46342874 epoch total loss 1.37008369
Trained batch 3548 batch loss 1.25482929 epoch total loss 1.37005126
Trained batch 3549 batch loss 1.10786629 epoch total loss 1.36997736
Trained batch 3550 batch loss 1.34147227 epoch total loss 1.36996937
Trained batch 3551 batch loss 1.37198532 epoch total loss 1.36997
Trained batch 3552 batch loss 1.25763631 epoch total loss 1.36993837
Trained batch 3553 batch loss 1.49378753 epoch total loss 1.36997318
Trained batch 3554 batch loss 1.31449568 epoch total loss 1.36995757
Trained batch 3555 batch loss 1.27710295 epoch total loss 1.36993146
Trained batch 3556 batch loss 1.19924736 epoch total loss 1.36988354
Trained batch 3557 batch loss 1.25471699 epoch total loss 1.36985111
Trained batch 3558 batch loss 1.28606749 epoch total loss 1.36982763
Trained batch 3559 batch loss 1.27179933 epoch total loss 1.36980009
Trained batch 3560 batch loss 1.27072501 epoch total loss 1.3697722
Trained batch 3561 batch loss 1.23973668 epoch total loss 1.36973572
Trained batch 3562 batch loss 1.16533494 epoch total loss 1.36967838
Trained batch 3563 batch loss 1.19708467 epoch total loss 1.36963
Trained batch 3564 batch loss 0.935971797 epoch total loss 1.36950839
Trained batch 3565 batch loss 1.34023595 epoch total loss 1.36950016
Trained batch 3566 batch loss 1.31229234 epoch total loss 1.36948419
Trained batch 3567 batch loss 1.45354724 epoch total loss 1.36950779
Trained batch 3568 batch loss 1.28108263 epoch total loss 1.36948299
Trained batch 3569 batch loss 1.41882777 epoch total loss 1.36949694
Trained batch 3570 batch loss 1.78378451 epoch total loss 1.36961293
Trained batch 3571 batch loss 1.45032263 epoch total loss 1.36963546
Trained batch 3572 batch loss 1.3331182 epoch total loss 1.36962521
Trained batch 3573 batch loss 1.23109221 epoch total loss 1.36958635
Trained batch 3574 batch loss 1.38488054 epoch total loss 1.36959064
Trained batch 3575 batch loss 1.18578565 epoch total loss 1.36953914
Trained batch 3576 batch loss 1.31442535 epoch total loss 1.36952376
Trained batch 3577 batch loss 1.23508525 epoch total loss 1.36948609
Trained batch 3578 batch loss 1.34973836 epoch total loss 1.36948061
Trained batch 3579 batch loss 1.06355858 epoch total loss 1.36939502
Trained batch 3580 batch loss 1.14278626 epoch total loss 1.36933172
Trained batch 3581 batch loss 1.24141622 epoch total loss 1.36929595
Trained batch 3582 batch loss 1.17831671 epoch total loss 1.36924255
Trained batch 3583 batch loss 1.25582385 epoch total loss 1.36921096
Trained batch 3584 batch loss 1.20404816 epoch total loss 1.36916482
Trained batch 3585 batch loss 1.17921615 epoch total loss 1.3691119
Trained batch 3586 batch loss 1.14419961 epoch total loss 1.36904907
Trained batch 3587 batch loss 1.17090845 epoch total loss 1.36899388
Trained batch 3588 batch loss 1.04725671 epoch total loss 1.36890423
Trained batch 3589 batch loss 1.15795517 epoch total loss 1.36884534
Trained batch 3590 batch loss 0.933004141 epoch total loss 1.36872399
Trained batch 3591 batch loss 1.12007666 epoch total loss 1.36865485
Trained batch 3592 batch loss 1.28979838 epoch total loss 1.36863291
Trained batch 3593 batch loss 1.22606397 epoch total loss 1.36859322
Trained batch 3594 batch loss 1.25112152 epoch total loss 1.36856055
Trained batch 3595 batch loss 1.32755375 epoch total loss 1.36854911
Trained batch 3596 batch loss 1.33430302 epoch total loss 1.36853969
Trained batch 3597 batch loss 1.39175451 epoch total loss 1.36854601
Trained batch 3598 batch loss 1.31829882 epoch total loss 1.36853206
Trained batch 3599 batch loss 1.3462584 epoch total loss 1.36852586
Trained batch 3600 batch loss 1.3202424 epoch total loss 1.36851251
Trained batch 3601 batch loss 1.24943137 epoch total loss 1.36847949
Trained batch 3602 batch loss 1.32017016 epoch total loss 1.36846614
Trained batch 3603 batch loss 1.17072594 epoch total loss 1.3684113
Trained batch 3604 batch loss 1.26075029 epoch total loss 1.36838138
Trained batch 3605 batch loss 1.06179106 epoch total loss 1.36829638
Trained batch 3606 batch loss 1.20655775 epoch total loss 1.36825156
Trained batch 3607 batch loss 1.13949537 epoch total loss 1.36818814
Trained batch 3608 batch loss 1.17884576 epoch total loss 1.36813569
Trained batch 3609 batch loss 1.11003125 epoch total loss 1.36806405
Trained batch 3610 batch loss 1.06180906 epoch total loss 1.36797929
Trained batch 3611 batch loss 1.10256 epoch total loss 1.36790574
Trained batch 3612 batch loss 1.16701508 epoch total loss 1.36785018
Trained batch 3613 batch loss 1.14829826 epoch total loss 1.36778939
Trained batch 3614 batch loss 1.33950329 epoch total loss 1.36778152
Trained batch 3615 batch loss 1.28632855 epoch total loss 1.36775899
Trained batch 3616 batch loss 1.41488385 epoch total loss 1.3677721
Trained batch 3617 batch loss 1.38285553 epoch total loss 1.36777627
Trained batch 3618 batch loss 1.41624594 epoch total loss 1.36778951
Trained batch 3619 batch loss 1.76563609 epoch total loss 1.36789954
Trained batch 3620 batch loss 1.47945261 epoch total loss 1.36793029
Trained batch 3621 batch loss 1.3078295 epoch total loss 1.3679136
Trained batch 3622 batch loss 1.16666484 epoch total loss 1.36785805
Trained batch 3623 batch loss 1.22820187 epoch total loss 1.36781943
Trained batch 3624 batch loss 1.25728559 epoch total loss 1.36778891
Trained batch 3625 batch loss 1.3278507 epoch total loss 1.36777782
Trained batch 3626 batch loss 1.29823816 epoch total loss 1.36775875
Trained batch 3627 batch loss 1.39274895 epoch total loss 1.36776555
Trained batch 3628 batch loss 1.29759407 epoch total loss 1.36774611
Trained batch 3629 batch loss 1.25224805 epoch total loss 1.36771441
Trained batch 3630 batch loss 1.1647619 epoch total loss 1.36765838
Trained batch 3631 batch loss 1.11905408 epoch total loss 1.36759
Trained batch 3632 batch loss 1.03181767 epoch total loss 1.36749756
Trained batch 3633 batch loss 1.0627315 epoch total loss 1.36741352
Trained batch 3634 batch loss 1.01658106 epoch total loss 1.36731708
Trained batch 3635 batch loss 0.924623311 epoch total loss 1.36719525
Trained batch 3636 batch loss 1.02457309 epoch total loss 1.36710107
Trained batch 3637 batch loss 0.951009274 epoch total loss 1.36698663
Trained batch 3638 batch loss 0.925177932 epoch total loss 1.36686528
Trained batch 3639 batch loss 1.01770365 epoch total loss 1.36676931
Trained batch 3640 batch loss 1.08602691 epoch total loss 1.36669207
Trained batch 3641 batch loss 1.01463926 epoch total loss 1.36659539
Trained batch 3642 batch loss 1.11791635 epoch total loss 1.36652708
Trained batch 3643 batch loss 1.11667109 epoch total loss 1.36645854
Trained batch 3644 batch loss 1.49397922 epoch total loss 1.36649358
Trained batch 3645 batch loss 1.41516256 epoch total loss 1.36650681
Trained batch 3646 batch loss 1.58550239 epoch total loss 1.3665669
Trained batch 3647 batch loss 1.51421094 epoch total loss 1.36660743
Trained batch 3648 batch loss 1.49603188 epoch total loss 1.36664283
Trained batch 3649 batch loss 1.40481675 epoch total loss 1.36665332
Trained batch 3650 batch loss 1.42976189 epoch total loss 1.36667061
Trained batch 3651 batch loss 1.38748789 epoch total loss 1.36667633
Trained batch 3652 batch loss 1.09185445 epoch total loss 1.36660111
Trained batch 3653 batch loss 1.22960448 epoch total loss 1.36656356
Trained batch 3654 batch loss 1.10670161 epoch total loss 1.36649251
Trained batch 3655 batch loss 1.05498123 epoch total loss 1.36640728
Trained batch 3656 batch loss 1.0616014 epoch total loss 1.36632395
Trained batch 3657 batch loss 1.0602541 epoch total loss 1.36624014
Trained batch 3658 batch loss 1.10083413 epoch total loss 1.36616766
Trained batch 3659 batch loss 1.03704429 epoch total loss 1.36607778
Trained batch 3660 batch loss 0.894340456 epoch total loss 1.36594892
Trained batch 3661 batch loss 1.20657277 epoch total loss 1.3659054
Trained batch 3662 batch loss 1.42487943 epoch total loss 1.3659215
Trained batch 3663 batch loss 1.45482063 epoch total loss 1.3659457
Trained batch 3664 batch loss 1.44199359 epoch total loss 1.36596644
Trained batch 3665 batch loss 1.47747087 epoch total loss 1.36599684
Trained batch 3666 batch loss 1.30873394 epoch total loss 1.36598122
Trained batch 3667 batch loss 1.34160638 epoch total loss 1.36597455
Trained batch 3668 batch loss 1.44395494 epoch total loss 1.36599576
Trained batch 3669 batch loss 1.38265705 epoch total loss 1.36600041
Trained batch 3670 batch loss 1.33433926 epoch total loss 1.36599183
Trained batch 3671 batch loss 1.45659804 epoch total loss 1.36601651
Trained batch 3672 batch loss 1.40163803 epoch total loss 1.36602628
Trained batch 3673 batch loss 1.22023392 epoch total loss 1.36598659
Trained batch 3674 batch loss 1.30757082 epoch total loss 1.36597061
Trained batch 3675 batch loss 1.23889792 epoch total loss 1.36593604
Trained batch 3676 batch loss 1.45481789 epoch total loss 1.36596012
Trained batch 3677 batch loss 1.43460059 epoch total loss 1.36597884
Trained batch 3678 batch loss 1.34121728 epoch total loss 1.36597216
Trained batch 3679 batch loss 1.19680882 epoch total loss 1.36592615
Trained batch 3680 batch loss 1.20042276 epoch total loss 1.36588109
Trained batch 3681 batch loss 1.4591285 epoch total loss 1.36590636
Trained batch 3682 batch loss 1.3519479 epoch total loss 1.36590266
Trained batch 3683 batch loss 1.40713596 epoch total loss 1.36591387
Trained batch 3684 batch loss 1.46885812 epoch total loss 1.36594176
Trained batch 3685 batch loss 1.28885984 epoch total loss 1.3659209
Trained batch 3686 batch loss 1.240731 epoch total loss 1.36588693
Trained batch 3687 batch loss 1.22714305 epoch total loss 1.36584926
Trained batch 3688 batch loss 1.27819061 epoch total loss 1.36582553
Trained batch 3689 batch loss 1.20189643 epoch total loss 1.36578107
Trained batch 3690 batch loss 1.4637816 epoch total loss 1.36580765
Trained batch 3691 batch loss 1.21189892 epoch total loss 1.36576593
Trained batch 3692 batch loss 1.52490711 epoch total loss 1.36580896
Trained batch 3693 batch loss 1.33317304 epoch total loss 1.36580014
Trained batch 3694 batch loss 1.12747228 epoch total loss 1.36573565
Trained batch 3695 batch loss 1.51911473 epoch total loss 1.36577713
Trained batch 3696 batch loss 1.22094226 epoch total loss 1.3657378
Trained batch 3697 batch loss 1.12193894 epoch total loss 1.36567199
Trained batch 3698 batch loss 1.14045727 epoch total loss 1.36561108
Trained batch 3699 batch loss 1.40662622 epoch total loss 1.36562216
Trained batch 3700 batch loss 1.27157104 epoch total loss 1.36559677
Trained batch 3701 batch loss 1.29188299 epoch total loss 1.36557686
Trained batch 3702 batch loss 1.29566276 epoch total loss 1.36555803
Trained batch 3703 batch loss 1.18835962 epoch total loss 1.36551023
Trained batch 3704 batch loss 1.18768096 epoch total loss 1.36546218
Trained batch 3705 batch loss 1.33198667 epoch total loss 1.36545312
Trained batch 3706 batch loss 1.26684248 epoch total loss 1.36542642
Trained batch 3707 batch loss 1.30908847 epoch total loss 1.36541128
Trained batch 3708 batch loss 1.18669498 epoch total loss 1.365363
Trained batch 3709 batch loss 1.30786169 epoch total loss 1.36534762
Trained batch 3710 batch loss 1.30325615 epoch total loss 1.36533082
Trained batch 3711 batch loss 1.28237271 epoch total loss 1.3653084
Trained batch 3712 batch loss 1.27411246 epoch total loss 1.36528385
Trained batch 3713 batch loss 1.35259175 epoch total loss 1.36528039
Trained batch 3714 batch loss 1.36093819 epoch total loss 1.3652792
Trained batch 3715 batch loss 1.25423455 epoch total loss 1.3652494
Trained batch 3716 batch loss 1.28727829 epoch total loss 1.3652283
Trained batch 3717 batch loss 1.33219838 epoch total loss 1.36521935
Trained batch 3718 batch loss 1.24460578 epoch total loss 1.36518693
Trained batch 3719 batch loss 1.3223803 epoch total loss 1.36517537
Trained batch 3720 batch loss 1.26238036 epoch total loss 1.36514771
Trained batch 3721 batch loss 1.37578142 epoch total loss 1.36515069
Trained batch 3722 batch loss 1.43298149 epoch total loss 1.36516893
Trained batch 3723 batch loss 1.27480769 epoch total loss 1.36514461
Trained batch 3724 batch loss 1.35901344 epoch total loss 1.36514294
Trained batch 3725 batch loss 1.40608454 epoch total loss 1.36515403
Trained batch 3726 batch loss 1.24474216 epoch total loss 1.36512172
Trained batch 3727 batch loss 1.3613354 epoch total loss 1.36512065
Trained batch 3728 batch loss 1.22014427 epoch total loss 1.36508179
Trained batch 3729 batch loss 1.184659 epoch total loss 1.36503339
Trained batch 3730 batch loss 1.40269113 epoch total loss 1.36504352
Trained batch 3731 batch loss 1.13748789 epoch total loss 1.3649826
Trained batch 3732 batch loss 1.33971834 epoch total loss 1.36497581
Trained batch 3733 batch loss 1.33314395 epoch total loss 1.36496723
Trained batch 3734 batch loss 1.35742617 epoch total loss 1.3649652
Trained batch 3735 batch loss 1.32390475 epoch total loss 1.36495423
Trained batch 3736 batch loss 1.2961328 epoch total loss 1.36493576
Trained batch 3737 batch loss 1.45168734 epoch total loss 1.36495888
Trained batch 3738 batch loss 1.31538081 epoch total loss 1.36494565
Trained batch 3739 batch loss 1.34981918 epoch total loss 1.3649416
Trained batch 3740 batch loss 1.20744729 epoch total loss 1.36489952
Trained batch 3741 batch loss 1.30322194 epoch total loss 1.36488307
Trained batch 3742 batch loss 1.22702599 epoch total loss 1.36484623
Trained batch 3743 batch loss 1.26085806 epoch total loss 1.36481833
Trained batch 3744 batch loss 1.2468884 epoch total loss 1.36478686
Trained batch 3745 batch loss 1.15132606 epoch total loss 1.36472988
Trained batch 3746 batch loss 1.33779478 epoch total loss 1.36472273
Trained batch 3747 batch loss 1.7159549 epoch total loss 1.36481643
Trained batch 3748 batch loss 1.44268703 epoch total loss 1.36483729
Trained batch 3749 batch loss 1.51789224 epoch total loss 1.36487818
Trained batch 3750 batch loss 1.46218562 epoch total loss 1.36490417
Trained batch 3751 batch loss 1.57445192 epoch total loss 1.36496
Trained batch 3752 batch loss 1.41430128 epoch total loss 1.36497307
Trained batch 3753 batch loss 1.37449253 epoch total loss 1.36497557
Trained batch 3754 batch loss 1.37365234 epoch total loss 1.36497784
Trained batch 3755 batch loss 1.46826756 epoch total loss 1.36500537
Trained batch 3756 batch loss 1.23509824 epoch total loss 1.36497068
Trained batch 3757 batch loss 1.31090927 epoch total loss 1.36495638
Trained batch 3758 batch loss 1.45143473 epoch total loss 1.36497951
Trained batch 3759 batch loss 1.36473262 epoch total loss 1.36497939
Trained batch 3760 batch loss 1.2727561 epoch total loss 1.36495495
Trained batch 3761 batch loss 1.25547504 epoch total loss 1.36492574
Trained batch 3762 batch loss 1.28515 epoch total loss 1.36490452
Trained batch 3763 batch loss 1.33799446 epoch total loss 1.36489737
Trained batch 3764 batch loss 1.30865705 epoch total loss 1.36488247
Trained batch 3765 batch loss 1.21341741 epoch total loss 1.36484218
Trained batch 3766 batch loss 1.2340498 epoch total loss 1.36480737
Trained batch 3767 batch loss 1.28327858 epoch total loss 1.36478579
Trained batch 3768 batch loss 1.18937027 epoch total loss 1.36473918
Trained batch 3769 batch loss 1.3407557 epoch total loss 1.36473286
Trained batch 3770 batch loss 1.1469667 epoch total loss 1.36467516
Trained batch 3771 batch loss 1.2446301 epoch total loss 1.36464334
Trained batch 3772 batch loss 1.16157842 epoch total loss 1.36458945
Trained batch 3773 batch loss 1.3102622 epoch total loss 1.36457503
Trained batch 3774 batch loss 1.52578688 epoch total loss 1.36461771
Trained batch 3775 batch loss 1.44163191 epoch total loss 1.36463809
Trained batch 3776 batch loss 1.66494644 epoch total loss 1.3647176
Trained batch 3777 batch loss 1.2965436 epoch total loss 1.3646996
Trained batch 3778 batch loss 1.37692 epoch total loss 1.36470282
Trained batch 3779 batch loss 1.34139681 epoch total loss 1.36469662
Trained batch 3780 batch loss 1.37091339 epoch total loss 1.36469829
Trained batch 3781 batch loss 1.44641089 epoch total loss 1.36471987
Trained batch 3782 batch loss 1.4582392 epoch total loss 1.36474454
Trained batch 3783 batch loss 1.92364073 epoch total loss 1.36489236
Trained batch 3784 batch loss 1.52990317 epoch total loss 1.36493587
Trained batch 3785 batch loss 1.6498096 epoch total loss 1.36501122
Trained batch 3786 batch loss 1.52762794 epoch total loss 1.36505425
Trained batch 3787 batch loss 1.49897814 epoch total loss 1.36508954
Trained batch 3788 batch loss 1.27916455 epoch total loss 1.36506689
Trained batch 3789 batch loss 1.22218323 epoch total loss 1.36502922
Trained batch 3790 batch loss 1.29537392 epoch total loss 1.36501086
Trained batch 3791 batch loss 1.22940767 epoch total loss 1.36497509
Trained batch 3792 batch loss 1.40718722 epoch total loss 1.3649863
Trained batch 3793 batch loss 1.27644539 epoch total loss 1.36496294
Trained batch 3794 batch loss 1.22060633 epoch total loss 1.36492491
Trained batch 3795 batch loss 1.35754895 epoch total loss 1.36492288
Trained batch 3796 batch loss 1.64070618 epoch total loss 1.36499548
Trained batch 3797 batch loss 1.25809574 epoch total loss 1.36496747
Trained batch 3798 batch loss 1.3178097 epoch total loss 1.36495507
Trained batch 3799 batch loss 1.27194083 epoch total loss 1.36493051
Trained batch 3800 batch loss 1.35491574 epoch total loss 1.36492789
Trained batch 3801 batch loss 1.3239367 epoch total loss 1.36491704
Trained batch 3802 batch loss 1.42655039 epoch total loss 1.36493337
Trained batch 3803 batch loss 1.46523154 epoch total loss 1.36495972
Trained batch 3804 batch loss 1.42174423 epoch total loss 1.36497474
Trained batch 3805 batch loss 1.51683271 epoch total loss 1.36501455
Trained batch 3806 batch loss 1.47028768 epoch total loss 1.36504221
Trained batch 3807 batch loss 1.43000972 epoch total loss 1.36505926
Trained batch 3808 batch loss 1.51783371 epoch total loss 1.36509943
Trained batch 3809 batch loss 1.54106355 epoch total loss 1.36514568
Trained batch 3810 batch loss 1.54865563 epoch total loss 1.36519384
Trained batch 3811 batch loss 1.15341318 epoch total loss 1.36513829
Trained batch 3812 batch loss 1.23870707 epoch total loss 1.36510515
Trained batch 3813 batch loss 1.06525588 epoch total loss 1.36502659
Trained batch 3814 batch loss 1.21127272 epoch total loss 1.3649863
Trained batch 3815 batch loss 0.938046575 epoch total loss 1.36487436
Trained batch 3816 batch loss 1.04717863 epoch total loss 1.36479115
Trained batch 3817 batch loss 1.41668868 epoch total loss 1.36480463
Trained batch 3818 batch loss 1.29349279 epoch total loss 1.36478603
Trained batch 3819 batch loss 1.24088359 epoch total loss 1.36475348
Trained batch 3820 batch loss 1.34156561 epoch total loss 1.36474752
Trained batch 3821 batch loss 1.49657035 epoch total loss 1.36478198
Trained batch 3822 batch loss 1.39490259 epoch total loss 1.36479
Trained batch 3823 batch loss 1.4212029 epoch total loss 1.36480474
Trained batch 3824 batch loss 1.36709642 epoch total loss 1.36480534
Trained batch 3825 batch loss 1.21699119 epoch total loss 1.3647666
Trained batch 3826 batch loss 1.14884567 epoch total loss 1.36471021
Trained batch 3827 batch loss 1.20790744 epoch total loss 1.36466932
Trained batch 3828 batch loss 1.42142224 epoch total loss 1.3646841
Trained batch 3829 batch loss 1.38078 epoch total loss 1.36468828
Trained batch 3830 batch loss 1.4339776 epoch total loss 1.3647064
Trained batch 3831 batch loss 1.35910845 epoch total loss 1.36470497
Trained batch 3832 batch loss 1.37448597 epoch total loss 1.36470747
Trained batch 3833 batch loss 1.14668059 epoch total loss 1.36465061
Trained batch 3834 batch loss 1.39694369 epoch total loss 1.36465895
Trained batch 3835 batch loss 1.29947162 epoch total loss 1.3646419
Trained batch 3836 batch loss 1.23271084 epoch total loss 1.36460757
Trained batch 3837 batch loss 1.32889283 epoch total loss 1.36459839
Trained batch 3838 batch loss 1.34742975 epoch total loss 1.36459398
Trained batch 3839 batch loss 1.40938318 epoch total loss 1.36460555
Trained batch 3840 batch loss 1.34169078 epoch total loss 1.36459959
Trained batch 3841 batch loss 1.40514159 epoch total loss 1.3646102
Trained batch 3842 batch loss 1.38191 epoch total loss 1.36461473
Trained batch 3843 batch loss 1.22966695 epoch total loss 1.36457956
Trained batch 3844 batch loss 1.21651101 epoch total loss 1.36454093
Trained batch 3845 batch loss 1.33659148 epoch total loss 1.36453366
Trained batch 3846 batch loss 1.32670736 epoch total loss 1.36452377
Trained batch 3847 batch loss 1.32882285 epoch total loss 1.36451447
Trained batch 3848 batch loss 1.10693836 epoch total loss 1.36444747
Trained batch 3849 batch loss 1.22227883 epoch total loss 1.36441052
Trained batch 3850 batch loss 1.24957514 epoch total loss 1.36438072
Trained batch 3851 batch loss 1.1676017 epoch total loss 1.36432958
Trained batch 3852 batch loss 1.17467356 epoch total loss 1.36428034
Trained batch 3853 batch loss 1.26964331 epoch total loss 1.36425579
Trained batch 3854 batch loss 1.15406704 epoch total loss 1.36420131
Trained batch 3855 batch loss 1.13369012 epoch total loss 1.36414158
Trained batch 3856 batch loss 1.13657236 epoch total loss 1.36408257
Trained batch 3857 batch loss 1.37766743 epoch total loss 1.36408603
Trained batch 3858 batch loss 1.35327148 epoch total loss 1.36408317
Trained batch 3859 batch loss 1.38604808 epoch total loss 1.36408889
Trained batch 3860 batch loss 1.47406936 epoch total loss 1.36411738
Trained batch 3861 batch loss 1.29776537 epoch total loss 1.36410022
Trained batch 3862 batch loss 1.27813196 epoch total loss 1.36407804
Trained batch 3863 batch loss 1.27978945 epoch total loss 1.36405623
Trained batch 3864 batch loss 1.47239482 epoch total loss 1.36408424
Trained batch 3865 batch loss 1.5079987 epoch total loss 1.36412132
Trained batch 3866 batch loss 1.43897438 epoch total loss 1.36414075
Trained batch 3867 batch loss 1.46085179 epoch total loss 1.36416578
Trained batch 3868 batch loss 1.1671685 epoch total loss 1.36411476
Trained batch 3869 batch loss 1.33208716 epoch total loss 1.36410654
Trained batch 3870 batch loss 1.24742055 epoch total loss 1.36407638
Trained batch 3871 batch loss 1.39154589 epoch total loss 1.36408353
Trained batch 3872 batch loss 1.28366601 epoch total loss 1.36406279
Trained batch 3873 batch loss 1.31282 epoch total loss 1.36404955
Trained batch 3874 batch loss 1.27558899 epoch total loss 1.36402667
Trained batch 3875 batch loss 1.27281499 epoch total loss 1.36400318
Trained batch 3876 batch loss 1.26835132 epoch total loss 1.36397851
Trained batch 3877 batch loss 1.35966027 epoch total loss 1.36397743
Trained batch 3878 batch loss 1.35713434 epoch total loss 1.36397564
Trained batch 3879 batch loss 1.36512399 epoch total loss 1.363976
Trained batch 3880 batch loss 1.2174921 epoch total loss 1.36393821
Trained batch 3881 batch loss 1.2301271 epoch total loss 1.36390364
Trained batch 3882 batch loss 1.40754175 epoch total loss 1.36391497
Trained batch 3883 batch loss 1.56884265 epoch total loss 1.36396766
Trained batch 3884 batch loss 1.40782607 epoch total loss 1.36397898
Trained batch 3885 batch loss 1.06473291 epoch total loss 1.36390197
Trained batch 3886 batch loss 1.00564957 epoch total loss 1.36380982
Trained batch 3887 batch loss 1.08652806 epoch total loss 1.36373854
Trained batch 3888 batch loss 0.925951 epoch total loss 1.36362588
Trained batch 3889 batch loss 1.24067652 epoch total loss 1.36359429
Trained batch 3890 batch loss 1.09193695 epoch total loss 1.36352444
Trained batch 3891 batch loss 1.26869965 epoch total loss 1.3635
Trained batch 3892 batch loss 1.28000951 epoch total loss 1.36347842
Trained batch 3893 batch loss 1.44071126 epoch total loss 1.36349833
Trained batch 3894 batch loss 1.49919534 epoch total loss 1.36353314
Trained batch 3895 batch loss 1.36551917 epoch total loss 1.36353374
Trained batch 3896 batch loss 1.44158792 epoch total loss 1.36355376
Trained batch 3897 batch loss 1.3297956 epoch total loss 1.36354494
Trained batch 3898 batch loss 1.34715009 epoch total loss 1.36354077
Trained batch 3899 batch loss 1.38673031 epoch total loss 1.36354673
Trained batch 3900 batch loss 1.52112281 epoch total loss 1.36358714
Trained batch 3901 batch loss 1.32999754 epoch total loss 1.36357856
Trained batch 3902 batch loss 1.36515319 epoch total loss 1.36357892
Trained batch 3903 batch loss 1.24807453 epoch total loss 1.36354935
Trained batch 3904 batch loss 1.27691185 epoch total loss 1.36352718
Trained batch 3905 batch loss 1.33218527 epoch total loss 1.36351907
Trained batch 3906 batch loss 1.39510083 epoch total loss 1.36352718
Trained batch 3907 batch loss 1.23203158 epoch total loss 1.36349344
Trained batch 3908 batch loss 1.4174118 epoch total loss 1.36350727
Trained batch 3909 batch loss 1.38022828 epoch total loss 1.36351156
Trained batch 3910 batch loss 1.20098615 epoch total loss 1.36347008
Trained batch 3911 batch loss 1.23405 epoch total loss 1.36343694
Trained batch 3912 batch loss 1.25168562 epoch total loss 1.36340833
Trained batch 3913 batch loss 1.20856547 epoch total loss 1.36336875
Trained batch 3914 batch loss 1.29115796 epoch total loss 1.36335027
Trained batch 3915 batch loss 1.19344008 epoch total loss 1.36330676
Trained batch 3916 batch loss 1.19491863 epoch total loss 1.36326385
Trained batch 3917 batch loss 1.33472836 epoch total loss 1.36325657
Trained batch 3918 batch loss 1.41027546 epoch total loss 1.36326849
Trained batch 3919 batch loss 1.14025021 epoch total loss 1.36321163
Trained batch 3920 batch loss 1.26261401 epoch total loss 1.363186
Trained batch 3921 batch loss 1.1405611 epoch total loss 1.36312926
Trained batch 3922 batch loss 1.36057377 epoch total loss 1.36312854
Trained batch 3923 batch loss 1.29540718 epoch total loss 1.36311126
Trained batch 3924 batch loss 1.25584829 epoch total loss 1.36308384
Trained batch 3925 batch loss 1.16616642 epoch total loss 1.36303365
Trained batch 3926 batch loss 1.39998984 epoch total loss 1.36304307
Trained batch 3927 batch loss 1.29275715 epoch total loss 1.36302519
Trained batch 3928 batch loss 1.29981852 epoch total loss 1.3630091
Trained batch 3929 batch loss 1.71488321 epoch total loss 1.36309874
Trained batch 3930 batch loss 1.28816414 epoch total loss 1.36307955
Trained batch 3931 batch loss 1.4528712 epoch total loss 1.36310244
Trained batch 3932 batch loss 1.33909488 epoch total loss 1.36309624
Trained batch 3933 batch loss 1.47364163 epoch total loss 1.36312437
Trained batch 3934 batch loss 1.4009701 epoch total loss 1.36313391
Trained batch 3935 batch loss 1.35127342 epoch total loss 1.36313081
Trained batch 3936 batch loss 1.16217422 epoch total loss 1.36307979
Trained batch 3937 batch loss 1.10338628 epoch total loss 1.36301386
Trained batch 3938 batch loss 1.0921514 epoch total loss 1.36294508
Trained batch 3939 batch loss 1.04576778 epoch total loss 1.36286461
Trained batch 3940 batch loss 1.39826357 epoch total loss 1.36287367
Trained batch 3941 batch loss 1.37822413 epoch total loss 1.36287761
Trained batch 3942 batch loss 1.37388921 epoch total loss 1.36288047
Trained batch 3943 batch loss 1.28476667 epoch total loss 1.36286056
Trained batch 3944 batch loss 1.30621946 epoch total loss 1.36284626
Trained batch 3945 batch loss 1.41203308 epoch total loss 1.36285865
Trained batch 3946 batch loss 1.42722154 epoch total loss 1.36287498
Trained batch 3947 batch loss 1.30681229 epoch total loss 1.3628608
Trained batch 3948 batch loss 1.27352047 epoch total loss 1.36283815
Trained batch 3949 batch loss 1.30469823 epoch total loss 1.36282337
Trained batch 3950 batch loss 1.16828597 epoch total loss 1.36277413
Trained batch 3951 batch loss 1.25664616 epoch total loss 1.36274731
Trained batch 3952 batch loss 1.21291327 epoch total loss 1.3627094
Trained batch 3953 batch loss 1.49996114 epoch total loss 1.36274421
Trained batch 3954 batch loss 1.19912815 epoch total loss 1.36270285
Trained batch 3955 batch loss 1.26819682 epoch total loss 1.36267889
Trained batch 3956 batch loss 1.15687907 epoch total loss 1.36262679
Trained batch 3957 batch loss 1.40093923 epoch total loss 1.36263645
Trained batch 3958 batch loss 1.24432051 epoch total loss 1.36260653
Trained batch 3959 batch loss 1.08789873 epoch total loss 1.36253715
Trained batch 3960 batch loss 1.19950676 epoch total loss 1.36249602
Trained batch 3961 batch loss 1.33019793 epoch total loss 1.36248791
Trained batch 3962 batch loss 1.28573513 epoch total loss 1.36246848
Trained batch 3963 batch loss 1.37007415 epoch total loss 1.36247039
Trained batch 3964 batch loss 1.41289067 epoch total loss 1.36248314
Trained batch 3965 batch loss 1.33183503 epoch total loss 1.36247551
Trained batch 3966 batch loss 1.57250881 epoch total loss 1.36252844
Trained batch 3967 batch loss 1.22026443 epoch total loss 1.36249256
Trained batch 3968 batch loss 1.28607011 epoch total loss 1.36247325
Trained batch 3969 batch loss 1.22443438 epoch total loss 1.36243856
Trained batch 3970 batch loss 1.3104322 epoch total loss 1.36242545
Trained batch 3971 batch loss 1.66132021 epoch total loss 1.36250067
Trained batch 3972 batch loss 1.3989 epoch total loss 1.36250985
Trained batch 3973 batch loss 1.35800147 epoch total loss 1.36250865
Trained batch 3974 batch loss 1.13616323 epoch total loss 1.36245179
Trained batch 3975 batch loss 1.18491673 epoch total loss 1.36240709
Trained batch 3976 batch loss 1.36544228 epoch total loss 1.3624078
Trained batch 3977 batch loss 1.15778661 epoch total loss 1.36235642
Trained batch 3978 batch loss 1.27385855 epoch total loss 1.36233413
Trained batch 3979 batch loss 1.4987396 epoch total loss 1.36236835
Trained batch 3980 batch loss 1.48887515 epoch total loss 1.36240017
Trained batch 3981 batch loss 1.16969609 epoch total loss 1.36235178
Trained batch 3982 batch loss 1.40213323 epoch total loss 1.36236179
Trained batch 3983 batch loss 1.35390234 epoch total loss 1.36235976
Trained batch 3984 batch loss 1.45744193 epoch total loss 1.3623836
Trained batch 3985 batch loss 1.4925034 epoch total loss 1.36241627
Trained batch 3986 batch loss 1.32015133 epoch total loss 1.36240578
Trained batch 3987 batch loss 1.35953879 epoch total loss 1.36240494
Trained batch 3988 batch loss 1.18058097 epoch total loss 1.3623594
Trained batch 3989 batch loss 1.23483491 epoch total loss 1.36232746
Trained batch 3990 batch loss 1.04338837 epoch total loss 1.36224759
Trained batch 3991 batch loss 1.33721328 epoch total loss 1.36224127
Trained batch 3992 batch loss 1.53278947 epoch total loss 1.36228406
Trained batch 3993 batch loss 1.3246932 epoch total loss 1.36227465
Trained batch 3994 batch loss 1.19192815 epoch total loss 1.36223197
Trained batch 3995 batch loss 1.46624303 epoch total loss 1.36225796
Trained batch 3996 batch loss 1.35076571 epoch total loss 1.3622551
Trained batch 3997 batch loss 1.41595578 epoch total loss 1.36226857
Trained batch 3998 batch loss 1.25745666 epoch total loss 1.36224222
Trained batch 3999 batch loss 1.25542545 epoch total loss 1.36221552
Trained batch 4000 batch loss 1.29020953 epoch total loss 1.36219752
Trained batch 4001 batch loss 1.34483576 epoch total loss 1.36219311
Trained batch 4002 batch loss 1.40413094 epoch total loss 1.36220372
Trained batch 4003 batch loss 1.38751817 epoch total loss 1.36221
Trained batch 4004 batch loss 1.36048949 epoch total loss 1.36220956
Trained batch 4005 batch loss 1.25980973 epoch total loss 1.36218405
Trained batch 4006 batch loss 1.22997141 epoch total loss 1.36215103
Trained batch 4007 batch loss 1.18072009 epoch total loss 1.36210573
Trained batch 4008 batch loss 1.35821736 epoch total loss 1.36210477
Trained batch 4009 batch loss 1.49853146 epoch total loss 1.36213875
Trained batch 4010 batch loss 1.44060171 epoch total loss 1.3621583
Trained batch 4011 batch loss 1.70352292 epoch total loss 1.36224341
Trained batch 4012 batch loss 1.59188282 epoch total loss 1.36230063
Trained batch 4013 batch loss 1.40269208 epoch total loss 1.36231077
Trained batch 4014 batch loss 1.7103858 epoch total loss 1.36239755
Trained batch 4015 batch loss 1.29058218 epoch total loss 1.36237955
Trained batch 4016 batch loss 1.28184533 epoch total loss 1.36235952
Trained batch 4017 batch loss 1.0155437 epoch total loss 1.36227322
Trained batch 4018 batch loss 1.20671034 epoch total loss 1.36223447
Trained batch 4019 batch loss 1.37729108 epoch total loss 1.36223829
Trained batch 4020 batch loss 0.959668577 epoch total loss 1.36213803
Trained batch 4021 batch loss 1.34936857 epoch total loss 1.36213493
Trained batch 4022 batch loss 1.36333179 epoch total loss 1.36213517
Trained batch 4023 batch loss 1.5399431 epoch total loss 1.3621794
Trained batch 4024 batch loss 1.48939323 epoch total loss 1.36221099
Trained batch 4025 batch loss 1.46605432 epoch total loss 1.36223674
Trained batch 4026 batch loss 1.32971549 epoch total loss 1.36222863
Trained batch 4027 batch loss 1.45222569 epoch total loss 1.36225092
Trained batch 4028 batch loss 1.34968305 epoch total loss 1.36224782
Trained batch 4029 batch loss 1.37680912 epoch total loss 1.36225152
Trained batch 4030 batch loss 1.38304377 epoch total loss 1.36225653
Trained batch 4031 batch loss 1.43897223 epoch total loss 1.3622756
Trained batch 4032 batch loss 1.31905293 epoch total loss 1.36226487
Trained batch 4033 batch loss 1.25383663 epoch total loss 1.36223793
Trained batch 4034 batch loss 0.965786934 epoch total loss 1.3621397
Trained batch 4035 batch loss 1.3874656 epoch total loss 1.36214602
Trained batch 4036 batch loss 1.252213 epoch total loss 1.36211884
Trained batch 4037 batch loss 1.51687527 epoch total loss 1.36215723
Trained batch 4038 batch loss 1.18919396 epoch total loss 1.36211431
Trained batch 4039 batch loss 1.16297746 epoch total loss 1.36206508
Trained batch 4040 batch loss 1.11285615 epoch total loss 1.36200333
Trained batch 4041 batch loss 1.24282932 epoch total loss 1.36197388
Trained batch 4042 batch loss 1.18908906 epoch total loss 1.36193109
Trained batch 4043 batch loss 1.21164227 epoch total loss 1.36189377
Trained batch 4044 batch loss 1.16767955 epoch total loss 1.36184573
Trained batch 4045 batch loss 1.16241384 epoch total loss 1.3617965
Trained batch 4046 batch loss 1.21656895 epoch total loss 1.36176062
Trained batch 4047 batch loss 1.33856249 epoch total loss 1.36175489
Trained batch 4048 batch loss 1.34908164 epoch total loss 1.36175179
Trained batch 4049 batch loss 1.15118122 epoch total loss 1.36169982
Trained batch 4050 batch loss 1.40949321 epoch total loss 1.36171162
Trained batch 4051 batch loss 1.43297601 epoch total loss 1.36172926
Trained batch 4052 batch loss 1.30075252 epoch total loss 1.36171424
Trained batch 4053 batch loss 1.30734372 epoch total loss 1.36170077
Trained batch 4054 batch loss 1.24704051 epoch total loss 1.36167252
Trained batch 4055 batch loss 1.33643913 epoch total loss 1.3616662
Trained batch 4056 batch loss 1.29549861 epoch total loss 1.36164987
Trained batch 4057 batch loss 1.25029778 epoch total loss 1.36162257
Trained batch 4058 batch loss 1.40917742 epoch total loss 1.36163425
Trained batch 4059 batch loss 1.3974303 epoch total loss 1.36164308
Trained batch 4060 batch loss 1.05931497 epoch total loss 1.36156857
Trained batch 4061 batch loss 1.03111327 epoch total loss 1.36148715
Trained batch 4062 batch loss 1.27392888 epoch total loss 1.36146569
Trained batch 4063 batch loss 1.23240185 epoch total loss 1.36143386
Trained batch 4064 batch loss 1.15617859 epoch total loss 1.36138344
Trained batch 4065 batch loss 1.2455852 epoch total loss 1.36135495
Trained batch 4066 batch loss 1.21934593 epoch total loss 1.3613199
Trained batch 4067 batch loss 1.38178957 epoch total loss 1.36132503
Trained batch 4068 batch loss 1.27021682 epoch total loss 1.36130261
Trained batch 4069 batch loss 1.13541102 epoch total loss 1.36124706
Trained batch 4070 batch loss 1.10679913 epoch total loss 1.36118448
Trained batch 4071 batch loss 1.18425059 epoch total loss 1.36114097
Trained batch 4072 batch loss 1.11539984 epoch total loss 1.36108065
Trained batch 4073 batch loss 1.37553275 epoch total loss 1.36108422
Trained batch 4074 batch loss 1.22519565 epoch total loss 1.36105084
Trained batch 4075 batch loss 1.27376699 epoch total loss 1.36102939
Trained batch 4076 batch loss 1.10239685 epoch total loss 1.36096597
Trained batch 4077 batch loss 1.20617557 epoch total loss 1.36092794
Trained batch 4078 batch loss 1.32478857 epoch total loss 1.36091912
Trained batch 4079 batch loss 1.35055971 epoch total loss 1.36091661
Trained batch 4080 batch loss 1.35887361 epoch total loss 1.36091602
Trained batch 4081 batch loss 1.44301498 epoch total loss 1.36093616
Trained batch 4082 batch loss 1.23182857 epoch total loss 1.36090457
Trained batch 4083 batch loss 1.1522429 epoch total loss 1.36085343
Trained batch 4084 batch loss 1.48736143 epoch total loss 1.36088443
Trained batch 4085 batch loss 1.25000906 epoch total loss 1.36085725
Trained batch 4086 batch loss 1.00425458 epoch total loss 1.36077011
Trained batch 4087 batch loss 1.44756913 epoch total loss 1.36079133
Trained batch 4088 batch loss 1.45700824 epoch total loss 1.36081493
Trained batch 4089 batch loss 1.32906485 epoch total loss 1.36080718
Trained batch 4090 batch loss 1.40279794 epoch total loss 1.36081743
Trained batch 4091 batch loss 1.17489541 epoch total loss 1.36077189
Trained batch 4092 batch loss 1.19748926 epoch total loss 1.36073196
Trained batch 4093 batch loss 1.19043016 epoch total loss 1.36069036
Trained batch 4094 batch loss 1.16264713 epoch total loss 1.36064196
Trained batch 4095 batch loss 1.17682862 epoch total loss 1.36059713
Trained batch 4096 batch loss 1.39805627 epoch total loss 1.36060619
Trained batch 4097 batch loss 1.31255519 epoch total loss 1.36059451
Trained batch 4098 batch loss 1.38233399 epoch total loss 1.36059976
Trained batch 4099 batch loss 1.29630935 epoch total loss 1.36058414
Trained batch 4100 batch loss 1.29879701 epoch total loss 1.360569
Trained batch 4101 batch loss 1.24188 epoch total loss 1.36054
Trained batch 4102 batch loss 1.19236612 epoch total loss 1.36049902
Trained batch 4103 batch loss 1.23587775 epoch total loss 1.36046863
Trained batch 4104 batch loss 1.13046038 epoch total loss 1.3604126
Trained batch 4105 batch loss 1.13473296 epoch total loss 1.36035764
Trained batch 4106 batch loss 1.1996963 epoch total loss 1.36031854
Trained batch 4107 batch loss 1.19458973 epoch total loss 1.36027825
Trained batch 4108 batch loss 1.21302378 epoch total loss 1.36024237
Trained batch 4109 batch loss 1.09857082 epoch total loss 1.36017871
Trained batch 4110 batch loss 1.41687608 epoch total loss 1.36019254
Trained batch 4111 batch loss 1.19437861 epoch total loss 1.36015213
Trained batch 4112 batch loss 1.14556479 epoch total loss 1.36009991
Trained batch 4113 batch loss 1.19858718 epoch total loss 1.36006069
Trained batch 4114 batch loss 1.60505664 epoch total loss 1.3601203
Trained batch 4115 batch loss 1.53671324 epoch total loss 1.36016309
Trained batch 4116 batch loss 1.31472397 epoch total loss 1.36015213
Trained batch 4117 batch loss 1.48245573 epoch total loss 1.36018181
Trained batch 4118 batch loss 1.16548848 epoch total loss 1.3601346
Trained batch 4119 batch loss 1.23922944 epoch total loss 1.36010528
Trained batch 4120 batch loss 1.46152949 epoch total loss 1.36012983
Trained batch 4121 batch loss 1.40971494 epoch total loss 1.36014187
Trained batch 4122 batch loss 1.2970109 epoch total loss 1.3601265
Trained batch 4123 batch loss 1.43936539 epoch total loss 1.36014569
Trained batch 4124 batch loss 1.36667526 epoch total loss 1.36014736
Trained batch 4125 batch loss 1.30613899 epoch total loss 1.36013424
Trained batch 4126 batch loss 1.39445066 epoch total loss 1.36014259
Trained batch 4127 batch loss 1.56789446 epoch total loss 1.36019289
Trained batch 4128 batch loss 1.22036886 epoch total loss 1.36015904
Trained batch 4129 batch loss 1.46455693 epoch total loss 1.36018419
Trained batch 4130 batch loss 1.41497946 epoch total loss 1.36019754
Trained batch 4131 batch loss 1.27118945 epoch total loss 1.36017597
Trained batch 4132 batch loss 1.29924905 epoch total loss 1.36016119
Trained batch 4133 batch loss 1.47066069 epoch total loss 1.36018789
Trained batch 4134 batch loss 1.19385064 epoch total loss 1.36014771
Trained batch 4135 batch loss 1.3510952 epoch total loss 1.36014545
Trained batch 4136 batch loss 1.42027831 epoch total loss 1.36016011
Trained batch 4137 batch loss 1.31672359 epoch total loss 1.36014962
Trained batch 4138 batch loss 1.40329206 epoch total loss 1.36016
Trained batch 4139 batch loss 1.34382033 epoch total loss 1.36015606
Trained batch 4140 batch loss 1.26611614 epoch total loss 1.36013341
Trained batch 4141 batch loss 1.43240833 epoch total loss 1.36015081
Trained batch 4142 batch loss 1.30158854 epoch total loss 1.36013675
Trained batch 4143 batch loss 1.1205169 epoch total loss 1.36007893
Trained batch 4144 batch loss 1.32730675 epoch total loss 1.36007106
Trained batch 4145 batch loss 1.32810831 epoch total loss 1.36006331
Trained batch 4146 batch loss 1.43247294 epoch total loss 1.36008084
Trained batch 4147 batch loss 1.36227775 epoch total loss 1.36008132
Trained batch 4148 batch loss 1.34627342 epoch total loss 1.36007798
Trained batch 4149 batch loss 1.30878949 epoch total loss 1.36006558
Trained batch 4150 batch loss 1.12497497 epoch total loss 1.36000896
Trained batch 4151 batch loss 1.1274364 epoch total loss 1.35995293
Trained batch 4152 batch loss 1.34020567 epoch total loss 1.35994816
Trained batch 4153 batch loss 1.28334308 epoch total loss 1.35992968
Trained batch 4154 batch loss 1.27106309 epoch total loss 1.35990834
Trained batch 4155 batch loss 1.21663475 epoch total loss 1.35987389
Trained batch 4156 batch loss 1.10702121 epoch total loss 1.35981297
Trained batch 4157 batch loss 1.1525768 epoch total loss 1.35976315
Trained batch 4158 batch loss 1.29848409 epoch total loss 1.35974836
Trained batch 4159 batch loss 0.998307347 epoch total loss 1.35966146
Trained batch 4160 batch loss 1.10659289 epoch total loss 1.35960054
Trained batch 4161 batch loss 1.25255871 epoch total loss 1.35957479
Trained batch 4162 batch loss 1.23098457 epoch total loss 1.35954392
Trained batch 4163 batch loss 1.37984884 epoch total loss 1.35954881
Trained batch 4164 batch loss 0.975384 epoch total loss 1.35945666
Trained batch 4165 batch loss 1.27215981 epoch total loss 1.35943556
Trained batch 4166 batch loss 1.41742039 epoch total loss 1.35944951
Trained batch 4167 batch loss 1.21425521 epoch total loss 1.3594147
Trained batch 4168 batch loss 1.29601812 epoch total loss 1.35939944
Trained batch 4169 batch loss 1.1179769 epoch total loss 1.35934162
Trained batch 4170 batch loss 1.36293864 epoch total loss 1.35934246
Trained batch 4171 batch loss 1.26979339 epoch total loss 1.359321
Trained batch 4172 batch loss 1.47366941 epoch total loss 1.35934842
Trained batch 4173 batch loss 1.36744094 epoch total loss 1.35935044
Trained batch 4174 batch loss 1.62680209 epoch total loss 1.35941458
Trained batch 4175 batch loss 1.53017914 epoch total loss 1.35945547
Trained batch 4176 batch loss 1.60939407 epoch total loss 1.35951531
Trained batch 4177 batch loss 1.60592973 epoch total loss 1.35957432
Trained batch 4178 batch loss 1.36566961 epoch total loss 1.35957575
Trained batch 4179 batch loss 1.37464809 epoch total loss 1.35957932
Trained batch 4180 batch loss 1.30257082 epoch total loss 1.35956573
Trained batch 4181 batch loss 1.35234308 epoch total loss 1.35956407
Trained batch 4182 batch loss 1.37781382 epoch total loss 1.35956848
Trained batch 4183 batch loss 1.52634847 epoch total loss 1.35960829
Trained batch 4184 batch loss 1.4012866 epoch total loss 1.35961831
Trained batch 4185 batch loss 1.29932141 epoch total loss 1.35960388
Trained batch 4186 batch loss 1.3374536 epoch total loss 1.35959864
Trained batch 4187 batch loss 1.29914141 epoch total loss 1.35958421
Trained batch 4188 batch loss 1.3693583 epoch total loss 1.35958648
Trained batch 4189 batch loss 1.061131 epoch total loss 1.35951519
Trained batch 4190 batch loss 1.19583714 epoch total loss 1.35947621
Trained batch 4191 batch loss 1.24928761 epoch total loss 1.35944986
Trained batch 4192 batch loss 1.46604061 epoch total loss 1.35947526
Trained batch 4193 batch loss 1.34879673 epoch total loss 1.35947275
Trained batch 4194 batch loss 1.33780205 epoch total loss 1.35946751
Trained batch 4195 batch loss 1.28714728 epoch total loss 1.35945034
Trained batch 4196 batch loss 1.23142958 epoch total loss 1.35941982
Trained batch 4197 batch loss 0.999236822 epoch total loss 1.35933387
Trained batch 4198 batch loss 1.05314791 epoch total loss 1.35926104
Trained batch 4199 batch loss 1.05956197 epoch total loss 1.35918963
Trained batch 4200 batch loss 1.47079504 epoch total loss 1.35921621
Trained batch 4201 batch loss 1.4925251 epoch total loss 1.35924792
Trained batch 4202 batch loss 1.41890812 epoch total loss 1.35926211
Trained batch 4203 batch loss 1.36688602 epoch total loss 1.3592639
Trained batch 4204 batch loss 1.27206922 epoch total loss 1.35924315
Trained batch 4205 batch loss 1.40267396 epoch total loss 1.35925353
Trained batch 4206 batch loss 1.36550236 epoch total loss 1.35925508
Trained batch 4207 batch loss 1.37860334 epoch total loss 1.35925961
Trained batch 4208 batch loss 1.22012377 epoch total loss 1.35922658
Trained batch 4209 batch loss 1.23476315 epoch total loss 1.35919702
Trained batch 4210 batch loss 1.12103295 epoch total loss 1.35914052
Trained batch 4211 batch loss 1.02325356 epoch total loss 1.35906076
Trained batch 4212 batch loss 1.27981448 epoch total loss 1.35904193
Trained batch 4213 batch loss 1.06095409 epoch total loss 1.35897124
Trained batch 4214 batch loss 1.3599844 epoch total loss 1.35897148
Trained batch 4215 batch loss 1.06633663 epoch total loss 1.35890198
Trained batch 4216 batch loss 0.958352566 epoch total loss 1.35880709
Trained batch 4217 batch loss 1.10299 epoch total loss 1.35874641
Trained batch 4218 batch loss 1.16596413 epoch total loss 1.35870063
Trained batch 4219 batch loss 1.1427002 epoch total loss 1.35864949
Trained batch 4220 batch loss 1.16083634 epoch total loss 1.35860252
Trained batch 4221 batch loss 1.16030931 epoch total loss 1.35855556
Trained batch 4222 batch loss 1.08539844 epoch total loss 1.35849082
Trained batch 4223 batch loss 0.98282063 epoch total loss 1.35840189
Trained batch 4224 batch loss 1.25070298 epoch total loss 1.35837638
Trained batch 4225 batch loss 1.05576491 epoch total loss 1.35830474
Trained batch 4226 batch loss 1.41107237 epoch total loss 1.35831726
Trained batch 4227 batch loss 1.67715216 epoch total loss 1.35839272
Trained batch 4228 batch loss 1.42269838 epoch total loss 1.35840786
Trained batch 4229 batch loss 1.61335933 epoch total loss 1.35846817
Trained batch 4230 batch loss 1.78615427 epoch total loss 1.35856926
Trained batch 4231 batch loss 1.75097704 epoch total loss 1.35866201
Trained batch 4232 batch loss 1.58342946 epoch total loss 1.35871518
Trained batch 4233 batch loss 1.49413848 epoch total loss 1.35874712
Trained batch 4234 batch loss 1.48084509 epoch total loss 1.35877597
Trained batch 4235 batch loss 1.34797835 epoch total loss 1.35877347
Trained batch 4236 batch loss 1.45065212 epoch total loss 1.35879517
Trained batch 4237 batch loss 1.56865597 epoch total loss 1.35884476
Trained batch 4238 batch loss 1.43735039 epoch total loss 1.35886335
Trained batch 4239 batch loss 1.40371788 epoch total loss 1.35887396
Trained batch 4240 batch loss 1.42080736 epoch total loss 1.35888851
Trained batch 4241 batch loss 1.28996015 epoch total loss 1.35887229
Trained batch 4242 batch loss 1.28285646 epoch total loss 1.35885441
Trained batch 4243 batch loss 1.44874358 epoch total loss 1.35887551
Trained batch 4244 batch loss 1.59455395 epoch total loss 1.35893118
Trained batch 4245 batch loss 1.419945 epoch total loss 1.35894549
Trained batch 4246 batch loss 1.48218691 epoch total loss 1.35897458
Trained batch 4247 batch loss 1.61644506 epoch total loss 1.35903513
Trained batch 4248 batch loss 1.45346403 epoch total loss 1.35905743
Trained batch 4249 batch loss 1.54846931 epoch total loss 1.35910201
Trained batch 4250 batch loss 1.49918759 epoch total loss 1.35913491
Trained batch 4251 batch loss 1.46638656 epoch total loss 1.35916007
Trained batch 4252 batch loss 1.35856795 epoch total loss 1.35916
Trained batch 4253 batch loss 1.32523918 epoch total loss 1.35915196
Trained batch 4254 batch loss 1.43360424 epoch total loss 1.35916948
Trained batch 4255 batch loss 1.29694068 epoch total loss 1.35915482
Trained batch 4256 batch loss 1.47242236 epoch total loss 1.3591814
Trained batch 4257 batch loss 1.36963534 epoch total loss 1.35918391
Trained batch 4258 batch loss 1.15767205 epoch total loss 1.35913658
Trained batch 4259 batch loss 1.12510085 epoch total loss 1.35908163
Trained batch 4260 batch loss 1.30292821 epoch total loss 1.35906839
Trained batch 4261 batch loss 1.50461745 epoch total loss 1.35910249
Trained batch 4262 batch loss 1.48355377 epoch total loss 1.35913169
Trained batch 4263 batch loss 1.3554337 epoch total loss 1.35913086
Trained batch 4264 batch loss 1.32893503 epoch total loss 1.35912371
Trained batch 4265 batch loss 1.19668984 epoch total loss 1.35908568
Trained batch 4266 batch loss 1.1089201 epoch total loss 1.35902703
Trained batch 4267 batch loss 1.01190281 epoch total loss 1.35894561
Trained batch 4268 batch loss 1.17054439 epoch total loss 1.3589015
Trained batch 4269 batch loss 1.08270502 epoch total loss 1.35883677
Trained batch 4270 batch loss 1.27670383 epoch total loss 1.35881758
Trained batch 4271 batch loss 1.06715715 epoch total loss 1.35874927
Trained batch 4272 batch loss 1.13496923 epoch total loss 1.35869682
Trained batch 4273 batch loss 1.29748738 epoch total loss 1.35868251
Trained batch 4274 batch loss 1.26810431 epoch total loss 1.35866129
Trained batch 4275 batch loss 1.07790947 epoch total loss 1.35859573
Trained batch 4276 batch loss 1.42137909 epoch total loss 1.35861039
Trained batch 4277 batch loss 1.06786489 epoch total loss 1.35854244
Trained batch 4278 batch loss 0.988369465 epoch total loss 1.3584559
Trained batch 4279 batch loss 1.3118118 epoch total loss 1.35844505
Trained batch 4280 batch loss 1.15730119 epoch total loss 1.35839796
Trained batch 4281 batch loss 1.36193657 epoch total loss 1.3583988
Trained batch 4282 batch loss 1.22339344 epoch total loss 1.35836732
Trained batch 4283 batch loss 1.42641759 epoch total loss 1.35838318
Trained batch 4284 batch loss 1.34937358 epoch total loss 1.35838115
Trained batch 4285 batch loss 1.28925145 epoch total loss 1.35836494
Trained batch 4286 batch loss 1.30184984 epoch total loss 1.35835171
Trained batch 4287 batch loss 1.24759746 epoch total loss 1.35832584
Trained batch 4288 batch loss 1.27149725 epoch total loss 1.35830557
Trained batch 4289 batch loss 1.27133465 epoch total loss 1.35828543
Trained batch 4290 batch loss 1.44618928 epoch total loss 1.35830593
Trained batch 4291 batch loss 1.26902795 epoch total loss 1.35828507
Trained batch 4292 batch loss 1.2092855 epoch total loss 1.35825038
Trained batch 4293 batch loss 1.19125104 epoch total loss 1.35821152
Trained batch 4294 batch loss 1.27368641 epoch total loss 1.35819197
Trained batch 4295 batch loss 1.31317842 epoch total loss 1.35818136
Trained batch 4296 batch loss 1.22839 epoch total loss 1.3581512
Trained batch 4297 batch loss 1.25654411 epoch total loss 1.35812759
Trained batch 4298 batch loss 1.23479176 epoch total loss 1.35809886
Trained batch 4299 batch loss 1.14758372 epoch total loss 1.35804987
Trained batch 4300 batch loss 1.15771651 epoch total loss 1.35800326
Trained batch 4301 batch loss 1.1496433 epoch total loss 1.35795474
Trained batch 4302 batch loss 1.1517725 epoch total loss 1.35790682
Trained batch 4303 batch loss 1.26156116 epoch total loss 1.35788453
Trained batch 4304 batch loss 1.23549414 epoch total loss 1.35785604
Trained batch 4305 batch loss 1.33578503 epoch total loss 1.35785091
Trained batch 4306 batch loss 1.3587538 epoch total loss 1.35785115
Trained batch 4307 batch loss 1.26264942 epoch total loss 1.35782909
Trained batch 4308 batch loss 1.46280372 epoch total loss 1.35785353
Trained batch 4309 batch loss 1.25101638 epoch total loss 1.35782874
Trained batch 4310 batch loss 1.21838355 epoch total loss 1.35779631
Trained batch 4311 batch loss 1.0358144 epoch total loss 1.35772157
Trained batch 4312 batch loss 1.05942082 epoch total loss 1.35765243
Trained batch 4313 batch loss 0.968086183 epoch total loss 1.35756218
Trained batch 4314 batch loss 1.00425267 epoch total loss 1.35748029
Trained batch 4315 batch loss 1.37086129 epoch total loss 1.35748339
Trained batch 4316 batch loss 1.37706292 epoch total loss 1.35748792
Trained batch 4317 batch loss 1.49525011 epoch total loss 1.35751987
Trained batch 4318 batch loss 1.27217638 epoch total loss 1.3575
Trained batch 4319 batch loss 1.23554337 epoch total loss 1.3574717
Trained batch 4320 batch loss 1.21996546 epoch total loss 1.35743988
Trained batch 4321 batch loss 1.26482463 epoch total loss 1.35741842
Trained batch 4322 batch loss 1.18767047 epoch total loss 1.35737908
Trained batch 4323 batch loss 1.38894463 epoch total loss 1.35738635
Trained batch 4324 batch loss 1.25322151 epoch total loss 1.35736239
Trained batch 4325 batch loss 1.28169572 epoch total loss 1.35734487
Trained batch 4326 batch loss 1.26914644 epoch total loss 1.35732448
Trained batch 4327 batch loss 1.1562 epoch total loss 1.35727799
Trained batch 4328 batch loss 1.34622931 epoch total loss 1.35727549
Trained batch 4329 batch loss 1.18440902 epoch total loss 1.35723555
Trained batch 4330 batch loss 1.35604656 epoch total loss 1.35723519
Trained batch 4331 batch loss 1.24482059 epoch total loss 1.35720921
Trained batch 4332 batch loss 1.07505095 epoch total loss 1.35714412
Trained batch 4333 batch loss 1.25262403 epoch total loss 1.35712
Trained batch 4334 batch loss 1.28377676 epoch total loss 1.35710299
Trained batch 4335 batch loss 1.09227037 epoch total loss 1.35704195
Trained batch 4336 batch loss 0.995902658 epoch total loss 1.35695875
Trained batch 4337 batch loss 1.27231884 epoch total loss 1.3569392
Trained batch 4338 batch loss 1.24829626 epoch total loss 1.35691428
Trained batch 4339 batch loss 1.30573404 epoch total loss 1.35690248
Trained batch 4340 batch loss 1.13232672 epoch total loss 1.35685062
Trained batch 4341 batch loss 1.1939019 epoch total loss 1.35681307
Trained batch 4342 batch loss 1.18360209 epoch total loss 1.35677326
Trained batch 4343 batch loss 1.15303135 epoch total loss 1.35672629
Trained batch 4344 batch loss 1.42613447 epoch total loss 1.35674226
Trained batch 4345 batch loss 1.28771818 epoch total loss 1.35672641
Trained batch 4346 batch loss 1.15561318 epoch total loss 1.35668015
Trained batch 4347 batch loss 1.11277771 epoch total loss 1.35662401
Trained batch 4348 batch loss 1.34903622 epoch total loss 1.35662234
Trained batch 4349 batch loss 1.35341167 epoch total loss 1.35662162
Trained batch 4350 batch loss 1.42628348 epoch total loss 1.3566376
Trained batch 4351 batch loss 1.38914442 epoch total loss 1.35664511
Trained batch 4352 batch loss 1.24108326 epoch total loss 1.35661852
Trained batch 4353 batch loss 1.17811036 epoch total loss 1.35657752
Trained batch 4354 batch loss 1.16120124 epoch total loss 1.35653269
Trained batch 4355 batch loss 1.0434351 epoch total loss 1.35646081
Trained batch 4356 batch loss 1.14338064 epoch total loss 1.35641193
Trained batch 4357 batch loss 1.08673799 epoch total loss 1.35635006
Trained batch 4358 batch loss 1.18440771 epoch total loss 1.35631061
Trained batch 4359 batch loss 1.28212094 epoch total loss 1.35629368
Trained batch 4360 batch loss 1.37423515 epoch total loss 1.35629773
Trained batch 4361 batch loss 1.2975961 epoch total loss 1.35628414
Trained batch 4362 batch loss 1.28098381 epoch total loss 1.35626686
Trained batch 4363 batch loss 1.34897721 epoch total loss 1.35626519
Trained batch 4364 batch loss 1.31896746 epoch total loss 1.35625672
Trained batch 4365 batch loss 1.41033626 epoch total loss 1.356269
Trained batch 4366 batch loss 1.08492875 epoch total loss 1.35620689
Trained batch 4367 batch loss 1.32226288 epoch total loss 1.35619915
Trained batch 4368 batch loss 1.43570173 epoch total loss 1.35621727
Trained batch 4369 batch loss 1.31749558 epoch total loss 1.35620832
Trained batch 4370 batch loss 1.33282733 epoch total loss 1.35620308
Trained batch 4371 batch loss 1.10647881 epoch total loss 1.35614598
Trained batch 4372 batch loss 1.31345713 epoch total loss 1.3561362
Trained batch 4373 batch loss 1.2574513 epoch total loss 1.35611355
Trained batch 4374 batch loss 1.32992089 epoch total loss 1.35610759
Trained batch 4375 batch loss 1.23177111 epoch total loss 1.35607922
Trained batch 4376 batch loss 1.17943358 epoch total loss 1.35603881
Trained batch 4377 batch loss 1.38230562 epoch total loss 1.35604477
Trained batch 4378 batch loss 1.29711103 epoch total loss 1.3560313
Trained batch 4379 batch loss 1.34784985 epoch total loss 1.35602939
Trained batch 4380 batch loss 1.33442259 epoch total loss 1.3560245
Trained batch 4381 batch loss 1.37640452 epoch total loss 1.35602915
Trained batch 4382 batch loss 1.3593657 epoch total loss 1.35602987
Trained batch 4383 batch loss 1.20079517 epoch total loss 1.35599446
Trained batch 4384 batch loss 1.31264257 epoch total loss 1.35598457
Trained batch 4385 batch loss 1.22112119 epoch total loss 1.35595381
Trained batch 4386 batch loss 1.01392865 epoch total loss 1.35587585
Trained batch 4387 batch loss 1.29332423 epoch total loss 1.35586166
Trained batch 4388 batch loss 1.39285624 epoch total loss 1.35587013
Trained batch 4389 batch loss 1.47696412 epoch total loss 1.35589778
Trained batch 4390 batch loss 1.21677303 epoch total loss 1.35586607
Trained batch 4391 batch loss 1.19043446 epoch total loss 1.3558284
Trained batch 4392 batch loss 1.28486347 epoch total loss 1.35581219
Trained batch 4393 batch loss 1.31431866 epoch total loss 1.35580277
Trained batch 4394 batch loss 1.05467284 epoch total loss 1.35573423
Trained batch 4395 batch loss 1.18237758 epoch total loss 1.35569489
Trained batch 4396 batch loss 1.31023264 epoch total loss 1.3556844
Trained batch 4397 batch loss 1.35819352 epoch total loss 1.35568511
Trained batch 4398 batch loss 1.3971405 epoch total loss 1.35569441
Trained batch 4399 batch loss 1.13418841 epoch total loss 1.35564411
Trained batch 4400 batch loss 1.15159488 epoch total loss 1.35559773
Trained batch 4401 batch loss 1.39040446 epoch total loss 1.3556056
Trained batch 4402 batch loss 1.35549879 epoch total loss 1.3556056
Trained batch 4403 batch loss 1.55030465 epoch total loss 1.35564983
Trained batch 4404 batch loss 1.62589836 epoch total loss 1.35571122
Trained batch 4405 batch loss 1.36169147 epoch total loss 1.35571265
Trained batch 4406 batch loss 1.31878543 epoch total loss 1.35570419
Trained batch 4407 batch loss 1.33143103 epoch total loss 1.3556987
Trained batch 4408 batch loss 1.00859833 epoch total loss 1.35562
Trained batch 4409 batch loss 1.14148617 epoch total loss 1.35557151
Trained batch 4410 batch loss 1.28641415 epoch total loss 1.35555589
Trained batch 4411 batch loss 1.35964918 epoch total loss 1.35555685
Trained batch 4412 batch loss 1.34536076 epoch total loss 1.35555446
Trained batch 4413 batch loss 1.46244466 epoch total loss 1.35557878
Trained batch 4414 batch loss 1.29716349 epoch total loss 1.35556555
Trained batch 4415 batch loss 1.23417521 epoch total loss 1.35553813
Trained batch 4416 batch loss 1.05711675 epoch total loss 1.35547054
Trained batch 4417 batch loss 1.07759809 epoch total loss 1.3554076
Trained batch 4418 batch loss 1.14243829 epoch total loss 1.35535944
Trained batch 4419 batch loss 1.28104138 epoch total loss 1.35534263
Trained batch 4420 batch loss 1.29322505 epoch total loss 1.35532868
Trained batch 4421 batch loss 1.356148 epoch total loss 1.3553288
Trained batch 4422 batch loss 1.15315104 epoch total loss 1.35528314
Trained batch 4423 batch loss 1.5770843 epoch total loss 1.35533333
Trained batch 4424 batch loss 1.30977368 epoch total loss 1.35532296
Trained batch 4425 batch loss 1.0631187 epoch total loss 1.35525692
Trained batch 4426 batch loss 0.883573711 epoch total loss 1.35515034
Trained batch 4427 batch loss 1.01777327 epoch total loss 1.35507417
Trained batch 4428 batch loss 1.00161755 epoch total loss 1.3549943
Trained batch 4429 batch loss 0.929028392 epoch total loss 1.3548981
Trained batch 4430 batch loss 1.04576874 epoch total loss 1.35482836
Trained batch 4431 batch loss 0.937359154 epoch total loss 1.35473418
Trained batch 4432 batch loss 1.05840659 epoch total loss 1.35466731
Trained batch 4433 batch loss 1.03442669 epoch total loss 1.35459518
Trained batch 4434 batch loss 0.977491856 epoch total loss 1.35451019
Trained batch 4435 batch loss 1.3807137 epoch total loss 1.35451603
Trained batch 4436 batch loss 1.12512958 epoch total loss 1.35446429
Trained batch 4437 batch loss 1.21402192 epoch total loss 1.3544327
Trained batch 4438 batch loss 1.41930747 epoch total loss 1.35444725
Trained batch 4439 batch loss 1.44695735 epoch total loss 1.35446811
Trained batch 4440 batch loss 1.26024878 epoch total loss 1.35444689
Trained batch 4441 batch loss 1.57052052 epoch total loss 1.35449553
Trained batch 4442 batch loss 1.49103785 epoch total loss 1.35452628
Trained batch 4443 batch loss 1.42550826 epoch total loss 1.35454214
Trained batch 4444 batch loss 1.59789205 epoch total loss 1.35459685
Trained batch 4445 batch loss 1.68023944 epoch total loss 1.35467017
Trained batch 4446 batch loss 1.66562533 epoch total loss 1.35474
Trained batch 4447 batch loss 1.69377685 epoch total loss 1.35481632
Trained batch 4448 batch loss 1.63858616 epoch total loss 1.35488009
Trained batch 4449 batch loss 1.32203293 epoch total loss 1.35487282
Trained batch 4450 batch loss 1.02189529 epoch total loss 1.35479796
Trained batch 4451 batch loss 1.1202991 epoch total loss 1.35474527
Trained batch 4452 batch loss 1.39266717 epoch total loss 1.35475373
Trained batch 4453 batch loss 1.29574227 epoch total loss 1.3547405
Trained batch 4454 batch loss 1.16989732 epoch total loss 1.35469902
Trained batch 4455 batch loss 1.12039971 epoch total loss 1.35464656
Trained batch 4456 batch loss 1.01721168 epoch total loss 1.35457075
Trained batch 4457 batch loss 1.37680387 epoch total loss 1.35457575
Trained batch 4458 batch loss 1.27732062 epoch total loss 1.35455847
Trained batch 4459 batch loss 1.16047478 epoch total loss 1.35451496
Trained batch 4460 batch loss 1.35662723 epoch total loss 1.35451543
Trained batch 4461 batch loss 1.38107443 epoch total loss 1.35452127
Trained batch 4462 batch loss 1.40539408 epoch total loss 1.35453272
Trained batch 4463 batch loss 1.22095239 epoch total loss 1.3545028
Trained batch 4464 batch loss 1.30579495 epoch total loss 1.35449183
Trained batch 4465 batch loss 1.29959989 epoch total loss 1.35447967
Trained batch 4466 batch loss 1.27718008 epoch total loss 1.35446239
Trained batch 4467 batch loss 1.15668106 epoch total loss 1.35441804
Trained batch 4468 batch loss 1.38658106 epoch total loss 1.35442531
Trained batch 4469 batch loss 1.38165796 epoch total loss 1.35443139
Trained batch 4470 batch loss 1.3721534 epoch total loss 1.35443544
Trained batch 4471 batch loss 1.40808153 epoch total loss 1.35444736
Trained batch 4472 batch loss 1.3141011 epoch total loss 1.3544383
Trained batch 4473 batch loss 1.29901135 epoch total loss 1.35442591
Trained batch 4474 batch loss 1.30984926 epoch total loss 1.35441601
Trained batch 4475 batch loss 1.2218231 epoch total loss 1.35438633
Trained batch 4476 batch loss 1.11081195 epoch total loss 1.35433197
Trained batch 4477 batch loss 1.32076263 epoch total loss 1.35432446
Trained batch 4478 batch loss 1.47504067 epoch total loss 1.3543514
Trained batch 4479 batch loss 1.45719254 epoch total loss 1.35437429
Trained batch 4480 batch loss 1.38592362 epoch total loss 1.35438132
Trained batch 4481 batch loss 1.36361313 epoch total loss 1.35438347
Trained batch 4482 batch loss 1.36475992 epoch total loss 1.35438573
Trained batch 4483 batch loss 1.30246878 epoch total loss 1.35437417
Trained batch 4484 batch loss 1.22906899 epoch total loss 1.35434616
Trained batch 4485 batch loss 1.21694469 epoch total loss 1.35431552
Trained batch 4486 batch loss 1.13534749 epoch total loss 1.35426664
Trained batch 4487 batch loss 1.39234948 epoch total loss 1.35427523
Trained batch 4488 batch loss 1.26819921 epoch total loss 1.35425603
Trained batch 4489 batch loss 1.12370598 epoch total loss 1.35420454
Trained batch 4490 batch loss 1.20829356 epoch total loss 1.35417211
Trained batch 4491 batch loss 1.25815225 epoch total loss 1.35415077
Trained batch 4492 batch loss 0.937753439 epoch total loss 1.35405815
Trained batch 4493 batch loss 1.22618806 epoch total loss 1.35402966
Trained batch 4494 batch loss 1.14648461 epoch total loss 1.35398352
Trained batch 4495 batch loss 1.31921721 epoch total loss 1.35397577
Trained batch 4496 batch loss 1.32177722 epoch total loss 1.35396862
Trained batch 4497 batch loss 1.2126745 epoch total loss 1.35393727
Trained batch 4498 batch loss 1.19879842 epoch total loss 1.3539027
Trained batch 4499 batch loss 1.35418427 epoch total loss 1.3539027
Trained batch 4500 batch loss 1.21945894 epoch total loss 1.35387278
Trained batch 4501 batch loss 1.37986767 epoch total loss 1.35387862
Trained batch 4502 batch loss 1.42868948 epoch total loss 1.35389519
Trained batch 4503 batch loss 1.31647396 epoch total loss 1.35388696
Trained batch 4504 batch loss 1.31102467 epoch total loss 1.35387743
Trained batch 4505 batch loss 1.19234848 epoch total loss 1.35384154
Trained batch 4506 batch loss 1.0787003 epoch total loss 1.35378051
Trained batch 4507 batch loss 1.32479846 epoch total loss 1.35377407
Trained batch 4508 batch loss 1.00666142 epoch total loss 1.35369706
Trained batch 4509 batch loss 1.03966618 epoch total loss 1.35362732
Trained batch 4510 batch loss 1.02796054 epoch total loss 1.35355508
Trained batch 4511 batch loss 0.945147157 epoch total loss 1.3534646
Trained batch 4512 batch loss 1.07549906 epoch total loss 1.35340309
Trained batch 4513 batch loss 1.33047819 epoch total loss 1.35339797
Trained batch 4514 batch loss 1.25210655 epoch total loss 1.35337555
Trained batch 4515 batch loss 1.33340323 epoch total loss 1.35337114
Trained batch 4516 batch loss 1.35253739 epoch total loss 1.3533709
Trained batch 4517 batch loss 1.18868852 epoch total loss 1.35333443
Trained batch 4518 batch loss 1.28712988 epoch total loss 1.35331976
Trained batch 4519 batch loss 1.25454342 epoch total loss 1.35329795
Trained batch 4520 batch loss 1.16567612 epoch total loss 1.35325634
Trained batch 4521 batch loss 1.11191392 epoch total loss 1.35320294
Trained batch 4522 batch loss 1.34148741 epoch total loss 1.35320032
Trained batch 4523 batch loss 1.23841119 epoch total loss 1.35317492
Trained batch 4524 batch loss 1.20947874 epoch total loss 1.3531431
Trained batch 4525 batch loss 1.18594837 epoch total loss 1.35310626
Trained batch 4526 batch loss 1.21532369 epoch total loss 1.35307574
Trained batch 4527 batch loss 1.16077948 epoch total loss 1.3530333
Trained batch 4528 batch loss 1.05856156 epoch total loss 1.35296822
Trained batch 4529 batch loss 1.33762336 epoch total loss 1.35296476
Trained batch 4530 batch loss 1.18144298 epoch total loss 1.35292697
Trained batch 4531 batch loss 1.31921935 epoch total loss 1.35291958
Trained batch 4532 batch loss 1.45861459 epoch total loss 1.35294282
Trained batch 4533 batch loss 1.39384627 epoch total loss 1.35295188
Trained batch 4534 batch loss 1.29788625 epoch total loss 1.35293984
Trained batch 4535 batch loss 1.29898214 epoch total loss 1.3529278
Trained batch 4536 batch loss 1.44480097 epoch total loss 1.35294807
Trained batch 4537 batch loss 1.50163054 epoch total loss 1.35298085
Trained batch 4538 batch loss 1.73031759 epoch total loss 1.35306406
Trained batch 4539 batch loss 1.53809786 epoch total loss 1.35310483
Trained batch 4540 batch loss 1.32210279 epoch total loss 1.35309803
Trained batch 4541 batch loss 1.34298658 epoch total loss 1.35309577
Trained batch 4542 batch loss 1.2614485 epoch total loss 1.3530755
Trained batch 4543 batch loss 1.31494749 epoch total loss 1.35306716
Trained batch 4544 batch loss 1.45519471 epoch total loss 1.35308957
Trained batch 4545 batch loss 1.45599949 epoch total loss 1.35311222
Trained batch 4546 batch loss 1.30396223 epoch total loss 1.35310149
Trained batch 4547 batch loss 1.41259742 epoch total loss 1.35311449
Trained batch 4548 batch loss 1.33481979 epoch total loss 1.35311055
Trained batch 4549 batch loss 1.37151456 epoch total loss 1.3531146
Trained batch 4550 batch loss 1.34312868 epoch total loss 1.35311246
Trained batch 4551 batch loss 1.29627419 epoch total loss 1.3531
Trained batch 4552 batch loss 1.35939169 epoch total loss 1.35310137
Trained batch 4553 batch loss 1.42578578 epoch total loss 1.35311735
Trained batch 4554 batch loss 1.44160557 epoch total loss 1.35313666
Trained batch 4555 batch loss 1.41409409 epoch total loss 1.35315013
Trained batch 4556 batch loss 1.44207609 epoch total loss 1.35316956
Trained batch 4557 batch loss 1.33940351 epoch total loss 1.35316658
Trained batch 4558 batch loss 1.30721331 epoch total loss 1.35315645
Trained batch 4559 batch loss 1.4477098 epoch total loss 1.35317719
Trained batch 4560 batch loss 1.0935601 epoch total loss 1.35312033
Trained batch 4561 batch loss 1.4639436 epoch total loss 1.35314453
Trained batch 4562 batch loss 1.3206073 epoch total loss 1.35313749
Trained batch 4563 batch loss 1.25348496 epoch total loss 1.35311568
Trained batch 4564 batch loss 1.15108657 epoch total loss 1.35307133
Trained batch 4565 batch loss 1.34247828 epoch total loss 1.35306895
Trained batch 4566 batch loss 1.43580961 epoch total loss 1.35308707
Trained batch 4567 batch loss 1.32937241 epoch total loss 1.35308194
Trained batch 4568 batch loss 1.39026213 epoch total loss 1.35309
Trained batch 4569 batch loss 1.13024187 epoch total loss 1.35304129
Trained batch 4570 batch loss 1.22341251 epoch total loss 1.35301304
Trained batch 4571 batch loss 1.15297163 epoch total loss 1.35296929
Trained batch 4572 batch loss 1.19811857 epoch total loss 1.35293543
Trained batch 4573 batch loss 1.28521729 epoch total loss 1.35292053
Trained batch 4574 batch loss 1.17237139 epoch total loss 1.35288107
Trained batch 4575 batch loss 1.39749503 epoch total loss 1.35289085
Trained batch 4576 batch loss 1.37822413 epoch total loss 1.35289645
Trained batch 4577 batch loss 1.31756401 epoch total loss 1.3528887
Trained batch 4578 batch loss 1.39015889 epoch total loss 1.35289681
Trained batch 4579 batch loss 1.45144916 epoch total loss 1.35291839
Trained batch 4580 batch loss 1.30686641 epoch total loss 1.35290825
Trained batch 4581 batch loss 1.38822985 epoch total loss 1.352916
Trained batch 4582 batch loss 1.35987282 epoch total loss 1.35291743
Trained batch 4583 batch loss 1.22147799 epoch total loss 1.35288882
Trained batch 4584 batch loss 1.30312967 epoch total loss 1.35287797
Trained batch 4585 batch loss 1.31650054 epoch total loss 1.35287011
Trained batch 4586 batch loss 1.17557478 epoch total loss 1.35283148
Trained batch 4587 batch loss 1.20950246 epoch total loss 1.35280013
Trained batch 4588 batch loss 1.23486066 epoch total loss 1.3527745
Trained batch 4589 batch loss 1.30053711 epoch total loss 1.35276318
Trained batch 4590 batch loss 1.20761895 epoch total loss 1.35273147
Trained batch 4591 batch loss 1.08038521 epoch total loss 1.35267222
Trained batch 4592 batch loss 1.42082334 epoch total loss 1.35268712
Trained batch 4593 batch loss 1.25583661 epoch total loss 1.35266602
Trained batch 4594 batch loss 1.37345362 epoch total loss 1.35267055
Trained batch 4595 batch loss 1.17146039 epoch total loss 1.35263109
Trained batch 4596 batch loss 1.14763689 epoch total loss 1.35258639
Trained batch 4597 batch loss 1.14351797 epoch total loss 1.35254097
Trained batch 4598 batch loss 1.1834445 epoch total loss 1.35250425
Trained batch 4599 batch loss 1.25508106 epoch total loss 1.35248303
Trained batch 4600 batch loss 1.12098098 epoch total loss 1.35243273
Trained batch 4601 batch loss 1.07557106 epoch total loss 1.35237253
Trained batch 4602 batch loss 1.1970557 epoch total loss 1.35233879
Trained batch 4603 batch loss 1.40932584 epoch total loss 1.35235119
Trained batch 4604 batch loss 1.49210024 epoch total loss 1.35238159
Trained batch 4605 batch loss 1.72159612 epoch total loss 1.35246181
Trained batch 4606 batch loss 1.43973553 epoch total loss 1.35248077
Trained batch 4607 batch loss 1.61437917 epoch total loss 1.35253763
Trained batch 4608 batch loss 1.33632374 epoch total loss 1.35253406
Trained batch 4609 batch loss 1.4680208 epoch total loss 1.35255921
Trained batch 4610 batch loss 1.33755207 epoch total loss 1.35255587
Trained batch 4611 batch loss 1.3729347 epoch total loss 1.3525604
Trained batch 4612 batch loss 1.38611305 epoch total loss 1.35256767
Trained batch 4613 batch loss 1.27014041 epoch total loss 1.35254979
Trained batch 4614 batch loss 1.36658442 epoch total loss 1.35255277
Trained batch 4615 batch loss 1.45851302 epoch total loss 1.35257578
Trained batch 4616 batch loss 1.40123272 epoch total loss 1.35258639
Trained batch 4617 batch loss 1.25289655 epoch total loss 1.35256481
Trained batch 4618 batch loss 1.43308067 epoch total loss 1.35258222
Trained batch 4619 batch loss 1.38461351 epoch total loss 1.35258913
Trained batch 4620 batch loss 1.37785292 epoch total loss 1.35259461
Trained batch 4621 batch loss 1.14409852 epoch total loss 1.35254955
Trained batch 4622 batch loss 1.31241608 epoch total loss 1.35254085
Trained batch 4623 batch loss 1.40559387 epoch total loss 1.35255241
Trained batch 4624 batch loss 1.25437117 epoch total loss 1.35253119
Trained batch 4625 batch loss 1.13400543 epoch total loss 1.35248387
Trained batch 4626 batch loss 1.24497938 epoch total loss 1.35246062
Trained batch 4627 batch loss 1.34100676 epoch total loss 1.35245812
Trained batch 4628 batch loss 1.25795925 epoch total loss 1.35243762
Trained batch 4629 batch loss 1.09399295 epoch total loss 1.35238183
Trained batch 4630 batch loss 1.16111779 epoch total loss 1.35234046
Trained batch 4631 batch loss 1.47674441 epoch total loss 1.35236728
Trained batch 4632 batch loss 1.47368562 epoch total loss 1.35239351
Trained batch 4633 batch loss 1.29387665 epoch total loss 1.35238087
Trained batch 4634 batch loss 1.29909039 epoch total loss 1.35236943
Trained batch 4635 batch loss 1.54517722 epoch total loss 1.35241103
Trained batch 4636 batch loss 1.15043211 epoch total loss 1.35236752
Trained batch 4637 batch loss 1.32214236 epoch total loss 1.35236096
Trained batch 4638 batch loss 1.2711184 epoch total loss 1.35234344
Trained batch 4639 batch loss 1.32203913 epoch total loss 1.352337
Trained batch 4640 batch loss 1.13035131 epoch total loss 1.35228908
Trained batch 4641 batch loss 1.191944 epoch total loss 1.35225463
Trained batch 4642 batch loss 1.13950908 epoch total loss 1.35220873
Trained batch 4643 batch loss 1.41211939 epoch total loss 1.35222173
Trained batch 4644 batch loss 1.39042306 epoch total loss 1.35223
Trained batch 4645 batch loss 1.20445335 epoch total loss 1.35219812
Trained batch 4646 batch loss 1.29020119 epoch total loss 1.35218477
Trained batch 4647 batch loss 1.20500338 epoch total loss 1.35215318
Trained batch 4648 batch loss 1.34970975 epoch total loss 1.35215259
Trained batch 4649 batch loss 1.40148163 epoch total loss 1.3521632
Trained batch 4650 batch loss 1.33124137 epoch total loss 1.35215867
Trained batch 4651 batch loss 1.2455225 epoch total loss 1.35213566
Trained batch 4652 batch loss 1.25271511 epoch total loss 1.35211444
Trained batch 4653 batch loss 1.15511429 epoch total loss 1.35207212
Trained batch 4654 batch loss 1.09421849 epoch total loss 1.35201669
Trained batch 4655 batch loss 1.15330839 epoch total loss 1.35197401
Trained batch 4656 batch loss 1.34522259 epoch total loss 1.35197258
Trained batch 4657 batch loss 1.09456146 epoch total loss 1.35191727
Trained batch 4658 batch loss 1.21084654 epoch total loss 1.35188699
Trained batch 4659 batch loss 1.07352233 epoch total loss 1.35182738
Trained batch 4660 batch loss 0.994718254 epoch total loss 1.35175073
Trained batch 4661 batch loss 1.12473142 epoch total loss 1.35170197
Trained batch 4662 batch loss 1.07101691 epoch total loss 1.35164165
Trained batch 4663 batch loss 0.959385514 epoch total loss 1.35155761
Trained batch 4664 batch loss 1.04714119 epoch total loss 1.3514924
Trained batch 4665 batch loss 0.974338531 epoch total loss 1.35141146
Trained batch 4666 batch loss 1.14548862 epoch total loss 1.35136735
Trained batch 4667 batch loss 1.09854794 epoch total loss 1.35131323
Trained batch 4668 batch loss 1.03649187 epoch total loss 1.35124576
Trained batch 4669 batch loss 1.33761096 epoch total loss 1.35124278
Trained batch 4670 batch loss 1.6008606 epoch total loss 1.35129631
Trained batch 4671 batch loss 1.4481039 epoch total loss 1.35131705
Trained batch 4672 batch loss 1.62840354 epoch total loss 1.35137641
Trained batch 4673 batch loss 1.44728017 epoch total loss 1.35139692
Trained batch 4674 batch loss 1.33911574 epoch total loss 1.3513943
Trained batch 4675 batch loss 1.22328317 epoch total loss 1.35136688
Trained batch 4676 batch loss 1.2408303 epoch total loss 1.35134315
Trained batch 4677 batch loss 1.42824209 epoch total loss 1.35135961
Trained batch 4678 batch loss 1.40682662 epoch total loss 1.35137153
Trained batch 4679 batch loss 1.43703163 epoch total loss 1.35138977
Trained batch 4680 batch loss 1.66788173 epoch total loss 1.35145748
Trained batch 4681 batch loss 1.44447291 epoch total loss 1.35147727
Trained batch 4682 batch loss 1.2108357 epoch total loss 1.35144722
Trained batch 4683 batch loss 1.30619323 epoch total loss 1.35143757
Trained batch 4684 batch loss 1.41158903 epoch total loss 1.35145044
Trained batch 4685 batch loss 1.46298158 epoch total loss 1.35147417
Trained batch 4686 batch loss 1.56398737 epoch total loss 1.35151958
Trained batch 4687 batch loss 1.46447134 epoch total loss 1.35154366
Trained batch 4688 batch loss 1.29146945 epoch total loss 1.35153079
Trained batch 4689 batch loss 1.38305247 epoch total loss 1.35153747
Trained batch 4690 batch loss 1.37482405 epoch total loss 1.35154247
Trained batch 4691 batch loss 1.32747889 epoch total loss 1.35153747
Trained batch 4692 batch loss 1.25634861 epoch total loss 1.35151708
Trained batch 4693 batch loss 1.25836754 epoch total loss 1.35149729
Trained batch 4694 batch loss 1.2537452 epoch total loss 1.35147643
Trained batch 4695 batch loss 1.30316591 epoch total loss 1.35146618
Trained batch 4696 batch loss 1.28382421 epoch total loss 1.35145175
Trained batch 4697 batch loss 1.27806973 epoch total loss 1.35143614
Trained batch 4698 batch loss 1.28062797 epoch total loss 1.351421
Trained batch 4699 batch loss 1.33784831 epoch total loss 1.35141814
Trained batch 4700 batch loss 1.27182245 epoch total loss 1.35140121
Trained batch 4701 batch loss 1.56363535 epoch total loss 1.35144639
Trained batch 4702 batch loss 1.27602434 epoch total loss 1.3514303
Trained batch 4703 batch loss 1.51062155 epoch total loss 1.35146415
Trained batch 4704 batch loss 1.4032464 epoch total loss 1.35147524
Trained batch 4705 batch loss 1.19976676 epoch total loss 1.35144293
Trained batch 4706 batch loss 1.27457571 epoch total loss 1.3514266
Trained batch 4707 batch loss 1.26365042 epoch total loss 1.35140789
Trained batch 4708 batch loss 1.34600735 epoch total loss 1.35140681
Trained batch 4709 batch loss 1.23562551 epoch total loss 1.35138226
Trained batch 4710 batch loss 1.51565242 epoch total loss 1.35141718
Trained batch 4711 batch loss 1.45210826 epoch total loss 1.35143852
Trained batch 4712 batch loss 1.09713542 epoch total loss 1.35138452
Trained batch 4713 batch loss 1.15175176 epoch total loss 1.3513422
Trained batch 4714 batch loss 1.15830564 epoch total loss 1.35130131
Trained batch 4715 batch loss 1.36705518 epoch total loss 1.35130465
Trained batch 4716 batch loss 1.56448436 epoch total loss 1.35134983
Trained batch 4717 batch loss 1.36087942 epoch total loss 1.35135186
Trained batch 4718 batch loss 1.50735128 epoch total loss 1.35138488
Trained batch 4719 batch loss 1.24465263 epoch total loss 1.35136223
Trained batch 4720 batch loss 1.31584871 epoch total loss 1.35135472
Trained batch 4721 batch loss 1.19062328 epoch total loss 1.35132074
Trained batch 4722 batch loss 1.24201453 epoch total loss 1.35129762
Trained batch 4723 batch loss 1.22157967 epoch total loss 1.35127008
Trained batch 4724 batch loss 1.15222216 epoch total loss 1.351228
Trained batch 4725 batch loss 1.23700893 epoch total loss 1.3512038
Trained batch 4726 batch loss 1.47007084 epoch total loss 1.35122895
Trained batch 4727 batch loss 1.22323513 epoch total loss 1.35120189
Trained batch 4728 batch loss 1.3852253 epoch total loss 1.35120904
Trained batch 4729 batch loss 1.36754107 epoch total loss 1.35121262
Trained batch 4730 batch loss 1.22510362 epoch total loss 1.35118592
Trained batch 4731 batch loss 1.3181957 epoch total loss 1.351179
Trained batch 4732 batch loss 1.23006511 epoch total loss 1.35115337
Trained batch 4733 batch loss 1.14116466 epoch total loss 1.35110903
Trained batch 4734 batch loss 1.27679682 epoch total loss 1.35109329
Trained batch 4735 batch loss 1.4873606 epoch total loss 1.35112202
Trained batch 4736 batch loss 1.43529654 epoch total loss 1.35113978
Trained batch 4737 batch loss 1.26844263 epoch total loss 1.35112238
Trained batch 4738 batch loss 1.30846572 epoch total loss 1.35111344
Trained batch 4739 batch loss 1.26544571 epoch total loss 1.35109532
Trained batch 4740 batch loss 1.1434052 epoch total loss 1.35105157
Trained batch 4741 batch loss 1.16980171 epoch total loss 1.3510133
Trained batch 4742 batch loss 1.21760607 epoch total loss 1.35098529
Trained batch 4743 batch loss 1.17563832 epoch total loss 1.35094833
Trained batch 4744 batch loss 1.24845994 epoch total loss 1.35092676
Trained batch 4745 batch loss 1.06873226 epoch total loss 1.35086727
Trained batch 4746 batch loss 1.1472019 epoch total loss 1.35082436
Trained batch 4747 batch loss 1.22111964 epoch total loss 1.35079706
Trained batch 4748 batch loss 1.11297083 epoch total loss 1.35074687
Trained batch 4749 batch loss 1.06042612 epoch total loss 1.35068572
Trained batch 4750 batch loss 1.08242655 epoch total loss 1.35062933
Trained batch 4751 batch loss 1.13534188 epoch total loss 1.35058403
Trained batch 4752 batch loss 1.0818491 epoch total loss 1.35052752
Trained batch 4753 batch loss 1.12645328 epoch total loss 1.35048032
Trained batch 4754 batch loss 1.2054925 epoch total loss 1.3504498
Trained batch 4755 batch loss 1.33593047 epoch total loss 1.35044682
Trained batch 4756 batch loss 1.15568066 epoch total loss 1.35040581
Trained batch 4757 batch loss 1.19230664 epoch total loss 1.35037267
Trained batch 4758 batch loss 1.19229245 epoch total loss 1.35033941
Trained batch 4759 batch loss 1.08496857 epoch total loss 1.35028362
Trained batch 4760 batch loss 1.36369419 epoch total loss 1.35028648
Trained batch 4761 batch loss 1.25281084 epoch total loss 1.3502661
Trained batch 4762 batch loss 1.10521317 epoch total loss 1.3502146
Trained batch 4763 batch loss 1.20751059 epoch total loss 1.35018456
Trained batch 4764 batch loss 1.15771127 epoch total loss 1.35014415
Trained batch 4765 batch loss 1.05334675 epoch total loss 1.35008192
Trained batch 4766 batch loss 0.980131865 epoch total loss 1.3500042
Trained batch 4767 batch loss 0.93328023 epoch total loss 1.34991682
Trained batch 4768 batch loss 1.09899771 epoch total loss 1.34986413
Trained batch 4769 batch loss 1.18078279 epoch total loss 1.34982872
Trained batch 4770 batch loss 1.18263388 epoch total loss 1.34979367
Trained batch 4771 batch loss 1.24328637 epoch total loss 1.34977126
Trained batch 4772 batch loss 1.08149946 epoch total loss 1.34971511
Trained batch 4773 batch loss 1.18125367 epoch total loss 1.34967971
Trained batch 4774 batch loss 1.12421417 epoch total loss 1.3496325
Trained batch 4775 batch loss 1.11411452 epoch total loss 1.34958315
Trained batch 4776 batch loss 1.10978007 epoch total loss 1.34953296
Trained batch 4777 batch loss 1.0752542 epoch total loss 1.34947562
Trained batch 4778 batch loss 1.11740983 epoch total loss 1.34942698
Trained batch 4779 batch loss 1.03007376 epoch total loss 1.34936023
Trained batch 4780 batch loss 1.07855964 epoch total loss 1.34930348
Trained batch 4781 batch loss 1.24695373 epoch total loss 1.34928215
Trained batch 4782 batch loss 1.20907021 epoch total loss 1.34925282
Trained batch 4783 batch loss 1.28039289 epoch total loss 1.3492384
Trained batch 4784 batch loss 1.14772892 epoch total loss 1.34919631
Trained batch 4785 batch loss 1.50731146 epoch total loss 1.34922934
Trained batch 4786 batch loss 1.27447665 epoch total loss 1.34921372
Trained batch 4787 batch loss 1.33422256 epoch total loss 1.3492105
Trained batch 4788 batch loss 1.20324934 epoch total loss 1.34918
Trained batch 4789 batch loss 1.25292099 epoch total loss 1.34916
Trained batch 4790 batch loss 1.22621572 epoch total loss 1.34913421
Trained batch 4791 batch loss 1.129987 epoch total loss 1.34908843
Trained batch 4792 batch loss 1.29266727 epoch total loss 1.34907663
Trained batch 4793 batch loss 1.26567471 epoch total loss 1.34905922
Trained batch 4794 batch loss 1.24832559 epoch total loss 1.34903824
Trained batch 4795 batch loss 1.32647109 epoch total loss 1.34903359
Trained batch 4796 batch loss 1.52617383 epoch total loss 1.34907055
Trained batch 4797 batch loss 1.31732416 epoch total loss 1.34906399
Trained batch 4798 batch loss 1.09842825 epoch total loss 1.34901178
Trained batch 4799 batch loss 1.53450894 epoch total loss 1.34905052
Trained batch 4800 batch loss 1.32642889 epoch total loss 1.34904587
Trained batch 4801 batch loss 1.43794966 epoch total loss 1.34906435
Trained batch 4802 batch loss 1.40363407 epoch total loss 1.34907579
Trained batch 4803 batch loss 1.2061944 epoch total loss 1.34904599
Trained batch 4804 batch loss 1.48121285 epoch total loss 1.34907353
Trained batch 4805 batch loss 1.44535267 epoch total loss 1.34909356
Trained batch 4806 batch loss 1.3701086 epoch total loss 1.34909797
Trained batch 4807 batch loss 1.4966445 epoch total loss 1.3491286
Trained batch 4808 batch loss 1.31367755 epoch total loss 1.34912121
Trained batch 4809 batch loss 1.38833761 epoch total loss 1.34912932
Trained batch 4810 batch loss 1.39977 epoch total loss 1.34913993
Trained batch 4811 batch loss 1.4346323 epoch total loss 1.34915757
Trained batch 4812 batch loss 1.44468021 epoch total loss 1.34917748
Trained batch 4813 batch loss 1.42648578 epoch total loss 1.34919357
Trained batch 4814 batch loss 1.37441385 epoch total loss 1.34919882
Trained batch 4815 batch loss 1.04374504 epoch total loss 1.3491354
Trained batch 4816 batch loss 1.13239908 epoch total loss 1.34909034
Trained batch 4817 batch loss 1.17248273 epoch total loss 1.34905374
Trained batch 4818 batch loss 1.20996499 epoch total loss 1.34902477
Trained batch 4819 batch loss 1.235677 epoch total loss 1.34900129
Trained batch 4820 batch loss 1.14853847 epoch total loss 1.34895968
Trained batch 4821 batch loss 1.17218852 epoch total loss 1.34892309
Trained batch 4822 batch loss 1.26720357 epoch total loss 1.34890616
Trained batch 4823 batch loss 1.44906116 epoch total loss 1.3489269
Trained batch 4824 batch loss 1.63383341 epoch total loss 1.34898591
Trained batch 4825 batch loss 1.31317866 epoch total loss 1.34897852
Trained batch 4826 batch loss 1.26563549 epoch total loss 1.34896123
Trained batch 4827 batch loss 1.50924063 epoch total loss 1.34899449
Trained batch 4828 batch loss 1.69400775 epoch total loss 1.3490659
Trained batch 4829 batch loss 1.26450491 epoch total loss 1.34904838
Trained batch 4830 batch loss 1.16243386 epoch total loss 1.34900975
Trained batch 4831 batch loss 1.0794524 epoch total loss 1.34895396
Trained batch 4832 batch loss 1.25969791 epoch total loss 1.3489356
Trained batch 4833 batch loss 1.14556944 epoch total loss 1.34889352
Trained batch 4834 batch loss 1.13975966 epoch total loss 1.34885013
Trained batch 4835 batch loss 1.34531426 epoch total loss 1.34884942
Trained batch 4836 batch loss 1.19618785 epoch total loss 1.34881794
Trained batch 4837 batch loss 1.186257 epoch total loss 1.34878421
Trained batch 4838 batch loss 1.18861175 epoch total loss 1.34875107
Trained batch 4839 batch loss 1.16265798 epoch total loss 1.34871268
Trained batch 4840 batch loss 1.26709747 epoch total loss 1.34869576
Trained batch 4841 batch loss 1.33612108 epoch total loss 1.34869313
Trained batch 4842 batch loss 1.23420906 epoch total loss 1.34866953
Trained batch 4843 batch loss 1.18977809 epoch total loss 1.34863675
Trained batch 4844 batch loss 1.09658909 epoch total loss 1.34858477
Trained batch 4845 batch loss 1.14021575 epoch total loss 1.34854174
Trained batch 4846 batch loss 1.11342883 epoch total loss 1.34849322
Trained batch 4847 batch loss 1.12406409 epoch total loss 1.34844685
Trained batch 4848 batch loss 1.19322133 epoch total loss 1.3484149
Trained batch 4849 batch loss 1.20776892 epoch total loss 1.34838593
Trained batch 4850 batch loss 1.22486115 epoch total loss 1.34836054
Trained batch 4851 batch loss 1.26419449 epoch total loss 1.34834313
Trained batch 4852 batch loss 1.3148694 epoch total loss 1.34833622
Trained batch 4853 batch loss 1.20356369 epoch total loss 1.34830642
Trained batch 4854 batch loss 1.45169866 epoch total loss 1.34832776
Trained batch 4855 batch loss 1.10952926 epoch total loss 1.34827852
Trained batch 4856 batch loss 1.29167664 epoch total loss 1.34826684
Trained batch 4857 batch loss 1.33500576 epoch total loss 1.3482641
Trained batch 4858 batch loss 1.09618163 epoch total loss 1.34821212
Trained batch 4859 batch loss 1.19598 epoch total loss 1.34818077
Trained batch 4860 batch loss 1.11875415 epoch total loss 1.34813356
Trained batch 4861 batch loss 1.15366375 epoch total loss 1.34809363
Trained batch 4862 batch loss 1.25968599 epoch total loss 1.34807539
Trained batch 4863 batch loss 1.22522306 epoch total loss 1.34805012
Trained batch 4864 batch loss 1.02943063 epoch total loss 1.34798467
Trained batch 4865 batch loss 1.06769276 epoch total loss 1.34792709
Trained batch 4866 batch loss 1.28649759 epoch total loss 1.34791446
Trained batch 4867 batch loss 1.18077755 epoch total loss 1.34788013
Trained batch 4868 batch loss 1.42164361 epoch total loss 1.34789526
Trained batch 4869 batch loss 1.31117272 epoch total loss 1.34788775
Trained batch 4870 batch loss 1.34331977 epoch total loss 1.3478868
Trained batch 4871 batch loss 1.42097259 epoch total loss 1.3479017
Trained batch 4872 batch loss 1.46681166 epoch total loss 1.34792614
Trained batch 4873 batch loss 1.43172669 epoch total loss 1.34794331
Trained batch 4874 batch loss 1.19147885 epoch total loss 1.34791124
Trained batch 4875 batch loss 1.29946446 epoch total loss 1.34790123
Trained batch 4876 batch loss 1.27785707 epoch total loss 1.34788692
Trained batch 4877 batch loss 1.36203563 epoch total loss 1.34788978
Trained batch 4878 batch loss 1.36619127 epoch total loss 1.34789348
Trained batch 4879 batch loss 1.38017321 epoch total loss 1.34790015
Trained batch 4880 batch loss 1.46199858 epoch total loss 1.34792352
Trained batch 4881 batch loss 1.1691041 epoch total loss 1.3478868
Trained batch 4882 batch loss 1.57689679 epoch total loss 1.34793365
Trained batch 4883 batch loss 1.08839309 epoch total loss 1.34788048
Trained batch 4884 batch loss 1.16007733 epoch total loss 1.3478421
Trained batch 4885 batch loss 1.10272014 epoch total loss 1.34779191
Trained batch 4886 batch loss 1.34514582 epoch total loss 1.34779131
Trained batch 4887 batch loss 1.18376875 epoch total loss 1.34775782
Trained batch 4888 batch loss 1.08770645 epoch total loss 1.34770465
Trained batch 4889 batch loss 1.12982559 epoch total loss 1.34766006
Trained batch 4890 batch loss 1.20589042 epoch total loss 1.3476311
Trained batch 4891 batch loss 1.34725547 epoch total loss 1.34763098
Trained batch 4892 batch loss 1.25046146 epoch total loss 1.34761119
Trained batch 4893 batch loss 1.35872841 epoch total loss 1.34761345
Trained batch 4894 batch loss 1.37198961 epoch total loss 1.34761846
Trained batch 4895 batch loss 1.32679367 epoch total loss 1.34761417
Trained batch 4896 batch loss 1.29610705 epoch total loss 1.34760356
Trained batch 4897 batch loss 1.29158139 epoch total loss 1.34759212
Trained batch 4898 batch loss 1.3435092 epoch total loss 1.3475914
Trained batch 4899 batch loss 1.15962803 epoch total loss 1.34755301
Trained batch 4900 batch loss 1.2784481 epoch total loss 1.34753883
Trained batch 4901 batch loss 1.13148212 epoch total loss 1.34749472
Trained batch 4902 batch loss 1.16919935 epoch total loss 1.34745848
Trained batch 4903 batch loss 1.200001 epoch total loss 1.34742844
Trained batch 4904 batch loss 1.11215472 epoch total loss 1.3473804
Trained batch 4905 batch loss 1.1717689 epoch total loss 1.34734464
Trained batch 4906 batch loss 1.13189602 epoch total loss 1.34730077
Trained batch 4907 batch loss 1.16265404 epoch total loss 1.3472631
Trained batch 4908 batch loss 1.17830288 epoch total loss 1.34722865
Trained batch 4909 batch loss 1.15934873 epoch total loss 1.34719038
Trained batch 4910 batch loss 1.12340331 epoch total loss 1.34714484
Trained batch 4911 batch loss 1.49983382 epoch total loss 1.34717596
Trained batch 4912 batch loss 1.16763783 epoch total loss 1.34713936
Trained batch 4913 batch loss 1.2953608 epoch total loss 1.34712887
Trained batch 4914 batch loss 1.21961665 epoch total loss 1.34710288
Trained batch 4915 batch loss 1.61942387 epoch total loss 1.34715831
Trained batch 4916 batch loss 1.19097209 epoch total loss 1.3471266
Trained batch 4917 batch loss 1.48799419 epoch total loss 1.34715521
Trained batch 4918 batch loss 1.42551064 epoch total loss 1.34717107
Trained batch 4919 batch loss 1.3252809 epoch total loss 1.34716654
Trained batch 4920 batch loss 1.42558813 epoch total loss 1.34718251
Trained batch 4921 batch loss 1.53365088 epoch total loss 1.34722042
Trained batch 4922 batch loss 1.28092766 epoch total loss 1.34720695
Trained batch 4923 batch loss 1.26269662 epoch total loss 1.34718978
Trained batch 4924 batch loss 1.25679231 epoch total loss 1.34717143
Trained batch 4925 batch loss 1.22390115 epoch total loss 1.34714651
Trained batch 4926 batch loss 1.28488755 epoch total loss 1.34713376
Trained batch 4927 batch loss 1.26440382 epoch total loss 1.34711695
Trained batch 4928 batch loss 1.04683411 epoch total loss 1.34705603
Trained batch 4929 batch loss 1.09678459 epoch total loss 1.34700525
Trained batch 4930 batch loss 1.15389013 epoch total loss 1.34696603
Trained batch 4931 batch loss 1.25858462 epoch total loss 1.34694815
Trained batch 4932 batch loss 0.932445943 epoch total loss 1.3468641
Trained batch 4933 batch loss 1.07555461 epoch total loss 1.34680915
Trained batch 4934 batch loss 1.17065215 epoch total loss 1.34677339
Trained batch 4935 batch loss 1.05928445 epoch total loss 1.34671509
Trained batch 4936 batch loss 1.01918256 epoch total loss 1.34664869
Trained batch 4937 batch loss 0.951260567 epoch total loss 1.34656858
Trained batch 4938 batch loss 0.95454669 epoch total loss 1.34648919
Trained batch 4939 batch loss 1.09764957 epoch total loss 1.34643888
Trained batch 4940 batch loss 1.09120464 epoch total loss 1.34638727
Trained batch 4941 batch loss 0.996068895 epoch total loss 1.34631634
Trained batch 4942 batch loss 1.41277313 epoch total loss 1.34632969
Trained batch 4943 batch loss 1.30111575 epoch total loss 1.34632063
Trained batch 4944 batch loss 1.00537467 epoch total loss 1.34625161
Trained batch 4945 batch loss 1.33693 epoch total loss 1.34624982
Trained batch 4946 batch loss 1.36259067 epoch total loss 1.34625316
Trained batch 4947 batch loss 1.36404586 epoch total loss 1.34625673
Trained batch 4948 batch loss 0.93090111 epoch total loss 1.34617281
Trained batch 4949 batch loss 1.22861457 epoch total loss 1.34614897
Trained batch 4950 batch loss 1.41302299 epoch total loss 1.34616256
Trained batch 4951 batch loss 1.2855401 epoch total loss 1.34615028
Trained batch 4952 batch loss 1.15773439 epoch total loss 1.34611225
Trained batch 4953 batch loss 1.11282051 epoch total loss 1.34606516
Trained batch 4954 batch loss 1.2611376 epoch total loss 1.346048
Trained batch 4955 batch loss 1.12980103 epoch total loss 1.34600437
Trained batch 4956 batch loss 1.4889791 epoch total loss 1.34603322
Trained batch 4957 batch loss 1.28192306 epoch total loss 1.34602022
Trained batch 4958 batch loss 1.18956757 epoch total loss 1.34598863
Trained batch 4959 batch loss 1.11871791 epoch total loss 1.34594274
Trained batch 4960 batch loss 0.92977196 epoch total loss 1.34585881
Trained batch 4961 batch loss 1.09198403 epoch total loss 1.34580767
Trained batch 4962 batch loss 1.28582263 epoch total loss 1.34579551
Trained batch 4963 batch loss 1.1482296 epoch total loss 1.34575582
Trained batch 4964 batch loss 1.26110148 epoch total loss 1.34573877
Trained batch 4965 batch loss 1.1792376 epoch total loss 1.34570515
Trained batch 4966 batch loss 0.993470311 epoch total loss 1.34563434
Trained batch 4967 batch loss 1.12988186 epoch total loss 1.34559083
Trained batch 4968 batch loss 1.27838 epoch total loss 1.34557736
Trained batch 4969 batch loss 1.36980891 epoch total loss 1.34558213
Trained batch 4970 batch loss 1.4784584 epoch total loss 1.34560895
Trained batch 4971 batch loss 1.26062846 epoch total loss 1.34559178
Trained batch 4972 batch loss 1.21470022 epoch total loss 1.34556556
Trained batch 4973 batch loss 0.996671259 epoch total loss 1.34549534
Trained batch 4974 batch loss 1.22318745 epoch total loss 1.34547079
Trained batch 4975 batch loss 1.05919909 epoch total loss 1.34541321
Trained batch 4976 batch loss 1.15222168 epoch total loss 1.34537435
Trained batch 4977 batch loss 1.10081136 epoch total loss 1.34532523
Trained batch 4978 batch loss 1.2577436 epoch total loss 1.34530759
Trained batch 4979 batch loss 1.32192993 epoch total loss 1.34530294
Trained batch 4980 batch loss 1.2498033 epoch total loss 1.34528375
Trained batch 4981 batch loss 1.36154199 epoch total loss 1.34528697
Trained batch 4982 batch loss 1.22120535 epoch total loss 1.34526205
Trained batch 4983 batch loss 1.06807244 epoch total loss 1.34520638
Trained batch 4984 batch loss 1.05510747 epoch total loss 1.34514821
Trained batch 4985 batch loss 1.20193243 epoch total loss 1.3451196
Trained batch 4986 batch loss 1.27913833 epoch total loss 1.34510636
Trained batch 4987 batch loss 1.12977648 epoch total loss 1.34506321
Trained batch 4988 batch loss 1.14522278 epoch total loss 1.34502304
Trained batch 4989 batch loss 1.20087767 epoch total loss 1.34499419
Trained batch 4990 batch loss 1.06238341 epoch total loss 1.34493756
Trained batch 4991 batch loss 1.16032147 epoch total loss 1.34490049
Trained batch 4992 batch loss 1.12908304 epoch total loss 1.34485722
Trained batch 4993 batch loss 1.14782977 epoch total loss 1.34481776
Trained batch 4994 batch loss 1.10481143 epoch total loss 1.34476984
Trained batch 4995 batch loss 1.01319909 epoch total loss 1.34470344
Trained batch 4996 batch loss 1.05793619 epoch total loss 1.34464598
Trained batch 4997 batch loss 1.13991475 epoch total loss 1.34460509
Trained batch 4998 batch loss 1.40527821 epoch total loss 1.34461725
Trained batch 4999 batch loss 1.03427494 epoch total loss 1.34455514
Trained batch 5000 batch loss 1.14919341 epoch total loss 1.34451616
Trained batch 5001 batch loss 1.32527351 epoch total loss 1.34451222
Trained batch 5002 batch loss 1.21357846 epoch total loss 1.344486
Trained batch 5003 batch loss 1.37435651 epoch total loss 1.34449208
Trained batch 5004 batch loss 1.30035901 epoch total loss 1.34448326
Trained batch 5005 batch loss 1.25004613 epoch total loss 1.3444643
Trained batch 5006 batch loss 1.36474228 epoch total loss 1.34446836
Trained batch 5007 batch loss 1.10939431 epoch total loss 1.34442139
Trained batch 5008 batch loss 1.13509262 epoch total loss 1.34437966
Trained batch 5009 batch loss 1.19475412 epoch total loss 1.34434974
Trained batch 5010 batch loss 1.27362323 epoch total loss 1.34433568
Trained batch 5011 batch loss 1.33654714 epoch total loss 1.34433413
Trained batch 5012 batch loss 1.22607756 epoch total loss 1.34431052
Trained batch 5013 batch loss 1.19363105 epoch total loss 1.34428048
Trained batch 5014 batch loss 1.23011267 epoch total loss 1.34425771
Trained batch 5015 batch loss 1.34486043 epoch total loss 1.34425771
Trained batch 5016 batch loss 1.43081808 epoch total loss 1.344275
Trained batch 5017 batch loss 1.36306345 epoch total loss 1.34427881
Trained batch 5018 batch loss 1.19642591 epoch total loss 1.34424925
Trained batch 5019 batch loss 1.26777899 epoch total loss 1.34423399
Trained batch 5020 batch loss 1.36247194 epoch total loss 1.34423757
Trained batch 5021 batch loss 1.34750879 epoch total loss 1.34423828
Trained batch 5022 batch loss 1.27518487 epoch total loss 1.34422457
Trained batch 5023 batch loss 1.5711329 epoch total loss 1.34426975
Trained batch 5024 batch loss 1.3023541 epoch total loss 1.34426141
Trained batch 5025 batch loss 1.35262632 epoch total loss 1.34426308
Trained batch 5026 batch loss 1.2421546 epoch total loss 1.34424269
Trained batch 5027 batch loss 1.33047628 epoch total loss 1.34424007
Trained batch 5028 batch loss 1.26160598 epoch total loss 1.34422362
Trained batch 5029 batch loss 1.35545993 epoch total loss 1.34422588
Trained batch 5030 batch loss 1.1591928 epoch total loss 1.34418905
Trained batch 5031 batch loss 1.22930837 epoch total loss 1.34416628
Trained batch 5032 batch loss 1.18921781 epoch total loss 1.34413552
Trained batch 5033 batch loss 1.14101291 epoch total loss 1.34409523
Trained batch 5034 batch loss 1.20344615 epoch total loss 1.34406734
Trained batch 5035 batch loss 1.09201646 epoch total loss 1.34401715
Trained batch 5036 batch loss 1.03150988 epoch total loss 1.34395516
Trained batch 5037 batch loss 1.10874271 epoch total loss 1.34390855
Trained batch 5038 batch loss 1.0420773 epoch total loss 1.34384859
Trained batch 5039 batch loss 1.13469172 epoch total loss 1.3438071
Trained batch 5040 batch loss 1.18238306 epoch total loss 1.34377503
Trained batch 5041 batch loss 1.04970372 epoch total loss 1.34371674
Trained batch 5042 batch loss 1.25823116 epoch total loss 1.34369981
Trained batch 5043 batch loss 1.2610482 epoch total loss 1.34368348
Trained batch 5044 batch loss 1.25691509 epoch total loss 1.34366632
Trained batch 5045 batch loss 0.938045382 epoch total loss 1.34358585
Trained batch 5046 batch loss 1.07914233 epoch total loss 1.3435334
Trained batch 5047 batch loss 1.18372369 epoch total loss 1.34350181
Trained batch 5048 batch loss 1.24657154 epoch total loss 1.34348249
Trained batch 5049 batch loss 1.3628056 epoch total loss 1.34348643
Trained batch 5050 batch loss 1.33025968 epoch total loss 1.34348369
Trained batch 5051 batch loss 1.26609802 epoch total loss 1.34346843
Trained batch 5052 batch loss 1.3262676 epoch total loss 1.34346497
Trained batch 5053 batch loss 1.38455653 epoch total loss 1.3434732
Trained batch 5054 batch loss 1.19514847 epoch total loss 1.34344387
Trained batch 5055 batch loss 1.27461874 epoch total loss 1.34343016
Trained batch 5056 batch loss 1.23398185 epoch total loss 1.34340847
Trained batch 5057 batch loss 1.30314612 epoch total loss 1.3434006
Trained batch 5058 batch loss 1.61229491 epoch total loss 1.34345376
Trained batch 5059 batch loss 1.58404422 epoch total loss 1.34350133
Trained batch 5060 batch loss 1.42731071 epoch total loss 1.34351778
Trained batch 5061 batch loss 1.36199808 epoch total loss 1.34352148
Trained batch 5062 batch loss 1.19389594 epoch total loss 1.34349191
Trained batch 5063 batch loss 1.36970448 epoch total loss 1.34349704
Trained batch 5064 batch loss 1.22546768 epoch total loss 1.34347379
Trained batch 5065 batch loss 1.54335773 epoch total loss 1.34351325
Trained batch 5066 batch loss 1.30130219 epoch total loss 1.34350491
Trained batch 5067 batch loss 1.25303257 epoch total loss 1.34348702
Trained batch 5068 batch loss 1.17036247 epoch total loss 1.34345281
Trained batch 5069 batch loss 1.22800779 epoch total loss 1.34343
Trained batch 5070 batch loss 1.39517164 epoch total loss 1.34344029
Trained batch 5071 batch loss 1.45410347 epoch total loss 1.34346211
Trained batch 5072 batch loss 1.43081462 epoch total loss 1.34347928
Trained batch 5073 batch loss 1.58196068 epoch total loss 1.34352636
Trained batch 5074 batch loss 1.26067376 epoch total loss 1.34351
Trained batch 5075 batch loss 1.18626845 epoch total loss 1.34347892
Trained batch 5076 batch loss 1.27657223 epoch total loss 1.34346581
Trained batch 5077 batch loss 1.21707726 epoch total loss 1.34344089
Trained batch 5078 batch loss 1.33419287 epoch total loss 1.34343898
Trained batch 5079 batch loss 1.21281922 epoch total loss 1.34341335
Trained batch 5080 batch loss 1.29816794 epoch total loss 1.34340441
Trained batch 5081 batch loss 1.1671443 epoch total loss 1.34336972
Trained batch 5082 batch loss 1.3327806 epoch total loss 1.3433677
Trained batch 5083 batch loss 1.30495119 epoch total loss 1.34336019
Trained batch 5084 batch loss 1.26911283 epoch total loss 1.34334552
Trained batch 5085 batch loss 1.34077573 epoch total loss 1.34334505
Trained batch 5086 batch loss 1.40136456 epoch total loss 1.34335649
Trained batch 5087 batch loss 1.35796642 epoch total loss 1.34335935
Trained batch 5088 batch loss 1.41041052 epoch total loss 1.34337258
Trained batch 5089 batch loss 1.46188688 epoch total loss 1.34339583
Trained batch 5090 batch loss 1.27213848 epoch total loss 1.34338188
Trained batch 5091 batch loss 1.26933646 epoch total loss 1.34336734
Trained batch 5092 batch loss 1.26350546 epoch total loss 1.34335172
Trained batch 5093 batch loss 1.45414782 epoch total loss 1.34337342
Trained batch 5094 batch loss 1.36288166 epoch total loss 1.34337723
Trained batch 5095 batch loss 1.02827454 epoch total loss 1.34331536
Trained batch 5096 batch loss 1.16663122 epoch total loss 1.34328067
Trained batch 5097 batch loss 1.18856931 epoch total loss 1.34325027
Trained batch 5098 batch loss 1.28562498 epoch total loss 1.34323907
Trained batch 5099 batch loss 1.28286326 epoch total loss 1.34322715
Trained batch 5100 batch loss 1.51567864 epoch total loss 1.343261
Trained batch 5101 batch loss 1.16263866 epoch total loss 1.34322548
Trained batch 5102 batch loss 1.42266273 epoch total loss 1.3432411
Trained batch 5103 batch loss 1.52668643 epoch total loss 1.3432771
Trained batch 5104 batch loss 1.41390347 epoch total loss 1.34329104
Trained batch 5105 batch loss 1.37626028 epoch total loss 1.34329748
Trained batch 5106 batch loss 1.4463768 epoch total loss 1.34331763
Trained batch 5107 batch loss 1.49247742 epoch total loss 1.34334695
Trained batch 5108 batch loss 1.38243914 epoch total loss 1.34335458
Trained batch 5109 batch loss 1.45300508 epoch total loss 1.34337604
Trained batch 5110 batch loss 1.34261286 epoch total loss 1.34337592
Trained batch 5111 batch loss 1.47232783 epoch total loss 1.34340107
Trained batch 5112 batch loss 1.22007966 epoch total loss 1.34337699
Trained batch 5113 batch loss 1.06449556 epoch total loss 1.3433224
Trained batch 5114 batch loss 1.25019646 epoch total loss 1.34330416
Trained batch 5115 batch loss 1.31173468 epoch total loss 1.34329796
Trained batch 5116 batch loss 1.10850775 epoch total loss 1.34325206
Trained batch 5117 batch loss 1.3122952 epoch total loss 1.3432461
Trained batch 5118 batch loss 1.17291546 epoch total loss 1.34321272
Trained batch 5119 batch loss 1.37115514 epoch total loss 1.34321821
Trained batch 5120 batch loss 1.2067287 epoch total loss 1.3431915
Trained batch 5121 batch loss 1.24798417 epoch total loss 1.34317291
Trained batch 5122 batch loss 1.28703785 epoch total loss 1.34316206
Trained batch 5123 batch loss 1.3777312 epoch total loss 1.34316874
Trained batch 5124 batch loss 1.26464665 epoch total loss 1.34315348
Trained batch 5125 batch loss 1.48576534 epoch total loss 1.34318125
Trained batch 5126 batch loss 1.36425436 epoch total loss 1.34318542
Trained batch 5127 batch loss 1.28027081 epoch total loss 1.34317315
Trained batch 5128 batch loss 1.08147645 epoch total loss 1.34312212
Trained batch 5129 batch loss 1.18480241 epoch total loss 1.34309125
Trained batch 5130 batch loss 1.26710927 epoch total loss 1.34307635
Trained batch 5131 batch loss 1.33988833 epoch total loss 1.34307575
Trained batch 5132 batch loss 1.16485906 epoch total loss 1.34304106
Trained batch 5133 batch loss 1.31144094 epoch total loss 1.34303498
Trained batch 5134 batch loss 1.39997411 epoch total loss 1.34304607
Trained batch 5135 batch loss 1.32340574 epoch total loss 1.34304214
Trained batch 5136 batch loss 1.24371529 epoch total loss 1.34302282
Trained batch 5137 batch loss 1.41823781 epoch total loss 1.34303749
Trained batch 5138 batch loss 1.36919618 epoch total loss 1.34304261
Trained batch 5139 batch loss 1.38365018 epoch total loss 1.34305048
Trained batch 5140 batch loss 1.39202726 epoch total loss 1.34306
Trained batch 5141 batch loss 1.23539662 epoch total loss 1.34303904
Trained batch 5142 batch loss 1.12841082 epoch total loss 1.34299731
Trained batch 5143 batch loss 1.09378302 epoch total loss 1.34294891
Trained batch 5144 batch loss 1.26833344 epoch total loss 1.34293437
Trained batch 5145 batch loss 1.24770737 epoch total loss 1.34291589
Trained batch 5146 batch loss 1.0116812 epoch total loss 1.34285152
Trained batch 5147 batch loss 1.54674816 epoch total loss 1.34289122
Trained batch 5148 batch loss 1.10015321 epoch total loss 1.34284401
Trained batch 5149 batch loss 1.16709042 epoch total loss 1.3428098
Trained batch 5150 batch loss 1.24188709 epoch total loss 1.34279025
Trained batch 5151 batch loss 1.2895025 epoch total loss 1.34277987
Trained batch 5152 batch loss 1.14717221 epoch total loss 1.34274185
Trained batch 5153 batch loss 1.0743506 epoch total loss 1.34268975
Trained batch 5154 batch loss 1.38428235 epoch total loss 1.34269786
Trained batch 5155 batch loss 1.14239025 epoch total loss 1.342659
Trained batch 5156 batch loss 1.42195368 epoch total loss 1.34267437
Trained batch 5157 batch loss 1.03196597 epoch total loss 1.34261405
Trained batch 5158 batch loss 1.03324819 epoch total loss 1.34255409
Trained batch 5159 batch loss 1.22877598 epoch total loss 1.34253204
Trained batch 5160 batch loss 1.24438047 epoch total loss 1.34251297
Trained batch 5161 batch loss 1.06655264 epoch total loss 1.34245956
Trained batch 5162 batch loss 1.1619513 epoch total loss 1.34242463
Trained batch 5163 batch loss 1.2468586 epoch total loss 1.34240615
Trained batch 5164 batch loss 1.19575012 epoch total loss 1.34237778
Trained batch 5165 batch loss 1.20132661 epoch total loss 1.34235036
Trained batch 5166 batch loss 1.12363434 epoch total loss 1.34230804
Trained batch 5167 batch loss 1.2978754 epoch total loss 1.34229946
Trained batch 5168 batch loss 1.24999034 epoch total loss 1.34228158
Trained batch 5169 batch loss 1.40794802 epoch total loss 1.34229422
Trained batch 5170 batch loss 1.28853512 epoch total loss 1.34228384
Trained batch 5171 batch loss 1.5131762 epoch total loss 1.34231687
Trained batch 5172 batch loss 1.37338018 epoch total loss 1.34232295
Trained batch 5173 batch loss 1.57775664 epoch total loss 1.34236836
Trained batch 5174 batch loss 1.46576083 epoch total loss 1.34239233
Trained batch 5175 batch loss 1.35920906 epoch total loss 1.34239554
Trained batch 5176 batch loss 1.58055758 epoch total loss 1.34244156
Trained batch 5177 batch loss 1.63361573 epoch total loss 1.34249783
Trained batch 5178 batch loss 1.41261482 epoch total loss 1.34251142
Trained batch 5179 batch loss 1.56222725 epoch total loss 1.34255373
Trained batch 5180 batch loss 1.45525932 epoch total loss 1.34257543
Trained batch 5181 batch loss 1.19867957 epoch total loss 1.34254777
Trained batch 5182 batch loss 1.47040558 epoch total loss 1.34257233
Trained batch 5183 batch loss 1.34674048 epoch total loss 1.34257317
Trained batch 5184 batch loss 1.29245019 epoch total loss 1.34256351
Trained batch 5185 batch loss 1.32518506 epoch total loss 1.34256017
Trained batch 5186 batch loss 1.6459527 epoch total loss 1.3426187
Trained batch 5187 batch loss 1.18184757 epoch total loss 1.34258759
Trained batch 5188 batch loss 1.14104569 epoch total loss 1.34254873
Trained batch 5189 batch loss 1.03765416 epoch total loss 1.34249
Trained batch 5190 batch loss 1.25804162 epoch total loss 1.34247375
Trained batch 5191 batch loss 1.12327218 epoch total loss 1.34243143
Trained batch 5192 batch loss 0.99503988 epoch total loss 1.34236455
Trained batch 5193 batch loss 1.01607037 epoch total loss 1.34230173
Trained batch 5194 batch loss 1.21643007 epoch total loss 1.34227741
Trained batch 5195 batch loss 1.00235605 epoch total loss 1.34221208
Trained batch 5196 batch loss 0.983451307 epoch total loss 1.34214294
Trained batch 5197 batch loss 1.06984496 epoch total loss 1.34209061
Trained batch 5198 batch loss 0.889423966 epoch total loss 1.34200358
Trained batch 5199 batch loss 0.930684805 epoch total loss 1.34192443
Trained batch 5200 batch loss 0.998861313 epoch total loss 1.34185851
Trained batch 5201 batch loss 1.01399422 epoch total loss 1.34179544
Trained batch 5202 batch loss 1.00311089 epoch total loss 1.34173036
Trained batch 5203 batch loss 0.871114254 epoch total loss 1.34163988
Trained batch 5204 batch loss 1.1142081 epoch total loss 1.34159613
Trained batch 5205 batch loss 1.33940363 epoch total loss 1.34159577
Trained batch 5206 batch loss 1.18784368 epoch total loss 1.34156621
Trained batch 5207 batch loss 1.36100113 epoch total loss 1.3415699
Trained batch 5208 batch loss 1.18979585 epoch total loss 1.34154081
Trained batch 5209 batch loss 1.3481164 epoch total loss 1.34154212
Trained batch 5210 batch loss 1.3355695 epoch total loss 1.34154093
Trained batch 5211 batch loss 1.30823779 epoch total loss 1.3415345
Trained batch 5212 batch loss 1.15954459 epoch total loss 1.34149957
Trained batch 5213 batch loss 1.38013256 epoch total loss 1.34150708
Trained batch 5214 batch loss 1.24544096 epoch total loss 1.34148872
Trained batch 5215 batch loss 1.15309274 epoch total loss 1.3414526
Trained batch 5216 batch loss 1.30531907 epoch total loss 1.34144568
Trained batch 5217 batch loss 1.06519961 epoch total loss 1.34139276
Trained batch 5218 batch loss 1.04387009 epoch total loss 1.34133577
Trained batch 5219 batch loss 1.14235687 epoch total loss 1.34129763
Trained batch 5220 batch loss 1.17671049 epoch total loss 1.34126616
Trained batch 5221 batch loss 1.24739599 epoch total loss 1.34124815
Trained batch 5222 batch loss 0.974657655 epoch total loss 1.34117794
Trained batch 5223 batch loss 1.23925662 epoch total loss 1.34115851
Trained batch 5224 batch loss 1.19152141 epoch total loss 1.34112978
Trained batch 5225 batch loss 1.17600894 epoch total loss 1.34109819
Trained batch 5226 batch loss 1.09605479 epoch total loss 1.34105122
Trained batch 5227 batch loss 1.03793871 epoch total loss 1.34099329
Trained batch 5228 batch loss 1.10044467 epoch total loss 1.34094739
Trained batch 5229 batch loss 1.12749386 epoch total loss 1.3409065
Trained batch 5230 batch loss 1.14893055 epoch total loss 1.34086978
Trained batch 5231 batch loss 1.25494039 epoch total loss 1.34085333
Trained batch 5232 batch loss 1.21805775 epoch total loss 1.34083
Trained batch 5233 batch loss 1.09739637 epoch total loss 1.34078336
Trained batch 5234 batch loss 0.997278035 epoch total loss 1.34071767
Trained batch 5235 batch loss 1.01797926 epoch total loss 1.34065604
Trained batch 5236 batch loss 1.20335793 epoch total loss 1.34062982
Trained batch 5237 batch loss 1.40474856 epoch total loss 1.34064209
Trained batch 5238 batch loss 1.25458694 epoch total loss 1.34062552
Trained batch 5239 batch loss 0.902633786 epoch total loss 1.34054196
Trained batch 5240 batch loss 1.27089524 epoch total loss 1.34052873
Trained batch 5241 batch loss 1.38129282 epoch total loss 1.34053648
Trained batch 5242 batch loss 1.21466899 epoch total loss 1.34051251
Trained batch 5243 batch loss 1.0101124 epoch total loss 1.34044957
Trained batch 5244 batch loss 1.20970547 epoch total loss 1.34042454
Trained batch 5245 batch loss 1.23342562 epoch total loss 1.34040415
Trained batch 5246 batch loss 1.2270968 epoch total loss 1.34038258
Trained batch 5247 batch loss 1.26733565 epoch total loss 1.34036875
Trained batch 5248 batch loss 1.25675821 epoch total loss 1.34035277
Trained batch 5249 batch loss 1.2498498 epoch total loss 1.34033561
Trained batch 5250 batch loss 1.01095247 epoch total loss 1.34027278
Trained batch 5251 batch loss 1.29407334 epoch total loss 1.34026396
Trained batch 5252 batch loss 1.04145992 epoch total loss 1.3402071
Trained batch 5253 batch loss 1.13819 epoch total loss 1.3401686
Trained batch 5254 batch loss 1.03172421 epoch total loss 1.34011
Trained batch 5255 batch loss 1.32765603 epoch total loss 1.34010756
Trained batch 5256 batch loss 1.35752738 epoch total loss 1.34011078
Trained batch 5257 batch loss 1.31756341 epoch total loss 1.34010649
Trained batch 5258 batch loss 1.22624135 epoch total loss 1.34008479
Trained batch 5259 batch loss 1.21429396 epoch total loss 1.34006095
Trained batch 5260 batch loss 1.2354852 epoch total loss 1.34004104
Trained batch 5261 batch loss 1.33638835 epoch total loss 1.34004033
Trained batch 5262 batch loss 1.39660954 epoch total loss 1.34005105
Trained batch 5263 batch loss 1.28249 epoch total loss 1.34004021
Trained batch 5264 batch loss 1.45670056 epoch total loss 1.34006226
Trained batch 5265 batch loss 1.30901432 epoch total loss 1.34005642
Trained batch 5266 batch loss 1.08396959 epoch total loss 1.34000778
Trained batch 5267 batch loss 1.37022495 epoch total loss 1.3400135
Trained batch 5268 batch loss 1.33885324 epoch total loss 1.34001327
Trained batch 5269 batch loss 1.3694334 epoch total loss 1.34001887
Trained batch 5270 batch loss 1.50657558 epoch total loss 1.34005046
Trained batch 5271 batch loss 1.3782053 epoch total loss 1.34005773
Trained batch 5272 batch loss 1.52274442 epoch total loss 1.34009242
Trained batch 5273 batch loss 1.23370254 epoch total loss 1.34007227
Trained batch 5274 batch loss 1.21253753 epoch total loss 1.34004807
Trained batch 5275 batch loss 1.25704157 epoch total loss 1.34003234
Trained batch 5276 batch loss 1.06469476 epoch total loss 1.33998013
Trained batch 5277 batch loss 1.29455471 epoch total loss 1.33997142
Trained batch 5278 batch loss 1.34396863 epoch total loss 1.33997214
Trained batch 5279 batch loss 1.18670726 epoch total loss 1.33994305
Trained batch 5280 batch loss 1.28130245 epoch total loss 1.33993196
Trained batch 5281 batch loss 1.29793692 epoch total loss 1.33992398
Trained batch 5282 batch loss 1.1663686 epoch total loss 1.3398912
Trained batch 5283 batch loss 1.22592735 epoch total loss 1.33986962
Trained batch 5284 batch loss 1.24403834 epoch total loss 1.3398515
Trained batch 5285 batch loss 1.3059659 epoch total loss 1.33984518
Trained batch 5286 batch loss 1.33701575 epoch total loss 1.33984458
Trained batch 5287 batch loss 1.39537227 epoch total loss 1.33985507
Trained batch 5288 batch loss 1.11895847 epoch total loss 1.33981335
Trained batch 5289 batch loss 1.18271232 epoch total loss 1.33978367
Trained batch 5290 batch loss 1.29349184 epoch total loss 1.33977485
Trained batch 5291 batch loss 1.19602084 epoch total loss 1.33974767
Trained batch 5292 batch loss 1.27986562 epoch total loss 1.33973634
Trained batch 5293 batch loss 1.38221252 epoch total loss 1.33974445
Trained batch 5294 batch loss 1.01535416 epoch total loss 1.33968306
Trained batch 5295 batch loss 1.28646803 epoch total loss 1.33967304
Trained batch 5296 batch loss 1.32212698 epoch total loss 1.33966982
Trained batch 5297 batch loss 1.34443378 epoch total loss 1.33967066
Trained batch 5298 batch loss 1.31430125 epoch total loss 1.33966589
Trained batch 5299 batch loss 1.35219312 epoch total loss 1.33966815
Trained batch 5300 batch loss 1.3561846 epoch total loss 1.33967125
Trained batch 5301 batch loss 1.21578813 epoch total loss 1.33964789
Trained batch 5302 batch loss 1.21186316 epoch total loss 1.33962381
Trained batch 5303 batch loss 1.18866563 epoch total loss 1.33959532
Trained batch 5304 batch loss 1.30306077 epoch total loss 1.33958852
Trained batch 5305 batch loss 1.29667044 epoch total loss 1.33958042
Trained batch 5306 batch loss 1.36656308 epoch total loss 1.33958554
Trained batch 5307 batch loss 1.40116286 epoch total loss 1.33959723
Trained batch 5308 batch loss 1.31179321 epoch total loss 1.33959198
Trained batch 5309 batch loss 1.12244678 epoch total loss 1.33955109
Trained batch 5310 batch loss 1.15222466 epoch total loss 1.33951581
Trained batch 5311 batch loss 1.37825632 epoch total loss 1.3395232
Trained batch 5312 batch loss 1.20283377 epoch total loss 1.33949745
Trained batch 5313 batch loss 1.54717982 epoch total loss 1.33953655
Trained batch 5314 batch loss 1.18274474 epoch total loss 1.33950698
Trained batch 5315 batch loss 1.28142738 epoch total loss 1.33949602
Trained batch 5316 batch loss 1.27185798 epoch total loss 1.33948338
Trained batch 5317 batch loss 1.26062644 epoch total loss 1.33946848
Trained batch 5318 batch loss 1.30502582 epoch total loss 1.33946204
Trained batch 5319 batch loss 1.19799006 epoch total loss 1.33943546
Trained batch 5320 batch loss 1.31569719 epoch total loss 1.33943105
Trained batch 5321 batch loss 1.30292463 epoch total loss 1.33942413
Trained batch 5322 batch loss 1.23704469 epoch total loss 1.33940482
Trained batch 5323 batch loss 1.43953073 epoch total loss 1.33942366
Trained batch 5324 batch loss 1.08873391 epoch total loss 1.33937657
Trained batch 5325 batch loss 1.27329695 epoch total loss 1.33936417
Trained batch 5326 batch loss 1.29884338 epoch total loss 1.33935654
Trained batch 5327 batch loss 1.24890161 epoch total loss 1.33933961
Trained batch 5328 batch loss 1.10994065 epoch total loss 1.33929658
Trained batch 5329 batch loss 1.29690504 epoch total loss 1.33928859
Trained batch 5330 batch loss 1.25419641 epoch total loss 1.33927262
Trained batch 5331 batch loss 1.10872781 epoch total loss 1.33922946
Trained batch 5332 batch loss 1.3267839 epoch total loss 1.33922708
Trained batch 5333 batch loss 1.14459491 epoch total loss 1.3391906
Trained batch 5334 batch loss 1.2091192 epoch total loss 1.33916616
Trained batch 5335 batch loss 1.24323916 epoch total loss 1.33914816
Trained batch 5336 batch loss 1.20104325 epoch total loss 1.3391223
Trained batch 5337 batch loss 1.15027332 epoch total loss 1.33908689
Trained batch 5338 batch loss 1.47040749 epoch total loss 1.33911157
Trained batch 5339 batch loss 1.36770809 epoch total loss 1.33911681
Trained batch 5340 batch loss 1.34122765 epoch total loss 1.33911729
Trained batch 5341 batch loss 1.22317791 epoch total loss 1.33909559
Trained batch 5342 batch loss 1.17198777 epoch total loss 1.33906424
Trained batch 5343 batch loss 1.26444888 epoch total loss 1.33905029
Trained batch 5344 batch loss 1.18524253 epoch total loss 1.33902156
Trained batch 5345 batch loss 1.17180681 epoch total loss 1.33899021
Trained batch 5346 batch loss 1.05807924 epoch total loss 1.33893764
Trained batch 5347 batch loss 1.24603391 epoch total loss 1.33892035
Trained batch 5348 batch loss 1.2948575 epoch total loss 1.33891213
Trained batch 5349 batch loss 1.07578325 epoch total loss 1.3388629
Trained batch 5350 batch loss 1.14108753 epoch total loss 1.33882594
Trained batch 5351 batch loss 1.237921 epoch total loss 1.33880711
Trained batch 5352 batch loss 1.07975364 epoch total loss 1.33875859
Trained batch 5353 batch loss 1.13285327 epoch total loss 1.3387202
Trained batch 5354 batch loss 1.13277578 epoch total loss 1.3386817
Trained batch 5355 batch loss 1.02334404 epoch total loss 1.33862281
Trained batch 5356 batch loss 1.04112196 epoch total loss 1.33856726
Trained batch 5357 batch loss 1.1882292 epoch total loss 1.33853912
Trained batch 5358 batch loss 1.18375742 epoch total loss 1.33851027
Trained batch 5359 batch loss 1.18857908 epoch total loss 1.33848226
Trained batch 5360 batch loss 1.15915656 epoch total loss 1.33844876
Trained batch 5361 batch loss 1.3978312 epoch total loss 1.33845985
Trained batch 5362 batch loss 1.29627252 epoch total loss 1.33845198
Trained batch 5363 batch loss 1.39234161 epoch total loss 1.33846211
Trained batch 5364 batch loss 1.23599088 epoch total loss 1.33844304
Trained batch 5365 batch loss 1.31471062 epoch total loss 1.33843863
Trained batch 5366 batch loss 1.36574221 epoch total loss 1.33844364
Trained batch 5367 batch loss 1.26291633 epoch total loss 1.33842957
Trained batch 5368 batch loss 1.3259356 epoch total loss 1.33842731
Trained batch 5369 batch loss 1.20866394 epoch total loss 1.33840311
Trained batch 5370 batch loss 1.10615754 epoch total loss 1.33835983
Trained batch 5371 batch loss 1.29821134 epoch total loss 1.33835232
Trained batch 5372 batch loss 1.52513385 epoch total loss 1.33838713
Trained batch 5373 batch loss 1.26999962 epoch total loss 1.33837438
Trained batch 5374 batch loss 1.26216757 epoch total loss 1.33836019
Trained batch 5375 batch loss 1.14395404 epoch total loss 1.33832407
Trained batch 5376 batch loss 1.29172087 epoch total loss 1.33831537
Trained batch 5377 batch loss 1.38349867 epoch total loss 1.33832371
Trained batch 5378 batch loss 1.35918 epoch total loss 1.33832765
Trained batch 5379 batch loss 1.48606491 epoch total loss 1.33835506
Trained batch 5380 batch loss 1.62500477 epoch total loss 1.33840835
Trained batch 5381 batch loss 1.76832461 epoch total loss 1.33848822
Trained batch 5382 batch loss 1.73626506 epoch total loss 1.33856213
Trained batch 5383 batch loss 1.51382101 epoch total loss 1.33859468
Trained batch 5384 batch loss 1.3165803 epoch total loss 1.33859062
Trained batch 5385 batch loss 1.3950882 epoch total loss 1.33860111
Trained batch 5386 batch loss 1.41361737 epoch total loss 1.33861494
Trained batch 5387 batch loss 1.37538838 epoch total loss 1.33862185
Trained batch 5388 batch loss 1.1835407 epoch total loss 1.33859301
Trained batch 5389 batch loss 1.49265981 epoch total loss 1.33862162
Trained batch 5390 batch loss 1.28667593 epoch total loss 1.33861196
Trained batch 5391 batch loss 1.2223053 epoch total loss 1.33859038
Trained batch 5392 batch loss 1.26880538 epoch total loss 1.33857751
Trained batch 5393 batch loss 1.28157759 epoch total loss 1.3385669
Trained batch 5394 batch loss 1.65998209 epoch total loss 1.33862662
Trained batch 5395 batch loss 1.71194315 epoch total loss 1.33869576
Trained batch 5396 batch loss 1.49307477 epoch total loss 1.33872437
Trained batch 5397 batch loss 1.28393745 epoch total loss 1.33871424
Trained batch 5398 batch loss 1.37087822 epoch total loss 1.33872032
Trained batch 5399 batch loss 1.39981294 epoch total loss 1.33873165
Trained batch 5400 batch loss 1.4131062 epoch total loss 1.33874536
Trained batch 5401 batch loss 1.25118649 epoch total loss 1.33872914
Trained batch 5402 batch loss 1.4417367 epoch total loss 1.33874822
Trained batch 5403 batch loss 1.45074344 epoch total loss 1.33876896
Trained batch 5404 batch loss 1.18984663 epoch total loss 1.33874142
Trained batch 5405 batch loss 1.1678344 epoch total loss 1.33870983
Trained batch 5406 batch loss 1.14678216 epoch total loss 1.33867431
Trained batch 5407 batch loss 1.23921108 epoch total loss 1.33865595
Trained batch 5408 batch loss 1.3548162 epoch total loss 1.33865893
Trained batch 5409 batch loss 1.09531879 epoch total loss 1.33861399
Trained batch 5410 batch loss 1.3034637 epoch total loss 1.33860743
Trained batch 5411 batch loss 1.2574122 epoch total loss 1.33859241
Trained batch 5412 batch loss 1.26820791 epoch total loss 1.33857942
Trained batch 5413 batch loss 1.48272586 epoch total loss 1.338606
Trained batch 5414 batch loss 1.27887738 epoch total loss 1.33859503
Trained batch 5415 batch loss 1.31169009 epoch total loss 1.33859
Trained batch 5416 batch loss 1.19323504 epoch total loss 1.3385632
Trained batch 5417 batch loss 1.20122838 epoch total loss 1.33853781
Trained batch 5418 batch loss 0.95752418 epoch total loss 1.33846748
Trained batch 5419 batch loss 1.45240283 epoch total loss 1.33848858
Trained batch 5420 batch loss 1.41955757 epoch total loss 1.33850348
Trained batch 5421 batch loss 1.45596743 epoch total loss 1.33852518
Trained batch 5422 batch loss 1.2998606 epoch total loss 1.33851802
Trained batch 5423 batch loss 1.22465277 epoch total loss 1.33849704
Trained batch 5424 batch loss 1.27245665 epoch total loss 1.33848488
Trained batch 5425 batch loss 1.21276343 epoch total loss 1.33846176
Trained batch 5426 batch loss 1.38472068 epoch total loss 1.33847022
Trained batch 5427 batch loss 1.39382374 epoch total loss 1.33848047
Trained batch 5428 batch loss 1.44259381 epoch total loss 1.33849967
Trained batch 5429 batch loss 1.35274529 epoch total loss 1.33850217
Trained batch 5430 batch loss 1.3871541 epoch total loss 1.33851123
Trained batch 5431 batch loss 1.3743794 epoch total loss 1.33851779
Trained batch 5432 batch loss 1.46147525 epoch total loss 1.33854043
Trained batch 5433 batch loss 1.36044335 epoch total loss 1.33854449
Trained batch 5434 batch loss 1.29205811 epoch total loss 1.3385359
Trained batch 5435 batch loss 1.30939519 epoch total loss 1.33853054
Trained batch 5436 batch loss 1.16313815 epoch total loss 1.33849823
Trained batch 5437 batch loss 1.2688632 epoch total loss 1.33848548
Trained batch 5438 batch loss 1.33490765 epoch total loss 1.33848488
Trained batch 5439 batch loss 1.61105895 epoch total loss 1.33853495
Trained batch 5440 batch loss 1.58299828 epoch total loss 1.33857989
Trained batch 5441 batch loss 1.41183567 epoch total loss 1.33859324
Trained batch 5442 batch loss 1.14957905 epoch total loss 1.33855855
Trained batch 5443 batch loss 1.15640724 epoch total loss 1.33852506
Trained batch 5444 batch loss 1.08009434 epoch total loss 1.33847761
Trained batch 5445 batch loss 1.10481048 epoch total loss 1.3384347
Trained batch 5446 batch loss 1.19918752 epoch total loss 1.33840907
Trained batch 5447 batch loss 1.18330383 epoch total loss 1.33838058
Trained batch 5448 batch loss 1.15760183 epoch total loss 1.33834743
Trained batch 5449 batch loss 1.10726953 epoch total loss 1.33830512
Trained batch 5450 batch loss 1.31597137 epoch total loss 1.33830094
Trained batch 5451 batch loss 1.23294497 epoch total loss 1.33828163
Trained batch 5452 batch loss 1.10020244 epoch total loss 1.33823788
Trained batch 5453 batch loss 1.18830919 epoch total loss 1.33821046
Trained batch 5454 batch loss 1.27686 epoch total loss 1.33819926
Trained batch 5455 batch loss 1.3773936 epoch total loss 1.33820641
Trained batch 5456 batch loss 1.18161118 epoch total loss 1.33817768
Trained batch 5457 batch loss 1.31472337 epoch total loss 1.33817351
Trained batch 5458 batch loss 1.51955581 epoch total loss 1.33820665
Trained batch 5459 batch loss 1.44830084 epoch total loss 1.3382268
Trained batch 5460 batch loss 1.17882729 epoch total loss 1.33819759
Trained batch 5461 batch loss 1.25124371 epoch total loss 1.33818173
Trained batch 5462 batch loss 1.24500537 epoch total loss 1.33816469
Trained batch 5463 batch loss 1.24149108 epoch total loss 1.33814704
Trained batch 5464 batch loss 1.28286266 epoch total loss 1.33813691
Trained batch 5465 batch loss 1.12692904 epoch total loss 1.33809829
Trained batch 5466 batch loss 1.03246498 epoch total loss 1.33804226
Trained batch 5467 batch loss 0.919417739 epoch total loss 1.33796573
Trained batch 5468 batch loss 0.815159917 epoch total loss 1.33787012
Trained batch 5469 batch loss 1.05900431 epoch total loss 1.3378191
Trained batch 5470 batch loss 1.17318106 epoch total loss 1.33778906
Trained batch 5471 batch loss 0.863142133 epoch total loss 1.33770227
Trained batch 5472 batch loss 0.946240544 epoch total loss 1.33763075
Trained batch 5473 batch loss 1.16640949 epoch total loss 1.33759952
Trained batch 5474 batch loss 0.945761859 epoch total loss 1.33752799
Trained batch 5475 batch loss 1.27814507 epoch total loss 1.33751714
Trained batch 5476 batch loss 1.30673075 epoch total loss 1.33751154
Trained batch 5477 batch loss 1.27539027 epoch total loss 1.3375001
Trained batch 5478 batch loss 1.35036826 epoch total loss 1.33750248
Trained batch 5479 batch loss 1.06077349 epoch total loss 1.33745193
Trained batch 5480 batch loss 1.12635088 epoch total loss 1.33741343
Trained batch 5481 batch loss 1.13524306 epoch total loss 1.33737659
Trained batch 5482 batch loss 1.14073706 epoch total loss 1.33734071
Trained batch 5483 batch loss 1.20528722 epoch total loss 1.33731663
Trained batch 5484 batch loss 1.32120347 epoch total loss 1.33731365
Trained batch 5485 batch loss 1.20941782 epoch total loss 1.33729041
Trained batch 5486 batch loss 1.18353856 epoch total loss 1.33726239
Trained batch 5487 batch loss 1.26733363 epoch total loss 1.33724952
Trained batch 5488 batch loss 1.01335764 epoch total loss 1.33719051
Trained batch 5489 batch loss 1.11213517 epoch total loss 1.3371495
Trained batch 5490 batch loss 1.25605297 epoch total loss 1.33713472
Trained batch 5491 batch loss 1.13337088 epoch total loss 1.33709764
Trained batch 5492 batch loss 1.06651425 epoch total loss 1.33704829
Trained batch 5493 batch loss 0.992674291 epoch total loss 1.33698559
Trained batch 5494 batch loss 1.27596331 epoch total loss 1.3369745
Trained batch 5495 batch loss 1.2706989 epoch total loss 1.33696246
Trained batch 5496 batch loss 1.15078092 epoch total loss 1.33692849
Trained batch 5497 batch loss 1.20124876 epoch total loss 1.33690381
Trained batch 5498 batch loss 1.35977864 epoch total loss 1.33690798
Trained batch 5499 batch loss 1.31715059 epoch total loss 1.33690453
Trained batch 5500 batch loss 1.47888267 epoch total loss 1.33693027
Trained batch 5501 batch loss 1.11698031 epoch total loss 1.33689034
Trained batch 5502 batch loss 1.25782955 epoch total loss 1.33687603
Trained batch 5503 batch loss 1.28900814 epoch total loss 1.33686733
Trained batch 5504 batch loss 1.11233044 epoch total loss 1.33682644
Trained batch 5505 batch loss 1.01527166 epoch total loss 1.33676803
Trained batch 5506 batch loss 1.63652158 epoch total loss 1.33682251
Trained batch 5507 batch loss 1.38966525 epoch total loss 1.33683217
Trained batch 5508 batch loss 1.27834868 epoch total loss 1.33682156
Trained batch 5509 batch loss 0.991370916 epoch total loss 1.33675873
Trained batch 5510 batch loss 1.31948054 epoch total loss 1.33675563
Trained batch 5511 batch loss 1.06324446 epoch total loss 1.33670604
Trained batch 5512 batch loss 1.11416256 epoch total loss 1.33666563
Trained batch 5513 batch loss 1.16245937 epoch total loss 1.33663404
Trained batch 5514 batch loss 0.871214449 epoch total loss 1.33654964
Trained batch 5515 batch loss 1.02826762 epoch total loss 1.33649373
Trained batch 5516 batch loss 1.35674906 epoch total loss 1.33649743
Trained batch 5517 batch loss 1.14870918 epoch total loss 1.33646345
Trained batch 5518 batch loss 1.14461613 epoch total loss 1.33642864
Trained batch 5519 batch loss 1.09234226 epoch total loss 1.33638442
Trained batch 5520 batch loss 1.16051471 epoch total loss 1.33635259
Trained batch 5521 batch loss 1.20641875 epoch total loss 1.3363291
Trained batch 5522 batch loss 1.19817865 epoch total loss 1.33630407
Trained batch 5523 batch loss 1.27740359 epoch total loss 1.33629346
Trained batch 5524 batch loss 1.13611543 epoch total loss 1.33625722
Trained batch 5525 batch loss 1.19516969 epoch total loss 1.33623171
Trained batch 5526 batch loss 1.3799392 epoch total loss 1.33623958
Trained batch 5527 batch loss 1.3748976 epoch total loss 1.33624661
Trained batch 5528 batch loss 1.23257065 epoch total loss 1.33622789
Trained batch 5529 batch loss 1.20767903 epoch total loss 1.33620453
Trained batch 5530 batch loss 1.373312 epoch total loss 1.33621132
Trained batch 5531 batch loss 1.55321038 epoch total loss 1.33625054
Trained batch 5532 batch loss 1.50260055 epoch total loss 1.33628058
Trained batch 5533 batch loss 1.43697429 epoch total loss 1.33629882
Trained batch 5534 batch loss 1.71354651 epoch total loss 1.33636689
Trained batch 5535 batch loss 1.22227633 epoch total loss 1.33634627
Trained batch 5536 batch loss 1.58187127 epoch total loss 1.33639073
Trained batch 5537 batch loss 1.52412319 epoch total loss 1.33642459
Trained batch 5538 batch loss 1.2002846 epoch total loss 1.33639991
Trained batch 5539 batch loss 1.33225524 epoch total loss 1.3363992
Trained batch 5540 batch loss 1.41642725 epoch total loss 1.33641362
Trained batch 5541 batch loss 1.27062297 epoch total loss 1.3364017
Trained batch 5542 batch loss 1.23506463 epoch total loss 1.33638346
Trained batch 5543 batch loss 1.0368607 epoch total loss 1.33632934
Trained batch 5544 batch loss 1.0880599 epoch total loss 1.33628452
Trained batch 5545 batch loss 1.24361587 epoch total loss 1.33626783
Trained batch 5546 batch loss 1.25422454 epoch total loss 1.33625305
Trained batch 5547 batch loss 1.53222203 epoch total loss 1.33628833
Trained batch 5548 batch loss 1.13184929 epoch total loss 1.3362515
Trained batch 5549 batch loss 0.979130149 epoch total loss 1.33618712
Trained batch 5550 batch loss 1.06702566 epoch total loss 1.33613861
Trained batch 5551 batch loss 1.39026809 epoch total loss 1.33614838
Trained batch 5552 batch loss 1.18903327 epoch total loss 1.3361218
Epoch 1 train loss 1.3361217975616455
Validated batch 1 batch loss 1.25901723
Validated batch 2 batch loss 1.38703394
Validated batch 3 batch loss 1.43273783
Validated batch 4 batch loss 1.55928576
Validated batch 5 batch loss 1.3620491
Validated batch 6 batch loss 1.24831724
Validated batch 7 batch loss 1.35215592
Validated batch 8 batch loss 1.21796608
Validated batch 9 batch loss 1.04119444
Validated batch 10 batch loss 1.28340852
Validated batch 11 batch loss 1.4164474
Validated batch 12 batch loss 1.34468591
Validated batch 13 batch loss 1.22519875
Validated batch 14 batch loss 0.946493626
Validated batch 15 batch loss 1.39862633
Validated batch 16 batch loss 1.20451903
Validated batch 17 batch loss 1.23001456
Validated batch 18 batch loss 1.47621346
Validated batch 19 batch loss 1.32079816
Validated batch 20 batch loss 0.992156565
Validated batch 21 batch loss 1.356686
Validated batch 22 batch loss 1.46073818
Validated batch 23 batch loss 1.30353355
Validated batch 24 batch loss 1.2290957
Validated batch 25 batch loss 1.35260475
Validated batch 26 batch loss 1.399822
Validated batch 27 batch loss 1.13711071
Validated batch 28 batch loss 1.2180866
Validated batch 29 batch loss 1.11681581
Validated batch 30 batch loss 1.34375441
Validated batch 31 batch loss 1.43459654
Validated batch 32 batch loss 1.0163306
Validated batch 33 batch loss 0.892436862
Validated batch 34 batch loss 1.50831246
Validated batch 35 batch loss 1.46566117
Validated batch 36 batch loss 1.56938195
Validated batch 37 batch loss 1.34680212
Validated batch 38 batch loss 1.21306729
Validated batch 39 batch loss 1.23866773
Validated batch 40 batch loss 1.30179965
Validated batch 41 batch loss 1.27727318
Validated batch 42 batch loss 1.28992128
Validated batch 43 batch loss 1.16556084
Validated batch 44 batch loss 1.27442098
Validated batch 45 batch loss 1.0152694
Validated batch 46 batch loss 1.26605916
Validated batch 47 batch loss 1.19716072
Validated batch 48 batch loss 1.26314723
Validated batch 49 batch loss 1.23816323
Validated batch 50 batch loss 1.07354665
Validated batch 51 batch loss 1.34327292
Validated batch 52 batch loss 1.44273448
Validated batch 53 batch loss 1.24963701
Validated batch 54 batch loss 1.44287157
Validated batch 55 batch loss 1.24253201
Validated batch 56 batch loss 1.22087646
Validated batch 57 batch loss 1.41646338
Validated batch 58 batch loss 1.49512982
Validated batch 59 batch loss 1.4418503
Validated batch 60 batch loss 1.42807555
Validated batch 61 batch loss 1.48435986
Validated batch 62 batch loss 1.47054195
Validated batch 63 batch loss 1.3758142
Validated batch 64 batch loss 1.2666527
Validated batch 65 batch loss 1.1898694
Validated batch 66 batch loss 1.19689083
Validated batch 67 batch loss 1.36030889
Validated batch 68 batch loss 1.38482368
Validated batch 69 batch loss 1.53429413
Validated batch 70 batch loss 1.50856972
Validated batch 71 batch loss 1.26430643
Validated batch 72 batch loss 1.34066629
Validated batch 73 batch loss 1.23829865
Validated batch 74 batch loss 1.3388896
Validated batch 75 batch loss 1.35371947
Validated batch 76 batch loss 1.50854754
Validated batch 77 batch loss 1.59886956
Validated batch 78 batch loss 1.16641057
Validated batch 79 batch loss 1.24524701
Validated batch 80 batch loss 1.23211098
Validated batch 81 batch loss 1.4377284
Validated batch 82 batch loss 1.46494579
Validated batch 83 batch loss 1.34584415
Validated batch 84 batch loss 1.14878035
Validated batch 85 batch loss 0.97826004
Validated batch 86 batch loss 1.03969109
Validated batch 87 batch loss 1.12761092
Validated batch 88 batch loss 1.22544289
Validated batch 89 batch loss 1.22219849
Validated batch 90 batch loss 1.3635745
Validated batch 91 batch loss 1.50261748
Validated batch 92 batch loss 1.33668685
Validated batch 93 batch loss 1.27266574
Validated batch 94 batch loss 1.23778057
Validated batch 95 batch loss 1.23316026
Validated batch 96 batch loss 1.44546497
Validated batch 97 batch loss 1.18489015
Validated batch 98 batch loss 1.02249181
Validated batch 99 batch loss 1.18484771
Validated batch 100 batch loss 1.29178143
Validated batch 101 batch loss 1.38348532
Validated batch 102 batch loss 1.35470212
Validated batch 103 batch loss 1.36231709
Validated batch 104 batch loss 1.37886012
Validated batch 105 batch loss 1.27872515
Validated batch 106 batch loss 1.18495548
Validated batch 107 batch loss 1.17095542
Validated batch 108 batch loss 1.30113924
Validated batch 109 batch loss 1.34885216
Validated batch 110 batch loss 1.21640277
Validated batch 111 batch loss 1.22130835
Validated batch 112 batch loss 1.45476294
Validated batch 113 batch loss 1.20360577
Validated batch 114 batch loss 1.47674131
Validated batch 115 batch loss 1.40148473
Validated batch 116 batch loss 1.26901901
Validated batch 117 batch loss 1.16500127
Validated batch 118 batch loss 1.3933723
Validated batch 119 batch loss 1.38730693
Validated batch 120 batch loss 1.32709312
Validated batch 121 batch loss 1.31240487
Validated batch 122 batch loss 1.41171765
Validated batch 123 batch loss 1.35783362
Validated batch 124 batch loss 1.65847754
Validated batch 125 batch loss 1.34196162
Validated batch 126 batch loss 1.23744893
Validated batch 127 batch loss 1.38629842
Validated batch 128 batch loss 1.47759712
Validated batch 129 batch loss 1.31743193
Validated batch 130 batch loss 1.27936423
Validated batch 131 batch loss 1.23167896
Validated batch 132 batch loss 1.32451439
Validated batch 133 batch loss 1.4402349
Validated batch 134 batch loss 1.30938828
Validated batch 135 batch loss 1.16629553
Validated batch 136 batch loss 1.33957708
Validated batch 137 batch loss 1.32819223
Validated batch 138 batch loss 1.47994447
Validated batch 139 batch loss 1.56968236
Validated batch 140 batch loss 1.1015085
Validated batch 141 batch loss 1.44599152
Validated batch 142 batch loss 1.42110515
Validated batch 143 batch loss 1.29106545
Validated batch 144 batch loss 1.44159019
Validated batch 145 batch loss 1.3943181
Validated batch 146 batch loss 1.37375593
Validated batch 147 batch loss 1.40231562
Validated batch 148 batch loss 1.41730738
Validated batch 149 batch loss 1.33251595
Validated batch 150 batch loss 1.39364171
Validated batch 151 batch loss 1.39521265
Validated batch 152 batch loss 1.32862473
Validated batch 153 batch loss 1.56224418
Validated batch 154 batch loss 1.42292643
Validated batch 155 batch loss 1.37669396
Validated batch 156 batch loss 1.21588469
Validated batch 157 batch loss 1.5146637
Validated batch 158 batch loss 1.45289063
Validated batch 159 batch loss 1.26271188
Validated batch 160 batch loss 1.27417874
Validated batch 161 batch loss 1.41608834
Validated batch 162 batch loss 1.15308607
Validated batch 163 batch loss 1.17526698
Validated batch 164 batch loss 1.1952312
Validated batch 165 batch loss 1.25587487
Validated batch 166 batch loss 1.21972346
Validated batch 167 batch loss 1.39071989
Validated batch 168 batch loss 1.32157373
Validated batch 169 batch loss 1.40303493
Validated batch 170 batch loss 1.29293966
Validated batch 171 batch loss 1.34408844
Validated batch 172 batch loss 1.48980045
Validated batch 173 batch loss 1.42196643
Validated batch 174 batch loss 1.3099401
Validated batch 175 batch loss 1.33436346
Validated batch 176 batch loss 1.29119647
Validated batch 177 batch loss 1.23343635
Validated batch 178 batch loss 1.2746048
Validated batch 179 batch loss 1.34180844
Validated batch 180 batch loss 1.40180922
Validated batch 181 batch loss 1.2980392
Validated batch 182 batch loss 1.4215883
Validated batch 183 batch loss 1.07038832
Validated batch 184 batch loss 1.33449554
Validated batch 185 batch loss 1.22083139
Validated batch 186 batch loss 1.37117589
Validated batch 187 batch loss 1.24008214
Validated batch 188 batch loss 1.38150382
Validated batch 189 batch loss 1.46362662
Validated batch 190 batch loss 1.27193213
Validated batch 191 batch loss 1.28928149
Validated batch 192 batch loss 1.29058623
Validated batch 193 batch loss 1.11606359
Validated batch 194 batch loss 1.4250536
Validated batch 195 batch loss 1.30021012
Validated batch 196 batch loss 1.07365525
Validated batch 197 batch loss 1.08908987
Validated batch 198 batch loss 1.36380982
Validated batch 199 batch loss 1.27610588
Validated batch 200 batch loss 1.54708898
Validated batch 201 batch loss 1.29215574
Validated batch 202 batch loss 1.21095359
Validated batch 203 batch loss 1.3581233
Validated batch 204 batch loss 1.33915353
Validated batch 205 batch loss 1.29350162
Validated batch 206 batch loss 1.285393
Validated batch 207 batch loss 1.39301205
Validated batch 208 batch loss 1.38329339
Validated batch 209 batch loss 1.33180428
Validated batch 210 batch loss 1.30442619
Validated batch 211 batch loss 1.44177151
Validated batch 212 batch loss 1.36578977
Validated batch 213 batch loss 1.31400788
Validated batch 214 batch loss 1.3709476
Validated batch 215 batch loss 1.52573395
Validated batch 216 batch loss 1.28566873
Validated batch 217 batch loss 1.42550826
Validated batch 218 batch loss 1.36507368
Validated batch 219 batch loss 1.41129899
Validated batch 220 batch loss 1.33775032
Validated batch 221 batch loss 1.23528
Validated batch 222 batch loss 1.23483729
Validated batch 223 batch loss 1.34603333
Validated batch 224 batch loss 1.32997394
Validated batch 225 batch loss 1.37663698
Validated batch 226 batch loss 1.35939288
Validated batch 227 batch loss 1.40596032
Validated batch 228 batch loss 1.44473386
Validated batch 229 batch loss 1.27711606
Validated batch 230 batch loss 1.47495818
Validated batch 231 batch loss 1.3325069
Validated batch 232 batch loss 1.26877809
Validated batch 233 batch loss 1.08991861
Validated batch 234 batch loss 1.30401933
Validated batch 235 batch loss 1.46570468
Validated batch 236 batch loss 1.40209579
Validated batch 237 batch loss 1.36551607
Validated batch 238 batch loss 1.34391057
Validated batch 239 batch loss 1.38187599
Validated batch 240 batch loss 1.50040233
Validated batch 241 batch loss 1.49414492
Validated batch 242 batch loss 1.35526633
Validated batch 243 batch loss 1.33450043
Validated batch 244 batch loss 1.29859579
Validated batch 245 batch loss 1.3368907
Validated batch 246 batch loss 1.30620992
Validated batch 247 batch loss 1.29505229
Validated batch 248 batch loss 1.31428432
Validated batch 249 batch loss 1.29742265
Validated batch 250 batch loss 1.46145558
Validated batch 251 batch loss 1.61375594
Validated batch 252 batch loss 1.58845568
Validated batch 253 batch loss 1.14943624
Validated batch 254 batch loss 1.10346735
Validated batch 255 batch loss 1.26219594
Validated batch 256 batch loss 1.03653932
Validated batch 257 batch loss 1.47505975
Validated batch 258 batch loss 1.11708915
Validated batch 259 batch loss 1.32668412
Validated batch 260 batch loss 1.5660876
Validated batch 261 batch loss 1.28600287
Validated batch 262 batch loss 1.24593854
Validated batch 263 batch loss 1.28400207
Validated batch 264 batch loss 1.18806624
Validated batch 265 batch loss 1.19599986
Validated batch 266 batch loss 1.09674251
Validated batch 267 batch loss 1.47186351
Validated batch 268 batch loss 1.53973031
Validated batch 269 batch loss 1.52508187
Validated batch 270 batch loss 1.26295185
Validated batch 271 batch loss 1.41603398
Validated batch 272 batch loss 1.51398396
Validated batch 273 batch loss 1.29821801
Validated batch 274 batch loss 1.20861661
Validated batch 275 batch loss 1.26424408
Validated batch 276 batch loss 1.40192652
Validated batch 277 batch loss 1.38706219
Validated batch 278 batch loss 1.18551481
Validated batch 279 batch loss 1.34983695
Validated batch 280 batch loss 1.30908024
Validated batch 281 batch loss 1.26408303
Validated batch 282 batch loss 1.28560233
Validated batch 283 batch loss 1.1994276
Validated batch 284 batch loss 1.31533861
Validated batch 285 batch loss 1.36830425
Validated batch 286 batch loss 1.33789086
Validated batch 287 batch loss 1.25499976
Validated batch 288 batch loss 1.1532948
Validated batch 289 batch loss 1.2481842
Validated batch 290 batch loss 1.43519092
Validated batch 291 batch loss 1.26752388
Validated batch 292 batch loss 1.21189702
Validated batch 293 batch loss 1.19910896
Validated batch 294 batch loss 1.38113821
Validated batch 295 batch loss 1.19895339
Validated batch 296 batch loss 1.39519286
Validated batch 297 batch loss 1.43436182
Validated batch 298 batch loss 1.2888279
Validated batch 299 batch loss 1.42045391
Validated batch 300 batch loss 1.26865637
Validated batch 301 batch loss 1.32732034
Validated batch 302 batch loss 1.32168937
Validated batch 303 batch loss 1.10600972
Validated batch 304 batch loss 1.5988133
Validated batch 305 batch loss 1.22646785
Validated batch 306 batch loss 1.27028894
Validated batch 307 batch loss 1.264871
Validated batch 308 batch loss 1.37070298
Validated batch 309 batch loss 1.44380677
Validated batch 310 batch loss 1.30864203
Validated batch 311 batch loss 1.42528868
Validated batch 312 batch loss 1.02313161
Validated batch 313 batch loss 1.27898073
Validated batch 314 batch loss 1.19474828
Validated batch 315 batch loss 1.32307434
Validated batch 316 batch loss 1.35624301
Validated batch 317 batch loss 1.47587144
Validated batch 318 batch loss 1.42225182
Validated batch 319 batch loss 1.31528687
Validated batch 320 batch loss 1.27767515
Validated batch 321 batch loss 1.43936634
Validated batch 322 batch loss 1.50022209
Validated batch 323 batch loss 1.14888597
Validated batch 324 batch loss 1.14023876
Validated batch 325 batch loss 1.14815259
Validated batch 326 batch loss 1.11518025
Validated batch 327 batch loss 1.32262552
Validated batch 328 batch loss 1.46242142
Validated batch 329 batch loss 1.44813561
Validated batch 330 batch loss 1.20943856
Validated batch 331 batch loss 1.23043823
Validated batch 332 batch loss 1.25368619
Validated batch 333 batch loss 1.53276837
Validated batch 334 batch loss 1.27984548
Validated batch 335 batch loss 1.33033156
Validated batch 336 batch loss 1.24385023
Validated batch 337 batch loss 1.45090365
Validated batch 338 batch loss 1.20439363
Validated batch 339 batch loss 1.28362179
Validated batch 340 batch loss 1.33510351
Validated batch 341 batch loss 1.42429268
Validated batch 342 batch loss 1.48218381
Validated batch 343 batch loss 1.40968776
Validated batch 344 batch loss 1.48288405
Validated batch 345 batch loss 1.15689528
Validated batch 346 batch loss 1.06457782
Validated batch 347 batch loss 1.34750795
Validated batch 348 batch loss 1.50507212
Validated batch 349 batch loss 1.39711142
Validated batch 350 batch loss 1.36766958
Validated batch 351 batch loss 1.26943398
Validated batch 352 batch loss 1.01024199
Validated batch 353 batch loss 1.23278546
Validated batch 354 batch loss 1.3909
Validated batch 355 batch loss 1.23396778
Validated batch 356 batch loss 1.53153062
Validated batch 357 batch loss 1.33171833
Validated batch 358 batch loss 1.28146768
Validated batch 359 batch loss 1.42905378
Validated batch 360 batch loss 1.34107816
Validated batch 361 batch loss 1.35352647
Validated batch 362 batch loss 1.45736217
Validated batch 363 batch loss 1.14105535
Validated batch 364 batch loss 1.10291481
Validated batch 365 batch loss 1.4149394
Validated batch 366 batch loss 1.39849913
Validated batch 367 batch loss 1.19694436
Validated batch 368 batch loss 1.48436904
Validated batch 369 batch loss 1.316113
Validated batch 370 batch loss 1.35396624
Validated batch 371 batch loss 1.33080518
Validated batch 372 batch loss 1.38475513
Validated batch 373 batch loss 1.41742349
Validated batch 374 batch loss 1.27573383
Validated batch 375 batch loss 1.19512546
Validated batch 376 batch loss 1.44008493
Validated batch 377 batch loss 1.30382299
Validated batch 378 batch loss 1.35561109
Validated batch 379 batch loss 1.06803942
Validated batch 380 batch loss 1.33910596
Validated batch 381 batch loss 1.25825047
Validated batch 382 batch loss 1.27355075
Validated batch 383 batch loss 1.13148177
Validated batch 384 batch loss 1.43681312
Validated batch 385 batch loss 1.22415376
Validated batch 386 batch loss 1.55759144
Validated batch 387 batch loss 1.17081046
Validated batch 388 batch loss 1.39386332
Validated batch 389 batch loss 1.41198683
Validated batch 390 batch loss 1.66860294
Validated batch 391 batch loss 1.43191767
Validated batch 392 batch loss 1.39274502
Validated batch 393 batch loss 1.16018558
Validated batch 394 batch loss 1.13771713
Validated batch 395 batch loss 1.34599531
Validated batch 396 batch loss 1.31217575
Validated batch 397 batch loss 1.25312316
Validated batch 398 batch loss 1.16584277
Validated batch 399 batch loss 1.50185573
Validated batch 400 batch loss 1.36416793
Validated batch 401 batch loss 1.31368816
Validated batch 402 batch loss 1.32099652
Validated batch 403 batch loss 1.34087217
Validated batch 404 batch loss 1.38577557
Validated batch 405 batch loss 1.52882051
Validated batch 406 batch loss 1.41213977
Validated batch 407 batch loss 1.16476464
Validated batch 408 batch loss 1.26722074
Validated batch 409 batch loss 1.30758381
Validated batch 410 batch loss 1.35813451
Validated batch 411 batch loss 1.22392774
Validated batch 412 batch loss 1.38797832
Validated batch 413 batch loss 1.41559124
Validated batch 414 batch loss 1.23997545
Validated batch 415 batch loss 1.24349236
Validated batch 416 batch loss 1.04523373
Validated batch 417 batch loss 1.35322011
Validated batch 418 batch loss 1.26489115
Validated batch 419 batch loss 1.4061836
Validated batch 420 batch loss 1.50243151
Validated batch 421 batch loss 1.51868188
Validated batch 422 batch loss 1.43504894
Validated batch 423 batch loss 1.21678519
Validated batch 424 batch loss 1.20394421
Validated batch 425 batch loss 1.13020515
Validated batch 426 batch loss 1.49382663
Validated batch 427 batch loss 1.47801876
Validated batch 428 batch loss 1.37904668
Validated batch 429 batch loss 1.09766769
Validated batch 430 batch loss 1.36446702
Validated batch 431 batch loss 1.35040796
Validated batch 432 batch loss 1.34474123
Validated batch 433 batch loss 1.27755547
Validated batch 434 batch loss 1.33954048
Validated batch 435 batch loss 1.37130451
Validated batch 436 batch loss 1.37569034
Validated batch 437 batch loss 1.45889914
Validated batch 438 batch loss 1.35409474
Validated batch 439 batch loss 1.10606885
Validated batch 440 batch loss 0.943285
Validated batch 441 batch loss 1.15701866
Validated batch 442 batch loss 1.37637663
Validated batch 443 batch loss 1.30683911
Validated batch 444 batch loss 1.2972672
Validated batch 445 batch loss 1.31657267
Validated batch 446 batch loss 1.26300883
Validated batch 447 batch loss 1.28802824
Validated batch 448 batch loss 1.29604101
Validated batch 449 batch loss 1.15643668
Validated batch 450 batch loss 1.21552455
Validated batch 451 batch loss 1.33755517
Validated batch 452 batch loss 1.08633137
Validated batch 453 batch loss 1.51804733
Validated batch 454 batch loss 1.2893194
Validated batch 455 batch loss 1.15890718
Validated batch 456 batch loss 1.32035792
Validated batch 457 batch loss 1.37558722
Validated batch 458 batch loss 1.25061405
Validated batch 459 batch loss 1.28471327
Validated batch 460 batch loss 1.28034425
Validated batch 461 batch loss 1.55302799
Validated batch 462 batch loss 1.4784987
Validated batch 463 batch loss 1.52423847
Validated batch 464 batch loss 1.42535102
Validated batch 465 batch loss 1.40960193
Validated batch 466 batch loss 1.23293388
Validated batch 467 batch loss 1.23770583
Validated batch 468 batch loss 1.38932323
Validated batch 469 batch loss 1.53670692
Validated batch 470 batch loss 1.14822662
Validated batch 471 batch loss 1.37023187
Validated batch 472 batch loss 1.08585513
Validated batch 473 batch loss 1.46607697
Validated batch 474 batch loss 1.19392633
Validated batch 475 batch loss 1.19729686
Validated batch 476 batch loss 1.30010533
Validated batch 477 batch loss 1.24143434
Validated batch 478 batch loss 1.22493982
Validated batch 479 batch loss 1.1475035
Validated batch 480 batch loss 1.30848598
Validated batch 481 batch loss 1.35604537
Validated batch 482 batch loss 1.47522163
Validated batch 483 batch loss 1.41008687
Validated batch 484 batch loss 1.21274364
Validated batch 485 batch loss 1.34569061
Validated batch 486 batch loss 1.29283071
Validated batch 487 batch loss 1.30830228
Validated batch 488 batch loss 1.24328506
Validated batch 489 batch loss 1.42192805
Validated batch 490 batch loss 1.1462121
Validated batch 491 batch loss 1.21099091
Validated batch 492 batch loss 1.11817837
Validated batch 493 batch loss 1.25437129
Validated batch 494 batch loss 1.16100478
Validated batch 495 batch loss 1.2042979
Validated batch 496 batch loss 1.34585
Validated batch 497 batch loss 1.49640429
Validated batch 498 batch loss 1.25604129
Validated batch 499 batch loss 1.41515803
Validated batch 500 batch loss 1.02389431
Validated batch 501 batch loss 1.34525561
Validated batch 502 batch loss 1.40091097
Validated batch 503 batch loss 1.23144984
Validated batch 504 batch loss 1.37567282
Validated batch 505 batch loss 1.34266853
Validated batch 506 batch loss 1.43515062
Validated batch 507 batch loss 1.30731273
Validated batch 508 batch loss 1.39522076
Validated batch 509 batch loss 1.12030649
Validated batch 510 batch loss 1.44318151
Validated batch 511 batch loss 1.44491434
Validated batch 512 batch loss 1.22592807
Validated batch 513 batch loss 1.12769127
Validated batch 514 batch loss 1.1784749
Validated batch 515 batch loss 1.24422729
Validated batch 516 batch loss 1.22252893
Validated batch 517 batch loss 1.32615185
Validated batch 518 batch loss 1.4917841
Validated batch 519 batch loss 1.23484921
Validated batch 520 batch loss 1.06863546
Validated batch 521 batch loss 1.31484175
Validated batch 522 batch loss 1.38015127
Validated batch 523 batch loss 1.28182673
Validated batch 524 batch loss 1.33575583
Validated batch 525 batch loss 1.35135472
Validated batch 526 batch loss 1.22371638
Validated batch 527 batch loss 1.49625778
Validated batch 528 batch loss 1.2791661
Validated batch 529 batch loss 1.3372829
Validated batch 530 batch loss 1.27011609
Validated batch 531 batch loss 1.44596612
Validated batch 532 batch loss 1.31891251
Validated batch 533 batch loss 1.35685182
Validated batch 534 batch loss 1.35748672
Validated batch 535 batch loss 1.41197646
Validated batch 536 batch loss 1.36342216
Validated batch 537 batch loss 1.40652156
Validated batch 538 batch loss 1.50452423
Validated batch 539 batch loss 1.47318649
Validated batch 540 batch loss 1.55928171
Validated batch 541 batch loss 1.44431317
Validated batch 542 batch loss 1.5282315
Validated batch 543 batch loss 1.34104097
Validated batch 544 batch loss 1.23801064
Validated batch 545 batch loss 1.3265655
Validated batch 546 batch loss 1.12876749
Validated batch 547 batch loss 1.44408369
Validated batch 548 batch loss 1.36963618
Validated batch 549 batch loss 1.31073308
Validated batch 550 batch loss 1.12344825
Validated batch 551 batch loss 1.17495918
Validated batch 552 batch loss 1.27458954
Validated batch 553 batch loss 1.21183097
Validated batch 554 batch loss 1.11174893
Validated batch 555 batch loss 1.22437668
Validated batch 556 batch loss 1.28832841
Validated batch 557 batch loss 1.30962574
Validated batch 558 batch loss 1.27499199
Validated batch 559 batch loss 1.4180367
Validated batch 560 batch loss 1.2818718
Validated batch 561 batch loss 1.18918133
Validated batch 562 batch loss 1.3878783
Validated batch 563 batch loss 1.3564285
Validated batch 564 batch loss 1.2134366
Validated batch 565 batch loss 1.09741664
Validated batch 566 batch loss 1.10466254
Validated batch 567 batch loss 1.08549428
Validated batch 568 batch loss 1.29083502
Validated batch 569 batch loss 1.27398252
Validated batch 570 batch loss 1.16086388
Validated batch 571 batch loss 1.43125725
Validated batch 572 batch loss 1.01319087
Validated batch 573 batch loss 1.23763323
Validated batch 574 batch loss 1.41585362
Validated batch 575 batch loss 1.61745369
Validated batch 576 batch loss 1.3493408
Validated batch 577 batch loss 1.13398445
Validated batch 578 batch loss 1.22535014
Validated batch 579 batch loss 1.39740205
Validated batch 580 batch loss 1.08000898
Validated batch 581 batch loss 1.4967407
Validated batch 582 batch loss 1.26455045
Validated batch 583 batch loss 1.16055846
Validated batch 584 batch loss 1.13638747
Validated batch 585 batch loss 1.259951
Validated batch 586 batch loss 1.16791165
Validated batch 587 batch loss 1.23679781
Validated batch 588 batch loss 1.38155973
Validated batch 589 batch loss 1.38743865
Validated batch 590 batch loss 1.25002575
Validated batch 591 batch loss 1.38720787
Validated batch 592 batch loss 1.34589422
Validated batch 593 batch loss 1.17486155
Validated batch 594 batch loss 1.28164482
Validated batch 595 batch loss 1.35997844
Validated batch 596 batch loss 1.06363964
Validated batch 597 batch loss 1.19207191
Validated batch 598 batch loss 1.40283895
Validated batch 599 batch loss 1.45572925
Validated batch 600 batch loss 1.20725143
Validated batch 601 batch loss 0.997793
Validated batch 602 batch loss 1.39198709
Validated batch 603 batch loss 1.19385767
Validated batch 604 batch loss 1.23324442
Validated batch 605 batch loss 1.53671384
Validated batch 606 batch loss 1.43511784
Validated batch 607 batch loss 1.04544127
Validated batch 608 batch loss 1.31191719
Validated batch 609 batch loss 1.38457727
Validated batch 610 batch loss 1.33833718
Validated batch 611 batch loss 1.40742159
Validated batch 612 batch loss 1.32403576
Validated batch 613 batch loss 1.37084103
Validated batch 614 batch loss 1.41788518
Validated batch 615 batch loss 1.32604146
Validated batch 616 batch loss 1.49859893
Validated batch 617 batch loss 1.24955487
Validated batch 618 batch loss 1.22569954
Validated batch 619 batch loss 1.32386875
Validated batch 620 batch loss 1.09929228
Validated batch 621 batch loss 1.36252415
Validated batch 622 batch loss 1.46583772
Validated batch 623 batch loss 1.415663
Validated batch 624 batch loss 1.39116263
Validated batch 625 batch loss 1.23572588
Validated batch 626 batch loss 1.12506151
Validated batch 627 batch loss 1.08922184
Validated batch 628 batch loss 1.14708638
Validated batch 629 batch loss 1.14914823
Validated batch 630 batch loss 1.34623885
Validated batch 631 batch loss 1.16162825
Validated batch 632 batch loss 1.2412287
Validated batch 633 batch loss 1.40049887
Validated batch 634 batch loss 1.43137121
Validated batch 635 batch loss 1.12665153
Validated batch 636 batch loss 1.19035816
Validated batch 637 batch loss 1.21987295
Validated batch 638 batch loss 1.21443832
Validated batch 639 batch loss 1.3622148
Validated batch 640 batch loss 1.4929
Validated batch 641 batch loss 1.32861841
Validated batch 642 batch loss 1.49720204
Validated batch 643 batch loss 1.50819612
Validated batch 644 batch loss 1.32924819
Validated batch 645 batch loss 1.56217885
Validated batch 646 batch loss 1.27820134
Validated batch 647 batch loss 1.30014777
Validated batch 648 batch loss 1.13146603
Validated batch 649 batch loss 1.02557468
Validated batch 650 batch loss 1.48546147
Validated batch 651 batch loss 1.11211908
Validated batch 652 batch loss 1.49490094
Validated batch 653 batch loss 1.26855528
Validated batch 654 batch loss 1.32519984
Validated batch 655 batch loss 1.49319577
Validated batch 656 batch loss 1.20095503
Validated batch 657 batch loss 1.24535537
Validated batch 658 batch loss 1.40607619
Validated batch 659 batch loss 1.28855848
Validated batch 660 batch loss 1.24411392
Validated batch 661 batch loss 1.12865
Validated batch 662 batch loss 1.37625647
Validated batch 663 batch loss 1.25525606
Validated batch 664 batch loss 1.37700868
Validated batch 665 batch loss 1.35762143
Validated batch 666 batch loss 1.51834011
Validated batch 667 batch loss 1.53137243
Validated batch 668 batch loss 1.4076134
Validated batch 669 batch loss 1.3728441
Validated batch 670 batch loss 1.25614107
Validated batch 671 batch loss 1.23318768
Validated batch 672 batch loss 1.06499755
Validated batch 673 batch loss 1.34655201
Validated batch 674 batch loss 1.3790946
Validated batch 675 batch loss 1.29694128
Validated batch 676 batch loss 1.36871326
Validated batch 677 batch loss 1.30372167
Validated batch 678 batch loss 1.40937448
Validated batch 679 batch loss 1.40790582
Validated batch 680 batch loss 1.19086766
Validated batch 681 batch loss 1.22743845
Validated batch 682 batch loss 1.39442456
Validated batch 683 batch loss 1.35706651
Validated batch 684 batch loss 1.42817187
Validated batch 685 batch loss 1.33813953
Validated batch 686 batch loss 1.25946569
Validated batch 687 batch loss 1.37183607
Validated batch 688 batch loss 1.31309295
Validated batch 689 batch loss 1.36143804
Validated batch 690 batch loss 1.15158403
Validated batch 691 batch loss 1.21028781
Validated batch 692 batch loss 1.30989671
Validated batch 693 batch loss 1.00420797
Validated batch 694 batch loss 0.96757257
Validated batch 695 batch loss 0.995326161
Validated batch 696 batch loss 1.14619148
Validated batch 697 batch loss 1.35966671
Validated batch 698 batch loss 1.38412523
Validated batch 699 batch loss 1.33115101
Validated batch 700 batch loss 1.24482572
Validated batch 701 batch loss 1.26834
Validated batch 702 batch loss 1.19591939
Validated batch 703 batch loss 1.26903939
Validated batch 704 batch loss 1.17421722
Validated batch 705 batch loss 1.43052077
Validated batch 706 batch loss 1.26941657
Validated batch 707 batch loss 1.3710109
Validated batch 708 batch loss 1.14780498
Validated batch 709 batch loss 1.28905678
Validated batch 710 batch loss 1.40314555
Validated batch 711 batch loss 1.41220701
Validated batch 712 batch loss 1.40598369
Validated batch 713 batch loss 1.20325661
Validated batch 714 batch loss 1.33179212
Validated batch 715 batch loss 1.25738478
Validated batch 716 batch loss 1.15123761
Validated batch 717 batch loss 1.3714143
Validated batch 718 batch loss 1.36753559
Validated batch 719 batch loss 1.36250305
Validated batch 720 batch loss 1.29583955
Validated batch 721 batch loss 1.22596955
Validated batch 722 batch loss 1.43468535
Validated batch 723 batch loss 1.51238036
Validated batch 724 batch loss 1.46759653
Validated batch 725 batch loss 1.20177484
Validated batch 726 batch loss 1.43202484
Validated batch 727 batch loss 1.44085622
Validated batch 728 batch loss 1.31568098
Validated batch 729 batch loss 1.37883925
Validated batch 730 batch loss 1.38734436
Validated batch 731 batch loss 1.41725469
Validated batch 732 batch loss 1.23790443
Validated batch 733 batch loss 1.19282341
Validated batch 734 batch loss 1.24204934
Validated batch 735 batch loss 1.16797578
Validated batch 736 batch loss 1.05646634
Validated batch 737 batch loss 1.26462889
Validated batch 738 batch loss 1.27421916
Epoch 1 val loss 1.3113243579864502
Start epoch 2 with learning rate 0.0003
Start distributed traininng...
Trained batch 1 batch loss 1.38503289 epoch total loss 1.38503289
Trained batch 2 batch loss 1.2747103 epoch total loss 1.32987165
Trained batch 3 batch loss 1.41034317 epoch total loss 1.35669553
Trained batch 4 batch loss 1.4198283 epoch total loss 1.37247872
Trained batch 5 batch loss 1.4008491 epoch total loss 1.37815285
Trained batch 6 batch loss 1.28336942 epoch total loss 1.36235559
Trained batch 7 batch loss 1.18087459 epoch total loss 1.33642972
Trained batch 8 batch loss 1.03787208 epoch total loss 1.29911
Trained batch 9 batch loss 1.19073403 epoch total loss 1.28706825
Trained batch 10 batch loss 1.23207688 epoch total loss 1.28156912
Trained batch 11 batch loss 1.43502712 epoch total loss 1.29551983
Trained batch 12 batch loss 1.1661346 epoch total loss 1.28473771
Trained batch 13 batch loss 1.27785969 epoch total loss 1.28420877
Trained batch 14 batch loss 1.16862762 epoch total loss 1.27595294
Trained batch 15 batch loss 1.28792357 epoch total loss 1.27675092
Trained batch 16 batch loss 1.36051881 epoch total loss 1.28198647
Trained batch 17 batch loss 1.3117919 epoch total loss 1.28373981
Trained batch 18 batch loss 1.41479969 epoch total loss 1.29102087
Trained batch 19 batch loss 1.2344166 epoch total loss 1.28804171
Trained batch 20 batch loss 1.27353323 epoch total loss 1.28731632
Trained batch 21 batch loss 1.02419746 epoch total loss 1.27478683
Trained batch 22 batch loss 1.44554973 epoch total loss 1.28254879
Trained batch 23 batch loss 1.19153237 epoch total loss 1.27859151
Trained batch 24 batch loss 1.12924421 epoch total loss 1.27236867
Trained batch 25 batch loss 1.24356413 epoch total loss 1.27121651
Trained batch 26 batch loss 1.24628794 epoch total loss 1.27025771
Trained batch 27 batch loss 1.15418601 epoch total loss 1.26595867
Trained batch 28 batch loss 1.06144869 epoch total loss 1.25865471
Trained batch 29 batch loss 1.11463892 epoch total loss 1.25368869
Trained batch 30 batch loss 1.30918455 epoch total loss 1.25553858
Trained batch 31 batch loss 1.24492395 epoch total loss 1.25519609
Trained batch 32 batch loss 1.2257762 epoch total loss 1.25427675
Trained batch 33 batch loss 1.11355 epoch total loss 1.25001228
Trained batch 34 batch loss 1.26244211 epoch total loss 1.25037789
Trained batch 35 batch loss 1.07085705 epoch total loss 1.24524879
Trained batch 36 batch loss 1.1867907 epoch total loss 1.24362493
Trained batch 37 batch loss 1.06807828 epoch total loss 1.2388804
Trained batch 38 batch loss 1.1663177 epoch total loss 1.23697078
Trained batch 39 batch loss 1.15777898 epoch total loss 1.23494029
Trained batch 40 batch loss 1.14158082 epoch total loss 1.23260629
Trained batch 41 batch loss 1.41551375 epoch total loss 1.23706746
Trained batch 42 batch loss 1.16420412 epoch total loss 1.23533261
Trained batch 43 batch loss 1.23615837 epoch total loss 1.23535168
Trained batch 44 batch loss 1.37256551 epoch total loss 1.2384702
Trained batch 45 batch loss 1.26876462 epoch total loss 1.23914349
Trained batch 46 batch loss 1.48886347 epoch total loss 1.24457216
Trained batch 47 batch loss 1.2269417 epoch total loss 1.24419701
Trained batch 48 batch loss 1.43290877 epoch total loss 1.24812853
Trained batch 49 batch loss 1.33985925 epoch total loss 1.2500006
Trained batch 50 batch loss 1.56755519 epoch total loss 1.25635159
Trained batch 51 batch loss 1.21266627 epoch total loss 1.25549507
Trained batch 52 batch loss 1.3033762 epoch total loss 1.25641584
Trained batch 53 batch loss 1.28301847 epoch total loss 1.25691783
Trained batch 54 batch loss 1.18234324 epoch total loss 1.25553679
Trained batch 55 batch loss 1.0676831 epoch total loss 1.25212121
Trained batch 56 batch loss 1.32355881 epoch total loss 1.25339699
Trained batch 57 batch loss 1.36791992 epoch total loss 1.25540614
Trained batch 58 batch loss 1.26519203 epoch total loss 1.25557482
Trained batch 59 batch loss 1.24839211 epoch total loss 1.25545311
Trained batch 60 batch loss 1.39215839 epoch total loss 1.25773156
Trained batch 61 batch loss 1.3855437 epoch total loss 1.25982678
Trained batch 62 batch loss 1.3545475 epoch total loss 1.26135457
Trained batch 63 batch loss 1.15349853 epoch total loss 1.25964248
Trained batch 64 batch loss 1.3886373 epoch total loss 1.26165795
Trained batch 65 batch loss 1.19015956 epoch total loss 1.26055801
Trained batch 66 batch loss 1.33665514 epoch total loss 1.261711
Trained batch 67 batch loss 1.30318189 epoch total loss 1.26233
Trained batch 68 batch loss 1.18027556 epoch total loss 1.2611233
Trained batch 69 batch loss 1.07732582 epoch total loss 1.25845957
Trained batch 70 batch loss 1.22537112 epoch total loss 1.2579869
Trained batch 71 batch loss 1.20194888 epoch total loss 1.25719762
Trained batch 72 batch loss 1.40710413 epoch total loss 1.25927973
Trained batch 73 batch loss 1.15479493 epoch total loss 1.25784838
Trained batch 74 batch loss 0.993685186 epoch total loss 1.25427854
Trained batch 75 batch loss 1.21451557 epoch total loss 1.25374842
Trained batch 76 batch loss 1.20362568 epoch total loss 1.25308895
Trained batch 77 batch loss 1.29449534 epoch total loss 1.25362659
Trained batch 78 batch loss 1.01476097 epoch total loss 1.25056434
Trained batch 79 batch loss 1.1864742 epoch total loss 1.24975312
Trained batch 80 batch loss 1.25087 epoch total loss 1.24976707
Trained batch 81 batch loss 1.13454366 epoch total loss 1.24834454
Trained batch 82 batch loss 1.115188 epoch total loss 1.24672067
Trained batch 83 batch loss 1.00838685 epoch total loss 1.24384916
Trained batch 84 batch loss 1.20414257 epoch total loss 1.24337637
Trained batch 85 batch loss 1.29594386 epoch total loss 1.24399483
Trained batch 86 batch loss 1.27124894 epoch total loss 1.24431181
Trained batch 87 batch loss 1.48092413 epoch total loss 1.24703145
Trained batch 88 batch loss 1.49184752 epoch total loss 1.24981344
Trained batch 89 batch loss 1.37891483 epoch total loss 1.25126398
Trained batch 90 batch loss 1.27372766 epoch total loss 1.2515136
Trained batch 91 batch loss 1.35951543 epoch total loss 1.25270033
Trained batch 92 batch loss 1.37294865 epoch total loss 1.25400746
Trained batch 93 batch loss 1.56980896 epoch total loss 1.25740314
Trained batch 94 batch loss 1.45681787 epoch total loss 1.25952458
Trained batch 95 batch loss 1.4218713 epoch total loss 1.26123357
Trained batch 96 batch loss 1.37020993 epoch total loss 1.26236868
Trained batch 97 batch loss 1.22684932 epoch total loss 1.26200259
Trained batch 98 batch loss 1.30881119 epoch total loss 1.26248014
Trained batch 99 batch loss 1.32982326 epoch total loss 1.26316035
Trained batch 100 batch loss 1.4073534 epoch total loss 1.2646023
Trained batch 101 batch loss 1.30099535 epoch total loss 1.26496267
Trained batch 102 batch loss 1.11570919 epoch total loss 1.26349938
Trained batch 103 batch loss 1.15508282 epoch total loss 1.26244688
Trained batch 104 batch loss 1.08857012 epoch total loss 1.26077509
Trained batch 105 batch loss 1.15405571 epoch total loss 1.25975859
Trained batch 106 batch loss 1.42298424 epoch total loss 1.26129854
Trained batch 107 batch loss 1.33150649 epoch total loss 1.26195478
Trained batch 108 batch loss 1.27539086 epoch total loss 1.26207912
Trained batch 109 batch loss 1.21389103 epoch total loss 1.26163709
Trained batch 110 batch loss 1.17611754 epoch total loss 1.26085973
Trained batch 111 batch loss 1.26376295 epoch total loss 1.26088583
Trained batch 112 batch loss 1.16870356 epoch total loss 1.26006281
Trained batch 113 batch loss 1.18672228 epoch total loss 1.25941372
Trained batch 114 batch loss 1.28162622 epoch total loss 1.25960863
Trained batch 115 batch loss 1.2840786 epoch total loss 1.2598213
Trained batch 116 batch loss 1.02047467 epoch total loss 1.25775802
Trained batch 117 batch loss 1.54432344 epoch total loss 1.2602073
Trained batch 118 batch loss 1.32079136 epoch total loss 1.26072073
Trained batch 119 batch loss 1.14796925 epoch total loss 1.25977314
Trained batch 120 batch loss 1.18123734 epoch total loss 1.2591188
Trained batch 121 batch loss 1.21825838 epoch total loss 1.25878108
Trained batch 122 batch loss 1.08331728 epoch total loss 1.25734282
Trained batch 123 batch loss 1.3229394 epoch total loss 1.25787616
Trained batch 124 batch loss 1.46712875 epoch total loss 1.25956368
Trained batch 125 batch loss 1.45576596 epoch total loss 1.26113331
Trained batch 126 batch loss 1.36677766 epoch total loss 1.26197171
Trained batch 127 batch loss 1.4384414 epoch total loss 1.26336133
Trained batch 128 batch loss 1.3168354 epoch total loss 1.26377904
Trained batch 129 batch loss 1.29835916 epoch total loss 1.26404703
Trained batch 130 batch loss 1.05865312 epoch total loss 1.26246715
Trained batch 131 batch loss 1.30575347 epoch total loss 1.26279759
Trained batch 132 batch loss 1.15429091 epoch total loss 1.26197565
Trained batch 133 batch loss 1.22178721 epoch total loss 1.26167345
Trained batch 134 batch loss 1.23355818 epoch total loss 1.26146352
Trained batch 135 batch loss 1.32837677 epoch total loss 1.26195931
Trained batch 136 batch loss 1.37169111 epoch total loss 1.26276612
Trained batch 137 batch loss 1.34886408 epoch total loss 1.26339459
Trained batch 138 batch loss 1.19663715 epoch total loss 1.26291084
Trained batch 139 batch loss 1.42668116 epoch total loss 1.26408899
Trained batch 140 batch loss 1.22892284 epoch total loss 1.26383781
Trained batch 141 batch loss 1.29409194 epoch total loss 1.26405251
Trained batch 142 batch loss 1.32295299 epoch total loss 1.26446724
Trained batch 143 batch loss 0.984759808 epoch total loss 1.26251125
Trained batch 144 batch loss 0.964439154 epoch total loss 1.2604413
Trained batch 145 batch loss 1.09760237 epoch total loss 1.25931823
Trained batch 146 batch loss 1.11888409 epoch total loss 1.25835633
Trained batch 147 batch loss 1.12285602 epoch total loss 1.25743449
Trained batch 148 batch loss 1.21428776 epoch total loss 1.25714302
Trained batch 149 batch loss 1.38700533 epoch total loss 1.25801456
Trained batch 150 batch loss 1.22860885 epoch total loss 1.25781846
Trained batch 151 batch loss 1.18052793 epoch total loss 1.25730669
Trained batch 152 batch loss 1.4072907 epoch total loss 1.25829339
Trained batch 153 batch loss 1.2757889 epoch total loss 1.25840771
Trained batch 154 batch loss 1.13632071 epoch total loss 1.25761497
Trained batch 155 batch loss 1.12084484 epoch total loss 1.25673258
Trained batch 156 batch loss 1.21971726 epoch total loss 1.25649524
Trained batch 157 batch loss 1.11559379 epoch total loss 1.25559783
Trained batch 158 batch loss 1.20728397 epoch total loss 1.25529206
Trained batch 159 batch loss 1.02425838 epoch total loss 1.25383902
Trained batch 160 batch loss 1.08922 epoch total loss 1.25281024
Trained batch 161 batch loss 0.996893167 epoch total loss 1.25122058
Trained batch 162 batch loss 1.34339499 epoch total loss 1.25178957
Trained batch 163 batch loss 1.05457258 epoch total loss 1.2505796
Trained batch 164 batch loss 1.15528774 epoch total loss 1.24999857
Trained batch 165 batch loss 1.07358146 epoch total loss 1.24892938
Trained batch 166 batch loss 1.23796201 epoch total loss 1.24886334
Trained batch 167 batch loss 1.31139922 epoch total loss 1.24923778
Trained batch 168 batch loss 1.27099526 epoch total loss 1.24936736
Trained batch 169 batch loss 1.12806118 epoch total loss 1.2486496
Trained batch 170 batch loss 1.24176979 epoch total loss 1.24860907
Trained batch 171 batch loss 1.19695354 epoch total loss 1.24830711
Trained batch 172 batch loss 1.38413763 epoch total loss 1.24909675
Trained batch 173 batch loss 1.41757631 epoch total loss 1.25007069
Trained batch 174 batch loss 1.23101628 epoch total loss 1.24996114
Trained batch 175 batch loss 1.18063617 epoch total loss 1.24956501
Trained batch 176 batch loss 1.17726421 epoch total loss 1.24915421
Trained batch 177 batch loss 1.09220552 epoch total loss 1.24826753
Trained batch 178 batch loss 1.08858514 epoch total loss 1.24737048
Trained batch 179 batch loss 1.21126044 epoch total loss 1.24716866
Trained batch 180 batch loss 1.33439827 epoch total loss 1.24765325
Trained batch 181 batch loss 1.25750637 epoch total loss 1.24770772
Trained batch 182 batch loss 1.47944319 epoch total loss 1.248981
Trained batch 183 batch loss 1.5295521 epoch total loss 1.25051427
Trained batch 184 batch loss 1.66598809 epoch total loss 1.25277221
Trained batch 185 batch loss 1.47929835 epoch total loss 1.25399661
Trained batch 186 batch loss 1.67764962 epoch total loss 1.25627434
Trained batch 187 batch loss 1.2822926 epoch total loss 1.25641346
Trained batch 188 batch loss 1.16106617 epoch total loss 1.25590634
Trained batch 189 batch loss 1.07986891 epoch total loss 1.25497484
Trained batch 190 batch loss 1.16653025 epoch total loss 1.25450933
Trained batch 191 batch loss 1.35067654 epoch total loss 1.25501287
Trained batch 192 batch loss 1.21855938 epoch total loss 1.25482309
Trained batch 193 batch loss 1.04006183 epoch total loss 1.25371027
Trained batch 194 batch loss 1.06480527 epoch total loss 1.25273657
Trained batch 195 batch loss 1.09351146 epoch total loss 1.25192
Trained batch 196 batch loss 0.923728228 epoch total loss 1.25024545
Trained batch 197 batch loss 1.01293039 epoch total loss 1.24904084
Trained batch 198 batch loss 1.17150366 epoch total loss 1.24864924
Trained batch 199 batch loss 1.20918179 epoch total loss 1.24845088
Trained batch 200 batch loss 1.23530865 epoch total loss 1.24838519
Trained batch 201 batch loss 1.26735687 epoch total loss 1.2484796
Trained batch 202 batch loss 1.13950801 epoch total loss 1.24794018
Trained batch 203 batch loss 1.30367577 epoch total loss 1.24821472
Trained batch 204 batch loss 1.33559871 epoch total loss 1.24864304
Trained batch 205 batch loss 1.08154464 epoch total loss 1.24782801
Trained batch 206 batch loss 1.2412715 epoch total loss 1.24779606
Trained batch 207 batch loss 1.60485983 epoch total loss 1.24952102
Trained batch 208 batch loss 1.53303587 epoch total loss 1.25088418
Trained batch 209 batch loss 1.63690364 epoch total loss 1.25273108
Trained batch 210 batch loss 1.22849441 epoch total loss 1.25261569
Trained batch 211 batch loss 1.30139256 epoch total loss 1.25284684
Trained batch 212 batch loss 1.28233016 epoch total loss 1.25298584
Trained batch 213 batch loss 1.38402891 epoch total loss 1.25360107
Trained batch 214 batch loss 1.21225858 epoch total loss 1.25340784
Trained batch 215 batch loss 1.15887666 epoch total loss 1.25296819
Trained batch 216 batch loss 1.09734392 epoch total loss 1.25224769
Trained batch 217 batch loss 1.15928602 epoch total loss 1.25181925
Trained batch 218 batch loss 1.25195765 epoch total loss 1.25181985
Trained batch 219 batch loss 1.28651702 epoch total loss 1.2519784
Trained batch 220 batch loss 1.37653613 epoch total loss 1.25254452
Trained batch 221 batch loss 1.27065969 epoch total loss 1.25262642
Trained batch 222 batch loss 1.25791788 epoch total loss 1.25265026
Trained batch 223 batch loss 1.22520828 epoch total loss 1.25252724
Trained batch 224 batch loss 1.16426623 epoch total loss 1.25213325
Trained batch 225 batch loss 1.15116525 epoch total loss 1.25168443
Trained batch 226 batch loss 1.27627516 epoch total loss 1.25179327
Trained batch 227 batch loss 1.24876821 epoch total loss 1.25177991
Trained batch 228 batch loss 1.10129106 epoch total loss 1.25112
Trained batch 229 batch loss 1.29069853 epoch total loss 1.25129282
Trained batch 230 batch loss 1.09022486 epoch total loss 1.25059247
Trained batch 231 batch loss 1.28430557 epoch total loss 1.25073838
Trained batch 232 batch loss 1.30118012 epoch total loss 1.25095582
Trained batch 233 batch loss 1.18215299 epoch total loss 1.25066054
Trained batch 234 batch loss 1.35518885 epoch total loss 1.25110722
Trained batch 235 batch loss 1.43658 epoch total loss 1.2518965
Trained batch 236 batch loss 1.36811209 epoch total loss 1.25238895
Trained batch 237 batch loss 1.17162395 epoch total loss 1.25204813
Trained batch 238 batch loss 1.43358207 epoch total loss 1.25281096
Trained batch 239 batch loss 1.45915723 epoch total loss 1.25367439
Trained batch 240 batch loss 1.39459777 epoch total loss 1.25426149
Trained batch 241 batch loss 1.28221118 epoch total loss 1.25437748
Trained batch 242 batch loss 1.40459573 epoch total loss 1.25499821
Trained batch 243 batch loss 1.41693294 epoch total loss 1.25566459
Trained batch 244 batch loss 1.2084893 epoch total loss 1.25547123
Trained batch 245 batch loss 1.29881978 epoch total loss 1.25564826
Trained batch 246 batch loss 1.07480741 epoch total loss 1.25491309
Trained batch 247 batch loss 0.930034518 epoch total loss 1.25359774
Trained batch 248 batch loss 1.08271754 epoch total loss 1.25290859
Trained batch 249 batch loss 1.16061568 epoch total loss 1.25253797
Trained batch 250 batch loss 1.28317428 epoch total loss 1.25266051
Trained batch 251 batch loss 1.2140038 epoch total loss 1.25250649
Trained batch 252 batch loss 1.12677646 epoch total loss 1.25200748
Trained batch 253 batch loss 1.04611111 epoch total loss 1.25119364
Trained batch 254 batch loss 1.03546345 epoch total loss 1.2503444
Trained batch 255 batch loss 1.08293569 epoch total loss 1.24968791
Trained batch 256 batch loss 1.09584665 epoch total loss 1.24908698
Trained batch 257 batch loss 1.25918698 epoch total loss 1.24912632
Trained batch 258 batch loss 1.27467799 epoch total loss 1.24922538
Trained batch 259 batch loss 1.38575816 epoch total loss 1.24975252
Trained batch 260 batch loss 1.69643474 epoch total loss 1.25147057
Trained batch 261 batch loss 1.11735177 epoch total loss 1.25095665
Trained batch 262 batch loss 1.27822542 epoch total loss 1.25106072
Trained batch 263 batch loss 1.28227508 epoch total loss 1.25117946
Trained batch 264 batch loss 1.16664624 epoch total loss 1.25085938
Trained batch 265 batch loss 1.11081314 epoch total loss 1.25033081
Trained batch 266 batch loss 1.1843822 epoch total loss 1.25008297
Trained batch 267 batch loss 1.18678808 epoch total loss 1.24984598
Trained batch 268 batch loss 1.13017023 epoch total loss 1.2493993
Trained batch 269 batch loss 1.17377424 epoch total loss 1.24911821
Trained batch 270 batch loss 1.10980415 epoch total loss 1.24860215
Trained batch 271 batch loss 1.01565015 epoch total loss 1.24774265
Trained batch 272 batch loss 1.17874646 epoch total loss 1.24748898
Trained batch 273 batch loss 1.13097048 epoch total loss 1.24706221
Trained batch 274 batch loss 1.14178038 epoch total loss 1.24667788
Trained batch 275 batch loss 1.18766618 epoch total loss 1.2464633
Trained batch 276 batch loss 1.1767745 epoch total loss 1.24621081
Trained batch 277 batch loss 1.3577776 epoch total loss 1.24661362
Trained batch 278 batch loss 1.15495658 epoch total loss 1.24628401
Trained batch 279 batch loss 1.44625592 epoch total loss 1.24700069
Trained batch 280 batch loss 1.25941658 epoch total loss 1.24704516
Trained batch 281 batch loss 1.11524057 epoch total loss 1.24657607
Trained batch 282 batch loss 1.42984581 epoch total loss 1.24722588
Trained batch 283 batch loss 1.3816781 epoch total loss 1.24770105
Trained batch 284 batch loss 1.25409126 epoch total loss 1.24772358
Trained batch 285 batch loss 1.34657454 epoch total loss 1.24807048
Trained batch 286 batch loss 1.30525124 epoch total loss 1.24827027
Trained batch 287 batch loss 1.26968873 epoch total loss 1.2483449
Trained batch 288 batch loss 1.1684401 epoch total loss 1.24806738
Trained batch 289 batch loss 1.19812799 epoch total loss 1.24789464
Trained batch 290 batch loss 1.22564793 epoch total loss 1.24781787
Trained batch 291 batch loss 1.25380516 epoch total loss 1.2478385
Trained batch 292 batch loss 1.26350784 epoch total loss 1.24789214
Trained batch 293 batch loss 1.11323655 epoch total loss 1.24743271
Trained batch 294 batch loss 0.960773945 epoch total loss 1.2464577
Trained batch 295 batch loss 0.88247788 epoch total loss 1.24522388
Trained batch 296 batch loss 1.08714628 epoch total loss 1.24468982
Trained batch 297 batch loss 1.0635711 epoch total loss 1.24408
Trained batch 298 batch loss 1.26970196 epoch total loss 1.24416602
Trained batch 299 batch loss 1.21589506 epoch total loss 1.24407148
Trained batch 300 batch loss 0.934839368 epoch total loss 1.24304068
Trained batch 301 batch loss 1.2469846 epoch total loss 1.24305379
Trained batch 302 batch loss 1.3745904 epoch total loss 1.24348938
Trained batch 303 batch loss 1.31493735 epoch total loss 1.24372518
Trained batch 304 batch loss 1.11356521 epoch total loss 1.24329698
Trained batch 305 batch loss 1.22068322 epoch total loss 1.24322283
Trained batch 306 batch loss 1.2669549 epoch total loss 1.24330044
Trained batch 307 batch loss 1.35311675 epoch total loss 1.24365807
Trained batch 308 batch loss 1.16541195 epoch total loss 1.24340403
Trained batch 309 batch loss 1.12504411 epoch total loss 1.24302101
Trained batch 310 batch loss 1.24100697 epoch total loss 1.24301445
Trained batch 311 batch loss 1.45044374 epoch total loss 1.24368143
Trained batch 312 batch loss 1.36663008 epoch total loss 1.24407554
Trained batch 313 batch loss 1.46971416 epoch total loss 1.2447964
Trained batch 314 batch loss 1.37842298 epoch total loss 1.24522197
Trained batch 315 batch loss 1.3079381 epoch total loss 1.24542105
Trained batch 316 batch loss 1.22204113 epoch total loss 1.24534714
Trained batch 317 batch loss 1.37628019 epoch total loss 1.2457602
Trained batch 318 batch loss 1.1612066 epoch total loss 1.24549425
Trained batch 319 batch loss 1.35671091 epoch total loss 1.24584293
Trained batch 320 batch loss 1.2686677 epoch total loss 1.24591422
Trained batch 321 batch loss 1.39134741 epoch total loss 1.24636734
Trained batch 322 batch loss 1.23194337 epoch total loss 1.24632251
Trained batch 323 batch loss 1.19844675 epoch total loss 1.24617434
Trained batch 324 batch loss 1.23784041 epoch total loss 1.24614871
Trained batch 325 batch loss 1.24616575 epoch total loss 1.24614871
Trained batch 326 batch loss 1.24810636 epoch total loss 1.24615467
Trained batch 327 batch loss 1.14552951 epoch total loss 1.24584699
Trained batch 328 batch loss 0.989653945 epoch total loss 1.24506593
Trained batch 329 batch loss 1.41056299 epoch total loss 1.24556887
Trained batch 330 batch loss 1.3997333 epoch total loss 1.24603605
Trained batch 331 batch loss 1.26056683 epoch total loss 1.24607992
Trained batch 332 batch loss 1.12493813 epoch total loss 1.24571502
Trained batch 333 batch loss 1.12701273 epoch total loss 1.24535859
Trained batch 334 batch loss 1.19161546 epoch total loss 1.24519765
Trained batch 335 batch loss 1.36265373 epoch total loss 1.24554825
Trained batch 336 batch loss 1.36612511 epoch total loss 1.24590707
Trained batch 337 batch loss 1.20559418 epoch total loss 1.2457875
Trained batch 338 batch loss 1.09212089 epoch total loss 1.24533284
Trained batch 339 batch loss 1.06498361 epoch total loss 1.24480081
Trained batch 340 batch loss 1.15606487 epoch total loss 1.24453986
Trained batch 341 batch loss 1.42179418 epoch total loss 1.24505961
Trained batch 342 batch loss 1.17113662 epoch total loss 1.24484348
Trained batch 343 batch loss 1.38082266 epoch total loss 1.24524
Trained batch 344 batch loss 1.37616539 epoch total loss 1.24562061
Trained batch 345 batch loss 1.47403848 epoch total loss 1.24628258
Trained batch 346 batch loss 1.24255157 epoch total loss 1.24627185
Trained batch 347 batch loss 1.32520032 epoch total loss 1.2464993
Trained batch 348 batch loss 1.28688288 epoch total loss 1.24661541
Trained batch 349 batch loss 1.25722194 epoch total loss 1.24664581
Trained batch 350 batch loss 1.35291219 epoch total loss 1.24694943
Trained batch 351 batch loss 1.25152802 epoch total loss 1.24696243
Trained batch 352 batch loss 1.17844176 epoch total loss 1.24676776
Trained batch 353 batch loss 1.42288733 epoch total loss 1.24726665
Trained batch 354 batch loss 1.39476085 epoch total loss 1.24768329
Trained batch 355 batch loss 1.12054706 epoch total loss 1.24732518
Trained batch 356 batch loss 1.21498656 epoch total loss 1.24723434
Trained batch 357 batch loss 1.38465905 epoch total loss 1.24761939
Trained batch 358 batch loss 1.07009077 epoch total loss 1.24712348
Trained batch 359 batch loss 1.18398428 epoch total loss 1.24694765
Trained batch 360 batch loss 1.19631708 epoch total loss 1.24680698
Trained batch 361 batch loss 1.22792578 epoch total loss 1.24675477
Trained batch 362 batch loss 1.25486684 epoch total loss 1.24677706
Trained batch 363 batch loss 1.14622736 epoch total loss 1.24650013
Trained batch 364 batch loss 1.01917911 epoch total loss 1.2458756
Trained batch 365 batch loss 1.27182293 epoch total loss 1.24594665
Trained batch 366 batch loss 1.12275696 epoch total loss 1.24561012
Trained batch 367 batch loss 1.10674167 epoch total loss 1.24523175
Trained batch 368 batch loss 1.09881544 epoch total loss 1.24483395
Trained batch 369 batch loss 1.01462221 epoch total loss 1.24421
Trained batch 370 batch loss 1.05929923 epoch total loss 1.24371028
Trained batch 371 batch loss 1.10403442 epoch total loss 1.24333382
Trained batch 372 batch loss 1.16948915 epoch total loss 1.24313521
Trained batch 373 batch loss 1.07052302 epoch total loss 1.24267256
Trained batch 374 batch loss 1.1308825 epoch total loss 1.24237359
Trained batch 375 batch loss 1.23008609 epoch total loss 1.2423408
Trained batch 376 batch loss 1.1960001 epoch total loss 1.24221766
Trained batch 377 batch loss 1.22458708 epoch total loss 1.24217081
Trained batch 378 batch loss 1.00771022 epoch total loss 1.24155056
Trained batch 379 batch loss 1.01623058 epoch total loss 1.24095607
Trained batch 380 batch loss 1.07840288 epoch total loss 1.24052835
Trained batch 381 batch loss 0.952641964 epoch total loss 1.23977268
Trained batch 382 batch loss 1.06748533 epoch total loss 1.23932159
Trained batch 383 batch loss 1.12951958 epoch total loss 1.23903489
Trained batch 384 batch loss 1.26024246 epoch total loss 1.2390902
Trained batch 385 batch loss 1.21541119 epoch total loss 1.23902869
Trained batch 386 batch loss 1.21550155 epoch total loss 1.23896778
Trained batch 387 batch loss 1.04963982 epoch total loss 1.23847866
Trained batch 388 batch loss 1.07030344 epoch total loss 1.23804522
Trained batch 389 batch loss 1.0586679 epoch total loss 1.23758399
Trained batch 390 batch loss 1.07386208 epoch total loss 1.23716426
Trained batch 391 batch loss 1.20082617 epoch total loss 1.23707128
Trained batch 392 batch loss 1.46077168 epoch total loss 1.23764205
Trained batch 393 batch loss 1.09140301 epoch total loss 1.23726988
Trained batch 394 batch loss 1.09331489 epoch total loss 1.2369045
Trained batch 395 batch loss 0.944143236 epoch total loss 1.23616338
Trained batch 396 batch loss 1.15535474 epoch total loss 1.23595941
Trained batch 397 batch loss 1.07483101 epoch total loss 1.2355535
Trained batch 398 batch loss 1.27218163 epoch total loss 1.23564553
Trained batch 399 batch loss 1.10517073 epoch total loss 1.23531854
Trained batch 400 batch loss 1.18303895 epoch total loss 1.23518789
Trained batch 401 batch loss 1.44851351 epoch total loss 1.2357198
Trained batch 402 batch loss 1.37798476 epoch total loss 1.23607373
Trained batch 403 batch loss 1.40133572 epoch total loss 1.23648381
Trained batch 404 batch loss 1.4305799 epoch total loss 1.23696423
Trained batch 405 batch loss 1.45013499 epoch total loss 1.23749053
Trained batch 406 batch loss 1.28391981 epoch total loss 1.23760486
Trained batch 407 batch loss 1.28450274 epoch total loss 1.23772013
Trained batch 408 batch loss 1.10437799 epoch total loss 1.23739338
Trained batch 409 batch loss 1.08230805 epoch total loss 1.23701417
Trained batch 410 batch loss 1.12151647 epoch total loss 1.23673248
Trained batch 411 batch loss 1.26284385 epoch total loss 1.23679602
Trained batch 412 batch loss 1.18846452 epoch total loss 1.23667872
Trained batch 413 batch loss 1.14023304 epoch total loss 1.23644519
Trained batch 414 batch loss 1.34065485 epoch total loss 1.23669696
Trained batch 415 batch loss 1.20660377 epoch total loss 1.23662436
Trained batch 416 batch loss 1.28474402 epoch total loss 1.23674
Trained batch 417 batch loss 1.2472806 epoch total loss 1.23676515
Trained batch 418 batch loss 1.3895123 epoch total loss 1.23713064
Trained batch 419 batch loss 1.10178566 epoch total loss 1.2368077
Trained batch 420 batch loss 1.28383374 epoch total loss 1.23691964
Trained batch 421 batch loss 1.30219936 epoch total loss 1.23707461
Trained batch 422 batch loss 1.12684536 epoch total loss 1.23681343
Trained batch 423 batch loss 1.17113745 epoch total loss 1.2366581
Trained batch 424 batch loss 1.20782232 epoch total loss 1.23659015
Trained batch 425 batch loss 1.12766659 epoch total loss 1.23633385
Trained batch 426 batch loss 1.25028992 epoch total loss 1.23636663
Trained batch 427 batch loss 1.4289124 epoch total loss 1.2368176
Trained batch 428 batch loss 1.18473148 epoch total loss 1.23669589
Trained batch 429 batch loss 1.34133804 epoch total loss 1.23693979
Trained batch 430 batch loss 1.48702717 epoch total loss 1.23752129
Trained batch 431 batch loss 1.48130393 epoch total loss 1.23808694
Trained batch 432 batch loss 1.26939142 epoch total loss 1.23815942
Trained batch 433 batch loss 1.14739394 epoch total loss 1.23794985
Trained batch 434 batch loss 1.07422674 epoch total loss 1.23757255
Trained batch 435 batch loss 0.916969478 epoch total loss 1.2368356
Trained batch 436 batch loss 0.870756149 epoch total loss 1.23599589
Trained batch 437 batch loss 1.11356139 epoch total loss 1.23571587
Trained batch 438 batch loss 1.00387442 epoch total loss 1.23518646
Trained batch 439 batch loss 0.782379508 epoch total loss 1.23415506
Trained batch 440 batch loss 0.975262403 epoch total loss 1.23356664
Trained batch 441 batch loss 0.820368 epoch total loss 1.23262978
Trained batch 442 batch loss 0.934804142 epoch total loss 1.23195601
Trained batch 443 batch loss 0.863626957 epoch total loss 1.23112452
Trained batch 444 batch loss 0.984149814 epoch total loss 1.23056829
Trained batch 445 batch loss 1.25561476 epoch total loss 1.23062456
Trained batch 446 batch loss 1.28269529 epoch total loss 1.23074138
Trained batch 447 batch loss 1.35592449 epoch total loss 1.23102129
Trained batch 448 batch loss 1.30851579 epoch total loss 1.23119438
Trained batch 449 batch loss 1.31435 epoch total loss 1.23137951
Trained batch 450 batch loss 1.18016791 epoch total loss 1.23126578
Trained batch 451 batch loss 1.50155723 epoch total loss 1.23186517
Trained batch 452 batch loss 1.43856108 epoch total loss 1.23232234
Trained batch 453 batch loss 1.45445538 epoch total loss 1.23281276
Trained batch 454 batch loss 1.53886378 epoch total loss 1.23348689
Trained batch 455 batch loss 1.63879037 epoch total loss 1.23437774
Trained batch 456 batch loss 1.53921771 epoch total loss 1.23504627
Trained batch 457 batch loss 1.53640699 epoch total loss 1.23570561
Trained batch 458 batch loss 1.44478762 epoch total loss 1.23616207
Trained batch 459 batch loss 1.00902355 epoch total loss 1.23566723
Trained batch 460 batch loss 1.076388 epoch total loss 1.23532104
Trained batch 461 batch loss 1.12666357 epoch total loss 1.23508537
Trained batch 462 batch loss 1.40105534 epoch total loss 1.23544455
Trained batch 463 batch loss 1.24071646 epoch total loss 1.23545599
Trained batch 464 batch loss 1.06180215 epoch total loss 1.23508179
Trained batch 465 batch loss 0.981617868 epoch total loss 1.23453677
Trained batch 466 batch loss 1.15025663 epoch total loss 1.23435593
Trained batch 467 batch loss 1.30168331 epoch total loss 1.2345
Trained batch 468 batch loss 1.23905528 epoch total loss 1.23450983
Trained batch 469 batch loss 1.39355516 epoch total loss 1.23484898
Trained batch 470 batch loss 1.3299855 epoch total loss 1.23505127
Trained batch 471 batch loss 1.24425435 epoch total loss 1.23507082
Trained batch 472 batch loss 1.30091238 epoch total loss 1.2352103
Trained batch 473 batch loss 1.15564775 epoch total loss 1.2350421
Trained batch 474 batch loss 1.26494896 epoch total loss 1.23510528
Trained batch 475 batch loss 1.24719834 epoch total loss 1.23513067
Trained batch 476 batch loss 1.27346802 epoch total loss 1.23521125
Trained batch 477 batch loss 1.24377227 epoch total loss 1.23522925
Trained batch 478 batch loss 1.18081856 epoch total loss 1.23511541
Trained batch 479 batch loss 1.30026293 epoch total loss 1.23525155
Trained batch 480 batch loss 1.16035223 epoch total loss 1.2350955
Trained batch 481 batch loss 1.41804242 epoch total loss 1.23547578
Trained batch 482 batch loss 1.2581811 epoch total loss 1.23552287
Trained batch 483 batch loss 1.13654447 epoch total loss 1.23531795
Trained batch 484 batch loss 1.18617201 epoch total loss 1.23521638
Trained batch 485 batch loss 1.23714554 epoch total loss 1.23522031
Trained batch 486 batch loss 1.17800117 epoch total loss 1.23510253
Trained batch 487 batch loss 1.343647 epoch total loss 1.23532534
Trained batch 488 batch loss 1.2707504 epoch total loss 1.23539793
Trained batch 489 batch loss 1.34482574 epoch total loss 1.23562181
Trained batch 490 batch loss 1.33006787 epoch total loss 1.23581457
Trained batch 491 batch loss 1.35155725 epoch total loss 1.23605025
Trained batch 492 batch loss 1.18469334 epoch total loss 1.23594594
Trained batch 493 batch loss 1.11887288 epoch total loss 1.23570848
Trained batch 494 batch loss 1.11748552 epoch total loss 1.23546922
Trained batch 495 batch loss 1.22799921 epoch total loss 1.2354542
Trained batch 496 batch loss 1.29069316 epoch total loss 1.23556554
Trained batch 497 batch loss 1.16342497 epoch total loss 1.23542047
Trained batch 498 batch loss 1.10319638 epoch total loss 1.23515499
Trained batch 499 batch loss 1.09500551 epoch total loss 1.23487413
Trained batch 500 batch loss 1.15257859 epoch total loss 1.23470962
Trained batch 501 batch loss 1.13012409 epoch total loss 1.23450089
Trained batch 502 batch loss 1.03539753 epoch total loss 1.23410428
Trained batch 503 batch loss 1.0830946 epoch total loss 1.23380399
Trained batch 504 batch loss 1.25797009 epoch total loss 1.23385191
Trained batch 505 batch loss 1.23249745 epoch total loss 1.23384929
Trained batch 506 batch loss 1.08371091 epoch total loss 1.23355258
Trained batch 507 batch loss 1.19025505 epoch total loss 1.23346722
Trained batch 508 batch loss 1.18565929 epoch total loss 1.23337305
Trained batch 509 batch loss 1.30544221 epoch total loss 1.23351467
Trained batch 510 batch loss 1.2930491 epoch total loss 1.23363137
Trained batch 511 batch loss 1.16081285 epoch total loss 1.2334888
Trained batch 512 batch loss 1.42196274 epoch total loss 1.23385692
Trained batch 513 batch loss 1.40446436 epoch total loss 1.23418951
Trained batch 514 batch loss 1.24938035 epoch total loss 1.23421907
Trained batch 515 batch loss 1.04773462 epoch total loss 1.23385692
Trained batch 516 batch loss 1.06392241 epoch total loss 1.23352766
Trained batch 517 batch loss 1.09800291 epoch total loss 1.23326552
Trained batch 518 batch loss 1.10228169 epoch total loss 1.23301268
Trained batch 519 batch loss 0.78888166 epoch total loss 1.23215687
Trained batch 520 batch loss 0.84568125 epoch total loss 1.23141372
Trained batch 521 batch loss 0.985494614 epoch total loss 1.23094165
Trained batch 522 batch loss 1.25959492 epoch total loss 1.23099661
Trained batch 523 batch loss 1.48194408 epoch total loss 1.23147631
Trained batch 524 batch loss 1.09064269 epoch total loss 1.23120761
Trained batch 525 batch loss 1.20920563 epoch total loss 1.23116577
Trained batch 526 batch loss 1.4218837 epoch total loss 1.23152828
Trained batch 527 batch loss 1.33897614 epoch total loss 1.23173213
Trained batch 528 batch loss 1.38935864 epoch total loss 1.23203075
Trained batch 529 batch loss 1.10969329 epoch total loss 1.23179936
Trained batch 530 batch loss 1.19100356 epoch total loss 1.23172235
Trained batch 531 batch loss 1.208637 epoch total loss 1.23167884
Trained batch 532 batch loss 1.27689385 epoch total loss 1.23176396
Trained batch 533 batch loss 1.29832649 epoch total loss 1.23188877
Trained batch 534 batch loss 1.26204097 epoch total loss 1.23194528
Trained batch 535 batch loss 1.26449919 epoch total loss 1.23200619
Trained batch 536 batch loss 1.37281799 epoch total loss 1.23226881
Trained batch 537 batch loss 1.36553574 epoch total loss 1.232517
Trained batch 538 batch loss 1.26859844 epoch total loss 1.23258412
Trained batch 539 batch loss 1.27432775 epoch total loss 1.2326616
Trained batch 540 batch loss 1.20041847 epoch total loss 1.23260188
Trained batch 541 batch loss 1.23069549 epoch total loss 1.23259842
Trained batch 542 batch loss 1.27649331 epoch total loss 1.23267937
Trained batch 543 batch loss 1.29298449 epoch total loss 1.23279047
Trained batch 544 batch loss 1.25455403 epoch total loss 1.23283052
Trained batch 545 batch loss 1.09206414 epoch total loss 1.2325722
Trained batch 546 batch loss 1.32670069 epoch total loss 1.23274457
Trained batch 547 batch loss 1.17701745 epoch total loss 1.23264265
Trained batch 548 batch loss 1.25309062 epoch total loss 1.23268008
Trained batch 549 batch loss 1.22147155 epoch total loss 1.2326597
Trained batch 550 batch loss 1.25133908 epoch total loss 1.23269367
Trained batch 551 batch loss 1.19419932 epoch total loss 1.23262382
Trained batch 552 batch loss 1.24009466 epoch total loss 1.23263741
Trained batch 553 batch loss 1.42871499 epoch total loss 1.23299193
Trained batch 554 batch loss 1.13508332 epoch total loss 1.23281515
Trained batch 555 batch loss 1.27969122 epoch total loss 1.23289955
Trained batch 556 batch loss 1.10376155 epoch total loss 1.23266733
Trained batch 557 batch loss 1.13021064 epoch total loss 1.23248339
Trained batch 558 batch loss 1.25074661 epoch total loss 1.23251605
Trained batch 559 batch loss 1.21816134 epoch total loss 1.2324903
Trained batch 560 batch loss 1.21021819 epoch total loss 1.23245049
Trained batch 561 batch loss 1.08575749 epoch total loss 1.23218906
Trained batch 562 batch loss 1.21564126 epoch total loss 1.23215961
Trained batch 563 batch loss 1.16061044 epoch total loss 1.23203242
Trained batch 564 batch loss 1.16749454 epoch total loss 1.23191798
Trained batch 565 batch loss 1.1008122 epoch total loss 1.231686
Trained batch 566 batch loss 1.18344235 epoch total loss 1.23160076
Trained batch 567 batch loss 1.28017282 epoch total loss 1.23168647
Trained batch 568 batch loss 1.30491376 epoch total loss 1.23181534
Trained batch 569 batch loss 1.29840398 epoch total loss 1.2319324
Trained batch 570 batch loss 1.1578238 epoch total loss 1.23180246
Trained batch 571 batch loss 1.16687953 epoch total loss 1.23168874
Trained batch 572 batch loss 1.19056237 epoch total loss 1.23161674
Trained batch 573 batch loss 1.17695725 epoch total loss 1.23152137
Trained batch 574 batch loss 1.08317959 epoch total loss 1.23126292
Trained batch 575 batch loss 1.22778714 epoch total loss 1.23125684
Trained batch 576 batch loss 1.08701634 epoch total loss 1.2310065
Trained batch 577 batch loss 1.04495478 epoch total loss 1.23068416
Trained batch 578 batch loss 1.14098644 epoch total loss 1.23052895
Trained batch 579 batch loss 1.11526632 epoch total loss 1.23032987
Trained batch 580 batch loss 1.1058836 epoch total loss 1.23011541
Trained batch 581 batch loss 0.91953063 epoch total loss 1.22958088
Trained batch 582 batch loss 1.12959015 epoch total loss 1.22940898
Trained batch 583 batch loss 1.076401 epoch total loss 1.2291466
Trained batch 584 batch loss 0.968411148 epoch total loss 1.2287
Trained batch 585 batch loss 0.996617377 epoch total loss 1.22830343
Trained batch 586 batch loss 1.0387609 epoch total loss 1.2279799
Trained batch 587 batch loss 1.10944462 epoch total loss 1.22777796
Trained batch 588 batch loss 1.05834985 epoch total loss 1.22748983
Trained batch 589 batch loss 1.32086563 epoch total loss 1.22764838
Trained batch 590 batch loss 1.23569071 epoch total loss 1.22766209
Trained batch 591 batch loss 1.16899467 epoch total loss 1.22756279
Trained batch 592 batch loss 1.45284283 epoch total loss 1.2279433
Trained batch 593 batch loss 1.22979879 epoch total loss 1.2279464
Trained batch 594 batch loss 1.24721408 epoch total loss 1.22797883
Trained batch 595 batch loss 1.33846378 epoch total loss 1.22816443
Trained batch 596 batch loss 1.206599 epoch total loss 1.22812831
Trained batch 597 batch loss 1.16568422 epoch total loss 1.22802377
Trained batch 598 batch loss 1.09399819 epoch total loss 1.22779965
Trained batch 599 batch loss 1.05092955 epoch total loss 1.22750437
Trained batch 600 batch loss 1.15460837 epoch total loss 1.22738278
Trained batch 601 batch loss 1.3004874 epoch total loss 1.22750437
Trained batch 602 batch loss 1.20544028 epoch total loss 1.22746778
Trained batch 603 batch loss 1.26120031 epoch total loss 1.2275238
Trained batch 604 batch loss 1.21387398 epoch total loss 1.22750115
Trained batch 605 batch loss 1.32678068 epoch total loss 1.22766531
Trained batch 606 batch loss 1.24966764 epoch total loss 1.22770166
Trained batch 607 batch loss 1.33139741 epoch total loss 1.22787249
Trained batch 608 batch loss 1.54195428 epoch total loss 1.22838902
Trained batch 609 batch loss 1.01731 epoch total loss 1.22804248
Trained batch 610 batch loss 1.27316678 epoch total loss 1.22811651
Trained batch 611 batch loss 1.37533212 epoch total loss 1.22835743
Trained batch 612 batch loss 1.04778731 epoch total loss 1.22806239
Trained batch 613 batch loss 1.0824796 epoch total loss 1.22782481
Trained batch 614 batch loss 1.42016768 epoch total loss 1.22813809
Trained batch 615 batch loss 1.25807166 epoch total loss 1.22818673
Trained batch 616 batch loss 1.48795581 epoch total loss 1.22860849
Trained batch 617 batch loss 1.18188632 epoch total loss 1.22853279
Trained batch 618 batch loss 1.24971247 epoch total loss 1.228567
Trained batch 619 batch loss 1.3250792 epoch total loss 1.22872293
Trained batch 620 batch loss 1.31111848 epoch total loss 1.22885573
Trained batch 621 batch loss 1.49774194 epoch total loss 1.2292887
Trained batch 622 batch loss 1.27003813 epoch total loss 1.22935426
Trained batch 623 batch loss 1.22970486 epoch total loss 1.22935474
Trained batch 624 batch loss 1.31130576 epoch total loss 1.22948599
Trained batch 625 batch loss 1.33094609 epoch total loss 1.22964835
Trained batch 626 batch loss 1.30383492 epoch total loss 1.22976685
Trained batch 627 batch loss 1.36394119 epoch total loss 1.22998083
Trained batch 628 batch loss 1.3184948 epoch total loss 1.23012173
Trained batch 629 batch loss 1.3017354 epoch total loss 1.2302357
Trained batch 630 batch loss 1.30149186 epoch total loss 1.23034883
Trained batch 631 batch loss 1.26121497 epoch total loss 1.2303977
Trained batch 632 batch loss 1.1939826 epoch total loss 1.23034012
Trained batch 633 batch loss 1.25672889 epoch total loss 1.23038173
Trained batch 634 batch loss 1.22657061 epoch total loss 1.23037577
Trained batch 635 batch loss 1.37058043 epoch total loss 1.23059654
Trained batch 636 batch loss 1.32253456 epoch total loss 1.23074114
Trained batch 637 batch loss 1.24799395 epoch total loss 1.2307682
Trained batch 638 batch loss 1.51940942 epoch total loss 1.2312206
Trained batch 639 batch loss 1.39143753 epoch total loss 1.2314713
Trained batch 640 batch loss 1.32637596 epoch total loss 1.2316196
Trained batch 641 batch loss 1.28304672 epoch total loss 1.23169971
Trained batch 642 batch loss 1.33453727 epoch total loss 1.23185992
Trained batch 643 batch loss 1.15868378 epoch total loss 1.23174608
Trained batch 644 batch loss 1.26654124 epoch total loss 1.2318002
Trained batch 645 batch loss 1.23707366 epoch total loss 1.2318083
Trained batch 646 batch loss 1.18752301 epoch total loss 1.23173976
Trained batch 647 batch loss 1.42817163 epoch total loss 1.23204327
Trained batch 648 batch loss 1.34485054 epoch total loss 1.23221743
Trained batch 649 batch loss 1.25933492 epoch total loss 1.23225915
Trained batch 650 batch loss 1.42734253 epoch total loss 1.23255932
Trained batch 651 batch loss 1.3632915 epoch total loss 1.23276019
Trained batch 652 batch loss 1.28568077 epoch total loss 1.23284137
Trained batch 653 batch loss 1.25326204 epoch total loss 1.23287261
Trained batch 654 batch loss 1.30726159 epoch total loss 1.23298633
Trained batch 655 batch loss 1.06261134 epoch total loss 1.23272622
Trained batch 656 batch loss 1.30113077 epoch total loss 1.23283052
Trained batch 657 batch loss 1.47423506 epoch total loss 1.23319793
Trained batch 658 batch loss 1.38858163 epoch total loss 1.2334342
Trained batch 659 batch loss 1.17792189 epoch total loss 1.23334992
Trained batch 660 batch loss 1.27710509 epoch total loss 1.2334162
Trained batch 661 batch loss 1.51399624 epoch total loss 1.23384058
Trained batch 662 batch loss 1.39987922 epoch total loss 1.23409152
Trained batch 663 batch loss 1.29820967 epoch total loss 1.2341882
Trained batch 664 batch loss 1.19581592 epoch total loss 1.23413038
Trained batch 665 batch loss 1.25630188 epoch total loss 1.23416376
Trained batch 666 batch loss 1.15501857 epoch total loss 1.23404491
Trained batch 667 batch loss 1.28207493 epoch total loss 1.23411691
Trained batch 668 batch loss 1.15271819 epoch total loss 1.23399508
Trained batch 669 batch loss 1.22591043 epoch total loss 1.23398292
Trained batch 670 batch loss 1.22286808 epoch total loss 1.23396635
Trained batch 671 batch loss 1.39308214 epoch total loss 1.23420346
Trained batch 672 batch loss 1.20504522 epoch total loss 1.23416007
Trained batch 673 batch loss 1.11663532 epoch total loss 1.23398542
Trained batch 674 batch loss 1.22922683 epoch total loss 1.23397839
Trained batch 675 batch loss 1.49029565 epoch total loss 1.23435807
Trained batch 676 batch loss 1.29150009 epoch total loss 1.23444259
Trained batch 677 batch loss 1.08866715 epoch total loss 1.2342273
Trained batch 678 batch loss 1.49919891 epoch total loss 1.23461819
Trained batch 679 batch loss 1.3614831 epoch total loss 1.23480499
Trained batch 680 batch loss 1.39420581 epoch total loss 1.23503947
Trained batch 681 batch loss 1.20219851 epoch total loss 1.23499131
Trained batch 682 batch loss 1.19465399 epoch total loss 1.23493207
Trained batch 683 batch loss 1.32466364 epoch total loss 1.23506343
Trained batch 684 batch loss 1.09793639 epoch total loss 1.23486304
Trained batch 685 batch loss 1.43619514 epoch total loss 1.23515701
Trained batch 686 batch loss 1.22714376 epoch total loss 1.23514533
Trained batch 687 batch loss 1.21291566 epoch total loss 1.23511291
Trained batch 688 batch loss 1.06385159 epoch total loss 1.234864
Trained batch 689 batch loss 1.18537462 epoch total loss 1.23479211
Trained batch 690 batch loss 1.1185168 epoch total loss 1.23462367
Trained batch 691 batch loss 0.917026103 epoch total loss 1.23416412
Trained batch 692 batch loss 1.20159686 epoch total loss 1.23411703
Trained batch 693 batch loss 1.06252372 epoch total loss 1.23386931
Trained batch 694 batch loss 1.16465 epoch total loss 1.23376966
Trained batch 695 batch loss 1.21753812 epoch total loss 1.23374629
Trained batch 696 batch loss 1.42082679 epoch total loss 1.23401511
Trained batch 697 batch loss 1.26059508 epoch total loss 1.23405325
Trained batch 698 batch loss 1.0417695 epoch total loss 1.23377776
Trained batch 699 batch loss 1.19735336 epoch total loss 1.23372567
Trained batch 700 batch loss 1.33449686 epoch total loss 1.23386955
Trained batch 701 batch loss 1.13800859 epoch total loss 1.23373282
Trained batch 702 batch loss 1.24238968 epoch total loss 1.2337451
Trained batch 703 batch loss 1.27094531 epoch total loss 1.23379803
Trained batch 704 batch loss 1.4934839 epoch total loss 1.23416686
Trained batch 705 batch loss 1.52019095 epoch total loss 1.23457253
Trained batch 706 batch loss 1.54007339 epoch total loss 1.23500538
Trained batch 707 batch loss 1.38839793 epoch total loss 1.23522234
Trained batch 708 batch loss 1.19289398 epoch total loss 1.2351625
Trained batch 709 batch loss 1.08283901 epoch total loss 1.23494768
Trained batch 710 batch loss 1.18210709 epoch total loss 1.23487329
Trained batch 711 batch loss 1.36442828 epoch total loss 1.23505545
Trained batch 712 batch loss 1.26868248 epoch total loss 1.23510265
Trained batch 713 batch loss 1.17602015 epoch total loss 1.2350198
Trained batch 714 batch loss 1.15860271 epoch total loss 1.23491287
Trained batch 715 batch loss 1.44425416 epoch total loss 1.23520565
Trained batch 716 batch loss 1.42940521 epoch total loss 1.23547685
Trained batch 717 batch loss 1.47715306 epoch total loss 1.23581398
Trained batch 718 batch loss 1.49488187 epoch total loss 1.23617482
Trained batch 719 batch loss 1.42438376 epoch total loss 1.23643649
Trained batch 720 batch loss 1.20252597 epoch total loss 1.2363894
Trained batch 721 batch loss 1.0455699 epoch total loss 1.23612475
Trained batch 722 batch loss 1.16574085 epoch total loss 1.23602724
Trained batch 723 batch loss 1.25135291 epoch total loss 1.23604846
Trained batch 724 batch loss 1.13463068 epoch total loss 1.23590839
Trained batch 725 batch loss 1.19087708 epoch total loss 1.23584628
Trained batch 726 batch loss 1.13910866 epoch total loss 1.23571301
Trained batch 727 batch loss 1.16754532 epoch total loss 1.23561919
Trained batch 728 batch loss 1.20792162 epoch total loss 1.23558116
Trained batch 729 batch loss 1.14518356 epoch total loss 1.23545718
Trained batch 730 batch loss 1.3225944 epoch total loss 1.23557651
Trained batch 731 batch loss 1.23813343 epoch total loss 1.23558009
Trained batch 732 batch loss 1.34564018 epoch total loss 1.23573041
Trained batch 733 batch loss 1.42534137 epoch total loss 1.23598909
Trained batch 734 batch loss 1.44704556 epoch total loss 1.23627663
Trained batch 735 batch loss 1.542786 epoch total loss 1.23669362
Trained batch 736 batch loss 1.48257518 epoch total loss 1.23702776
Trained batch 737 batch loss 1.36040115 epoch total loss 1.23719525
Trained batch 738 batch loss 1.435709 epoch total loss 1.23746419
Trained batch 739 batch loss 1.42297065 epoch total loss 1.23771524
Trained batch 740 batch loss 1.32734585 epoch total loss 1.23783636
Trained batch 741 batch loss 1.20995939 epoch total loss 1.23779869
Trained batch 742 batch loss 1.3093015 epoch total loss 1.23789513
Trained batch 743 batch loss 1.20637512 epoch total loss 1.23785269
Trained batch 744 batch loss 1.20555401 epoch total loss 1.2378093
Trained batch 745 batch loss 1.25264406 epoch total loss 1.23782921
Trained batch 746 batch loss 1.22617292 epoch total loss 1.23781359
Trained batch 747 batch loss 1.08467364 epoch total loss 1.23760855
Trained batch 748 batch loss 1.16922593 epoch total loss 1.23751712
Trained batch 749 batch loss 1.23955894 epoch total loss 1.23751986
Trained batch 750 batch loss 1.42154133 epoch total loss 1.23776531
Trained batch 751 batch loss 1.24179792 epoch total loss 1.23777068
Trained batch 752 batch loss 1.27370501 epoch total loss 1.23781848
Trained batch 753 batch loss 1.39731288 epoch total loss 1.23803031
Trained batch 754 batch loss 1.37958455 epoch total loss 1.23821807
Trained batch 755 batch loss 1.0520395 epoch total loss 1.23797143
Trained batch 756 batch loss 0.971533537 epoch total loss 1.23761904
Trained batch 757 batch loss 1.24127698 epoch total loss 1.23762393
Trained batch 758 batch loss 1.36063123 epoch total loss 1.23778617
Trained batch 759 batch loss 1.41282058 epoch total loss 1.23801684
Trained batch 760 batch loss 1.52465796 epoch total loss 1.23839402
Trained batch 761 batch loss 1.47849655 epoch total loss 1.23870957
Trained batch 762 batch loss 1.39500892 epoch total loss 1.23891473
Trained batch 763 batch loss 1.36823523 epoch total loss 1.23908412
Trained batch 764 batch loss 1.24817514 epoch total loss 1.23909605
Trained batch 765 batch loss 1.29333138 epoch total loss 1.23916698
Trained batch 766 batch loss 1.45329642 epoch total loss 1.23944652
Trained batch 767 batch loss 1.62391746 epoch total loss 1.2399478
Trained batch 768 batch loss 1.40799344 epoch total loss 1.24016654
Trained batch 769 batch loss 1.17083931 epoch total loss 1.24007642
Trained batch 770 batch loss 1.28476381 epoch total loss 1.24013448
Trained batch 771 batch loss 1.34079671 epoch total loss 1.24026513
Trained batch 772 batch loss 1.16107762 epoch total loss 1.24016249
Trained batch 773 batch loss 1.22936118 epoch total loss 1.24014854
Trained batch 774 batch loss 1.03084016 epoch total loss 1.23987806
Trained batch 775 batch loss 1.07741845 epoch total loss 1.23966849
Trained batch 776 batch loss 1.10992098 epoch total loss 1.23950124
Trained batch 777 batch loss 1.12296259 epoch total loss 1.23935127
Trained batch 778 batch loss 1.1475842 epoch total loss 1.23923337
Trained batch 779 batch loss 0.98821336 epoch total loss 1.23891115
Trained batch 780 batch loss 1.03848219 epoch total loss 1.23865414
Trained batch 781 batch loss 1.28305101 epoch total loss 1.238711
Trained batch 782 batch loss 1.36699152 epoch total loss 1.23887503
Trained batch 783 batch loss 1.74712443 epoch total loss 1.23952413
Trained batch 784 batch loss 1.65877414 epoch total loss 1.2400589
Trained batch 785 batch loss 1.65802276 epoch total loss 1.24059129
Trained batch 786 batch loss 1.33175707 epoch total loss 1.2407074
Trained batch 787 batch loss 1.24039125 epoch total loss 1.24070704
Trained batch 788 batch loss 1.30884039 epoch total loss 1.24079347
Trained batch 789 batch loss 1.3701632 epoch total loss 1.24095738
Trained batch 790 batch loss 1.20677674 epoch total loss 1.24091423
Trained batch 791 batch loss 1.17464757 epoch total loss 1.24083042
Trained batch 792 batch loss 1.37221026 epoch total loss 1.24099624
Trained batch 793 batch loss 1.11930025 epoch total loss 1.24084282
Trained batch 794 batch loss 1.21732783 epoch total loss 1.24081326
Trained batch 795 batch loss 1.30461597 epoch total loss 1.24089348
Trained batch 796 batch loss 1.45858979 epoch total loss 1.24116695
Trained batch 797 batch loss 1.73573112 epoch total loss 1.24178755
Trained batch 798 batch loss 1.40713334 epoch total loss 1.24199474
Trained batch 799 batch loss 1.23721075 epoch total loss 1.24198866
Trained batch 800 batch loss 1.35815239 epoch total loss 1.24213386
Trained batch 801 batch loss 1.4058888 epoch total loss 1.2423383
Trained batch 802 batch loss 1.35439241 epoch total loss 1.24247801
Trained batch 803 batch loss 1.32016015 epoch total loss 1.24257481
Trained batch 804 batch loss 1.29765821 epoch total loss 1.24264324
Trained batch 805 batch loss 1.36100674 epoch total loss 1.24279034
Trained batch 806 batch loss 1.18515694 epoch total loss 1.24271882
Trained batch 807 batch loss 1.19060218 epoch total loss 1.24265432
Trained batch 808 batch loss 1.18506825 epoch total loss 1.24258304
Trained batch 809 batch loss 1.19717026 epoch total loss 1.24252689
Trained batch 810 batch loss 1.1860745 epoch total loss 1.24245715
Trained batch 811 batch loss 0.988006949 epoch total loss 1.24214351
Trained batch 812 batch loss 1.3336159 epoch total loss 1.24225616
Trained batch 813 batch loss 1.06464958 epoch total loss 1.24203765
Trained batch 814 batch loss 1.15635514 epoch total loss 1.24193239
Trained batch 815 batch loss 1.02713919 epoch total loss 1.24166894
Trained batch 816 batch loss 1.51685143 epoch total loss 1.24200606
Trained batch 817 batch loss 1.27806163 epoch total loss 1.24205029
Trained batch 818 batch loss 1.09104383 epoch total loss 1.24186563
Trained batch 819 batch loss 1.08780682 epoch total loss 1.24167764
Trained batch 820 batch loss 1.13807666 epoch total loss 1.24155128
Trained batch 821 batch loss 1.33669305 epoch total loss 1.24166715
Trained batch 822 batch loss 1.28707206 epoch total loss 1.24172235
Trained batch 823 batch loss 1.43572664 epoch total loss 1.24195802
Trained batch 824 batch loss 1.30319679 epoch total loss 1.24203241
Trained batch 825 batch loss 1.27863884 epoch total loss 1.24207687
Trained batch 826 batch loss 1.13963115 epoch total loss 1.24195278
Trained batch 827 batch loss 1.21502829 epoch total loss 1.24192035
Trained batch 828 batch loss 1.31557679 epoch total loss 1.24200928
Trained batch 829 batch loss 1.39296472 epoch total loss 1.24219131
Trained batch 830 batch loss 1.31191874 epoch total loss 1.24227536
Trained batch 831 batch loss 1.41202271 epoch total loss 1.24247956
Trained batch 832 batch loss 1.31658101 epoch total loss 1.24256849
Trained batch 833 batch loss 1.36552763 epoch total loss 1.24271607
Trained batch 834 batch loss 1.33061349 epoch total loss 1.24282146
Trained batch 835 batch loss 1.3538419 epoch total loss 1.24295437
Trained batch 836 batch loss 1.25285101 epoch total loss 1.24296618
Trained batch 837 batch loss 1.09692597 epoch total loss 1.24279177
Trained batch 838 batch loss 1.16353548 epoch total loss 1.24269724
Trained batch 839 batch loss 1.21690118 epoch total loss 1.24266648
Trained batch 840 batch loss 1.22123587 epoch total loss 1.24264085
Trained batch 841 batch loss 1.47537303 epoch total loss 1.24291766
Trained batch 842 batch loss 1.39956903 epoch total loss 1.24310362
Trained batch 843 batch loss 1.38801861 epoch total loss 1.24327552
Trained batch 844 batch loss 1.19155097 epoch total loss 1.24321425
Trained batch 845 batch loss 1.02160692 epoch total loss 1.24295199
Trained batch 846 batch loss 1.20438552 epoch total loss 1.24290633
Trained batch 847 batch loss 0.97369194 epoch total loss 1.2425884
Trained batch 848 batch loss 1.0961324 epoch total loss 1.24241579
Trained batch 849 batch loss 1.09164977 epoch total loss 1.24223828
Trained batch 850 batch loss 1.10139894 epoch total loss 1.24207258
Trained batch 851 batch loss 1.07399225 epoch total loss 1.24187505
Trained batch 852 batch loss 1.18832195 epoch total loss 1.24181223
Trained batch 853 batch loss 1.1197865 epoch total loss 1.24166918
Trained batch 854 batch loss 0.989223361 epoch total loss 1.24137366
Trained batch 855 batch loss 1.181301 epoch total loss 1.24130332
Trained batch 856 batch loss 1.30725193 epoch total loss 1.24138033
Trained batch 857 batch loss 1.27819204 epoch total loss 1.24142337
Trained batch 858 batch loss 1.17118251 epoch total loss 1.24134135
Trained batch 859 batch loss 1.30026388 epoch total loss 1.24141
Trained batch 860 batch loss 1.37363505 epoch total loss 1.2415638
Trained batch 861 batch loss 1.08362651 epoch total loss 1.24138033
Trained batch 862 batch loss 1.28377187 epoch total loss 1.24142957
Trained batch 863 batch loss 1.17575026 epoch total loss 1.24135351
Trained batch 864 batch loss 1.36644363 epoch total loss 1.24149835
Trained batch 865 batch loss 1.17702603 epoch total loss 1.24142373
Trained batch 866 batch loss 1.21264982 epoch total loss 1.24139047
Trained batch 867 batch loss 1.00686562 epoch total loss 1.24112
Trained batch 868 batch loss 1.08207512 epoch total loss 1.24093676
Trained batch 869 batch loss 1.26223302 epoch total loss 1.24096119
Trained batch 870 batch loss 1.24757576 epoch total loss 1.2409687
Trained batch 871 batch loss 1.2682035 epoch total loss 1.241
Trained batch 872 batch loss 1.38885987 epoch total loss 1.24116969
Trained batch 873 batch loss 1.33824027 epoch total loss 1.24128079
Trained batch 874 batch loss 1.1779871 epoch total loss 1.24120843
Trained batch 875 batch loss 1.24863446 epoch total loss 1.2412169
Trained batch 876 batch loss 1.09209931 epoch total loss 1.24104667
Trained batch 877 batch loss 1.04897928 epoch total loss 1.24082756
Trained batch 878 batch loss 0.995225072 epoch total loss 1.2405479
Trained batch 879 batch loss 1.08051598 epoch total loss 1.24036586
Trained batch 880 batch loss 1.11450195 epoch total loss 1.24022281
Trained batch 881 batch loss 1.08098793 epoch total loss 1.24004209
Trained batch 882 batch loss 1.31418383 epoch total loss 1.24012613
Trained batch 883 batch loss 1.29702926 epoch total loss 1.24019051
Trained batch 884 batch loss 1.43239832 epoch total loss 1.24040794
Trained batch 885 batch loss 1.45679128 epoch total loss 1.24065244
Trained batch 886 batch loss 1.31325769 epoch total loss 1.24073434
Trained batch 887 batch loss 1.30563045 epoch total loss 1.24080753
Trained batch 888 batch loss 1.27636695 epoch total loss 1.24084759
Trained batch 889 batch loss 1.22385395 epoch total loss 1.24082851
Trained batch 890 batch loss 1.35673869 epoch total loss 1.24095869
Trained batch 891 batch loss 1.39076257 epoch total loss 1.24112678
Trained batch 892 batch loss 1.39715874 epoch total loss 1.24130177
Trained batch 893 batch loss 1.27704394 epoch total loss 1.24134195
Trained batch 894 batch loss 1.21095574 epoch total loss 1.24130785
Trained batch 895 batch loss 1.23660183 epoch total loss 1.24130261
Trained batch 896 batch loss 1.36681342 epoch total loss 1.24144268
Trained batch 897 batch loss 1.16905832 epoch total loss 1.24136198
Trained batch 898 batch loss 1.19222641 epoch total loss 1.24130726
Trained batch 899 batch loss 1.37763739 epoch total loss 1.24145901
Trained batch 900 batch loss 1.16036534 epoch total loss 1.24136901
Trained batch 901 batch loss 1.35325897 epoch total loss 1.24149311
Trained batch 902 batch loss 1.31362653 epoch total loss 1.2415731
Trained batch 903 batch loss 1.291152 epoch total loss 1.24162793
Trained batch 904 batch loss 1.28143299 epoch total loss 1.24167192
Trained batch 905 batch loss 1.29327655 epoch total loss 1.24172902
Trained batch 906 batch loss 1.30382204 epoch total loss 1.24179757
Trained batch 907 batch loss 1.34650278 epoch total loss 1.24191308
Trained batch 908 batch loss 1.4436202 epoch total loss 1.24213517
Trained batch 909 batch loss 1.37166727 epoch total loss 1.24227774
Trained batch 910 batch loss 1.38064432 epoch total loss 1.24242973
Trained batch 911 batch loss 1.45472312 epoch total loss 1.24266279
Trained batch 912 batch loss 1.11379218 epoch total loss 1.24252141
Trained batch 913 batch loss 1.16141796 epoch total loss 1.24243259
Trained batch 914 batch loss 1.23225 epoch total loss 1.24242151
Trained batch 915 batch loss 1.09062326 epoch total loss 1.24225557
Trained batch 916 batch loss 1.09304404 epoch total loss 1.24209261
Trained batch 917 batch loss 1.33468306 epoch total loss 1.24219358
Trained batch 918 batch loss 1.19765413 epoch total loss 1.24214506
Trained batch 919 batch loss 1.22683632 epoch total loss 1.24212837
Trained batch 920 batch loss 1.10307705 epoch total loss 1.24197721
Trained batch 921 batch loss 1.33207798 epoch total loss 1.24207497
Trained batch 922 batch loss 1.08620906 epoch total loss 1.24190593
Trained batch 923 batch loss 1.090397 epoch total loss 1.24174178
Trained batch 924 batch loss 1.30190492 epoch total loss 1.24180686
Trained batch 925 batch loss 1.33966565 epoch total loss 1.24191272
Trained batch 926 batch loss 1.31096435 epoch total loss 1.24198723
Trained batch 927 batch loss 1.1531589 epoch total loss 1.2418915
Trained batch 928 batch loss 1.05656826 epoch total loss 1.24169171
Trained batch 929 batch loss 0.897644281 epoch total loss 1.24132144
Trained batch 930 batch loss 0.988710523 epoch total loss 1.24104989
Trained batch 931 batch loss 1.2845428 epoch total loss 1.24109662
Trained batch 932 batch loss 1.09551477 epoch total loss 1.24094033
Trained batch 933 batch loss 1.27642322 epoch total loss 1.24097836
Trained batch 934 batch loss 1.36044693 epoch total loss 1.24110627
Trained batch 935 batch loss 1.12890017 epoch total loss 1.24098623
Trained batch 936 batch loss 1.27444804 epoch total loss 1.24102199
Trained batch 937 batch loss 1.50999939 epoch total loss 1.24130905
Trained batch 938 batch loss 1.18125057 epoch total loss 1.24124503
Trained batch 939 batch loss 1.18431318 epoch total loss 1.24118447
Trained batch 940 batch loss 0.976171494 epoch total loss 1.24090254
Trained batch 941 batch loss 1.24418318 epoch total loss 1.240906
Trained batch 942 batch loss 1.25909352 epoch total loss 1.24092519
Trained batch 943 batch loss 1.25517213 epoch total loss 1.24094021
Trained batch 944 batch loss 1.2150923 epoch total loss 1.24091291
Trained batch 945 batch loss 1.17321599 epoch total loss 1.24084127
Trained batch 946 batch loss 1.16297638 epoch total loss 1.2407589
Trained batch 947 batch loss 0.936833739 epoch total loss 1.24043798
Trained batch 948 batch loss 1.02255237 epoch total loss 1.24020827
Trained batch 949 batch loss 1.04525292 epoch total loss 1.24000287
Trained batch 950 batch loss 1.05998445 epoch total loss 1.23981333
Trained batch 951 batch loss 1.40002954 epoch total loss 1.23998177
Trained batch 952 batch loss 1.14853287 epoch total loss 1.23988569
Trained batch 953 batch loss 1.25378203 epoch total loss 1.23990035
Trained batch 954 batch loss 1.08148241 epoch total loss 1.23973429
Trained batch 955 batch loss 1.24324477 epoch total loss 1.23973799
Trained batch 956 batch loss 1.13317847 epoch total loss 1.23962653
Trained batch 957 batch loss 1.1705184 epoch total loss 1.23955441
Trained batch 958 batch loss 1.15945649 epoch total loss 1.23947072
Trained batch 959 batch loss 1.29620051 epoch total loss 1.23952985
Trained batch 960 batch loss 1.49657345 epoch total loss 1.23979759
Trained batch 961 batch loss 1.2199471 epoch total loss 1.23977697
Trained batch 962 batch loss 1.15034986 epoch total loss 1.23968399
Trained batch 963 batch loss 1.20093167 epoch total loss 1.23964381
Trained batch 964 batch loss 1.05098605 epoch total loss 1.23944819
Trained batch 965 batch loss 1.10852122 epoch total loss 1.23931241
Trained batch 966 batch loss 1.1716404 epoch total loss 1.23924243
Trained batch 967 batch loss 1.23035157 epoch total loss 1.23923326
Trained batch 968 batch loss 1.2866447 epoch total loss 1.23928213
Trained batch 969 batch loss 1.25720406 epoch total loss 1.23930061
Trained batch 970 batch loss 1.37574077 epoch total loss 1.23944128
Trained batch 971 batch loss 1.30982316 epoch total loss 1.23951375
Trained batch 972 batch loss 1.19847512 epoch total loss 1.23947155
Trained batch 973 batch loss 1.34367514 epoch total loss 1.2395786
Trained batch 974 batch loss 1.23878562 epoch total loss 1.23957777
Trained batch 975 batch loss 1.15812552 epoch total loss 1.2394942
Trained batch 976 batch loss 1.03295207 epoch total loss 1.23928261
Trained batch 977 batch loss 1.07259703 epoch total loss 1.23911202
Trained batch 978 batch loss 1.39695573 epoch total loss 1.23927343
Trained batch 979 batch loss 0.999111 epoch total loss 1.2390281
Trained batch 980 batch loss 1.04833293 epoch total loss 1.23883355
Trained batch 981 batch loss 1.06730437 epoch total loss 1.23865867
Trained batch 982 batch loss 1.10338783 epoch total loss 1.23852086
Trained batch 983 batch loss 1.0091964 epoch total loss 1.23828757
Trained batch 984 batch loss 1.20960355 epoch total loss 1.23825848
Trained batch 985 batch loss 1.27563047 epoch total loss 1.23829639
Trained batch 986 batch loss 1.32936585 epoch total loss 1.23838866
Trained batch 987 batch loss 1.37571096 epoch total loss 1.23852789
Trained batch 988 batch loss 1.2194041 epoch total loss 1.23850846
Trained batch 989 batch loss 1.20455456 epoch total loss 1.23847413
Trained batch 990 batch loss 1.2013092 epoch total loss 1.23843658
Trained batch 991 batch loss 1.09674859 epoch total loss 1.23829365
Trained batch 992 batch loss 1.18134832 epoch total loss 1.23823631
Trained batch 993 batch loss 1.37846911 epoch total loss 1.23837745
Trained batch 994 batch loss 1.41437316 epoch total loss 1.2385546
Trained batch 995 batch loss 1.35290813 epoch total loss 1.23866951
Trained batch 996 batch loss 1.33700466 epoch total loss 1.23876834
Trained batch 997 batch loss 1.39296293 epoch total loss 1.23892295
Trained batch 998 batch loss 1.08720803 epoch total loss 1.23877084
Trained batch 999 batch loss 1.27212739 epoch total loss 1.23880422
Trained batch 1000 batch loss 1.25774157 epoch total loss 1.23882318
Trained batch 1001 batch loss 1.10125446 epoch total loss 1.23868561
Trained batch 1002 batch loss 1.06511939 epoch total loss 1.2385124
Trained batch 1003 batch loss 1.09883428 epoch total loss 1.23837316
Trained batch 1004 batch loss 1.07652688 epoch total loss 1.23821199
Trained batch 1005 batch loss 1.13537455 epoch total loss 1.23810959
Trained batch 1006 batch loss 1.24693167 epoch total loss 1.23811841
Trained batch 1007 batch loss 1.20099962 epoch total loss 1.23808157
Trained batch 1008 batch loss 1.17520666 epoch total loss 1.23801923
Trained batch 1009 batch loss 1.33423018 epoch total loss 1.2381146
Trained batch 1010 batch loss 1.1861856 epoch total loss 1.2380631
Trained batch 1011 batch loss 1.19550109 epoch total loss 1.23802102
Trained batch 1012 batch loss 1.30198193 epoch total loss 1.23808432
Trained batch 1013 batch loss 1.21258855 epoch total loss 1.23805916
Trained batch 1014 batch loss 1.3462441 epoch total loss 1.23816586
Trained batch 1015 batch loss 1.21667886 epoch total loss 1.23814464
Trained batch 1016 batch loss 1.12728405 epoch total loss 1.23803556
Trained batch 1017 batch loss 1.25679564 epoch total loss 1.23805404
Trained batch 1018 batch loss 1.11206675 epoch total loss 1.2379303
Trained batch 1019 batch loss 1.37832379 epoch total loss 1.23806798
Trained batch 1020 batch loss 1.27400446 epoch total loss 1.23810327
Trained batch 1021 batch loss 1.25309062 epoch total loss 1.23811793
Trained batch 1022 batch loss 1.20945048 epoch total loss 1.23808992
Trained batch 1023 batch loss 1.3394171 epoch total loss 1.23818898
Trained batch 1024 batch loss 1.36394656 epoch total loss 1.23831177
Trained batch 1025 batch loss 1.26541233 epoch total loss 1.23833823
Trained batch 1026 batch loss 1.22503781 epoch total loss 1.23832524
Trained batch 1027 batch loss 0.877962351 epoch total loss 1.23797441
Trained batch 1028 batch loss 1.15008485 epoch total loss 1.23788881
Trained batch 1029 batch loss 1.19173467 epoch total loss 1.23784399
Trained batch 1030 batch loss 1.24395025 epoch total loss 1.23784983
Trained batch 1031 batch loss 1.08503723 epoch total loss 1.23770165
Trained batch 1032 batch loss 1.02021766 epoch total loss 1.23749101
Trained batch 1033 batch loss 1.14844596 epoch total loss 1.23740482
Trained batch 1034 batch loss 1.20412827 epoch total loss 1.23737252
Trained batch 1035 batch loss 1.17637622 epoch total loss 1.23731363
Trained batch 1036 batch loss 1.17544186 epoch total loss 1.2372539
Trained batch 1037 batch loss 1.30810547 epoch total loss 1.23732221
Trained batch 1038 batch loss 1.19925785 epoch total loss 1.23728549
Trained batch 1039 batch loss 1.07301354 epoch total loss 1.23712742
Trained batch 1040 batch loss 1.14290547 epoch total loss 1.23703682
Trained batch 1041 batch loss 1.04686832 epoch total loss 1.2368542
Trained batch 1042 batch loss 1.15419686 epoch total loss 1.2367748
Trained batch 1043 batch loss 1.16364384 epoch total loss 1.23670471
Trained batch 1044 batch loss 1.2236855 epoch total loss 1.23669219
Trained batch 1045 batch loss 1.27960634 epoch total loss 1.23673332
Trained batch 1046 batch loss 1.20641911 epoch total loss 1.23670435
Trained batch 1047 batch loss 1.33748066 epoch total loss 1.23680067
Trained batch 1048 batch loss 1.2693851 epoch total loss 1.23683178
Trained batch 1049 batch loss 1.25161755 epoch total loss 1.23684585
Trained batch 1050 batch loss 1.10642505 epoch total loss 1.23672163
Trained batch 1051 batch loss 1.17129934 epoch total loss 1.23665941
Trained batch 1052 batch loss 1.19563031 epoch total loss 1.23662043
Trained batch 1053 batch loss 1.28659821 epoch total loss 1.23666787
Trained batch 1054 batch loss 0.932376862 epoch total loss 1.23637915
Trained batch 1055 batch loss 1.09141386 epoch total loss 1.23624182
Trained batch 1056 batch loss 1.11189795 epoch total loss 1.23612404
Trained batch 1057 batch loss 0.974373281 epoch total loss 1.23587644
Trained batch 1058 batch loss 1.11703432 epoch total loss 1.23576415
Trained batch 1059 batch loss 1.03001237 epoch total loss 1.23556983
Trained batch 1060 batch loss 1.1252563 epoch total loss 1.23546576
Trained batch 1061 batch loss 0.97547996 epoch total loss 1.23522079
Trained batch 1062 batch loss 0.923095644 epoch total loss 1.23492682
Trained batch 1063 batch loss 1.07738757 epoch total loss 1.23477864
Trained batch 1064 batch loss 0.97221446 epoch total loss 1.23453188
Trained batch 1065 batch loss 1.08591914 epoch total loss 1.23439229
Trained batch 1066 batch loss 1.00278008 epoch total loss 1.23417509
Trained batch 1067 batch loss 1.51544714 epoch total loss 1.23443878
Trained batch 1068 batch loss 1.2468183 epoch total loss 1.23445034
Trained batch 1069 batch loss 1.32770717 epoch total loss 1.2345376
Trained batch 1070 batch loss 1.23177779 epoch total loss 1.2345351
Trained batch 1071 batch loss 1.21097744 epoch total loss 1.23451304
Trained batch 1072 batch loss 1.27032614 epoch total loss 1.23454654
Trained batch 1073 batch loss 1.1466105 epoch total loss 1.23446453
Trained batch 1074 batch loss 1.27570283 epoch total loss 1.23450303
Trained batch 1075 batch loss 1.25826192 epoch total loss 1.23452508
Trained batch 1076 batch loss 1.38006604 epoch total loss 1.23466039
Trained batch 1077 batch loss 1.50125122 epoch total loss 1.23490798
Trained batch 1078 batch loss 1.39635324 epoch total loss 1.23505771
Trained batch 1079 batch loss 1.61356878 epoch total loss 1.23540843
Trained batch 1080 batch loss 1.37506282 epoch total loss 1.23553789
Trained batch 1081 batch loss 1.48158884 epoch total loss 1.23576546
Trained batch 1082 batch loss 1.37303233 epoch total loss 1.2358923
Trained batch 1083 batch loss 1.46327543 epoch total loss 1.23610222
Trained batch 1084 batch loss 1.19192886 epoch total loss 1.23606145
Trained batch 1085 batch loss 1.43568742 epoch total loss 1.23624539
Trained batch 1086 batch loss 1.20777464 epoch total loss 1.23621917
Trained batch 1087 batch loss 1.27954662 epoch total loss 1.2362591
Trained batch 1088 batch loss 1.3217 epoch total loss 1.23633754
Trained batch 1089 batch loss 1.35116959 epoch total loss 1.23644304
Trained batch 1090 batch loss 1.12267375 epoch total loss 1.23633862
Trained batch 1091 batch loss 1.27698636 epoch total loss 1.23637593
Trained batch 1092 batch loss 1.42948174 epoch total loss 1.23655272
Trained batch 1093 batch loss 1.37364149 epoch total loss 1.23667812
Trained batch 1094 batch loss 1.06828094 epoch total loss 1.23652422
Trained batch 1095 batch loss 1.13616168 epoch total loss 1.23643243
Trained batch 1096 batch loss 1.09222388 epoch total loss 1.23630083
Trained batch 1097 batch loss 1.06387746 epoch total loss 1.23614359
Trained batch 1098 batch loss 1.10380554 epoch total loss 1.23602307
Trained batch 1099 batch loss 1.0665307 epoch total loss 1.23586881
Trained batch 1100 batch loss 0.972446322 epoch total loss 1.23562932
Trained batch 1101 batch loss 1.55073667 epoch total loss 1.23591554
Trained batch 1102 batch loss 1.29950738 epoch total loss 1.23597336
Trained batch 1103 batch loss 1.09621346 epoch total loss 1.23584664
Trained batch 1104 batch loss 1.20888937 epoch total loss 1.2358222
Trained batch 1105 batch loss 1.24677896 epoch total loss 1.2358321
Trained batch 1106 batch loss 1.53706658 epoch total loss 1.23610449
Trained batch 1107 batch loss 1.19502187 epoch total loss 1.23606741
Trained batch 1108 batch loss 1.17023993 epoch total loss 1.23600805
Trained batch 1109 batch loss 1.23174596 epoch total loss 1.23600423
Trained batch 1110 batch loss 1.09604979 epoch total loss 1.23587811
Trained batch 1111 batch loss 1.32766509 epoch total loss 1.23596072
Trained batch 1112 batch loss 1.28922081 epoch total loss 1.23600852
Trained batch 1113 batch loss 1.1924454 epoch total loss 1.23596942
Trained batch 1114 batch loss 1.40406561 epoch total loss 1.23612034
Trained batch 1115 batch loss 1.34615767 epoch total loss 1.23621905
Trained batch 1116 batch loss 1.3126657 epoch total loss 1.23628759
Trained batch 1117 batch loss 1.43336904 epoch total loss 1.23646402
Trained batch 1118 batch loss 1.20244753 epoch total loss 1.23643351
Trained batch 1119 batch loss 1.24545479 epoch total loss 1.23644161
Trained batch 1120 batch loss 1.17554069 epoch total loss 1.23638725
Trained batch 1121 batch loss 1.35709989 epoch total loss 1.2364949
Trained batch 1122 batch loss 1.17665064 epoch total loss 1.23644149
Trained batch 1123 batch loss 1.14367867 epoch total loss 1.23635888
Trained batch 1124 batch loss 1.33147216 epoch total loss 1.23644352
Trained batch 1125 batch loss 1.19963217 epoch total loss 1.23641074
Trained batch 1126 batch loss 1.25507319 epoch total loss 1.23642731
Trained batch 1127 batch loss 1.23759258 epoch total loss 1.23642826
Trained batch 1128 batch loss 1.10569525 epoch total loss 1.23631239
Trained batch 1129 batch loss 1.17681742 epoch total loss 1.2362597
Trained batch 1130 batch loss 1.17980051 epoch total loss 1.23620975
Trained batch 1131 batch loss 1.19811213 epoch total loss 1.23617601
Trained batch 1132 batch loss 1.12202835 epoch total loss 1.23607528
Trained batch 1133 batch loss 1.0271064 epoch total loss 1.23589075
Trained batch 1134 batch loss 1.01832545 epoch total loss 1.23569894
Trained batch 1135 batch loss 1.17865944 epoch total loss 1.23564875
Trained batch 1136 batch loss 1.01228857 epoch total loss 1.23545218
Trained batch 1137 batch loss 1.26188684 epoch total loss 1.2354753
Trained batch 1138 batch loss 1.22535706 epoch total loss 1.23546648
Trained batch 1139 batch loss 1.17479694 epoch total loss 1.23541319
Trained batch 1140 batch loss 1.35268641 epoch total loss 1.23551607
Trained batch 1141 batch loss 1.30142665 epoch total loss 1.23557377
Trained batch 1142 batch loss 1.35049629 epoch total loss 1.23567438
Trained batch 1143 batch loss 1.32596362 epoch total loss 1.2357533
Trained batch 1144 batch loss 1.230147 epoch total loss 1.23574841
Trained batch 1145 batch loss 1.10849333 epoch total loss 1.23563731
Trained batch 1146 batch loss 1.2092272 epoch total loss 1.23561418
Trained batch 1147 batch loss 1.17713916 epoch total loss 1.23556328
Trained batch 1148 batch loss 1.15869284 epoch total loss 1.23549628
Trained batch 1149 batch loss 1.30442595 epoch total loss 1.23555624
Trained batch 1150 batch loss 1.17083633 epoch total loss 1.2355
Trained batch 1151 batch loss 1.35372066 epoch total loss 1.23560274
Trained batch 1152 batch loss 1.23446345 epoch total loss 1.23560178
Trained batch 1153 batch loss 1.28955841 epoch total loss 1.23564851
Trained batch 1154 batch loss 1.20666456 epoch total loss 1.23562336
Trained batch 1155 batch loss 1.2554965 epoch total loss 1.23564065
Trained batch 1156 batch loss 1.29176259 epoch total loss 1.23568916
Trained batch 1157 batch loss 1.38459516 epoch total loss 1.23581791
Trained batch 1158 batch loss 1.26871014 epoch total loss 1.23584628
Trained batch 1159 batch loss 1.33537126 epoch total loss 1.23593211
Trained batch 1160 batch loss 1.39096463 epoch total loss 1.23606575
Trained batch 1161 batch loss 1.3889873 epoch total loss 1.23619759
Trained batch 1162 batch loss 1.37811613 epoch total loss 1.23631978
Trained batch 1163 batch loss 1.51163697 epoch total loss 1.23655641
Trained batch 1164 batch loss 1.44477177 epoch total loss 1.23673534
Trained batch 1165 batch loss 1.29074669 epoch total loss 1.23678172
Trained batch 1166 batch loss 1.37623525 epoch total loss 1.23690128
Trained batch 1167 batch loss 1.38443637 epoch total loss 1.23702765
Trained batch 1168 batch loss 1.32641506 epoch total loss 1.23710418
Trained batch 1169 batch loss 1.34319377 epoch total loss 1.2371949
Trained batch 1170 batch loss 1.45255899 epoch total loss 1.23737895
Trained batch 1171 batch loss 1.09117818 epoch total loss 1.23725414
Trained batch 1172 batch loss 1.18605232 epoch total loss 1.23721039
Trained batch 1173 batch loss 1.23782659 epoch total loss 1.23721087
Trained batch 1174 batch loss 1.15611887 epoch total loss 1.23714185
Trained batch 1175 batch loss 0.990905523 epoch total loss 1.23693228
Trained batch 1176 batch loss 0.993597865 epoch total loss 1.23672533
Trained batch 1177 batch loss 1.18406379 epoch total loss 1.23668063
Trained batch 1178 batch loss 1.11710906 epoch total loss 1.23657906
Trained batch 1179 batch loss 1.34427786 epoch total loss 1.23667037
Trained batch 1180 batch loss 1.39702344 epoch total loss 1.23680627
Trained batch 1181 batch loss 1.3671391 epoch total loss 1.23691666
Trained batch 1182 batch loss 1.33512175 epoch total loss 1.23699975
Trained batch 1183 batch loss 1.17053795 epoch total loss 1.23694348
Trained batch 1184 batch loss 1.6194998 epoch total loss 1.23726666
Trained batch 1185 batch loss 1.31194258 epoch total loss 1.2373296
Trained batch 1186 batch loss 1.09585965 epoch total loss 1.23721027
Trained batch 1187 batch loss 1.09774971 epoch total loss 1.23709285
Trained batch 1188 batch loss 1.31536937 epoch total loss 1.23715878
Trained batch 1189 batch loss 1.10920215 epoch total loss 1.23705125
Trained batch 1190 batch loss 1.0975163 epoch total loss 1.23693395
Trained batch 1191 batch loss 1.11920297 epoch total loss 1.23683512
Trained batch 1192 batch loss 1.25446832 epoch total loss 1.23685
Trained batch 1193 batch loss 1.10155034 epoch total loss 1.23673654
Trained batch 1194 batch loss 1.04594851 epoch total loss 1.2365768
Trained batch 1195 batch loss 1.15624928 epoch total loss 1.23650956
Trained batch 1196 batch loss 1.21461296 epoch total loss 1.2364912
Trained batch 1197 batch loss 1.13501096 epoch total loss 1.23640645
Trained batch 1198 batch loss 1.1856395 epoch total loss 1.23636413
Trained batch 1199 batch loss 1.23474956 epoch total loss 1.2363627
Trained batch 1200 batch loss 1.08177578 epoch total loss 1.23623395
Trained batch 1201 batch loss 1.07657766 epoch total loss 1.23610091
Trained batch 1202 batch loss 1.00472403 epoch total loss 1.23590851
Trained batch 1203 batch loss 1.16966319 epoch total loss 1.23585343
Trained batch 1204 batch loss 1.01863921 epoch total loss 1.23567307
Trained batch 1205 batch loss 1.00366127 epoch total loss 1.23548055
Trained batch 1206 batch loss 1.12719488 epoch total loss 1.23539078
Trained batch 1207 batch loss 1.19760525 epoch total loss 1.23535943
Trained batch 1208 batch loss 1.34357429 epoch total loss 1.23544908
Trained batch 1209 batch loss 1.2875526 epoch total loss 1.23549223
Trained batch 1210 batch loss 1.12794161 epoch total loss 1.2354033
Trained batch 1211 batch loss 1.29252708 epoch total loss 1.23545051
Trained batch 1212 batch loss 1.21275842 epoch total loss 1.23543179
Trained batch 1213 batch loss 1.19496083 epoch total loss 1.23539841
Trained batch 1214 batch loss 1.17769933 epoch total loss 1.23535085
Trained batch 1215 batch loss 1.10805535 epoch total loss 1.23524606
Trained batch 1216 batch loss 1.21972334 epoch total loss 1.23523331
Trained batch 1217 batch loss 1.29235399 epoch total loss 1.23528028
Trained batch 1218 batch loss 1.3302846 epoch total loss 1.23535824
Trained batch 1219 batch loss 1.27918208 epoch total loss 1.23539424
Trained batch 1220 batch loss 1.31518054 epoch total loss 1.23545957
Trained batch 1221 batch loss 1.29380882 epoch total loss 1.23550737
Trained batch 1222 batch loss 1.23867106 epoch total loss 1.23551
Trained batch 1223 batch loss 1.31737804 epoch total loss 1.23557699
Trained batch 1224 batch loss 1.30881262 epoch total loss 1.23563683
Trained batch 1225 batch loss 1.43787444 epoch total loss 1.23580194
Trained batch 1226 batch loss 1.05531931 epoch total loss 1.23565459
Trained batch 1227 batch loss 1.19306076 epoch total loss 1.23562
Trained batch 1228 batch loss 1.19629169 epoch total loss 1.23558795
Trained batch 1229 batch loss 1.18882918 epoch total loss 1.23554993
Trained batch 1230 batch loss 1.32883167 epoch total loss 1.23562574
Trained batch 1231 batch loss 1.40014672 epoch total loss 1.23575938
Trained batch 1232 batch loss 1.44256902 epoch total loss 1.23592734
Trained batch 1233 batch loss 1.28067672 epoch total loss 1.23596358
Trained batch 1234 batch loss 1.55268502 epoch total loss 1.23622024
Trained batch 1235 batch loss 1.42070091 epoch total loss 1.23636961
Trained batch 1236 batch loss 1.54901528 epoch total loss 1.23662269
Trained batch 1237 batch loss 1.38742042 epoch total loss 1.23674452
Trained batch 1238 batch loss 1.36310971 epoch total loss 1.23684669
Trained batch 1239 batch loss 1.3376745 epoch total loss 1.23692799
Trained batch 1240 batch loss 1.32486868 epoch total loss 1.23699892
Trained batch 1241 batch loss 1.30913901 epoch total loss 1.23705697
Trained batch 1242 batch loss 1.31806386 epoch total loss 1.2371223
Trained batch 1243 batch loss 1.24966192 epoch total loss 1.23713231
Trained batch 1244 batch loss 1.27647185 epoch total loss 1.23716402
Trained batch 1245 batch loss 1.21147943 epoch total loss 1.23714328
Trained batch 1246 batch loss 1.24233508 epoch total loss 1.23714745
Trained batch 1247 batch loss 1.21581841 epoch total loss 1.23713028
Trained batch 1248 batch loss 1.18504262 epoch total loss 1.23708856
Trained batch 1249 batch loss 1.23575425 epoch total loss 1.23708749
Trained batch 1250 batch loss 1.15238547 epoch total loss 1.23701978
Trained batch 1251 batch loss 1.20625496 epoch total loss 1.23699522
Trained batch 1252 batch loss 1.20686865 epoch total loss 1.23697114
Trained batch 1253 batch loss 1.03058541 epoch total loss 1.23680651
Trained batch 1254 batch loss 1.23919415 epoch total loss 1.2368083
Trained batch 1255 batch loss 1.26944375 epoch total loss 1.23683429
Trained batch 1256 batch loss 1.11879838 epoch total loss 1.23674035
Trained batch 1257 batch loss 1.2440784 epoch total loss 1.23674607
Trained batch 1258 batch loss 1.43314183 epoch total loss 1.23690224
Trained batch 1259 batch loss 1.34501219 epoch total loss 1.23698807
Trained batch 1260 batch loss 1.42056811 epoch total loss 1.23713374
Trained batch 1261 batch loss 1.30001831 epoch total loss 1.23718357
Trained batch 1262 batch loss 1.2107687 epoch total loss 1.23716271
Trained batch 1263 batch loss 1.29641509 epoch total loss 1.23720956
Trained batch 1264 batch loss 1.31044948 epoch total loss 1.23726749
Trained batch 1265 batch loss 1.41852164 epoch total loss 1.23741078
Trained batch 1266 batch loss 1.34945035 epoch total loss 1.23749936
Trained batch 1267 batch loss 1.49688792 epoch total loss 1.23770416
Trained batch 1268 batch loss 1.50475025 epoch total loss 1.2379148
Trained batch 1269 batch loss 1.41429639 epoch total loss 1.2380538
Trained batch 1270 batch loss 1.58155465 epoch total loss 1.23832417
Trained batch 1271 batch loss 1.5458796 epoch total loss 1.23856616
Trained batch 1272 batch loss 1.11936617 epoch total loss 1.23847246
Trained batch 1273 batch loss 1.2889502 epoch total loss 1.23851216
Trained batch 1274 batch loss 1.12174761 epoch total loss 1.23842049
Trained batch 1275 batch loss 1.03533268 epoch total loss 1.2382611
Trained batch 1276 batch loss 1.4460187 epoch total loss 1.23842394
Trained batch 1277 batch loss 1.27548814 epoch total loss 1.23845303
Trained batch 1278 batch loss 1.19310784 epoch total loss 1.23841751
Trained batch 1279 batch loss 1.27485633 epoch total loss 1.23844612
Trained batch 1280 batch loss 1.77696395 epoch total loss 1.23886681
Trained batch 1281 batch loss 1.27443838 epoch total loss 1.23889458
Trained batch 1282 batch loss 1.20811784 epoch total loss 1.2388705
Trained batch 1283 batch loss 1.26513886 epoch total loss 1.23889101
Trained batch 1284 batch loss 1.16173875 epoch total loss 1.23883092
Trained batch 1285 batch loss 1.29386282 epoch total loss 1.23887372
Trained batch 1286 batch loss 1.27550173 epoch total loss 1.23890221
Trained batch 1287 batch loss 1.33049822 epoch total loss 1.23897338
Trained batch 1288 batch loss 1.38476682 epoch total loss 1.23908651
Trained batch 1289 batch loss 1.47929263 epoch total loss 1.23927283
Trained batch 1290 batch loss 1.46133327 epoch total loss 1.23944497
Trained batch 1291 batch loss 1.56453669 epoch total loss 1.23969686
Trained batch 1292 batch loss 1.29190087 epoch total loss 1.23973715
Trained batch 1293 batch loss 1.34303951 epoch total loss 1.23981714
Trained batch 1294 batch loss 1.47775424 epoch total loss 1.24000096
Trained batch 1295 batch loss 1.16126585 epoch total loss 1.23994017
Trained batch 1296 batch loss 1.05432606 epoch total loss 1.239797
Trained batch 1297 batch loss 1.01005125 epoch total loss 1.23961973
Trained batch 1298 batch loss 1.16564465 epoch total loss 1.23956275
Trained batch 1299 batch loss 1.04776454 epoch total loss 1.23941517
Trained batch 1300 batch loss 0.890802205 epoch total loss 1.23914695
Trained batch 1301 batch loss 1.15692949 epoch total loss 1.23908377
Trained batch 1302 batch loss 1.1033442 epoch total loss 1.23897958
Trained batch 1303 batch loss 1.3032937 epoch total loss 1.23902893
Trained batch 1304 batch loss 1.23884964 epoch total loss 1.23902881
Trained batch 1305 batch loss 1.54468322 epoch total loss 1.23926306
Trained batch 1306 batch loss 1.32106435 epoch total loss 1.23932564
Trained batch 1307 batch loss 1.08802629 epoch total loss 1.23920989
Trained batch 1308 batch loss 1.34758782 epoch total loss 1.23929274
Trained batch 1309 batch loss 1.34343934 epoch total loss 1.23937225
Trained batch 1310 batch loss 1.232723 epoch total loss 1.23936713
Trained batch 1311 batch loss 1.27276599 epoch total loss 1.23939252
Trained batch 1312 batch loss 1.12200356 epoch total loss 1.23930299
Trained batch 1313 batch loss 1.3442626 epoch total loss 1.23938298
Trained batch 1314 batch loss 1.10677457 epoch total loss 1.23928201
Trained batch 1315 batch loss 1.27631128 epoch total loss 1.23931026
Trained batch 1316 batch loss 0.925857663 epoch total loss 1.23907208
Trained batch 1317 batch loss 1.1681186 epoch total loss 1.2390182
Trained batch 1318 batch loss 1.14705014 epoch total loss 1.23894846
Trained batch 1319 batch loss 1.11526394 epoch total loss 1.23885465
Trained batch 1320 batch loss 1.23879421 epoch total loss 1.23885465
Trained batch 1321 batch loss 1.20982146 epoch total loss 1.23883259
Trained batch 1322 batch loss 1.09530115 epoch total loss 1.23872411
Trained batch 1323 batch loss 1.15571165 epoch total loss 1.23866141
Trained batch 1324 batch loss 1.28520703 epoch total loss 1.23869646
Trained batch 1325 batch loss 1.34582424 epoch total loss 1.2387774
Trained batch 1326 batch loss 1.26532316 epoch total loss 1.23879743
Trained batch 1327 batch loss 1.27341604 epoch total loss 1.23882353
Trained batch 1328 batch loss 1.34550989 epoch total loss 1.23890388
Trained batch 1329 batch loss 1.19452417 epoch total loss 1.2388705
Trained batch 1330 batch loss 1.1425674 epoch total loss 1.23879802
Trained batch 1331 batch loss 1.20576799 epoch total loss 1.23877335
Trained batch 1332 batch loss 1.162848 epoch total loss 1.23871624
Trained batch 1333 batch loss 1.29002583 epoch total loss 1.23875475
Trained batch 1334 batch loss 1.30051541 epoch total loss 1.23880112
Trained batch 1335 batch loss 1.31015444 epoch total loss 1.23885453
Trained batch 1336 batch loss 1.12648368 epoch total loss 1.23877048
Trained batch 1337 batch loss 1.13711643 epoch total loss 1.23869443
Trained batch 1338 batch loss 1.3361764 epoch total loss 1.23876727
Trained batch 1339 batch loss 1.33928502 epoch total loss 1.23884225
Trained batch 1340 batch loss 1.22420049 epoch total loss 1.2388314
Trained batch 1341 batch loss 1.26045442 epoch total loss 1.23884749
Trained batch 1342 batch loss 1.30184853 epoch total loss 1.23889446
Trained batch 1343 batch loss 1.4090054 epoch total loss 1.23902118
Trained batch 1344 batch loss 1.30751991 epoch total loss 1.2390722
Trained batch 1345 batch loss 1.53103757 epoch total loss 1.23928916
Trained batch 1346 batch loss 1.25025034 epoch total loss 1.23929739
Trained batch 1347 batch loss 1.40079069 epoch total loss 1.2394172
Trained batch 1348 batch loss 1.49054158 epoch total loss 1.23960352
Trained batch 1349 batch loss 1.18445134 epoch total loss 1.23956263
Trained batch 1350 batch loss 1.26026571 epoch total loss 1.23957801
Trained batch 1351 batch loss 1.27754068 epoch total loss 1.23960614
Trained batch 1352 batch loss 1.27906072 epoch total loss 1.23963535
Trained batch 1353 batch loss 1.42702556 epoch total loss 1.23977375
Trained batch 1354 batch loss 1.37767959 epoch total loss 1.23987567
Trained batch 1355 batch loss 1.29060149 epoch total loss 1.23991311
Trained batch 1356 batch loss 1.43733776 epoch total loss 1.24005878
Trained batch 1357 batch loss 1.28800845 epoch total loss 1.24009407
Trained batch 1358 batch loss 1.39865208 epoch total loss 1.24021077
Trained batch 1359 batch loss 1.44305205 epoch total loss 1.24036
Trained batch 1360 batch loss 1.36291957 epoch total loss 1.24045014
Trained batch 1361 batch loss 1.44979453 epoch total loss 1.24060404
Trained batch 1362 batch loss 0.821622729 epoch total loss 1.24029636
Trained batch 1363 batch loss 1.09216154 epoch total loss 1.24018776
Trained batch 1364 batch loss 1.12076437 epoch total loss 1.24010015
Trained batch 1365 batch loss 1.30801058 epoch total loss 1.24014986
Trained batch 1366 batch loss 1.16864014 epoch total loss 1.24009752
Trained batch 1367 batch loss 1.02982807 epoch total loss 1.23994362
Trained batch 1368 batch loss 1.20235741 epoch total loss 1.23991621
Trained batch 1369 batch loss 1.29338431 epoch total loss 1.23995519
Trained batch 1370 batch loss 1.26421976 epoch total loss 1.23997283
Trained batch 1371 batch loss 1.20819426 epoch total loss 1.2399497
Trained batch 1372 batch loss 1.3215158 epoch total loss 1.24000919
Trained batch 1373 batch loss 1.22684765 epoch total loss 1.23999953
Trained batch 1374 batch loss 1.11708713 epoch total loss 1.23991013
Trained batch 1375 batch loss 1.0608449 epoch total loss 1.23977983
Trained batch 1376 batch loss 1.02042627 epoch total loss 1.23962033
Trained batch 1377 batch loss 1.02821994 epoch total loss 1.23946691
Trained batch 1378 batch loss 1.07954764 epoch total loss 1.2393508
Trained batch 1379 batch loss 1.08608592 epoch total loss 1.23923969
Trained batch 1380 batch loss 0.989334404 epoch total loss 1.23905861
Trained batch 1381 batch loss 1.27729142 epoch total loss 1.23908639
Trained batch 1382 batch loss 0.981608748 epoch total loss 1.2389
Trained batch 1383 batch loss 1.26340222 epoch total loss 1.23891771
Trained batch 1384 batch loss 1.45783329 epoch total loss 1.2390759
Trained batch 1385 batch loss 1.22875834 epoch total loss 1.23906851
Trained batch 1386 batch loss 1.07287073 epoch total loss 1.23894858
Trained batch 1387 batch loss 1.21174288 epoch total loss 1.23892903
Trained batch 1388 batch loss 1.38188684 epoch total loss 1.23903191
Trained batch 1389 batch loss 1.33972764 epoch total loss 1.23910451
Trained batch 1390 batch loss 1.46269178 epoch total loss 1.23926532
Trained batch 1391 batch loss 1.47534335 epoch total loss 1.23943496
Trained batch 1392 batch loss 1.02678 epoch total loss 1.23928225
Trained batch 1393 batch loss 0.993229687 epoch total loss 1.23910558
Trained batch 1394 batch loss 0.992137194 epoch total loss 1.23892844
Trained batch 1395 batch loss 1.11100817 epoch total loss 1.23883677
Trained batch 1396 batch loss 1.352386 epoch total loss 1.23891807
Trained batch 1397 batch loss 1.59035659 epoch total loss 1.2391696
Trained batch 1398 batch loss 1.36671472 epoch total loss 1.23926091
Trained batch 1399 batch loss 1.40128207 epoch total loss 1.23937666
Trained batch 1400 batch loss 1.25483632 epoch total loss 1.23938775
Trained batch 1401 batch loss 1.20402598 epoch total loss 1.23936248
Trained batch 1402 batch loss 1.16918945 epoch total loss 1.23931241
Trained batch 1403 batch loss 1.29003417 epoch total loss 1.23934853
Trained batch 1404 batch loss 1.40776956 epoch total loss 1.23946846
Trained batch 1405 batch loss 1.39037037 epoch total loss 1.23957586
Trained batch 1406 batch loss 1.37922716 epoch total loss 1.23967528
Trained batch 1407 batch loss 1.2879014 epoch total loss 1.2397095
Trained batch 1408 batch loss 1.47839034 epoch total loss 1.23987901
Trained batch 1409 batch loss 1.45963407 epoch total loss 1.24003494
Trained batch 1410 batch loss 1.44503307 epoch total loss 1.24018037
Trained batch 1411 batch loss 1.46899116 epoch total loss 1.2403425
Trained batch 1412 batch loss 1.43897128 epoch total loss 1.24048316
Trained batch 1413 batch loss 1.49571061 epoch total loss 1.24066377
Trained batch 1414 batch loss 1.3856144 epoch total loss 1.24076629
Trained batch 1415 batch loss 1.44702148 epoch total loss 1.24091208
Trained batch 1416 batch loss 1.09831548 epoch total loss 1.24081135
Trained batch 1417 batch loss 1.16322446 epoch total loss 1.24075663
Trained batch 1418 batch loss 1.29197502 epoch total loss 1.24079275
Trained batch 1419 batch loss 1.10402775 epoch total loss 1.24069631
Trained batch 1420 batch loss 1.26290035 epoch total loss 1.24071205
Trained batch 1421 batch loss 1.26450133 epoch total loss 1.24072874
Trained batch 1422 batch loss 1.39133787 epoch total loss 1.24083471
Trained batch 1423 batch loss 1.25227737 epoch total loss 1.2408427
Trained batch 1424 batch loss 1.37007165 epoch total loss 1.24093354
Trained batch 1425 batch loss 1.13743186 epoch total loss 1.24086094
Trained batch 1426 batch loss 1.13184559 epoch total loss 1.24078441
Trained batch 1427 batch loss 1.18888354 epoch total loss 1.24074805
Trained batch 1428 batch loss 1.3468771 epoch total loss 1.24082243
Trained batch 1429 batch loss 1.25108051 epoch total loss 1.24082959
Trained batch 1430 batch loss 1.23909175 epoch total loss 1.24082839
Trained batch 1431 batch loss 1.18934584 epoch total loss 1.24079239
Trained batch 1432 batch loss 1.38651872 epoch total loss 1.2408942
Trained batch 1433 batch loss 1.15729332 epoch total loss 1.24083591
Trained batch 1434 batch loss 1.32063222 epoch total loss 1.24089158
Trained batch 1435 batch loss 1.20810318 epoch total loss 1.24086869
Trained batch 1436 batch loss 1.39127111 epoch total loss 1.24097347
Trained batch 1437 batch loss 1.42536139 epoch total loss 1.24110174
Trained batch 1438 batch loss 1.26987064 epoch total loss 1.24112177
Trained batch 1439 batch loss 1.34820759 epoch total loss 1.24119627
Trained batch 1440 batch loss 1.4227674 epoch total loss 1.24132228
Trained batch 1441 batch loss 1.27006769 epoch total loss 1.24134219
Trained batch 1442 batch loss 1.43254375 epoch total loss 1.24147475
Trained batch 1443 batch loss 1.33319068 epoch total loss 1.24153829
Trained batch 1444 batch loss 1.491961 epoch total loss 1.24171174
Trained batch 1445 batch loss 1.42972469 epoch total loss 1.24184179
Trained batch 1446 batch loss 1.41791749 epoch total loss 1.24196362
Trained batch 1447 batch loss 1.30692172 epoch total loss 1.24200845
Trained batch 1448 batch loss 1.39783692 epoch total loss 1.24211609
Trained batch 1449 batch loss 1.41849804 epoch total loss 1.24223781
Trained batch 1450 batch loss 1.42073655 epoch total loss 1.24236095
Trained batch 1451 batch loss 1.28205121 epoch total loss 1.24238837
Trained batch 1452 batch loss 1.50237966 epoch total loss 1.2425673
Trained batch 1453 batch loss 1.63973308 epoch total loss 1.24284065
Trained batch 1454 batch loss 1.32062674 epoch total loss 1.24289417
Trained batch 1455 batch loss 1.31767082 epoch total loss 1.24294555
Trained batch 1456 batch loss 1.4829638 epoch total loss 1.24311042
Trained batch 1457 batch loss 1.42107725 epoch total loss 1.24323249
Trained batch 1458 batch loss 1.37528634 epoch total loss 1.24332309
Trained batch 1459 batch loss 1.31487775 epoch total loss 1.24337208
Trained batch 1460 batch loss 1.35824442 epoch total loss 1.24345076
Trained batch 1461 batch loss 1.56227279 epoch total loss 1.24366891
Trained batch 1462 batch loss 1.36926699 epoch total loss 1.24375486
Trained batch 1463 batch loss 1.4418807 epoch total loss 1.24389029
Trained batch 1464 batch loss 1.30392528 epoch total loss 1.24393129
Trained batch 1465 batch loss 1.29402924 epoch total loss 1.24396551
Trained batch 1466 batch loss 1.2393508 epoch total loss 1.24396241
Trained batch 1467 batch loss 1.3605473 epoch total loss 1.24404192
Trained batch 1468 batch loss 1.33040547 epoch total loss 1.24410081
Trained batch 1469 batch loss 1.36737978 epoch total loss 1.24418473
Trained batch 1470 batch loss 1.29552805 epoch total loss 1.24421966
Trained batch 1471 batch loss 1.24343061 epoch total loss 1.24421918
Trained batch 1472 batch loss 1.30020428 epoch total loss 1.24425709
Trained batch 1473 batch loss 1.33857501 epoch total loss 1.24432123
Trained batch 1474 batch loss 1.34554303 epoch total loss 1.24438989
Trained batch 1475 batch loss 1.2198422 epoch total loss 1.24437332
Trained batch 1476 batch loss 1.30787253 epoch total loss 1.24441624
Trained batch 1477 batch loss 1.27445412 epoch total loss 1.24443662
Trained batch 1478 batch loss 1.35497415 epoch total loss 1.24451137
Trained batch 1479 batch loss 1.35937929 epoch total loss 1.24458909
Trained batch 1480 batch loss 1.41300154 epoch total loss 1.24470282
Trained batch 1481 batch loss 1.22044945 epoch total loss 1.24468648
Trained batch 1482 batch loss 1.24064779 epoch total loss 1.24468362
Trained batch 1483 batch loss 1.14430201 epoch total loss 1.24461603
Trained batch 1484 batch loss 0.835751772 epoch total loss 1.24434042
Trained batch 1485 batch loss 1.09607768 epoch total loss 1.24424064
Trained batch 1486 batch loss 0.91977787 epoch total loss 1.24402225
Trained batch 1487 batch loss 1.06072211 epoch total loss 1.24389899
Trained batch 1488 batch loss 1.0518074 epoch total loss 1.24376976
Trained batch 1489 batch loss 0.999764681 epoch total loss 1.24360597
Trained batch 1490 batch loss 1.00183928 epoch total loss 1.24344373
Trained batch 1491 batch loss 1.112046 epoch total loss 1.24335551
Trained batch 1492 batch loss 1.00398982 epoch total loss 1.24319518
Trained batch 1493 batch loss 0.994461775 epoch total loss 1.24302864
Trained batch 1494 batch loss 0.928058 epoch total loss 1.24281776
Trained batch 1495 batch loss 1.04830027 epoch total loss 1.2426877
Trained batch 1496 batch loss 1.17375731 epoch total loss 1.24264157
Trained batch 1497 batch loss 1.34507513 epoch total loss 1.24271
Trained batch 1498 batch loss 1.29948461 epoch total loss 1.2427479
Trained batch 1499 batch loss 1.21843219 epoch total loss 1.24273169
Trained batch 1500 batch loss 1.48786902 epoch total loss 1.24289513
Trained batch 1501 batch loss 1.37116313 epoch total loss 1.2429806
Trained batch 1502 batch loss 1.29404175 epoch total loss 1.24301457
Trained batch 1503 batch loss 1.0668081 epoch total loss 1.24289739
Trained batch 1504 batch loss 1.12552381 epoch total loss 1.24281931
Trained batch 1505 batch loss 1.48893952 epoch total loss 1.24298275
Trained batch 1506 batch loss 1.48618293 epoch total loss 1.24314427
Trained batch 1507 batch loss 1.42910433 epoch total loss 1.24326766
Trained batch 1508 batch loss 1.50117791 epoch total loss 1.24343872
Trained batch 1509 batch loss 1.30650282 epoch total loss 1.24348056
Trained batch 1510 batch loss 1.21577287 epoch total loss 1.2434622
Trained batch 1511 batch loss 1.45447779 epoch total loss 1.2436018
Trained batch 1512 batch loss 1.4164412 epoch total loss 1.24371612
Trained batch 1513 batch loss 1.04091895 epoch total loss 1.24358213
Trained batch 1514 batch loss 1.05450177 epoch total loss 1.2434572
Trained batch 1515 batch loss 0.994483769 epoch total loss 1.24329281
Trained batch 1516 batch loss 1.1642915 epoch total loss 1.24324071
Trained batch 1517 batch loss 1.14740849 epoch total loss 1.24317753
Trained batch 1518 batch loss 1.16782093 epoch total loss 1.24312794
Trained batch 1519 batch loss 1.06043172 epoch total loss 1.24300766
Trained batch 1520 batch loss 0.967342615 epoch total loss 1.24282622
Trained batch 1521 batch loss 1.0754056 epoch total loss 1.24271619
Trained batch 1522 batch loss 1.31331205 epoch total loss 1.24276268
Trained batch 1523 batch loss 1.54341745 epoch total loss 1.2429601
Trained batch 1524 batch loss 1.44426644 epoch total loss 1.24309218
Trained batch 1525 batch loss 1.25024223 epoch total loss 1.24309683
Trained batch 1526 batch loss 1.29577911 epoch total loss 1.2431314
Trained batch 1527 batch loss 1.14448583 epoch total loss 1.24306679
Trained batch 1528 batch loss 1.25715768 epoch total loss 1.24307597
Trained batch 1529 batch loss 1.0759002 epoch total loss 1.24296665
Trained batch 1530 batch loss 1.39276 epoch total loss 1.24306452
Trained batch 1531 batch loss 1.40821886 epoch total loss 1.24317241
Trained batch 1532 batch loss 1.34250534 epoch total loss 1.24323726
Trained batch 1533 batch loss 1.3787955 epoch total loss 1.24332571
Trained batch 1534 batch loss 1.16080093 epoch total loss 1.24327195
Trained batch 1535 batch loss 1.31553245 epoch total loss 1.24331903
Trained batch 1536 batch loss 1.14426303 epoch total loss 1.24325454
Trained batch 1537 batch loss 1.30918372 epoch total loss 1.24329746
Trained batch 1538 batch loss 1.26100826 epoch total loss 1.2433089
Trained batch 1539 batch loss 1.34418154 epoch total loss 1.24337447
Trained batch 1540 batch loss 1.39882529 epoch total loss 1.24347544
Trained batch 1541 batch loss 1.412166 epoch total loss 1.24358487
Trained batch 1542 batch loss 1.53398764 epoch total loss 1.2437731
Trained batch 1543 batch loss 1.51545691 epoch total loss 1.24394929
Trained batch 1544 batch loss 1.43600988 epoch total loss 1.24407363
Trained batch 1545 batch loss 1.36315107 epoch total loss 1.24415076
Trained batch 1546 batch loss 1.185431 epoch total loss 1.24411273
Trained batch 1547 batch loss 0.995369315 epoch total loss 1.24395192
Trained batch 1548 batch loss 1.41582298 epoch total loss 1.2440629
Trained batch 1549 batch loss 1.29985309 epoch total loss 1.2440989
Trained batch 1550 batch loss 1.29056311 epoch total loss 1.24412894
Trained batch 1551 batch loss 1.08500803 epoch total loss 1.2440263
Trained batch 1552 batch loss 1.45077276 epoch total loss 1.24415946
Trained batch 1553 batch loss 1.31924129 epoch total loss 1.24420786
Trained batch 1554 batch loss 1.25638604 epoch total loss 1.24421561
Trained batch 1555 batch loss 1.1469152 epoch total loss 1.24415314
Trained batch 1556 batch loss 0.965188503 epoch total loss 1.24397385
Trained batch 1557 batch loss 1.12483704 epoch total loss 1.24389732
Trained batch 1558 batch loss 1.05559242 epoch total loss 1.24377644
Trained batch 1559 batch loss 1.01087761 epoch total loss 1.24362707
Trained batch 1560 batch loss 1.06582856 epoch total loss 1.24351311
Trained batch 1561 batch loss 1.12948334 epoch total loss 1.24344
Trained batch 1562 batch loss 1.28701055 epoch total loss 1.24346793
Trained batch 1563 batch loss 1.37789536 epoch total loss 1.243554
Trained batch 1564 batch loss 1.23342943 epoch total loss 1.24354744
Trained batch 1565 batch loss 1.45065165 epoch total loss 1.24367976
Trained batch 1566 batch loss 1.29782462 epoch total loss 1.24371445
Trained batch 1567 batch loss 1.70491076 epoch total loss 1.24400878
Trained batch 1568 batch loss 1.13231301 epoch total loss 1.24393749
Trained batch 1569 batch loss 1.20133185 epoch total loss 1.24391031
Trained batch 1570 batch loss 0.892567873 epoch total loss 1.24368656
Trained batch 1571 batch loss 1.33263958 epoch total loss 1.24374318
Trained batch 1572 batch loss 1.39169645 epoch total loss 1.24383736
Trained batch 1573 batch loss 1.45435357 epoch total loss 1.24397111
Trained batch 1574 batch loss 1.38684249 epoch total loss 1.24406195
Trained batch 1575 batch loss 1.20352519 epoch total loss 1.2440362
Trained batch 1576 batch loss 1.04333496 epoch total loss 1.24390876
Trained batch 1577 batch loss 0.991153598 epoch total loss 1.24374855
Trained batch 1578 batch loss 1.04771173 epoch total loss 1.24362433
Trained batch 1579 batch loss 1.00386345 epoch total loss 1.24347258
Trained batch 1580 batch loss 1.14727187 epoch total loss 1.24341166
Trained batch 1581 batch loss 1.22081029 epoch total loss 1.24339736
Trained batch 1582 batch loss 0.959478 epoch total loss 1.24321783
Trained batch 1583 batch loss 1.16300821 epoch total loss 1.24316716
Trained batch 1584 batch loss 0.990433 epoch total loss 1.24300766
Trained batch 1585 batch loss 1.24889839 epoch total loss 1.24301136
Trained batch 1586 batch loss 1.20732808 epoch total loss 1.24298882
Trained batch 1587 batch loss 1.15587234 epoch total loss 1.24293387
Trained batch 1588 batch loss 1.26384246 epoch total loss 1.2429471
Trained batch 1589 batch loss 0.951648593 epoch total loss 1.24276376
Trained batch 1590 batch loss 1.14482284 epoch total loss 1.24270213
Trained batch 1591 batch loss 1.18460536 epoch total loss 1.24266553
Trained batch 1592 batch loss 1.26985049 epoch total loss 1.2426827
Trained batch 1593 batch loss 1.4399066 epoch total loss 1.24280655
Trained batch 1594 batch loss 1.31943083 epoch total loss 1.2428546
Trained batch 1595 batch loss 1.25900626 epoch total loss 1.24286473
Trained batch 1596 batch loss 1.2799139 epoch total loss 1.24288797
Trained batch 1597 batch loss 1.17758656 epoch total loss 1.24284708
Trained batch 1598 batch loss 1.23220611 epoch total loss 1.24284041
Trained batch 1599 batch loss 1.18628144 epoch total loss 1.242805
Trained batch 1600 batch loss 1.20492673 epoch total loss 1.2427814
Trained batch 1601 batch loss 1.23057556 epoch total loss 1.24277377
Trained batch 1602 batch loss 1.27458096 epoch total loss 1.24279356
Trained batch 1603 batch loss 1.05677676 epoch total loss 1.24267757
Trained batch 1604 batch loss 1.27556682 epoch total loss 1.24269795
Trained batch 1605 batch loss 1.10670912 epoch total loss 1.24261332
Trained batch 1606 batch loss 1.26603007 epoch total loss 1.24262786
Trained batch 1607 batch loss 1.13726318 epoch total loss 1.24256217
Trained batch 1608 batch loss 1.26005566 epoch total loss 1.24257302
Trained batch 1609 batch loss 1.15645695 epoch total loss 1.24251962
Trained batch 1610 batch loss 1.04550385 epoch total loss 1.24239719
Trained batch 1611 batch loss 1.10373616 epoch total loss 1.24231112
Trained batch 1612 batch loss 1.14864707 epoch total loss 1.24225307
Trained batch 1613 batch loss 1.27427149 epoch total loss 1.24227297
Trained batch 1614 batch loss 1.09893835 epoch total loss 1.24218416
Trained batch 1615 batch loss 1.16333532 epoch total loss 1.24213541
Trained batch 1616 batch loss 1.29149055 epoch total loss 1.24216592
Trained batch 1617 batch loss 1.25767636 epoch total loss 1.24217546
Trained batch 1618 batch loss 1.24342108 epoch total loss 1.24217629
Trained batch 1619 batch loss 1.35969925 epoch total loss 1.24224889
Trained batch 1620 batch loss 1.20045388 epoch total loss 1.24222302
Trained batch 1621 batch loss 1.20156431 epoch total loss 1.24219799
Trained batch 1622 batch loss 1.04803872 epoch total loss 1.2420783
Trained batch 1623 batch loss 0.953228474 epoch total loss 1.24190032
Trained batch 1624 batch loss 0.921183944 epoch total loss 1.2417028
Trained batch 1625 batch loss 1.10464787 epoch total loss 1.24161851
Trained batch 1626 batch loss 1.2404592 epoch total loss 1.2416178
Trained batch 1627 batch loss 1.42667913 epoch total loss 1.24173152
Trained batch 1628 batch loss 1.45326352 epoch total loss 1.24186146
Trained batch 1629 batch loss 1.29802465 epoch total loss 1.24189579
Trained batch 1630 batch loss 1.18210363 epoch total loss 1.2418592
Trained batch 1631 batch loss 1.12436986 epoch total loss 1.2417872
Trained batch 1632 batch loss 1.16844785 epoch total loss 1.24174225
Trained batch 1633 batch loss 1.13463402 epoch total loss 1.24167669
Trained batch 1634 batch loss 1.30507267 epoch total loss 1.24171543
Trained batch 1635 batch loss 1.21557212 epoch total loss 1.24169946
Trained batch 1636 batch loss 1.4432013 epoch total loss 1.2418226
Trained batch 1637 batch loss 1.18899202 epoch total loss 1.24179029
Trained batch 1638 batch loss 1.04855835 epoch total loss 1.2416724
Trained batch 1639 batch loss 1.13649273 epoch total loss 1.24160826
Trained batch 1640 batch loss 1.16531944 epoch total loss 1.24156165
Trained batch 1641 batch loss 1.14769435 epoch total loss 1.24150443
Trained batch 1642 batch loss 1.26664209 epoch total loss 1.24151981
Trained batch 1643 batch loss 1.04800129 epoch total loss 1.24140191
Trained batch 1644 batch loss 1.11020017 epoch total loss 1.24132216
Trained batch 1645 batch loss 1.12728477 epoch total loss 1.2412529
Trained batch 1646 batch loss 1.13464177 epoch total loss 1.24118805
Trained batch 1647 batch loss 0.923712075 epoch total loss 1.24099529
Trained batch 1648 batch loss 1.06433725 epoch total loss 1.24088812
Trained batch 1649 batch loss 1.08187342 epoch total loss 1.24079168
Trained batch 1650 batch loss 1.27160668 epoch total loss 1.24081039
Trained batch 1651 batch loss 1.31826246 epoch total loss 1.24085736
Trained batch 1652 batch loss 1.1918596 epoch total loss 1.24082768
Trained batch 1653 batch loss 1.42917311 epoch total loss 1.24094164
Trained batch 1654 batch loss 0.911007166 epoch total loss 1.24074209
Trained batch 1655 batch loss 1.33019781 epoch total loss 1.24079609
Trained batch 1656 batch loss 1.28881752 epoch total loss 1.24082518
Trained batch 1657 batch loss 1.33350039 epoch total loss 1.24088109
Trained batch 1658 batch loss 1.12588155 epoch total loss 1.24081171
Trained batch 1659 batch loss 1.51465213 epoch total loss 1.24097681
Trained batch 1660 batch loss 1.02204418 epoch total loss 1.24084485
Trained batch 1661 batch loss 1.33830249 epoch total loss 1.24090362
Trained batch 1662 batch loss 1.19247413 epoch total loss 1.24087441
Trained batch 1663 batch loss 1.11910224 epoch total loss 1.24080122
Trained batch 1664 batch loss 1.04381382 epoch total loss 1.24068272
Trained batch 1665 batch loss 1.01869023 epoch total loss 1.24054945
Trained batch 1666 batch loss 1.19027162 epoch total loss 1.24051929
Trained batch 1667 batch loss 1.31115317 epoch total loss 1.2405616
Trained batch 1668 batch loss 1.44921422 epoch total loss 1.24068666
Trained batch 1669 batch loss 1.16859853 epoch total loss 1.2406435
Trained batch 1670 batch loss 1.34418488 epoch total loss 1.24070561
Trained batch 1671 batch loss 1.30559969 epoch total loss 1.24074447
Trained batch 1672 batch loss 1.03991985 epoch total loss 1.24062443
Trained batch 1673 batch loss 1.25027013 epoch total loss 1.24063015
Trained batch 1674 batch loss 1.2107892 epoch total loss 1.24061227
Trained batch 1675 batch loss 1.00335097 epoch total loss 1.24047065
Trained batch 1676 batch loss 1.16532779 epoch total loss 1.24042583
Trained batch 1677 batch loss 1.03556967 epoch total loss 1.24030364
Trained batch 1678 batch loss 1.10359 epoch total loss 1.2402221
Trained batch 1679 batch loss 1.30941546 epoch total loss 1.24026334
Trained batch 1680 batch loss 1.12926579 epoch total loss 1.24019718
Trained batch 1681 batch loss 1.11712289 epoch total loss 1.24012399
Trained batch 1682 batch loss 1.28967333 epoch total loss 1.24015355
Trained batch 1683 batch loss 1.1451931 epoch total loss 1.24009717
Trained batch 1684 batch loss 1.13806415 epoch total loss 1.24003661
Trained batch 1685 batch loss 1.44505382 epoch total loss 1.24015832
Trained batch 1686 batch loss 1.54863167 epoch total loss 1.24034119
Trained batch 1687 batch loss 1.24653625 epoch total loss 1.24034488
Trained batch 1688 batch loss 1.2484355 epoch total loss 1.24034977
Trained batch 1689 batch loss 1.16131067 epoch total loss 1.24030304
Trained batch 1690 batch loss 1.31143928 epoch total loss 1.24034512
Trained batch 1691 batch loss 1.20176816 epoch total loss 1.24032235
Trained batch 1692 batch loss 1.51361251 epoch total loss 1.24048388
Trained batch 1693 batch loss 1.24549091 epoch total loss 1.24048686
Trained batch 1694 batch loss 1.2107271 epoch total loss 1.24046934
Trained batch 1695 batch loss 1.40137601 epoch total loss 1.24056423
Trained batch 1696 batch loss 1.25350094 epoch total loss 1.24057174
Trained batch 1697 batch loss 1.42260981 epoch total loss 1.24067903
Trained batch 1698 batch loss 1.38910103 epoch total loss 1.24076653
Trained batch 1699 batch loss 1.11864901 epoch total loss 1.24069464
Trained batch 1700 batch loss 1.36636925 epoch total loss 1.24076867
Trained batch 1701 batch loss 1.33904397 epoch total loss 1.24082637
Trained batch 1702 batch loss 1.28965533 epoch total loss 1.2408551
Trained batch 1703 batch loss 1.37573946 epoch total loss 1.24093425
Trained batch 1704 batch loss 1.20887482 epoch total loss 1.24091554
Trained batch 1705 batch loss 1.19252932 epoch total loss 1.24088717
Trained batch 1706 batch loss 1.35889339 epoch total loss 1.24095631
Trained batch 1707 batch loss 1.35109627 epoch total loss 1.24102092
Trained batch 1708 batch loss 1.39958811 epoch total loss 1.24111378
Trained batch 1709 batch loss 1.35384953 epoch total loss 1.2411797
Trained batch 1710 batch loss 1.2755419 epoch total loss 1.24119985
Trained batch 1711 batch loss 1.44786906 epoch total loss 1.24132049
Trained batch 1712 batch loss 1.16897964 epoch total loss 1.24127829
Trained batch 1713 batch loss 1.2576685 epoch total loss 1.24128771
Trained batch 1714 batch loss 0.896649241 epoch total loss 1.24108672
Trained batch 1715 batch loss 1.43851399 epoch total loss 1.24120188
Trained batch 1716 batch loss 1.32671809 epoch total loss 1.24125159
Trained batch 1717 batch loss 1.30375981 epoch total loss 1.24128795
Trained batch 1718 batch loss 1.31591678 epoch total loss 1.24133146
Trained batch 1719 batch loss 1.29043293 epoch total loss 1.24136007
Trained batch 1720 batch loss 1.08795238 epoch total loss 1.24127078
Trained batch 1721 batch loss 1.12563074 epoch total loss 1.24120367
Trained batch 1722 batch loss 1.1165179 epoch total loss 1.24113131
Trained batch 1723 batch loss 1.25091386 epoch total loss 1.24113703
Trained batch 1724 batch loss 1.09755826 epoch total loss 1.2410537
Trained batch 1725 batch loss 1.24953175 epoch total loss 1.24105871
Trained batch 1726 batch loss 1.10831726 epoch total loss 1.24098182
Trained batch 1727 batch loss 1.12633693 epoch total loss 1.2409153
Trained batch 1728 batch loss 1.04946768 epoch total loss 1.24080455
Trained batch 1729 batch loss 1.15303743 epoch total loss 1.24075389
Trained batch 1730 batch loss 1.02743649 epoch total loss 1.24063051
Trained batch 1731 batch loss 0.887865 epoch total loss 1.24042678
Trained batch 1732 batch loss 1.0778718 epoch total loss 1.24033296
Trained batch 1733 batch loss 1.12679863 epoch total loss 1.2402674
Trained batch 1734 batch loss 1.22129786 epoch total loss 1.24025631
Trained batch 1735 batch loss 0.97803092 epoch total loss 1.24010515
Trained batch 1736 batch loss 1.10625148 epoch total loss 1.24002802
Trained batch 1737 batch loss 1.44108319 epoch total loss 1.2401439
Trained batch 1738 batch loss 1.21670282 epoch total loss 1.24013042
Trained batch 1739 batch loss 1.3679266 epoch total loss 1.24020386
Trained batch 1740 batch loss 1.06500149 epoch total loss 1.24010313
Trained batch 1741 batch loss 1.26215 epoch total loss 1.24011588
Trained batch 1742 batch loss 1.26784515 epoch total loss 1.24013174
Trained batch 1743 batch loss 1.13269436 epoch total loss 1.24007022
Trained batch 1744 batch loss 1.29030204 epoch total loss 1.24009895
Trained batch 1745 batch loss 1.29249227 epoch total loss 1.24012899
Trained batch 1746 batch loss 1.25624681 epoch total loss 1.24013829
Trained batch 1747 batch loss 1.36111414 epoch total loss 1.24020755
Trained batch 1748 batch loss 1.43588018 epoch total loss 1.24031949
Trained batch 1749 batch loss 1.31462765 epoch total loss 1.24036193
Trained batch 1750 batch loss 1.21846867 epoch total loss 1.24034941
Trained batch 1751 batch loss 1.21161902 epoch total loss 1.24033308
Trained batch 1752 batch loss 1.26441884 epoch total loss 1.24034679
Trained batch 1753 batch loss 1.08031499 epoch total loss 1.24025559
Trained batch 1754 batch loss 1.26065147 epoch total loss 1.24026728
Trained batch 1755 batch loss 1.20423174 epoch total loss 1.24024677
Trained batch 1756 batch loss 1.26278222 epoch total loss 1.24025953
Trained batch 1757 batch loss 1.24395597 epoch total loss 1.24026155
Trained batch 1758 batch loss 1.18823886 epoch total loss 1.24023199
Trained batch 1759 batch loss 1.23333406 epoch total loss 1.24022818
Trained batch 1760 batch loss 1.32849407 epoch total loss 1.24027836
Trained batch 1761 batch loss 1.31054544 epoch total loss 1.2403183
Trained batch 1762 batch loss 1.28404713 epoch total loss 1.24034297
Trained batch 1763 batch loss 1.11868095 epoch total loss 1.24027395
Trained batch 1764 batch loss 1.2166425 epoch total loss 1.24026048
Trained batch 1765 batch loss 1.4158237 epoch total loss 1.24036
Trained batch 1766 batch loss 1.28630102 epoch total loss 1.24038601
Trained batch 1767 batch loss 1.27670264 epoch total loss 1.24040651
Trained batch 1768 batch loss 1.35413623 epoch total loss 1.24047089
Trained batch 1769 batch loss 1.22634363 epoch total loss 1.2404629
Trained batch 1770 batch loss 1.31860065 epoch total loss 1.24050713
Trained batch 1771 batch loss 1.29627895 epoch total loss 1.2405386
Trained batch 1772 batch loss 1.25971222 epoch total loss 1.24054945
Trained batch 1773 batch loss 1.29658306 epoch total loss 1.24058115
Trained batch 1774 batch loss 1.15581548 epoch total loss 1.24053323
Trained batch 1775 batch loss 1.2416662 epoch total loss 1.24053395
Trained batch 1776 batch loss 1.02829969 epoch total loss 1.2404145
Trained batch 1777 batch loss 1.22770083 epoch total loss 1.24040735
Trained batch 1778 batch loss 1.13392258 epoch total loss 1.2403475
Trained batch 1779 batch loss 1.35099578 epoch total loss 1.24040973
Trained batch 1780 batch loss 1.1604284 epoch total loss 1.24036479
Trained batch 1781 batch loss 1.17055762 epoch total loss 1.24032569
Trained batch 1782 batch loss 1.37833202 epoch total loss 1.24040318
Trained batch 1783 batch loss 1.27402759 epoch total loss 1.24042201
Trained batch 1784 batch loss 1.59577489 epoch total loss 1.24062109
Trained batch 1785 batch loss 1.50770271 epoch total loss 1.24077082
Trained batch 1786 batch loss 1.31255531 epoch total loss 1.24081099
Trained batch 1787 batch loss 1.27952302 epoch total loss 1.24083269
Trained batch 1788 batch loss 1.3059231 epoch total loss 1.24086905
Trained batch 1789 batch loss 1.23051786 epoch total loss 1.2408632
Trained batch 1790 batch loss 1.24363279 epoch total loss 1.24086475
Trained batch 1791 batch loss 1.09752011 epoch total loss 1.24078465
Trained batch 1792 batch loss 1.25558639 epoch total loss 1.24079299
Trained batch 1793 batch loss 1.22695422 epoch total loss 1.24078524
Trained batch 1794 batch loss 1.31640208 epoch total loss 1.24082744
Trained batch 1795 batch loss 1.25534368 epoch total loss 1.24083555
Trained batch 1796 batch loss 1.35457897 epoch total loss 1.24089885
Trained batch 1797 batch loss 1.26781368 epoch total loss 1.24091387
Trained batch 1798 batch loss 0.773947954 epoch total loss 1.24065411
Trained batch 1799 batch loss 1.00462019 epoch total loss 1.24052286
Trained batch 1800 batch loss 0.934307873 epoch total loss 1.24035275
Trained batch 1801 batch loss 0.901448786 epoch total loss 1.24016452
Trained batch 1802 batch loss 1.0472343 epoch total loss 1.24005747
Trained batch 1803 batch loss 0.978253365 epoch total loss 1.23991227
Trained batch 1804 batch loss 1.09042239 epoch total loss 1.2398293
Trained batch 1805 batch loss 1.06460857 epoch total loss 1.23973227
Trained batch 1806 batch loss 1.25505972 epoch total loss 1.23974085
Trained batch 1807 batch loss 1.09132612 epoch total loss 1.23965871
Trained batch 1808 batch loss 1.07671642 epoch total loss 1.23956847
Trained batch 1809 batch loss 1.00192356 epoch total loss 1.23943722
Trained batch 1810 batch loss 1.31171274 epoch total loss 1.23947716
Trained batch 1811 batch loss 1.18513227 epoch total loss 1.23944712
Trained batch 1812 batch loss 1.06332493 epoch total loss 1.23934984
Trained batch 1813 batch loss 1.31926751 epoch total loss 1.23939395
Trained batch 1814 batch loss 1.17866433 epoch total loss 1.23936045
Trained batch 1815 batch loss 1.32620859 epoch total loss 1.23940837
Trained batch 1816 batch loss 1.51311266 epoch total loss 1.23955905
Trained batch 1817 batch loss 1.44309 epoch total loss 1.23967111
Trained batch 1818 batch loss 1.22788727 epoch total loss 1.23966455
Trained batch 1819 batch loss 1.11876822 epoch total loss 1.23959804
Trained batch 1820 batch loss 1.40578294 epoch total loss 1.23968935
Trained batch 1821 batch loss 1.30278039 epoch total loss 1.23972392
Trained batch 1822 batch loss 1.38574576 epoch total loss 1.23980415
Trained batch 1823 batch loss 1.09663844 epoch total loss 1.23972559
Trained batch 1824 batch loss 1.3080796 epoch total loss 1.23976314
Trained batch 1825 batch loss 1.27082634 epoch total loss 1.23978007
Trained batch 1826 batch loss 1.24965358 epoch total loss 1.23978555
Trained batch 1827 batch loss 1.22348905 epoch total loss 1.23977661
Trained batch 1828 batch loss 1.29857254 epoch total loss 1.23980868
Trained batch 1829 batch loss 1.29079962 epoch total loss 1.23983657
Trained batch 1830 batch loss 1.25898147 epoch total loss 1.23984706
Trained batch 1831 batch loss 1.26399493 epoch total loss 1.23986018
Trained batch 1832 batch loss 1.10592198 epoch total loss 1.2397871
Trained batch 1833 batch loss 1.10449409 epoch total loss 1.23971331
Trained batch 1834 batch loss 1.15467536 epoch total loss 1.23966706
Trained batch 1835 batch loss 1.08169317 epoch total loss 1.23958099
Trained batch 1836 batch loss 1.1749562 epoch total loss 1.23954582
Trained batch 1837 batch loss 1.21767628 epoch total loss 1.23953402
Trained batch 1838 batch loss 1.2102263 epoch total loss 1.23951805
Trained batch 1839 batch loss 0.938446701 epoch total loss 1.23935437
Trained batch 1840 batch loss 1.22523665 epoch total loss 1.23934674
Trained batch 1841 batch loss 1.24750054 epoch total loss 1.23935115
Trained batch 1842 batch loss 1.06084847 epoch total loss 1.23925424
Trained batch 1843 batch loss 1.05819 epoch total loss 1.23915589
Trained batch 1844 batch loss 0.973897099 epoch total loss 1.23901212
Trained batch 1845 batch loss 1.07874584 epoch total loss 1.23892534
Trained batch 1846 batch loss 1.23855972 epoch total loss 1.2389251
Trained batch 1847 batch loss 1.24469864 epoch total loss 1.2389282
Trained batch 1848 batch loss 1.21624017 epoch total loss 1.23891592
Trained batch 1849 batch loss 1.09229088 epoch total loss 1.23883665
Trained batch 1850 batch loss 0.974007368 epoch total loss 1.23869348
Trained batch 1851 batch loss 1.02829933 epoch total loss 1.23857987
Trained batch 1852 batch loss 1.06646013 epoch total loss 1.23848689
Trained batch 1853 batch loss 0.892850041 epoch total loss 1.23830032
Trained batch 1854 batch loss 1.13066161 epoch total loss 1.23824227
Trained batch 1855 batch loss 0.949568033 epoch total loss 1.23808658
Trained batch 1856 batch loss 1.18765759 epoch total loss 1.23805952
Trained batch 1857 batch loss 1.26877892 epoch total loss 1.23807597
Trained batch 1858 batch loss 1.20848775 epoch total loss 1.23806012
Trained batch 1859 batch loss 0.819926143 epoch total loss 1.23783517
Trained batch 1860 batch loss 1.17747295 epoch total loss 1.23780262
Trained batch 1861 batch loss 1.32009554 epoch total loss 1.23784685
Trained batch 1862 batch loss 1.30033255 epoch total loss 1.23788047
Trained batch 1863 batch loss 1.25398088 epoch total loss 1.23788905
Trained batch 1864 batch loss 1.05826855 epoch total loss 1.23779273
Trained batch 1865 batch loss 1.25879622 epoch total loss 1.23780394
Trained batch 1866 batch loss 1.05979049 epoch total loss 1.23770857
Trained batch 1867 batch loss 1.17171597 epoch total loss 1.23767316
Trained batch 1868 batch loss 1.03760624 epoch total loss 1.23756611
Trained batch 1869 batch loss 1.04630721 epoch total loss 1.23746383
Trained batch 1870 batch loss 0.937039316 epoch total loss 1.23730314
Trained batch 1871 batch loss 1.10001969 epoch total loss 1.23722982
Trained batch 1872 batch loss 1.38847744 epoch total loss 1.23731053
Trained batch 1873 batch loss 1.25669634 epoch total loss 1.2373209
Trained batch 1874 batch loss 1.0857656 epoch total loss 1.23724
Trained batch 1875 batch loss 1.29669154 epoch total loss 1.23727167
Trained batch 1876 batch loss 1.13233697 epoch total loss 1.23721564
Trained batch 1877 batch loss 1.19960225 epoch total loss 1.23719573
Trained batch 1878 batch loss 1.27202845 epoch total loss 1.23721421
Trained batch 1879 batch loss 1.25634503 epoch total loss 1.23722434
Trained batch 1880 batch loss 1.40895748 epoch total loss 1.23731577
Trained batch 1881 batch loss 1.36041546 epoch total loss 1.2373811
Trained batch 1882 batch loss 1.24096882 epoch total loss 1.23738301
Trained batch 1883 batch loss 1.20407009 epoch total loss 1.23736537
Trained batch 1884 batch loss 1.35848403 epoch total loss 1.23742962
Trained batch 1885 batch loss 1.43809128 epoch total loss 1.23753595
Trained batch 1886 batch loss 1.28378272 epoch total loss 1.23756051
Trained batch 1887 batch loss 1.33935547 epoch total loss 1.23761439
Trained batch 1888 batch loss 1.32959199 epoch total loss 1.23766315
Trained batch 1889 batch loss 1.33793414 epoch total loss 1.2377162
Trained batch 1890 batch loss 1.25454402 epoch total loss 1.23772514
Trained batch 1891 batch loss 1.21554494 epoch total loss 1.23771346
Trained batch 1892 batch loss 1.05004656 epoch total loss 1.23761427
Trained batch 1893 batch loss 1.14798236 epoch total loss 1.23756683
Trained batch 1894 batch loss 1.27885151 epoch total loss 1.23758864
Trained batch 1895 batch loss 1.34587145 epoch total loss 1.23764586
Trained batch 1896 batch loss 1.29466712 epoch total loss 1.23767591
Trained batch 1897 batch loss 1.25966382 epoch total loss 1.23768759
Trained batch 1898 batch loss 1.18504918 epoch total loss 1.23765981
Trained batch 1899 batch loss 1.15152168 epoch total loss 1.23761451
Trained batch 1900 batch loss 0.999938905 epoch total loss 1.23748946
Trained batch 1901 batch loss 1.30796289 epoch total loss 1.23752654
Trained batch 1902 batch loss 1.34601545 epoch total loss 1.23758352
Trained batch 1903 batch loss 1.22974133 epoch total loss 1.23757935
Trained batch 1904 batch loss 1.14561415 epoch total loss 1.23753095
Trained batch 1905 batch loss 1.2180109 epoch total loss 1.23752081
Trained batch 1906 batch loss 1.20346665 epoch total loss 1.23750281
Trained batch 1907 batch loss 1.18723059 epoch total loss 1.23747647
Trained batch 1908 batch loss 1.18479347 epoch total loss 1.23744893
Trained batch 1909 batch loss 1.10349524 epoch total loss 1.23737872
Trained batch 1910 batch loss 1.57947421 epoch total loss 1.23755789
Trained batch 1911 batch loss 1.3699789 epoch total loss 1.23762715
Trained batch 1912 batch loss 1.19857883 epoch total loss 1.23760664
Trained batch 1913 batch loss 1.36157787 epoch total loss 1.23767149
Trained batch 1914 batch loss 1.26980722 epoch total loss 1.2376883
Trained batch 1915 batch loss 1.3682549 epoch total loss 1.23775637
Trained batch 1916 batch loss 1.22581792 epoch total loss 1.23775017
Trained batch 1917 batch loss 1.08007634 epoch total loss 1.23766792
Trained batch 1918 batch loss 1.18100154 epoch total loss 1.23763835
Trained batch 1919 batch loss 1.18172574 epoch total loss 1.23760915
Trained batch 1920 batch loss 1.2498455 epoch total loss 1.23761547
Trained batch 1921 batch loss 1.26980686 epoch total loss 1.23763216
Trained batch 1922 batch loss 1.16322327 epoch total loss 1.23759353
Trained batch 1923 batch loss 1.22920716 epoch total loss 1.23758924
Trained batch 1924 batch loss 1.35530436 epoch total loss 1.23765039
Trained batch 1925 batch loss 1.51189518 epoch total loss 1.23779285
Trained batch 1926 batch loss 1.21343589 epoch total loss 1.23778021
Trained batch 1927 batch loss 1.40684474 epoch total loss 1.23786783
Trained batch 1928 batch loss 1.21212256 epoch total loss 1.23785448
Trained batch 1929 batch loss 1.30603302 epoch total loss 1.23788989
Trained batch 1930 batch loss 1.19864154 epoch total loss 1.23786962
Trained batch 1931 batch loss 1.16365862 epoch total loss 1.23783112
Trained batch 1932 batch loss 1.20324862 epoch total loss 1.23781335
Trained batch 1933 batch loss 1.37671232 epoch total loss 1.23788512
Trained batch 1934 batch loss 1.43181872 epoch total loss 1.23798549
Trained batch 1935 batch loss 1.23165131 epoch total loss 1.23798227
Trained batch 1936 batch loss 1.23375106 epoch total loss 1.23798
Trained batch 1937 batch loss 1.07088208 epoch total loss 1.2378937
Trained batch 1938 batch loss 1.11386228 epoch total loss 1.23782969
Trained batch 1939 batch loss 1.29308081 epoch total loss 1.23785806
Trained batch 1940 batch loss 1.34037232 epoch total loss 1.23791087
Trained batch 1941 batch loss 1.35912466 epoch total loss 1.23797333
Trained batch 1942 batch loss 1.31534028 epoch total loss 1.23801327
Trained batch 1943 batch loss 1.44887209 epoch total loss 1.23812175
Trained batch 1944 batch loss 1.20277381 epoch total loss 1.23810363
Trained batch 1945 batch loss 1.17534733 epoch total loss 1.23807132
Trained batch 1946 batch loss 1.10915053 epoch total loss 1.23800516
Trained batch 1947 batch loss 1.28816211 epoch total loss 1.23803079
Trained batch 1948 batch loss 1.11457443 epoch total loss 1.23796737
Trained batch 1949 batch loss 1.21597958 epoch total loss 1.23795617
Trained batch 1950 batch loss 1.19779289 epoch total loss 1.23793554
Trained batch 1951 batch loss 1.18201089 epoch total loss 1.23790693
Trained batch 1952 batch loss 1.18636131 epoch total loss 1.23788047
Trained batch 1953 batch loss 1.26246548 epoch total loss 1.2378931
Trained batch 1954 batch loss 1.2763989 epoch total loss 1.23791277
Trained batch 1955 batch loss 1.18306398 epoch total loss 1.23788476
Trained batch 1956 batch loss 1.1297121 epoch total loss 1.23782945
Trained batch 1957 batch loss 1.22201526 epoch total loss 1.23782134
Trained batch 1958 batch loss 1.24445212 epoch total loss 1.23782468
Trained batch 1959 batch loss 1.33839869 epoch total loss 1.23787594
Trained batch 1960 batch loss 1.43343687 epoch total loss 1.23797572
Trained batch 1961 batch loss 1.24768496 epoch total loss 1.23798072
Trained batch 1962 batch loss 1.14078808 epoch total loss 1.23793125
Trained batch 1963 batch loss 1.132249 epoch total loss 1.23787737
Trained batch 1964 batch loss 1.15999651 epoch total loss 1.23783767
Trained batch 1965 batch loss 1.11036241 epoch total loss 1.23777282
Trained batch 1966 batch loss 1.17273211 epoch total loss 1.2377398
Trained batch 1967 batch loss 1.02986336 epoch total loss 1.23763406
Trained batch 1968 batch loss 1.0539062 epoch total loss 1.23754072
Trained batch 1969 batch loss 1.13768208 epoch total loss 1.23749
Trained batch 1970 batch loss 1.04529178 epoch total loss 1.23739254
Trained batch 1971 batch loss 1.05096591 epoch total loss 1.23729801
Trained batch 1972 batch loss 1.07777905 epoch total loss 1.23721719
Trained batch 1973 batch loss 0.857695401 epoch total loss 1.23702478
Trained batch 1974 batch loss 0.942432404 epoch total loss 1.23687553
Trained batch 1975 batch loss 0.987101197 epoch total loss 1.23674905
Trained batch 1976 batch loss 0.983076096 epoch total loss 1.23662066
Trained batch 1977 batch loss 1.08234382 epoch total loss 1.23654258
Trained batch 1978 batch loss 1.25428605 epoch total loss 1.23655164
Trained batch 1979 batch loss 1.28198385 epoch total loss 1.23657465
Trained batch 1980 batch loss 1.02345991 epoch total loss 1.236467
Trained batch 1981 batch loss 1.28758836 epoch total loss 1.23649275
Trained batch 1982 batch loss 0.917734265 epoch total loss 1.23633194
Trained batch 1983 batch loss 1.23514843 epoch total loss 1.23633134
Trained batch 1984 batch loss 1.18472433 epoch total loss 1.23630536
Trained batch 1985 batch loss 1.21984243 epoch total loss 1.23629701
Trained batch 1986 batch loss 1.07025146 epoch total loss 1.23621345
Trained batch 1987 batch loss 1.22340488 epoch total loss 1.23620701
Trained batch 1988 batch loss 1.09731174 epoch total loss 1.23613715
Trained batch 1989 batch loss 0.957074583 epoch total loss 1.23599684
Trained batch 1990 batch loss 0.893098712 epoch total loss 1.23582447
Trained batch 1991 batch loss 0.929190636 epoch total loss 1.23567045
Trained batch 1992 batch loss 1.09343112 epoch total loss 1.23559916
Trained batch 1993 batch loss 1.07733512 epoch total loss 1.23551977
Trained batch 1994 batch loss 1.12307191 epoch total loss 1.23546338
Trained batch 1995 batch loss 1.08184958 epoch total loss 1.23538637
Trained batch 1996 batch loss 1.00212026 epoch total loss 1.23526955
Trained batch 1997 batch loss 1.18510044 epoch total loss 1.23524439
Trained batch 1998 batch loss 1.11767352 epoch total loss 1.2351855
Trained batch 1999 batch loss 1.23767745 epoch total loss 1.23518682
Trained batch 2000 batch loss 1.14241195 epoch total loss 1.23514032
Trained batch 2001 batch loss 1.23782611 epoch total loss 1.23514175
Trained batch 2002 batch loss 1.17549467 epoch total loss 1.23511195
Trained batch 2003 batch loss 1.04615772 epoch total loss 1.23501754
Trained batch 2004 batch loss 0.997885525 epoch total loss 1.23489916
Trained batch 2005 batch loss 1.13517642 epoch total loss 1.23484957
Trained batch 2006 batch loss 1.03659272 epoch total loss 1.23475075
Trained batch 2007 batch loss 1.04363358 epoch total loss 1.2346555
Trained batch 2008 batch loss 1.08447623 epoch total loss 1.23458076
Trained batch 2009 batch loss 0.991346 epoch total loss 1.23445976
Trained batch 2010 batch loss 1.20618057 epoch total loss 1.23444569
Trained batch 2011 batch loss 1.14407468 epoch total loss 1.23440075
Trained batch 2012 batch loss 1.00429404 epoch total loss 1.23428643
Trained batch 2013 batch loss 1.06911278 epoch total loss 1.23420441
Trained batch 2014 batch loss 1.06298721 epoch total loss 1.2341193
Trained batch 2015 batch loss 1.17554677 epoch total loss 1.23409033
Trained batch 2016 batch loss 1.22333241 epoch total loss 1.23408496
Trained batch 2017 batch loss 1.22399771 epoch total loss 1.23408
Trained batch 2018 batch loss 0.879196286 epoch total loss 1.233904
Trained batch 2019 batch loss 0.912844896 epoch total loss 1.23374498
Trained batch 2020 batch loss 0.997368693 epoch total loss 1.23362792
Trained batch 2021 batch loss 1.07933092 epoch total loss 1.23355162
Trained batch 2022 batch loss 1.05373812 epoch total loss 1.23346269
Trained batch 2023 batch loss 1.28890538 epoch total loss 1.23349
Trained batch 2024 batch loss 1.34653556 epoch total loss 1.23354578
Trained batch 2025 batch loss 1.03388083 epoch total loss 1.23344731
Trained batch 2026 batch loss 0.990000248 epoch total loss 1.23332715
Trained batch 2027 batch loss 1.1991601 epoch total loss 1.23331022
Trained batch 2028 batch loss 1.174667 epoch total loss 1.23328125
Trained batch 2029 batch loss 1.17168188 epoch total loss 1.23325098
Trained batch 2030 batch loss 1.08993912 epoch total loss 1.23318028
Trained batch 2031 batch loss 1.10877812 epoch total loss 1.23311913
Trained batch 2032 batch loss 1.04267502 epoch total loss 1.23302543
Trained batch 2033 batch loss 1.14072931 epoch total loss 1.23297989
Trained batch 2034 batch loss 0.942879558 epoch total loss 1.23283732
Trained batch 2035 batch loss 1.39564395 epoch total loss 1.23291731
Trained batch 2036 batch loss 1.090698 epoch total loss 1.23284745
Trained batch 2037 batch loss 1.08093703 epoch total loss 1.23277295
Trained batch 2038 batch loss 1.04875481 epoch total loss 1.2326827
Trained batch 2039 batch loss 0.946179628 epoch total loss 1.23254216
Trained batch 2040 batch loss 1.08982873 epoch total loss 1.2324723
Trained batch 2041 batch loss 1.2569958 epoch total loss 1.23248434
Trained batch 2042 batch loss 1.27413487 epoch total loss 1.23250473
Trained batch 2043 batch loss 0.993869901 epoch total loss 1.2323879
Trained batch 2044 batch loss 1.10094547 epoch total loss 1.23232353
Trained batch 2045 batch loss 1.18245363 epoch total loss 1.23229909
Trained batch 2046 batch loss 0.872346 epoch total loss 1.23212326
Trained batch 2047 batch loss 1.20611095 epoch total loss 1.2321105
Trained batch 2048 batch loss 1.24722993 epoch total loss 1.23211789
Trained batch 2049 batch loss 1.40753257 epoch total loss 1.23220348
Trained batch 2050 batch loss 1.38380694 epoch total loss 1.23227739
Trained batch 2051 batch loss 1.72159135 epoch total loss 1.23251605
Trained batch 2052 batch loss 1.48491979 epoch total loss 1.23263896
Trained batch 2053 batch loss 1.48909807 epoch total loss 1.23276389
Trained batch 2054 batch loss 1.47879767 epoch total loss 1.23288369
Trained batch 2055 batch loss 1.23902345 epoch total loss 1.23288667
Trained batch 2056 batch loss 1.29366827 epoch total loss 1.23291624
Trained batch 2057 batch loss 1.30690789 epoch total loss 1.23295212
Trained batch 2058 batch loss 1.16142035 epoch total loss 1.23291743
Trained batch 2059 batch loss 1.03830743 epoch total loss 1.2328229
Trained batch 2060 batch loss 1.21405804 epoch total loss 1.23281384
Trained batch 2061 batch loss 1.37572956 epoch total loss 1.2328831
Trained batch 2062 batch loss 1.36049807 epoch total loss 1.23294508
Trained batch 2063 batch loss 1.24504375 epoch total loss 1.23295093
Trained batch 2064 batch loss 1.47639358 epoch total loss 1.23306894
Trained batch 2065 batch loss 1.42960346 epoch total loss 1.23316407
Trained batch 2066 batch loss 1.37360573 epoch total loss 1.23323202
Trained batch 2067 batch loss 1.28788173 epoch total loss 1.23325849
Trained batch 2068 batch loss 1.40493131 epoch total loss 1.23334157
Trained batch 2069 batch loss 1.36482608 epoch total loss 1.23340499
Trained batch 2070 batch loss 1.0528065 epoch total loss 1.23331773
Trained batch 2071 batch loss 1.43534636 epoch total loss 1.23341525
Trained batch 2072 batch loss 1.24024689 epoch total loss 1.23341858
Trained batch 2073 batch loss 1.28982973 epoch total loss 1.23344576
Trained batch 2074 batch loss 1.22815454 epoch total loss 1.23344326
Trained batch 2075 batch loss 1.36720371 epoch total loss 1.23350775
Trained batch 2076 batch loss 1.22554326 epoch total loss 1.23350394
Trained batch 2077 batch loss 1.23122692 epoch total loss 1.23350286
Trained batch 2078 batch loss 1.19579601 epoch total loss 1.23348463
Trained batch 2079 batch loss 1.0852232 epoch total loss 1.23341334
Trained batch 2080 batch loss 1.01245892 epoch total loss 1.23330712
Trained batch 2081 batch loss 0.976627111 epoch total loss 1.23318374
Trained batch 2082 batch loss 1.26002824 epoch total loss 1.23319662
Trained batch 2083 batch loss 1.28013062 epoch total loss 1.23321915
Trained batch 2084 batch loss 1.04491687 epoch total loss 1.23312879
Trained batch 2085 batch loss 1.24162006 epoch total loss 1.23313284
Trained batch 2086 batch loss 1.11785281 epoch total loss 1.23307765
Trained batch 2087 batch loss 1.11945724 epoch total loss 1.23302317
Trained batch 2088 batch loss 1.15591228 epoch total loss 1.23298633
Trained batch 2089 batch loss 1.50597632 epoch total loss 1.23311687
Trained batch 2090 batch loss 0.991419792 epoch total loss 1.23300123
Trained batch 2091 batch loss 1.03029335 epoch total loss 1.23290431
Trained batch 2092 batch loss 1.42556453 epoch total loss 1.23299634
Trained batch 2093 batch loss 1.39092422 epoch total loss 1.2330718
Trained batch 2094 batch loss 1.34520555 epoch total loss 1.23312533
Trained batch 2095 batch loss 1.36615205 epoch total loss 1.23318887
Trained batch 2096 batch loss 1.24817657 epoch total loss 1.23319614
Trained batch 2097 batch loss 1.0338378 epoch total loss 1.23310113
Trained batch 2098 batch loss 1.11136651 epoch total loss 1.23304307
Trained batch 2099 batch loss 1.01617289 epoch total loss 1.23293972
Trained batch 2100 batch loss 1.10796165 epoch total loss 1.23288012
Trained batch 2101 batch loss 1.00504816 epoch total loss 1.23277175
Trained batch 2102 batch loss 1.15416288 epoch total loss 1.23273432
Trained batch 2103 batch loss 1.16971493 epoch total loss 1.23270428
Trained batch 2104 batch loss 1.19621599 epoch total loss 1.232687
Trained batch 2105 batch loss 1.20961356 epoch total loss 1.23267615
Trained batch 2106 batch loss 1.01931739 epoch total loss 1.23257482
Trained batch 2107 batch loss 1.19651461 epoch total loss 1.23255765
Trained batch 2108 batch loss 1.15252817 epoch total loss 1.23251975
Trained batch 2109 batch loss 1.26697636 epoch total loss 1.23253608
Trained batch 2110 batch loss 1.18527019 epoch total loss 1.23251379
Trained batch 2111 batch loss 0.93234539 epoch total loss 1.23237157
Trained batch 2112 batch loss 1.24646044 epoch total loss 1.23237824
Trained batch 2113 batch loss 1.27904654 epoch total loss 1.23240042
Trained batch 2114 batch loss 1.16431904 epoch total loss 1.23236823
Trained batch 2115 batch loss 1.19999766 epoch total loss 1.23235285
Trained batch 2116 batch loss 1.10548806 epoch total loss 1.23229289
Trained batch 2117 batch loss 1.27863443 epoch total loss 1.23231471
Trained batch 2118 batch loss 1.18748796 epoch total loss 1.23229361
Trained batch 2119 batch loss 1.14213026 epoch total loss 1.23225105
Trained batch 2120 batch loss 1.10273576 epoch total loss 1.23218989
Trained batch 2121 batch loss 1.33325827 epoch total loss 1.23223758
Trained batch 2122 batch loss 1.14456415 epoch total loss 1.23219621
Trained batch 2123 batch loss 1.30208051 epoch total loss 1.23222911
Trained batch 2124 batch loss 1.1528877 epoch total loss 1.2321918
Trained batch 2125 batch loss 1.24607778 epoch total loss 1.23219836
Trained batch 2126 batch loss 1.52898431 epoch total loss 1.23233795
Trained batch 2127 batch loss 1.3060782 epoch total loss 1.23237264
Trained batch 2128 batch loss 1.09757185 epoch total loss 1.23230934
Trained batch 2129 batch loss 1.0624398 epoch total loss 1.23222959
Trained batch 2130 batch loss 0.975907445 epoch total loss 1.23210919
Trained batch 2131 batch loss 1.03142667 epoch total loss 1.23201501
Trained batch 2132 batch loss 1.41430521 epoch total loss 1.23210061
Trained batch 2133 batch loss 1.25165832 epoch total loss 1.23210979
Trained batch 2134 batch loss 1.34905338 epoch total loss 1.23216462
Trained batch 2135 batch loss 1.23176789 epoch total loss 1.23216438
Trained batch 2136 batch loss 1.28767717 epoch total loss 1.23219025
Trained batch 2137 batch loss 1.10064054 epoch total loss 1.23212874
Trained batch 2138 batch loss 1.36897671 epoch total loss 1.23219264
Trained batch 2139 batch loss 1.19440031 epoch total loss 1.23217499
Trained batch 2140 batch loss 0.943335 epoch total loss 1.23204
Trained batch 2141 batch loss 1.20851898 epoch total loss 1.23202908
Trained batch 2142 batch loss 1.22325635 epoch total loss 1.23202491
Trained batch 2143 batch loss 1.2965045 epoch total loss 1.23205495
Trained batch 2144 batch loss 1.08498597 epoch total loss 1.23198628
Trained batch 2145 batch loss 1.18947804 epoch total loss 1.2319665
Trained batch 2146 batch loss 1.37173235 epoch total loss 1.2320317
Trained batch 2147 batch loss 1.51643991 epoch total loss 1.23216414
Trained batch 2148 batch loss 1.4720242 epoch total loss 1.23227572
Trained batch 2149 batch loss 1.50082469 epoch total loss 1.23240066
Trained batch 2150 batch loss 1.19816566 epoch total loss 1.2323848
Trained batch 2151 batch loss 1.2674464 epoch total loss 1.23240101
Trained batch 2152 batch loss 0.911560893 epoch total loss 1.23225188
Trained batch 2153 batch loss 1.08264494 epoch total loss 1.2321825
Trained batch 2154 batch loss 1.14585543 epoch total loss 1.23214233
Trained batch 2155 batch loss 1.37611365 epoch total loss 1.23220921
Trained batch 2156 batch loss 1.3406899 epoch total loss 1.23225951
Trained batch 2157 batch loss 1.43625307 epoch total loss 1.23235404
Trained batch 2158 batch loss 1.14846325 epoch total loss 1.23231518
Trained batch 2159 batch loss 1.08800948 epoch total loss 1.23224831
Trained batch 2160 batch loss 0.992316365 epoch total loss 1.23213732
Trained batch 2161 batch loss 1.17768717 epoch total loss 1.23211205
Trained batch 2162 batch loss 1.18362284 epoch total loss 1.23208964
Trained batch 2163 batch loss 1.16529989 epoch total loss 1.23205876
Trained batch 2164 batch loss 1.15645671 epoch total loss 1.23202384
Trained batch 2165 batch loss 1.19567728 epoch total loss 1.23200703
Trained batch 2166 batch loss 1.25392509 epoch total loss 1.23201716
Trained batch 2167 batch loss 1.1636157 epoch total loss 1.23198557
Trained batch 2168 batch loss 1.38361883 epoch total loss 1.23205543
Trained batch 2169 batch loss 1.21265888 epoch total loss 1.23204648
Trained batch 2170 batch loss 1.35106206 epoch total loss 1.23210132
Trained batch 2171 batch loss 1.11655581 epoch total loss 1.23204803
Trained batch 2172 batch loss 1.28436315 epoch total loss 1.23207223
Trained batch 2173 batch loss 1.22895074 epoch total loss 1.2320708
Trained batch 2174 batch loss 1.22094762 epoch total loss 1.23206568
Trained batch 2175 batch loss 1.35967612 epoch total loss 1.23212433
Trained batch 2176 batch loss 1.33196378 epoch total loss 1.23217022
Trained batch 2177 batch loss 1.2463038 epoch total loss 1.23217678
Trained batch 2178 batch loss 1.18369555 epoch total loss 1.23215437
Trained batch 2179 batch loss 1.24393153 epoch total loss 1.23215985
Trained batch 2180 batch loss 1.10557246 epoch total loss 1.23210168
Trained batch 2181 batch loss 1.24484646 epoch total loss 1.23210752
Trained batch 2182 batch loss 1.1015029 epoch total loss 1.23204768
Trained batch 2183 batch loss 1.16137767 epoch total loss 1.23201537
Trained batch 2184 batch loss 1.14358592 epoch total loss 1.23197484
Trained batch 2185 batch loss 1.30863023 epoch total loss 1.23200989
Trained batch 2186 batch loss 1.2965374 epoch total loss 1.23203945
Trained batch 2187 batch loss 1.19852328 epoch total loss 1.23202407
Trained batch 2188 batch loss 1.3505199 epoch total loss 1.23207831
Trained batch 2189 batch loss 1.46381009 epoch total loss 1.23218417
Trained batch 2190 batch loss 1.38041782 epoch total loss 1.23225188
Trained batch 2191 batch loss 1.18388247 epoch total loss 1.23222983
Trained batch 2192 batch loss 0.986432731 epoch total loss 1.23211753
Trained batch 2193 batch loss 1.06249309 epoch total loss 1.23204029
Trained batch 2194 batch loss 1.05976903 epoch total loss 1.23196173
Trained batch 2195 batch loss 1.20897865 epoch total loss 1.23195124
Trained batch 2196 batch loss 1.39011323 epoch total loss 1.23202336
Trained batch 2197 batch loss 1.12555814 epoch total loss 1.23197484
Trained batch 2198 batch loss 1.24921882 epoch total loss 1.23198271
Trained batch 2199 batch loss 1.16640234 epoch total loss 1.23195291
Trained batch 2200 batch loss 1.17855179 epoch total loss 1.23192859
Trained batch 2201 batch loss 1.1511246 epoch total loss 1.23189187
Trained batch 2202 batch loss 1.37214184 epoch total loss 1.23195553
Trained batch 2203 batch loss 0.939614654 epoch total loss 1.23182285
Trained batch 2204 batch loss 1.20868325 epoch total loss 1.23181236
Trained batch 2205 batch loss 1.17987287 epoch total loss 1.23178887
Trained batch 2206 batch loss 1.1903199 epoch total loss 1.23177016
Trained batch 2207 batch loss 1.10210323 epoch total loss 1.23171139
Trained batch 2208 batch loss 1.13081157 epoch total loss 1.23166573
Trained batch 2209 batch loss 1.06867909 epoch total loss 1.23159182
Trained batch 2210 batch loss 1.09897685 epoch total loss 1.23153186
Trained batch 2211 batch loss 1.06118917 epoch total loss 1.23145485
Trained batch 2212 batch loss 1.24557805 epoch total loss 1.23146117
Trained batch 2213 batch loss 1.14044356 epoch total loss 1.23142
Trained batch 2214 batch loss 1.12541962 epoch total loss 1.23137224
Trained batch 2215 batch loss 1.16034746 epoch total loss 1.23134017
Trained batch 2216 batch loss 1.13985479 epoch total loss 1.23129892
Trained batch 2217 batch loss 1.08589292 epoch total loss 1.23123336
Trained batch 2218 batch loss 1.12107825 epoch total loss 1.23118365
Trained batch 2219 batch loss 1.29114377 epoch total loss 1.23121071
Trained batch 2220 batch loss 1.37810218 epoch total loss 1.23127699
Trained batch 2221 batch loss 1.42195606 epoch total loss 1.2313627
Trained batch 2222 batch loss 1.35758948 epoch total loss 1.23141956
Trained batch 2223 batch loss 1.45557499 epoch total loss 1.23152041
Trained batch 2224 batch loss 1.37575 epoch total loss 1.23158526
Trained batch 2225 batch loss 1.44090319 epoch total loss 1.23167932
Trained batch 2226 batch loss 1.55824327 epoch total loss 1.23182607
Trained batch 2227 batch loss 1.4944911 epoch total loss 1.23194396
Trained batch 2228 batch loss 1.4330833 epoch total loss 1.23203433
Trained batch 2229 batch loss 1.45056796 epoch total loss 1.23213243
Trained batch 2230 batch loss 1.21991241 epoch total loss 1.23212695
Trained batch 2231 batch loss 1.4079051 epoch total loss 1.23220575
Trained batch 2232 batch loss 1.35962069 epoch total loss 1.23226285
Trained batch 2233 batch loss 1.28752923 epoch total loss 1.23228765
Trained batch 2234 batch loss 1.42792082 epoch total loss 1.23237526
Trained batch 2235 batch loss 1.22925663 epoch total loss 1.23237383
Trained batch 2236 batch loss 1.53946829 epoch total loss 1.23251116
Trained batch 2237 batch loss 1.2590872 epoch total loss 1.23252308
Trained batch 2238 batch loss 1.09603763 epoch total loss 1.23246205
Trained batch 2239 batch loss 1.11293268 epoch total loss 1.23240864
Trained batch 2240 batch loss 1.15842962 epoch total loss 1.23237562
Trained batch 2241 batch loss 1.18525076 epoch total loss 1.23235464
Trained batch 2242 batch loss 0.965343952 epoch total loss 1.23223555
Trained batch 2243 batch loss 0.965762913 epoch total loss 1.23211682
Trained batch 2244 batch loss 1.02522659 epoch total loss 1.23202455
Trained batch 2245 batch loss 1.0448823 epoch total loss 1.23194122
Trained batch 2246 batch loss 0.933696747 epoch total loss 1.23180842
Trained batch 2247 batch loss 0.940800428 epoch total loss 1.23167896
Trained batch 2248 batch loss 0.906467199 epoch total loss 1.23153424
Trained batch 2249 batch loss 0.941836476 epoch total loss 1.2314055
Trained batch 2250 batch loss 0.824629068 epoch total loss 1.23122478
Trained batch 2251 batch loss 0.94956553 epoch total loss 1.23109961
Trained batch 2252 batch loss 1.00112915 epoch total loss 1.23099744
Trained batch 2253 batch loss 0.949809551 epoch total loss 1.23087263
Trained batch 2254 batch loss 1.01381695 epoch total loss 1.23077631
Trained batch 2255 batch loss 1.18854022 epoch total loss 1.23075759
Trained batch 2256 batch loss 1.30871356 epoch total loss 1.23079216
Trained batch 2257 batch loss 1.22883499 epoch total loss 1.23079121
Trained batch 2258 batch loss 1.40490723 epoch total loss 1.23086834
Trained batch 2259 batch loss 1.04842269 epoch total loss 1.23078752
Trained batch 2260 batch loss 1.06966889 epoch total loss 1.23071623
Trained batch 2261 batch loss 1.40441775 epoch total loss 1.230793
Trained batch 2262 batch loss 1.30012035 epoch total loss 1.23082364
Trained batch 2263 batch loss 1.50329852 epoch total loss 1.23094404
Trained batch 2264 batch loss 0.99182111 epoch total loss 1.23083842
Trained batch 2265 batch loss 1.30316329 epoch total loss 1.23087037
Trained batch 2266 batch loss 1.10422349 epoch total loss 1.23081446
Trained batch 2267 batch loss 1.09131968 epoch total loss 1.23075294
Trained batch 2268 batch loss 1.20190668 epoch total loss 1.23074019
Trained batch 2269 batch loss 1.02807295 epoch total loss 1.2306509
Trained batch 2270 batch loss 1.03250849 epoch total loss 1.23056364
Trained batch 2271 batch loss 0.890164077 epoch total loss 1.23041368
Trained batch 2272 batch loss 0.993804693 epoch total loss 1.23030961
Trained batch 2273 batch loss 0.974095106 epoch total loss 1.23019695
Trained batch 2274 batch loss 1.00231624 epoch total loss 1.23009658
Trained batch 2275 batch loss 1.04076076 epoch total loss 1.23001337
Trained batch 2276 batch loss 1.03903484 epoch total loss 1.22992957
Trained batch 2277 batch loss 1.09390175 epoch total loss 1.22986984
Trained batch 2278 batch loss 0.977006 epoch total loss 1.22975886
Trained batch 2279 batch loss 1.27313828 epoch total loss 1.22977793
Trained batch 2280 batch loss 1.67267537 epoch total loss 1.22997212
Trained batch 2281 batch loss 1.72762883 epoch total loss 1.23019028
Trained batch 2282 batch loss 1.50197577 epoch total loss 1.23030937
Trained batch 2283 batch loss 1.62971497 epoch total loss 1.23048425
Trained batch 2284 batch loss 1.40945792 epoch total loss 1.23056257
Trained batch 2285 batch loss 1.16507506 epoch total loss 1.23053396
Trained batch 2286 batch loss 1.28906178 epoch total loss 1.23055959
Trained batch 2287 batch loss 1.3870635 epoch total loss 1.23062789
Trained batch 2288 batch loss 1.06624365 epoch total loss 1.23055601
Trained batch 2289 batch loss 1.15535831 epoch total loss 1.23052311
Trained batch 2290 batch loss 1.17422855 epoch total loss 1.23049855
Trained batch 2291 batch loss 1.15854764 epoch total loss 1.2304672
Trained batch 2292 batch loss 1.24415648 epoch total loss 1.23047316
Trained batch 2293 batch loss 1.18151486 epoch total loss 1.2304517
Trained batch 2294 batch loss 0.962990046 epoch total loss 1.23033512
Trained batch 2295 batch loss 1.04515266 epoch total loss 1.23025441
Trained batch 2296 batch loss 1.26231623 epoch total loss 1.23026836
Trained batch 2297 batch loss 1.30174303 epoch total loss 1.23029947
Trained batch 2298 batch loss 1.42430222 epoch total loss 1.23038387
Trained batch 2299 batch loss 1.14749885 epoch total loss 1.23034775
Trained batch 2300 batch loss 1.09970427 epoch total loss 1.23029101
Trained batch 2301 batch loss 1.06332767 epoch total loss 1.23021829
Trained batch 2302 batch loss 1.05840659 epoch total loss 1.23014367
Trained batch 2303 batch loss 1.04262781 epoch total loss 1.23006237
Trained batch 2304 batch loss 1.19541597 epoch total loss 1.23004723
Trained batch 2305 batch loss 1.25523949 epoch total loss 1.23005807
Trained batch 2306 batch loss 1.12624848 epoch total loss 1.23001313
Trained batch 2307 batch loss 1.06852126 epoch total loss 1.22994316
Trained batch 2308 batch loss 1.201033 epoch total loss 1.22993052
Trained batch 2309 batch loss 1.12400055 epoch total loss 1.22988462
Trained batch 2310 batch loss 1.25718141 epoch total loss 1.22989643
Trained batch 2311 batch loss 1.13314557 epoch total loss 1.22985458
Trained batch 2312 batch loss 1.35166347 epoch total loss 1.22990716
Trained batch 2313 batch loss 1.309901 epoch total loss 1.22994173
Trained batch 2314 batch loss 1.24462438 epoch total loss 1.22994804
Trained batch 2315 batch loss 1.33989823 epoch total loss 1.22999561
Trained batch 2316 batch loss 1.23313868 epoch total loss 1.22999692
Trained batch 2317 batch loss 1.05518389 epoch total loss 1.22992146
Trained batch 2318 batch loss 1.25593948 epoch total loss 1.22993267
Trained batch 2319 batch loss 1.11751413 epoch total loss 1.22988415
Trained batch 2320 batch loss 1.37288833 epoch total loss 1.22994578
Trained batch 2321 batch loss 1.32377172 epoch total loss 1.22998619
Trained batch 2322 batch loss 1.13341367 epoch total loss 1.22994447
Trained batch 2323 batch loss 1.34004617 epoch total loss 1.22999191
Trained batch 2324 batch loss 1.16250634 epoch total loss 1.22996294
Trained batch 2325 batch loss 1.12537909 epoch total loss 1.229918
Trained batch 2326 batch loss 1.35475016 epoch total loss 1.22997165
Trained batch 2327 batch loss 1.30780458 epoch total loss 1.23000515
Trained batch 2328 batch loss 1.34675527 epoch total loss 1.23005521
Trained batch 2329 batch loss 1.036309 epoch total loss 1.22997212
Trained batch 2330 batch loss 1.06572247 epoch total loss 1.22990155
Trained batch 2331 batch loss 1.23249173 epoch total loss 1.22990263
Trained batch 2332 batch loss 0.973585963 epoch total loss 1.22979271
Trained batch 2333 batch loss 1.0097003 epoch total loss 1.22969842
Trained batch 2334 batch loss 1.10980129 epoch total loss 1.22964716
Trained batch 2335 batch loss 1.26980066 epoch total loss 1.22966433
Trained batch 2336 batch loss 1.21033871 epoch total loss 1.2296561
Trained batch 2337 batch loss 1.18030548 epoch total loss 1.229635
Trained batch 2338 batch loss 1.08944547 epoch total loss 1.22957504
Trained batch 2339 batch loss 1.17485619 epoch total loss 1.22955155
Trained batch 2340 batch loss 1.06770515 epoch total loss 1.22948241
Trained batch 2341 batch loss 1.29681468 epoch total loss 1.22951114
Trained batch 2342 batch loss 1.2347424 epoch total loss 1.22951341
Trained batch 2343 batch loss 1.0209868 epoch total loss 1.22942448
Trained batch 2344 batch loss 1.28690577 epoch total loss 1.22944891
Trained batch 2345 batch loss 1.20322835 epoch total loss 1.22943771
Trained batch 2346 batch loss 1.36790562 epoch total loss 1.22949672
Trained batch 2347 batch loss 1.27006388 epoch total loss 1.229514
Trained batch 2348 batch loss 1.08917236 epoch total loss 1.22945428
Trained batch 2349 batch loss 1.32386804 epoch total loss 1.22949445
Trained batch 2350 batch loss 1.26149619 epoch total loss 1.22950804
Trained batch 2351 batch loss 1.43857181 epoch total loss 1.22959697
Trained batch 2352 batch loss 1.38125443 epoch total loss 1.22966146
Trained batch 2353 batch loss 1.38470542 epoch total loss 1.22972739
Trained batch 2354 batch loss 1.10935616 epoch total loss 1.22967625
Trained batch 2355 batch loss 1.2779274 epoch total loss 1.22969675
Trained batch 2356 batch loss 1.07753408 epoch total loss 1.22963214
Trained batch 2357 batch loss 1.07911861 epoch total loss 1.22956836
Trained batch 2358 batch loss 1.05018926 epoch total loss 1.22949231
Trained batch 2359 batch loss 1.23538423 epoch total loss 1.22949481
Trained batch 2360 batch loss 1.20705533 epoch total loss 1.22948527
Trained batch 2361 batch loss 1.15369582 epoch total loss 1.22945321
Trained batch 2362 batch loss 1.17204523 epoch total loss 1.22942889
Trained batch 2363 batch loss 1.15607643 epoch total loss 1.22939789
Trained batch 2364 batch loss 1.11260855 epoch total loss 1.22934842
Trained batch 2365 batch loss 1.26210952 epoch total loss 1.22936237
Trained batch 2366 batch loss 1.20885313 epoch total loss 1.22935367
Trained batch 2367 batch loss 1.13586962 epoch total loss 1.22931421
Trained batch 2368 batch loss 1.12316942 epoch total loss 1.22926939
Trained batch 2369 batch loss 1.13301528 epoch total loss 1.22922873
Trained batch 2370 batch loss 0.971653581 epoch total loss 1.22912014
Trained batch 2371 batch loss 1.14393175 epoch total loss 1.22908425
Trained batch 2372 batch loss 1.05535483 epoch total loss 1.22901106
Trained batch 2373 batch loss 1.03571153 epoch total loss 1.22892952
Trained batch 2374 batch loss 1.14414239 epoch total loss 1.22889376
Trained batch 2375 batch loss 1.37006843 epoch total loss 1.22895324
Trained batch 2376 batch loss 1.21731818 epoch total loss 1.22894835
Trained batch 2377 batch loss 1.32484603 epoch total loss 1.22898865
Trained batch 2378 batch loss 1.38736367 epoch total loss 1.22905529
Trained batch 2379 batch loss 1.05451429 epoch total loss 1.22898197
Trained batch 2380 batch loss 1.19138575 epoch total loss 1.22896612
Trained batch 2381 batch loss 1.17258787 epoch total loss 1.22894251
Trained batch 2382 batch loss 1.35004854 epoch total loss 1.2289933
Trained batch 2383 batch loss 1.03002346 epoch total loss 1.22890985
Trained batch 2384 batch loss 1.03477168 epoch total loss 1.22882843
Trained batch 2385 batch loss 0.965459466 epoch total loss 1.22871804
Trained batch 2386 batch loss 1.3005507 epoch total loss 1.22874808
Trained batch 2387 batch loss 1.40200913 epoch total loss 1.22882068
Trained batch 2388 batch loss 1.18986392 epoch total loss 1.22880447
Trained batch 2389 batch loss 1.13660383 epoch total loss 1.22876585
Trained batch 2390 batch loss 1.1870805 epoch total loss 1.22874844
Trained batch 2391 batch loss 1.17711818 epoch total loss 1.22872674
Trained batch 2392 batch loss 1.23134899 epoch total loss 1.22872794
Trained batch 2393 batch loss 1.18168437 epoch total loss 1.22870827
Trained batch 2394 batch loss 1.17659712 epoch total loss 1.22868645
Trained batch 2395 batch loss 1.1571753 epoch total loss 1.22865665
Trained batch 2396 batch loss 1.01559377 epoch total loss 1.22856772
Trained batch 2397 batch loss 0.973285437 epoch total loss 1.22846127
Trained batch 2398 batch loss 1.12183976 epoch total loss 1.2284168
Trained batch 2399 batch loss 1.39897645 epoch total loss 1.22848785
Trained batch 2400 batch loss 1.19692123 epoch total loss 1.22847474
Trained batch 2401 batch loss 1.24289131 epoch total loss 1.2284807
Trained batch 2402 batch loss 1.09814453 epoch total loss 1.22842646
Trained batch 2403 batch loss 1.30784023 epoch total loss 1.2284596
Trained batch 2404 batch loss 1.22480643 epoch total loss 1.22845805
Trained batch 2405 batch loss 1.04896069 epoch total loss 1.22838342
Trained batch 2406 batch loss 1.24612927 epoch total loss 1.22839081
Trained batch 2407 batch loss 1.14069343 epoch total loss 1.22835433
Trained batch 2408 batch loss 1.41056776 epoch total loss 1.22843
Trained batch 2409 batch loss 1.06478596 epoch total loss 1.22836208
Trained batch 2410 batch loss 1.12603426 epoch total loss 1.22831964
Trained batch 2411 batch loss 0.932333529 epoch total loss 1.22819686
Trained batch 2412 batch loss 0.985035121 epoch total loss 1.22809613
Trained batch 2413 batch loss 1.37132907 epoch total loss 1.22815537
Trained batch 2414 batch loss 1.11162281 epoch total loss 1.22810709
Trained batch 2415 batch loss 1.21474695 epoch total loss 1.22810161
Trained batch 2416 batch loss 1.14317155 epoch total loss 1.22806644
Trained batch 2417 batch loss 1.2192862 epoch total loss 1.22806275
Trained batch 2418 batch loss 1.19368482 epoch total loss 1.22804856
Trained batch 2419 batch loss 1.20723903 epoch total loss 1.22804
Trained batch 2420 batch loss 0.895775497 epoch total loss 1.22790265
Trained batch 2421 batch loss 1.12604189 epoch total loss 1.22786057
Trained batch 2422 batch loss 1.27648067 epoch total loss 1.2278806
Trained batch 2423 batch loss 1.26331484 epoch total loss 1.22789526
Trained batch 2424 batch loss 1.09830153 epoch total loss 1.22784185
Trained batch 2425 batch loss 1.43371415 epoch total loss 1.22792661
Trained batch 2426 batch loss 1.37887907 epoch total loss 1.22798896
Trained batch 2427 batch loss 1.39985621 epoch total loss 1.22805977
Trained batch 2428 batch loss 1.23301244 epoch total loss 1.22806168
Trained batch 2429 batch loss 1.32115781 epoch total loss 1.22810006
Trained batch 2430 batch loss 1.20625055 epoch total loss 1.228091
Trained batch 2431 batch loss 1.29614067 epoch total loss 1.22811902
Trained batch 2432 batch loss 1.38240862 epoch total loss 1.22818244
Trained batch 2433 batch loss 1.21547699 epoch total loss 1.22817731
Trained batch 2434 batch loss 1.27824509 epoch total loss 1.22819781
Trained batch 2435 batch loss 1.32416725 epoch total loss 1.22823727
Trained batch 2436 batch loss 1.33611131 epoch total loss 1.22828162
Trained batch 2437 batch loss 1.26059556 epoch total loss 1.22829485
Trained batch 2438 batch loss 1.26594353 epoch total loss 1.22831023
Trained batch 2439 batch loss 1.22089434 epoch total loss 1.22830725
Trained batch 2440 batch loss 1.25245082 epoch total loss 1.22831714
Trained batch 2441 batch loss 1.22353363 epoch total loss 1.22831523
Trained batch 2442 batch loss 1.16714132 epoch total loss 1.2282902
Trained batch 2443 batch loss 1.24919081 epoch total loss 1.22829878
Trained batch 2444 batch loss 1.47256732 epoch total loss 1.2283988
Trained batch 2445 batch loss 1.33752 epoch total loss 1.22844338
Trained batch 2446 batch loss 1.40859437 epoch total loss 1.22851706
Trained batch 2447 batch loss 1.19530761 epoch total loss 1.22850347
Trained batch 2448 batch loss 1.08012462 epoch total loss 1.22844279
Trained batch 2449 batch loss 1.09190059 epoch total loss 1.228387
Trained batch 2450 batch loss 1.08554769 epoch total loss 1.2283287
Trained batch 2451 batch loss 1.06787086 epoch total loss 1.22826326
Trained batch 2452 batch loss 0.990512133 epoch total loss 1.22816622
Trained batch 2453 batch loss 1.10766912 epoch total loss 1.22811711
Trained batch 2454 batch loss 0.994746089 epoch total loss 1.22802198
Trained batch 2455 batch loss 0.927803397 epoch total loss 1.22789967
Trained batch 2456 batch loss 1.03316975 epoch total loss 1.2278204
Trained batch 2457 batch loss 1.07189822 epoch total loss 1.22775686
Trained batch 2458 batch loss 1.10426283 epoch total loss 1.22770667
Trained batch 2459 batch loss 1.45450211 epoch total loss 1.22779894
Trained batch 2460 batch loss 1.33246303 epoch total loss 1.2278415
Trained batch 2461 batch loss 1.40631115 epoch total loss 1.22791398
Trained batch 2462 batch loss 1.23061228 epoch total loss 1.22791505
Trained batch 2463 batch loss 1.42180169 epoch total loss 1.22799385
Trained batch 2464 batch loss 1.39734077 epoch total loss 1.22806263
Trained batch 2465 batch loss 1.11850405 epoch total loss 1.22801816
Trained batch 2466 batch loss 1.36862588 epoch total loss 1.22807515
Trained batch 2467 batch loss 1.46990144 epoch total loss 1.22817326
Trained batch 2468 batch loss 1.48601854 epoch total loss 1.22827768
Trained batch 2469 batch loss 1.46374714 epoch total loss 1.22837317
Trained batch 2470 batch loss 1.45816457 epoch total loss 1.22846615
Trained batch 2471 batch loss 1.24936163 epoch total loss 1.22847462
Trained batch 2472 batch loss 1.17245245 epoch total loss 1.22845197
Trained batch 2473 batch loss 1.41988206 epoch total loss 1.22852933
Trained batch 2474 batch loss 1.48378801 epoch total loss 1.22863257
Trained batch 2475 batch loss 1.51182699 epoch total loss 1.22874689
Trained batch 2476 batch loss 1.40554523 epoch total loss 1.2288183
Trained batch 2477 batch loss 1.45601368 epoch total loss 1.22891009
Trained batch 2478 batch loss 1.19295621 epoch total loss 1.22889555
Trained batch 2479 batch loss 1.3893981 epoch total loss 1.22896028
Trained batch 2480 batch loss 1.09246612 epoch total loss 1.22890532
Trained batch 2481 batch loss 1.51263499 epoch total loss 1.22901964
Trained batch 2482 batch loss 1.28072906 epoch total loss 1.2290405
Trained batch 2483 batch loss 1.1903069 epoch total loss 1.22902489
Trained batch 2484 batch loss 1.35672069 epoch total loss 1.22907627
Trained batch 2485 batch loss 1.2871747 epoch total loss 1.22909963
Trained batch 2486 batch loss 1.34266734 epoch total loss 1.22914529
Trained batch 2487 batch loss 1.30639482 epoch total loss 1.2291764
Trained batch 2488 batch loss 1.31169486 epoch total loss 1.22920954
Trained batch 2489 batch loss 1.22746325 epoch total loss 1.22920895
Trained batch 2490 batch loss 1.17419553 epoch total loss 1.22918689
Trained batch 2491 batch loss 1.2240448 epoch total loss 1.22918487
Trained batch 2492 batch loss 1.42783165 epoch total loss 1.2292645
Trained batch 2493 batch loss 1.21736383 epoch total loss 1.22925973
Trained batch 2494 batch loss 1.31344557 epoch total loss 1.22929347
Trained batch 2495 batch loss 1.33911753 epoch total loss 1.22933745
Trained batch 2496 batch loss 1.26509213 epoch total loss 1.22935188
Trained batch 2497 batch loss 1.34826136 epoch total loss 1.22939944
Trained batch 2498 batch loss 1.21917343 epoch total loss 1.22939539
Trained batch 2499 batch loss 1.38140368 epoch total loss 1.22945619
Trained batch 2500 batch loss 1.17188931 epoch total loss 1.22943306
Trained batch 2501 batch loss 1.2617501 epoch total loss 1.22944605
Trained batch 2502 batch loss 1.5609597 epoch total loss 1.2295785
Trained batch 2503 batch loss 1.36157703 epoch total loss 1.2296313
Trained batch 2504 batch loss 1.43328178 epoch total loss 1.22971261
Trained batch 2505 batch loss 1.24787164 epoch total loss 1.22971988
Trained batch 2506 batch loss 1.34540224 epoch total loss 1.22976601
Trained batch 2507 batch loss 1.40524483 epoch total loss 1.22983611
Trained batch 2508 batch loss 1.38712883 epoch total loss 1.22989881
Trained batch 2509 batch loss 1.21014404 epoch total loss 1.22989094
Trained batch 2510 batch loss 1.22663879 epoch total loss 1.22988963
Trained batch 2511 batch loss 1.11160922 epoch total loss 1.22984254
Trained batch 2512 batch loss 1.2161634 epoch total loss 1.22983706
Trained batch 2513 batch loss 1.33013666 epoch total loss 1.22987688
Trained batch 2514 batch loss 1.30837727 epoch total loss 1.22990811
Trained batch 2515 batch loss 1.27644014 epoch total loss 1.22992659
Trained batch 2516 batch loss 1.19302201 epoch total loss 1.22991192
Trained batch 2517 batch loss 1.33076084 epoch total loss 1.2299521
Trained batch 2518 batch loss 1.34493279 epoch total loss 1.22999775
Trained batch 2519 batch loss 1.34920084 epoch total loss 1.23004496
Trained batch 2520 batch loss 1.45003629 epoch total loss 1.23013222
Trained batch 2521 batch loss 1.40416765 epoch total loss 1.23020124
Trained batch 2522 batch loss 1.36525095 epoch total loss 1.23025477
Trained batch 2523 batch loss 1.03387916 epoch total loss 1.23017704
Trained batch 2524 batch loss 1.30722845 epoch total loss 1.23020744
Trained batch 2525 batch loss 1.19185579 epoch total loss 1.2301923
Trained batch 2526 batch loss 1.42967772 epoch total loss 1.23027134
Trained batch 2527 batch loss 1.36783326 epoch total loss 1.23032582
Trained batch 2528 batch loss 1.1445961 epoch total loss 1.23029184
Trained batch 2529 batch loss 1.21340656 epoch total loss 1.23028517
Trained batch 2530 batch loss 1.12668848 epoch total loss 1.23024416
Trained batch 2531 batch loss 1.35519171 epoch total loss 1.23029363
Trained batch 2532 batch loss 1.24709988 epoch total loss 1.23030019
Trained batch 2533 batch loss 1.23601377 epoch total loss 1.23030245
Trained batch 2534 batch loss 1.40352845 epoch total loss 1.23037088
Trained batch 2535 batch loss 1.25324249 epoch total loss 1.23037982
Trained batch 2536 batch loss 1.3664521 epoch total loss 1.23043346
Trained batch 2537 batch loss 1.31662738 epoch total loss 1.23046756
Trained batch 2538 batch loss 1.35102975 epoch total loss 1.230515
Trained batch 2539 batch loss 1.355093 epoch total loss 1.230564
Trained batch 2540 batch loss 1.20752788 epoch total loss 1.23055494
Trained batch 2541 batch loss 1.19477093 epoch total loss 1.23054087
Trained batch 2542 batch loss 1.1372503 epoch total loss 1.23050416
Trained batch 2543 batch loss 1.04367793 epoch total loss 1.23043072
Trained batch 2544 batch loss 1.1200633 epoch total loss 1.23038733
Trained batch 2545 batch loss 1.26026869 epoch total loss 1.23039913
Trained batch 2546 batch loss 1.21694601 epoch total loss 1.23039389
Trained batch 2547 batch loss 1.21980298 epoch total loss 1.23038971
Trained batch 2548 batch loss 1.24062502 epoch total loss 1.23039377
Trained batch 2549 batch loss 1.43680549 epoch total loss 1.23047471
Trained batch 2550 batch loss 0.943673432 epoch total loss 1.23036218
Trained batch 2551 batch loss 0.985211909 epoch total loss 1.23026609
Trained batch 2552 batch loss 1.06363046 epoch total loss 1.23020077
Trained batch 2553 batch loss 0.940510869 epoch total loss 1.23008728
Trained batch 2554 batch loss 0.906959414 epoch total loss 1.2299608
Trained batch 2555 batch loss 0.995388389 epoch total loss 1.22986901
Trained batch 2556 batch loss 1.39414132 epoch total loss 1.22993314
Trained batch 2557 batch loss 0.965884328 epoch total loss 1.22982991
Trained batch 2558 batch loss 0.94811213 epoch total loss 1.22971976
Trained batch 2559 batch loss 0.931975126 epoch total loss 1.22960329
Trained batch 2560 batch loss 1.10318172 epoch total loss 1.22955394
Trained batch 2561 batch loss 0.915442586 epoch total loss 1.22943139
Trained batch 2562 batch loss 1.15450454 epoch total loss 1.22940218
Trained batch 2563 batch loss 1.16879964 epoch total loss 1.22937846
Trained batch 2564 batch loss 1.14820051 epoch total loss 1.22934675
Trained batch 2565 batch loss 1.31212473 epoch total loss 1.22937906
Trained batch 2566 batch loss 1.00371957 epoch total loss 1.22929108
Trained batch 2567 batch loss 0.966455102 epoch total loss 1.22918868
Trained batch 2568 batch loss 0.956302 epoch total loss 1.22908247
Trained batch 2569 batch loss 0.778915286 epoch total loss 1.22890711
Trained batch 2570 batch loss 1.03069508 epoch total loss 1.2288301
Trained batch 2571 batch loss 0.827685416 epoch total loss 1.22867405
Trained batch 2572 batch loss 0.847681403 epoch total loss 1.22852588
Trained batch 2573 batch loss 0.852043271 epoch total loss 1.22837961
Trained batch 2574 batch loss 0.908632457 epoch total loss 1.22825539
Trained batch 2575 batch loss 0.978175402 epoch total loss 1.22815824
Trained batch 2576 batch loss 0.995884299 epoch total loss 1.22806811
Trained batch 2577 batch loss 1.09523273 epoch total loss 1.2280165
Trained batch 2578 batch loss 0.856001496 epoch total loss 1.22787225
Trained batch 2579 batch loss 0.844531894 epoch total loss 1.2277236
Trained batch 2580 batch loss 0.7562868 epoch total loss 1.22754085
Trained batch 2581 batch loss 1.07810879 epoch total loss 1.22748291
Trained batch 2582 batch loss 1.22135401 epoch total loss 1.22748065
Trained batch 2583 batch loss 1.19815207 epoch total loss 1.22746933
Trained batch 2584 batch loss 1.205585 epoch total loss 1.22746086
Trained batch 2585 batch loss 1.2869401 epoch total loss 1.22748387
Trained batch 2586 batch loss 1.33590627 epoch total loss 1.22752571
Trained batch 2587 batch loss 1.2101984 epoch total loss 1.22751904
Trained batch 2588 batch loss 1.27721596 epoch total loss 1.22753823
Trained batch 2589 batch loss 1.01502848 epoch total loss 1.22745621
Trained batch 2590 batch loss 1.11003935 epoch total loss 1.22741091
Trained batch 2591 batch loss 1.22897315 epoch total loss 1.22741151
Trained batch 2592 batch loss 1.25181723 epoch total loss 1.22742081
Trained batch 2593 batch loss 1.27391374 epoch total loss 1.22743881
Trained batch 2594 batch loss 1.07961631 epoch total loss 1.22738183
Trained batch 2595 batch loss 1.32409894 epoch total loss 1.22741914
Trained batch 2596 batch loss 1.28880334 epoch total loss 1.22744274
Trained batch 2597 batch loss 1.26886201 epoch total loss 1.22745872
Trained batch 2598 batch loss 0.962352753 epoch total loss 1.22735667
Trained batch 2599 batch loss 1.11175418 epoch total loss 1.22731221
Trained batch 2600 batch loss 1.07536471 epoch total loss 1.22725379
Trained batch 2601 batch loss 1.23827863 epoch total loss 1.22725809
Trained batch 2602 batch loss 1.48760509 epoch total loss 1.2273581
Trained batch 2603 batch loss 1.00146198 epoch total loss 1.22727132
Trained batch 2604 batch loss 1.06759179 epoch total loss 1.22720993
Trained batch 2605 batch loss 0.787249207 epoch total loss 1.22704113
Trained batch 2606 batch loss 0.865703464 epoch total loss 1.22690248
Trained batch 2607 batch loss 1.05398285 epoch total loss 1.22683609
Trained batch 2608 batch loss 1.04596376 epoch total loss 1.22676671
Trained batch 2609 batch loss 0.950961947 epoch total loss 1.22666109
Trained batch 2610 batch loss 1.2490555 epoch total loss 1.22666955
Trained batch 2611 batch loss 1.4181335 epoch total loss 1.22674298
Trained batch 2612 batch loss 1.55467486 epoch total loss 1.22686851
Trained batch 2613 batch loss 1.46106839 epoch total loss 1.22695816
Trained batch 2614 batch loss 1.43289161 epoch total loss 1.22703695
Trained batch 2615 batch loss 1.32967925 epoch total loss 1.22707617
Trained batch 2616 batch loss 1.36859977 epoch total loss 1.22713029
Trained batch 2617 batch loss 1.16820467 epoch total loss 1.22710776
Trained batch 2618 batch loss 1.24971342 epoch total loss 1.22711647
Trained batch 2619 batch loss 1.36667323 epoch total loss 1.22716975
Trained batch 2620 batch loss 1.4473772 epoch total loss 1.22725368
Trained batch 2621 batch loss 1.24435246 epoch total loss 1.22726023
Trained batch 2622 batch loss 1.21494377 epoch total loss 1.22725558
Trained batch 2623 batch loss 1.31306446 epoch total loss 1.22728825
Trained batch 2624 batch loss 1.39794207 epoch total loss 1.22735322
Trained batch 2625 batch loss 1.40370131 epoch total loss 1.22742045
Trained batch 2626 batch loss 1.30727029 epoch total loss 1.22745097
Trained batch 2627 batch loss 1.40722644 epoch total loss 1.22751939
Trained batch 2628 batch loss 1.29956639 epoch total loss 1.22754681
Trained batch 2629 batch loss 1.32576561 epoch total loss 1.22758412
Trained batch 2630 batch loss 1.24642265 epoch total loss 1.22759128
Trained batch 2631 batch loss 1.25609982 epoch total loss 1.22760212
Trained batch 2632 batch loss 1.19053948 epoch total loss 1.22758794
Trained batch 2633 batch loss 1.17773283 epoch total loss 1.22756898
Trained batch 2634 batch loss 1.07518315 epoch total loss 1.22751117
Trained batch 2635 batch loss 1.10324299 epoch total loss 1.22746396
Trained batch 2636 batch loss 1.07821012 epoch total loss 1.22740734
Trained batch 2637 batch loss 1.09021103 epoch total loss 1.22735536
Trained batch 2638 batch loss 0.96777308 epoch total loss 1.22725701
Trained batch 2639 batch loss 1.14457524 epoch total loss 1.22722566
Trained batch 2640 batch loss 1.10403275 epoch total loss 1.22717893
Trained batch 2641 batch loss 1.14263678 epoch total loss 1.22714686
Trained batch 2642 batch loss 1.22899795 epoch total loss 1.22714758
Trained batch 2643 batch loss 1.21871543 epoch total loss 1.22714448
Trained batch 2644 batch loss 1.07858181 epoch total loss 1.22708821
Trained batch 2645 batch loss 1.37156892 epoch total loss 1.22714293
Trained batch 2646 batch loss 1.40084779 epoch total loss 1.22720861
Trained batch 2647 batch loss 1.28976953 epoch total loss 1.22723222
Trained batch 2648 batch loss 1.00348699 epoch total loss 1.2271477
Trained batch 2649 batch loss 1.12895203 epoch total loss 1.22711062
Trained batch 2650 batch loss 1.09358 epoch total loss 1.2270602
Trained batch 2651 batch loss 1.33469081 epoch total loss 1.22710073
Trained batch 2652 batch loss 1.19613087 epoch total loss 1.22708905
Trained batch 2653 batch loss 1.27749157 epoch total loss 1.22710812
Trained batch 2654 batch loss 1.40561461 epoch total loss 1.22717535
Trained batch 2655 batch loss 1.38018918 epoch total loss 1.22723293
Trained batch 2656 batch loss 1.2923727 epoch total loss 1.22725749
Trained batch 2657 batch loss 1.40496397 epoch total loss 1.22732437
Trained batch 2658 batch loss 1.47115707 epoch total loss 1.22741616
Trained batch 2659 batch loss 1.22804964 epoch total loss 1.2274164
Trained batch 2660 batch loss 1.20254803 epoch total loss 1.2274071
Trained batch 2661 batch loss 1.38816047 epoch total loss 1.22746754
Trained batch 2662 batch loss 1.08576167 epoch total loss 1.22741425
Trained batch 2663 batch loss 1.16538322 epoch total loss 1.22739089
Trained batch 2664 batch loss 1.4451797 epoch total loss 1.22747266
Trained batch 2665 batch loss 1.29047632 epoch total loss 1.22749627
Trained batch 2666 batch loss 1.40884805 epoch total loss 1.22756433
Trained batch 2667 batch loss 1.2561636 epoch total loss 1.22757506
Trained batch 2668 batch loss 1.30290711 epoch total loss 1.22760332
Trained batch 2669 batch loss 1.12112367 epoch total loss 1.22756338
Trained batch 2670 batch loss 1.411515 epoch total loss 1.22763228
Trained batch 2671 batch loss 1.51874113 epoch total loss 1.22774136
Trained batch 2672 batch loss 1.4282527 epoch total loss 1.22781634
Trained batch 2673 batch loss 1.47096837 epoch total loss 1.2279073
Trained batch 2674 batch loss 1.44069481 epoch total loss 1.22798693
Trained batch 2675 batch loss 1.42237437 epoch total loss 1.22805953
Trained batch 2676 batch loss 1.31668043 epoch total loss 1.22809267
Trained batch 2677 batch loss 1.25489235 epoch total loss 1.22810268
Trained batch 2678 batch loss 1.32163656 epoch total loss 1.22813761
Trained batch 2679 batch loss 1.29193258 epoch total loss 1.22816145
Trained batch 2680 batch loss 1.26012051 epoch total loss 1.22817326
Trained batch 2681 batch loss 1.36401653 epoch total loss 1.22822392
Trained batch 2682 batch loss 1.44094193 epoch total loss 1.22830319
Trained batch 2683 batch loss 1.45602918 epoch total loss 1.22838819
Trained batch 2684 batch loss 1.44655454 epoch total loss 1.22846937
Trained batch 2685 batch loss 1.38288319 epoch total loss 1.22852695
Trained batch 2686 batch loss 1.20662498 epoch total loss 1.22851872
Trained batch 2687 batch loss 1.27318466 epoch total loss 1.22853529
Trained batch 2688 batch loss 1.26113343 epoch total loss 1.22854745
Trained batch 2689 batch loss 1.41094828 epoch total loss 1.22861528
Trained batch 2690 batch loss 1.25002587 epoch total loss 1.22862327
Trained batch 2691 batch loss 1.07318544 epoch total loss 1.22856557
Trained batch 2692 batch loss 1.27681255 epoch total loss 1.22858346
Trained batch 2693 batch loss 1.16550052 epoch total loss 1.22856009
Trained batch 2694 batch loss 0.99145633 epoch total loss 1.22847199
Trained batch 2695 batch loss 1.21912777 epoch total loss 1.22846866
Trained batch 2696 batch loss 1.23581088 epoch total loss 1.2284714
Trained batch 2697 batch loss 1.09875453 epoch total loss 1.22842324
Trained batch 2698 batch loss 1.05925393 epoch total loss 1.22836053
Trained batch 2699 batch loss 1.18387783 epoch total loss 1.22834408
Trained batch 2700 batch loss 1.30822897 epoch total loss 1.22837365
Trained batch 2701 batch loss 1.20473266 epoch total loss 1.22836494
Trained batch 2702 batch loss 1.09080637 epoch total loss 1.22831404
Trained batch 2703 batch loss 1.23183858 epoch total loss 1.22831535
Trained batch 2704 batch loss 1.08524573 epoch total loss 1.22826242
Trained batch 2705 batch loss 1.03379333 epoch total loss 1.22819054
Trained batch 2706 batch loss 0.873182893 epoch total loss 1.22805941
Trained batch 2707 batch loss 1.25136137 epoch total loss 1.22806799
Trained batch 2708 batch loss 1.20334351 epoch total loss 1.22805893
Trained batch 2709 batch loss 1.30664182 epoch total loss 1.2280879
Trained batch 2710 batch loss 0.999832571 epoch total loss 1.22800362
Trained batch 2711 batch loss 0.996647716 epoch total loss 1.22791827
Trained batch 2712 batch loss 1.24037385 epoch total loss 1.22792292
Trained batch 2713 batch loss 1.39651418 epoch total loss 1.22798502
Trained batch 2714 batch loss 1.11880195 epoch total loss 1.22794485
Trained batch 2715 batch loss 1.24862862 epoch total loss 1.22795248
Trained batch 2716 batch loss 1.14017701 epoch total loss 1.22792
Trained batch 2717 batch loss 1.06396985 epoch total loss 1.22785974
Trained batch 2718 batch loss 1.14152956 epoch total loss 1.22782803
Trained batch 2719 batch loss 1.10656118 epoch total loss 1.22778344
Trained batch 2720 batch loss 1.0284574 epoch total loss 1.22771013
Trained batch 2721 batch loss 1.13276875 epoch total loss 1.22767532
Trained batch 2722 batch loss 1.02574039 epoch total loss 1.22760105
Trained batch 2723 batch loss 1.27751231 epoch total loss 1.22761941
Trained batch 2724 batch loss 1.31624472 epoch total loss 1.22765195
Trained batch 2725 batch loss 1.23108351 epoch total loss 1.22765315
Trained batch 2726 batch loss 1.22945619 epoch total loss 1.22765386
Trained batch 2727 batch loss 1.10714221 epoch total loss 1.22760975
Trained batch 2728 batch loss 1.06605864 epoch total loss 1.22755051
Trained batch 2729 batch loss 0.925193191 epoch total loss 1.22743976
Trained batch 2730 batch loss 1.24010921 epoch total loss 1.22744441
Trained batch 2731 batch loss 1.08877695 epoch total loss 1.22739363
Trained batch 2732 batch loss 1.13758564 epoch total loss 1.22736073
Trained batch 2733 batch loss 1.02189255 epoch total loss 1.22728562
Trained batch 2734 batch loss 1.12116611 epoch total loss 1.22724676
Trained batch 2735 batch loss 1.0620482 epoch total loss 1.22718632
Trained batch 2736 batch loss 1.2188673 epoch total loss 1.22718334
Trained batch 2737 batch loss 1.16277456 epoch total loss 1.22715974
Trained batch 2738 batch loss 0.985266209 epoch total loss 1.22707152
Trained batch 2739 batch loss 1.03386128 epoch total loss 1.22700095
Trained batch 2740 batch loss 1.01112008 epoch total loss 1.22692215
Trained batch 2741 batch loss 1.04567409 epoch total loss 1.22685611
Trained batch 2742 batch loss 1.14219809 epoch total loss 1.22682512
Trained batch 2743 batch loss 1.05856991 epoch total loss 1.22676384
Trained batch 2744 batch loss 1.29058695 epoch total loss 1.22678709
Trained batch 2745 batch loss 1.19800842 epoch total loss 1.2267766
Trained batch 2746 batch loss 1.247015 epoch total loss 1.22678399
Trained batch 2747 batch loss 1.35889769 epoch total loss 1.22683203
Trained batch 2748 batch loss 1.24803257 epoch total loss 1.22683978
Trained batch 2749 batch loss 1.19129395 epoch total loss 1.22682691
Trained batch 2750 batch loss 1.24478245 epoch total loss 1.22683346
Trained batch 2751 batch loss 1.26920533 epoch total loss 1.22684884
Trained batch 2752 batch loss 1.13173604 epoch total loss 1.22681439
Trained batch 2753 batch loss 1.08320272 epoch total loss 1.22676218
Trained batch 2754 batch loss 1.01688457 epoch total loss 1.226686
Trained batch 2755 batch loss 1.20478261 epoch total loss 1.22667801
Trained batch 2756 batch loss 1.11761117 epoch total loss 1.22663856
Trained batch 2757 batch loss 1.24113309 epoch total loss 1.2266438
Trained batch 2758 batch loss 1.21953797 epoch total loss 1.22664118
Trained batch 2759 batch loss 1.39243948 epoch total loss 1.22670126
Trained batch 2760 batch loss 1.32242453 epoch total loss 1.22673595
Trained batch 2761 batch loss 1.25445259 epoch total loss 1.22674596
Trained batch 2762 batch loss 1.30660403 epoch total loss 1.22677493
Trained batch 2763 batch loss 1.26582193 epoch total loss 1.226789
Trained batch 2764 batch loss 1.44096959 epoch total loss 1.22686648
Trained batch 2765 batch loss 1.15161169 epoch total loss 1.2268393
Trained batch 2766 batch loss 1.28439295 epoch total loss 1.22686017
Trained batch 2767 batch loss 1.41302145 epoch total loss 1.2269274
Trained batch 2768 batch loss 1.23639011 epoch total loss 1.22693086
Trained batch 2769 batch loss 1.32807493 epoch total loss 1.22696733
Trained batch 2770 batch loss 1.26625943 epoch total loss 1.22698164
Trained batch 2771 batch loss 1.34043825 epoch total loss 1.22702253
Trained batch 2772 batch loss 1.19724131 epoch total loss 1.2270118
Trained batch 2773 batch loss 1.33309221 epoch total loss 1.22705
Trained batch 2774 batch loss 1.33522987 epoch total loss 1.22708893
Trained batch 2775 batch loss 1.20781291 epoch total loss 1.22708201
Trained batch 2776 batch loss 1.3152051 epoch total loss 1.22711372
Trained batch 2777 batch loss 1.34043181 epoch total loss 1.22715449
Trained batch 2778 batch loss 1.17505968 epoch total loss 1.22713578
Trained batch 2779 batch loss 1.20661056 epoch total loss 1.22712839
Trained batch 2780 batch loss 1.00369489 epoch total loss 1.22704792
Trained batch 2781 batch loss 1.30053353 epoch total loss 1.22707438
Trained batch 2782 batch loss 1.18579912 epoch total loss 1.2270596
Trained batch 2783 batch loss 1.05810404 epoch total loss 1.22699881
Trained batch 2784 batch loss 1.0640924 epoch total loss 1.22694039
Trained batch 2785 batch loss 1.15270281 epoch total loss 1.22691369
Trained batch 2786 batch loss 1.24594831 epoch total loss 1.22692049
Trained batch 2787 batch loss 1.25851047 epoch total loss 1.22693181
Trained batch 2788 batch loss 1.18113303 epoch total loss 1.22691536
Trained batch 2789 batch loss 1.09663558 epoch total loss 1.22686875
Trained batch 2790 batch loss 1.20005751 epoch total loss 1.22685909
Trained batch 2791 batch loss 1.16739869 epoch total loss 1.22683775
Trained batch 2792 batch loss 1.26108754 epoch total loss 1.22685
Trained batch 2793 batch loss 1.21087837 epoch total loss 1.22684431
Trained batch 2794 batch loss 1.1403029 epoch total loss 1.22681332
Trained batch 2795 batch loss 1.06555247 epoch total loss 1.22675574
Trained batch 2796 batch loss 1.14774084 epoch total loss 1.22672749
Trained batch 2797 batch loss 1.03032494 epoch total loss 1.22665715
Trained batch 2798 batch loss 0.943946 epoch total loss 1.22655618
Trained batch 2799 batch loss 1.04380107 epoch total loss 1.22649086
Trained batch 2800 batch loss 1.25837755 epoch total loss 1.22650218
Trained batch 2801 batch loss 1.22504 epoch total loss 1.2265017
Trained batch 2802 batch loss 1.52980399 epoch total loss 1.22661
Trained batch 2803 batch loss 1.27812529 epoch total loss 1.2266283
Trained batch 2804 batch loss 1.19080746 epoch total loss 1.22661555
Trained batch 2805 batch loss 1.03260696 epoch total loss 1.22654641
Trained batch 2806 batch loss 1.26043689 epoch total loss 1.22655845
Trained batch 2807 batch loss 1.02651989 epoch total loss 1.22648728
Trained batch 2808 batch loss 1.09766173 epoch total loss 1.22644138
Trained batch 2809 batch loss 1.04583716 epoch total loss 1.22637713
Trained batch 2810 batch loss 1.28064 epoch total loss 1.22639644
Trained batch 2811 batch loss 1.15420914 epoch total loss 1.22637081
Trained batch 2812 batch loss 1.05072474 epoch total loss 1.22630835
Trained batch 2813 batch loss 0.872658372 epoch total loss 1.22618258
Trained batch 2814 batch loss 0.991636634 epoch total loss 1.22609925
Trained batch 2815 batch loss 0.861315787 epoch total loss 1.22596967
Trained batch 2816 batch loss 0.689019501 epoch total loss 1.22577906
Trained batch 2817 batch loss 1.06368756 epoch total loss 1.22572148
Trained batch 2818 batch loss 0.832793474 epoch total loss 1.225582
Trained batch 2819 batch loss 1.03478432 epoch total loss 1.22551429
Trained batch 2820 batch loss 1.035429 epoch total loss 1.22544694
Trained batch 2821 batch loss 1.2852931 epoch total loss 1.22546816
Trained batch 2822 batch loss 1.42868829 epoch total loss 1.22554016
Trained batch 2823 batch loss 1.3195765 epoch total loss 1.22557354
Trained batch 2824 batch loss 1.49522913 epoch total loss 1.22566891
Trained batch 2825 batch loss 1.43871486 epoch total loss 1.22574437
Trained batch 2826 batch loss 1.31002712 epoch total loss 1.22577417
Trained batch 2827 batch loss 1.16993308 epoch total loss 1.22575438
Trained batch 2828 batch loss 1.14019775 epoch total loss 1.2257241
Trained batch 2829 batch loss 1.18410146 epoch total loss 1.22570944
Trained batch 2830 batch loss 1.13267219 epoch total loss 1.22567654
Trained batch 2831 batch loss 1.19890606 epoch total loss 1.22566712
Trained batch 2832 batch loss 1.28825188 epoch total loss 1.22568917
Trained batch 2833 batch loss 1.14610076 epoch total loss 1.22566104
Trained batch 2834 batch loss 1.30026436 epoch total loss 1.22568738
Trained batch 2835 batch loss 1.06087244 epoch total loss 1.22562921
Trained batch 2836 batch loss 1.14008021 epoch total loss 1.22559905
Trained batch 2837 batch loss 1.19921112 epoch total loss 1.22558975
Trained batch 2838 batch loss 1.21112251 epoch total loss 1.22558475
Trained batch 2839 batch loss 1.25832009 epoch total loss 1.22559631
Trained batch 2840 batch loss 1.11032677 epoch total loss 1.22555566
Trained batch 2841 batch loss 1.04093385 epoch total loss 1.22549069
Trained batch 2842 batch loss 1.09964907 epoch total loss 1.22544646
Trained batch 2843 batch loss 1.04532552 epoch total loss 1.22538304
Trained batch 2844 batch loss 0.916350245 epoch total loss 1.22527444
Trained batch 2845 batch loss 1.03299761 epoch total loss 1.22520685
Trained batch 2846 batch loss 1.08246207 epoch total loss 1.22515666
Trained batch 2847 batch loss 1.10999119 epoch total loss 1.22511625
Trained batch 2848 batch loss 1.01488638 epoch total loss 1.22504246
Trained batch 2849 batch loss 1.13087153 epoch total loss 1.22500944
Trained batch 2850 batch loss 1.20667076 epoch total loss 1.225003
Trained batch 2851 batch loss 1.07820797 epoch total loss 1.22495151
Trained batch 2852 batch loss 1.13487422 epoch total loss 1.22491992
Trained batch 2853 batch loss 1.14250016 epoch total loss 1.22489095
Trained batch 2854 batch loss 1.17981076 epoch total loss 1.22487521
Trained batch 2855 batch loss 1.20842528 epoch total loss 1.22486949
Trained batch 2856 batch loss 1.33657825 epoch total loss 1.22490871
Trained batch 2857 batch loss 1.13449526 epoch total loss 1.224877
Trained batch 2858 batch loss 1.34474325 epoch total loss 1.22491896
Trained batch 2859 batch loss 1.20355725 epoch total loss 1.22491145
Trained batch 2860 batch loss 1.17593122 epoch total loss 1.2248944
Trained batch 2861 batch loss 1.12387359 epoch total loss 1.22485912
Trained batch 2862 batch loss 1.3657999 epoch total loss 1.22490823
Trained batch 2863 batch loss 1.1123364 epoch total loss 1.22486889
Trained batch 2864 batch loss 1.1092205 epoch total loss 1.22482848
Trained batch 2865 batch loss 1.12345433 epoch total loss 1.2247932
Trained batch 2866 batch loss 1.04029465 epoch total loss 1.22472882
Trained batch 2867 batch loss 1.12925851 epoch total loss 1.22469544
Trained batch 2868 batch loss 1.17570651 epoch total loss 1.2246784
Trained batch 2869 batch loss 0.943088233 epoch total loss 1.22458029
Trained batch 2870 batch loss 0.939721227 epoch total loss 1.22448099
Trained batch 2871 batch loss 1.20407867 epoch total loss 1.22447395
Trained batch 2872 batch loss 1.1413728 epoch total loss 1.22444499
Trained batch 2873 batch loss 1.3272059 epoch total loss 1.22448075
Trained batch 2874 batch loss 1.20605397 epoch total loss 1.22447431
Trained batch 2875 batch loss 1.38634706 epoch total loss 1.22453058
Trained batch 2876 batch loss 1.09278822 epoch total loss 1.2244848
Trained batch 2877 batch loss 1.50523591 epoch total loss 1.22458231
Trained batch 2878 batch loss 1.32091188 epoch total loss 1.22461569
Trained batch 2879 batch loss 1.23865962 epoch total loss 1.2246207
Trained batch 2880 batch loss 1.15782273 epoch total loss 1.22459745
Trained batch 2881 batch loss 0.994443536 epoch total loss 1.22451746
Trained batch 2882 batch loss 1.22969949 epoch total loss 1.22451937
Trained batch 2883 batch loss 1.36959529 epoch total loss 1.22456968
Trained batch 2884 batch loss 1.0691433 epoch total loss 1.2245158
Trained batch 2885 batch loss 1.45420086 epoch total loss 1.22459531
Trained batch 2886 batch loss 1.12350392 epoch total loss 1.22456026
Trained batch 2887 batch loss 1.17173016 epoch total loss 1.22454202
Trained batch 2888 batch loss 0.982266605 epoch total loss 1.2244581
Trained batch 2889 batch loss 1.56605327 epoch total loss 1.22457635
Trained batch 2890 batch loss 1.00368059 epoch total loss 1.2245
Trained batch 2891 batch loss 1.27916753 epoch total loss 1.22451878
Trained batch 2892 batch loss 0.965708077 epoch total loss 1.22442925
Trained batch 2893 batch loss 1.06680119 epoch total loss 1.22437489
Trained batch 2894 batch loss 0.984858811 epoch total loss 1.22429204
Trained batch 2895 batch loss 1.2633884 epoch total loss 1.22430563
Trained batch 2896 batch loss 1.21585965 epoch total loss 1.22430265
Trained batch 2897 batch loss 1.35420275 epoch total loss 1.22434759
Trained batch 2898 batch loss 1.20166 epoch total loss 1.22433972
Trained batch 2899 batch loss 1.24266481 epoch total loss 1.22434604
Trained batch 2900 batch loss 1.1602093 epoch total loss 1.22432387
Trained batch 2901 batch loss 1.25969803 epoch total loss 1.22433615
Trained batch 2902 batch loss 1.39474821 epoch total loss 1.2243948
Trained batch 2903 batch loss 1.2368027 epoch total loss 1.22439909
Trained batch 2904 batch loss 1.13996518 epoch total loss 1.22437
Trained batch 2905 batch loss 1.16615331 epoch total loss 1.22435
Trained batch 2906 batch loss 1.02874649 epoch total loss 1.22428274
Trained batch 2907 batch loss 1.16525304 epoch total loss 1.22426248
Trained batch 2908 batch loss 1.21393228 epoch total loss 1.2242589
Trained batch 2909 batch loss 0.903620183 epoch total loss 1.22414863
Trained batch 2910 batch loss 1.13503039 epoch total loss 1.22411799
Trained batch 2911 batch loss 1.12309027 epoch total loss 1.2240833
Trained batch 2912 batch loss 1.08975649 epoch total loss 1.22403717
Trained batch 2913 batch loss 1.11193061 epoch total loss 1.22399867
Trained batch 2914 batch loss 1.00442648 epoch total loss 1.22392333
Trained batch 2915 batch loss 1.36650491 epoch total loss 1.2239722
Trained batch 2916 batch loss 1.20008719 epoch total loss 1.22396398
Trained batch 2917 batch loss 1.37112296 epoch total loss 1.22401452
Trained batch 2918 batch loss 1.18594384 epoch total loss 1.22400141
Trained batch 2919 batch loss 0.989169836 epoch total loss 1.22392106
Trained batch 2920 batch loss 1.52687013 epoch total loss 1.22402477
Trained batch 2921 batch loss 1.26190329 epoch total loss 1.22403777
Trained batch 2922 batch loss 1.25771248 epoch total loss 1.22404933
Trained batch 2923 batch loss 1.33597076 epoch total loss 1.2240876
Trained batch 2924 batch loss 1.27113175 epoch total loss 1.22410369
Trained batch 2925 batch loss 1.14233804 epoch total loss 1.22407579
Trained batch 2926 batch loss 1.3545078 epoch total loss 1.22412038
Trained batch 2927 batch loss 1.19074297 epoch total loss 1.22410893
Trained batch 2928 batch loss 1.20836091 epoch total loss 1.22410345
Trained batch 2929 batch loss 1.25465775 epoch total loss 1.22411394
Trained batch 2930 batch loss 1.20209217 epoch total loss 1.22410643
Trained batch 2931 batch loss 1.14461899 epoch total loss 1.22407925
Trained batch 2932 batch loss 1.12001133 epoch total loss 1.22404385
Trained batch 2933 batch loss 0.922049105 epoch total loss 1.22394085
Trained batch 2934 batch loss 0.966711283 epoch total loss 1.22385323
Trained batch 2935 batch loss 0.998250365 epoch total loss 1.22377634
Trained batch 2936 batch loss 1.12677646 epoch total loss 1.22374332
Trained batch 2937 batch loss 0.944427609 epoch total loss 1.22364819
Trained batch 2938 batch loss 0.997596741 epoch total loss 1.22357118
Trained batch 2939 batch loss 1.01729679 epoch total loss 1.22350109
Trained batch 2940 batch loss 0.919610798 epoch total loss 1.22339773
Trained batch 2941 batch loss 0.988566697 epoch total loss 1.22331786
Trained batch 2942 batch loss 0.9392308 epoch total loss 1.2232213
Trained batch 2943 batch loss 0.962408841 epoch total loss 1.22313261
Trained batch 2944 batch loss 0.952099919 epoch total loss 1.22304058
Trained batch 2945 batch loss 0.905905902 epoch total loss 1.22293293
Trained batch 2946 batch loss 1.21019781 epoch total loss 1.22292864
Trained batch 2947 batch loss 1.11285079 epoch total loss 1.22289133
Trained batch 2948 batch loss 1.16335845 epoch total loss 1.22287107
Trained batch 2949 batch loss 1.06455529 epoch total loss 1.2228173
Trained batch 2950 batch loss 1.00741923 epoch total loss 1.22274435
Trained batch 2951 batch loss 0.935866594 epoch total loss 1.22264707
Trained batch 2952 batch loss 0.952830374 epoch total loss 1.22255564
Trained batch 2953 batch loss 0.919871628 epoch total loss 1.22245324
Trained batch 2954 batch loss 0.873509049 epoch total loss 1.2223351
Trained batch 2955 batch loss 0.928006291 epoch total loss 1.22223544
Trained batch 2956 batch loss 0.877727509 epoch total loss 1.22211885
Trained batch 2957 batch loss 1.19335747 epoch total loss 1.2221092
Trained batch 2958 batch loss 1.18403912 epoch total loss 1.22209632
Trained batch 2959 batch loss 1.23990571 epoch total loss 1.2221024
Trained batch 2960 batch loss 1.21599817 epoch total loss 1.22210038
Trained batch 2961 batch loss 1.30052376 epoch total loss 1.22212684
Trained batch 2962 batch loss 1.428509 epoch total loss 1.22219646
Trained batch 2963 batch loss 1.3787148 epoch total loss 1.22224927
Trained batch 2964 batch loss 1.42358387 epoch total loss 1.22231722
Trained batch 2965 batch loss 1.37309325 epoch total loss 1.222368
Trained batch 2966 batch loss 1.18785381 epoch total loss 1.22235644
Trained batch 2967 batch loss 1.11760831 epoch total loss 1.22232115
Trained batch 2968 batch loss 1.4345634 epoch total loss 1.22239256
Trained batch 2969 batch loss 1.16187382 epoch total loss 1.22237217
Trained batch 2970 batch loss 1.39113879 epoch total loss 1.22242904
Trained batch 2971 batch loss 1.4245249 epoch total loss 1.22249711
Trained batch 2972 batch loss 1.15217912 epoch total loss 1.22247338
Trained batch 2973 batch loss 1.20557678 epoch total loss 1.22246766
Trained batch 2974 batch loss 1.27696657 epoch total loss 1.22248602
Trained batch 2975 batch loss 1.11517215 epoch total loss 1.2224499
Trained batch 2976 batch loss 1.42682564 epoch total loss 1.22251856
Trained batch 2977 batch loss 1.53022134 epoch total loss 1.22262192
Trained batch 2978 batch loss 1.66891026 epoch total loss 1.22277188
Trained batch 2979 batch loss 1.32635963 epoch total loss 1.22280669
Trained batch 2980 batch loss 1.20449686 epoch total loss 1.22280049
Trained batch 2981 batch loss 1.30194902 epoch total loss 1.22282708
Trained batch 2982 batch loss 1.34020853 epoch total loss 1.22286642
Trained batch 2983 batch loss 1.21429098 epoch total loss 1.22286355
Trained batch 2984 batch loss 1.35856926 epoch total loss 1.22290909
Trained batch 2985 batch loss 1.10083103 epoch total loss 1.2228682
Trained batch 2986 batch loss 1.21408296 epoch total loss 1.22286522
Trained batch 2987 batch loss 1.30232573 epoch total loss 1.22289181
Trained batch 2988 batch loss 1.22253406 epoch total loss 1.22289169
Trained batch 2989 batch loss 1.49955082 epoch total loss 1.22298419
Trained batch 2990 batch loss 1.37589455 epoch total loss 1.22303534
Trained batch 2991 batch loss 1.35582304 epoch total loss 1.22307968
Trained batch 2992 batch loss 1.4423517 epoch total loss 1.223153
Trained batch 2993 batch loss 1.4269731 epoch total loss 1.22322118
Trained batch 2994 batch loss 1.27783084 epoch total loss 1.22323942
Trained batch 2995 batch loss 1.11035466 epoch total loss 1.22320163
Trained batch 2996 batch loss 1.36698222 epoch total loss 1.22324967
Trained batch 2997 batch loss 1.23529446 epoch total loss 1.22325373
Trained batch 2998 batch loss 1.24857724 epoch total loss 1.22326207
Trained batch 2999 batch loss 1.27153718 epoch total loss 1.22327816
Trained batch 3000 batch loss 1.04240859 epoch total loss 1.22321796
Trained batch 3001 batch loss 1.05227602 epoch total loss 1.22316098
Trained batch 3002 batch loss 1.11719251 epoch total loss 1.2231257
Trained batch 3003 batch loss 1.06238937 epoch total loss 1.22307217
Trained batch 3004 batch loss 1.12815213 epoch total loss 1.22304058
Trained batch 3005 batch loss 1.26453507 epoch total loss 1.22305441
Trained batch 3006 batch loss 0.893450141 epoch total loss 1.22294486
Trained batch 3007 batch loss 1.13377821 epoch total loss 1.22291517
Trained batch 3008 batch loss 0.7669276 epoch total loss 1.22276354
Trained batch 3009 batch loss 0.86436367 epoch total loss 1.22264445
Trained batch 3010 batch loss 0.92224896 epoch total loss 1.22254467
Trained batch 3011 batch loss 0.975116491 epoch total loss 1.22246242
Trained batch 3012 batch loss 1.11756206 epoch total loss 1.22242773
Trained batch 3013 batch loss 1.1548723 epoch total loss 1.2224052
Trained batch 3014 batch loss 1.12939286 epoch total loss 1.22237432
Trained batch 3015 batch loss 1.15525365 epoch total loss 1.22235215
Trained batch 3016 batch loss 1.28533316 epoch total loss 1.22237301
Trained batch 3017 batch loss 1.46639299 epoch total loss 1.22245383
Trained batch 3018 batch loss 1.23722291 epoch total loss 1.22245884
Trained batch 3019 batch loss 1.28865838 epoch total loss 1.22248065
Trained batch 3020 batch loss 1.20934343 epoch total loss 1.22247624
Trained batch 3021 batch loss 1.19240618 epoch total loss 1.22246635
Trained batch 3022 batch loss 1.25876951 epoch total loss 1.22247839
Trained batch 3023 batch loss 1.33787298 epoch total loss 1.22251654
Trained batch 3024 batch loss 1.17959034 epoch total loss 1.22250235
Trained batch 3025 batch loss 1.32797468 epoch total loss 1.22253716
Trained batch 3026 batch loss 1.35703278 epoch total loss 1.22258162
Trained batch 3027 batch loss 0.998590589 epoch total loss 1.2225076
Trained batch 3028 batch loss 1.28075337 epoch total loss 1.22252679
Trained batch 3029 batch loss 1.47883487 epoch total loss 1.22261143
Trained batch 3030 batch loss 1.48240876 epoch total loss 1.22269714
Trained batch 3031 batch loss 1.36175203 epoch total loss 1.22274303
Trained batch 3032 batch loss 1.25526023 epoch total loss 1.22275388
Trained batch 3033 batch loss 1.2522856 epoch total loss 1.22276354
Trained batch 3034 batch loss 1.23005128 epoch total loss 1.22276592
Trained batch 3035 batch loss 1.1158725 epoch total loss 1.22273076
Trained batch 3036 batch loss 1.14238453 epoch total loss 1.22270429
Trained batch 3037 batch loss 1.20640659 epoch total loss 1.22269881
Trained batch 3038 batch loss 1.17419839 epoch total loss 1.22268295
Trained batch 3039 batch loss 1.11421525 epoch total loss 1.22264731
Trained batch 3040 batch loss 1.17573512 epoch total loss 1.22263181
Trained batch 3041 batch loss 1.2047832 epoch total loss 1.22262597
Trained batch 3042 batch loss 1.12722826 epoch total loss 1.22259462
Trained batch 3043 batch loss 1.1063211 epoch total loss 1.22255635
Trained batch 3044 batch loss 1.19830608 epoch total loss 1.22254837
Trained batch 3045 batch loss 1.22222614 epoch total loss 1.22254825
Trained batch 3046 batch loss 0.986919045 epoch total loss 1.22247088
Trained batch 3047 batch loss 0.86377883 epoch total loss 1.2223531
Trained batch 3048 batch loss 1.04084146 epoch total loss 1.22229362
Trained batch 3049 batch loss 0.804700136 epoch total loss 1.22215664
Trained batch 3050 batch loss 0.910012722 epoch total loss 1.22205424
Trained batch 3051 batch loss 0.969397962 epoch total loss 1.22197139
Trained batch 3052 batch loss 1.00990391 epoch total loss 1.22190201
Trained batch 3053 batch loss 1.1030097 epoch total loss 1.22186303
Trained batch 3054 batch loss 1.09671259 epoch total loss 1.22182202
Trained batch 3055 batch loss 1.10354221 epoch total loss 1.22178328
Trained batch 3056 batch loss 1.3736794 epoch total loss 1.22183311
Trained batch 3057 batch loss 1.2941227 epoch total loss 1.22185671
Trained batch 3058 batch loss 1.15781856 epoch total loss 1.22183573
Trained batch 3059 batch loss 1.25480151 epoch total loss 1.22184658
Trained batch 3060 batch loss 1.25338531 epoch total loss 1.22185683
Trained batch 3061 batch loss 1.01142752 epoch total loss 1.22178817
Trained batch 3062 batch loss 1.41685557 epoch total loss 1.22185183
Trained batch 3063 batch loss 1.29445398 epoch total loss 1.22187555
Trained batch 3064 batch loss 1.09216511 epoch total loss 1.22183323
Trained batch 3065 batch loss 1.09755135 epoch total loss 1.2217927
Trained batch 3066 batch loss 1.33304906 epoch total loss 1.22182894
Trained batch 3067 batch loss 1.3912406 epoch total loss 1.22188425
Trained batch 3068 batch loss 1.12176037 epoch total loss 1.22185171
Trained batch 3069 batch loss 1.18990088 epoch total loss 1.22184122
Trained batch 3070 batch loss 1.3798697 epoch total loss 1.22189271
Trained batch 3071 batch loss 1.36832213 epoch total loss 1.2219404
Trained batch 3072 batch loss 1.41650724 epoch total loss 1.22200382
Trained batch 3073 batch loss 1.30966675 epoch total loss 1.22203231
Trained batch 3074 batch loss 1.43136525 epoch total loss 1.22210038
Trained batch 3075 batch loss 1.09251094 epoch total loss 1.2220583
Trained batch 3076 batch loss 1.28047442 epoch total loss 1.22207725
Trained batch 3077 batch loss 1.29567468 epoch total loss 1.22210121
Trained batch 3078 batch loss 1.10496533 epoch total loss 1.22206306
Trained batch 3079 batch loss 1.23453951 epoch total loss 1.22206724
Trained batch 3080 batch loss 1.16541636 epoch total loss 1.22204888
Trained batch 3081 batch loss 1.23004854 epoch total loss 1.22205138
Trained batch 3082 batch loss 1.12825334 epoch total loss 1.22202098
Trained batch 3083 batch loss 1.13912773 epoch total loss 1.22199404
Trained batch 3084 batch loss 1.15394413 epoch total loss 1.22197199
Trained batch 3085 batch loss 1.18029785 epoch total loss 1.22195852
Trained batch 3086 batch loss 1.19551849 epoch total loss 1.22195
Trained batch 3087 batch loss 1.21699 epoch total loss 1.22194839
Trained batch 3088 batch loss 1.24620843 epoch total loss 1.22195625
Trained batch 3089 batch loss 1.08129907 epoch total loss 1.22191072
Trained batch 3090 batch loss 1.28762555 epoch total loss 1.22193193
Trained batch 3091 batch loss 1.24314356 epoch total loss 1.22193885
Trained batch 3092 batch loss 1.4159565 epoch total loss 1.22200155
Trained batch 3093 batch loss 1.25058651 epoch total loss 1.22201085
Trained batch 3094 batch loss 1.35520709 epoch total loss 1.22205389
Trained batch 3095 batch loss 1.3170073 epoch total loss 1.22208452
Trained batch 3096 batch loss 0.766693473 epoch total loss 1.22193742
Trained batch 3097 batch loss 0.959553 epoch total loss 1.22185266
Trained batch 3098 batch loss 0.993030131 epoch total loss 1.22177875
Trained batch 3099 batch loss 0.895112038 epoch total loss 1.22167325
Trained batch 3100 batch loss 0.742657542 epoch total loss 1.22151875
Trained batch 3101 batch loss 0.874350309 epoch total loss 1.22140682
Trained batch 3102 batch loss 0.916296184 epoch total loss 1.22130847
Trained batch 3103 batch loss 0.813138366 epoch total loss 1.22117698
Trained batch 3104 batch loss 0.970438242 epoch total loss 1.22109616
Trained batch 3105 batch loss 0.979525 epoch total loss 1.22101831
Trained batch 3106 batch loss 1.174541 epoch total loss 1.22100341
Trained batch 3107 batch loss 1.14821339 epoch total loss 1.22097993
Trained batch 3108 batch loss 1.33197379 epoch total loss 1.22101569
Trained batch 3109 batch loss 1.23784161 epoch total loss 1.22102106
Trained batch 3110 batch loss 1.31231737 epoch total loss 1.22105038
Trained batch 3111 batch loss 1.2667594 epoch total loss 1.22106516
Trained batch 3112 batch loss 1.47465527 epoch total loss 1.22114658
Trained batch 3113 batch loss 1.44610548 epoch total loss 1.22121882
Trained batch 3114 batch loss 1.27707732 epoch total loss 1.22123682
Trained batch 3115 batch loss 1.39692211 epoch total loss 1.22129321
Trained batch 3116 batch loss 1.35413253 epoch total loss 1.22133589
Trained batch 3117 batch loss 1.3877666 epoch total loss 1.22138929
Trained batch 3118 batch loss 1.41957855 epoch total loss 1.22145283
Trained batch 3119 batch loss 1.37623298 epoch total loss 1.22150242
Trained batch 3120 batch loss 1.38561225 epoch total loss 1.22155499
Trained batch 3121 batch loss 1.375247 epoch total loss 1.22160423
Trained batch 3122 batch loss 1.32404459 epoch total loss 1.22163701
Trained batch 3123 batch loss 1.33330774 epoch total loss 1.22167277
Trained batch 3124 batch loss 1.28212976 epoch total loss 1.2216922
Trained batch 3125 batch loss 1.4321183 epoch total loss 1.22175956
Trained batch 3126 batch loss 1.35195553 epoch total loss 1.22180116
Trained batch 3127 batch loss 1.37299979 epoch total loss 1.22184956
Trained batch 3128 batch loss 1.39347863 epoch total loss 1.22190452
Trained batch 3129 batch loss 1.05442929 epoch total loss 1.22185099
Trained batch 3130 batch loss 1.30296779 epoch total loss 1.22187686
Trained batch 3131 batch loss 1.18137074 epoch total loss 1.22186399
Trained batch 3132 batch loss 1.05873847 epoch total loss 1.22181189
Trained batch 3133 batch loss 1.30984151 epoch total loss 1.22184
Trained batch 3134 batch loss 1.32271624 epoch total loss 1.22187221
Trained batch 3135 batch loss 1.31658447 epoch total loss 1.22190237
Trained batch 3136 batch loss 1.28437591 epoch total loss 1.2219224
Trained batch 3137 batch loss 1.12900865 epoch total loss 1.22189271
Trained batch 3138 batch loss 1.52335644 epoch total loss 1.2219888
Trained batch 3139 batch loss 1.12105274 epoch total loss 1.22195661
Trained batch 3140 batch loss 1.32906151 epoch total loss 1.22199082
Trained batch 3141 batch loss 1.13757396 epoch total loss 1.22196388
Trained batch 3142 batch loss 1.3271836 epoch total loss 1.22199738
Trained batch 3143 batch loss 1.17700386 epoch total loss 1.22198308
Trained batch 3144 batch loss 0.986518383 epoch total loss 1.22190821
Trained batch 3145 batch loss 1.00584269 epoch total loss 1.22183955
Trained batch 3146 batch loss 1.06834197 epoch total loss 1.22179079
Trained batch 3147 batch loss 1.04325891 epoch total loss 1.22173405
Trained batch 3148 batch loss 0.960312366 epoch total loss 1.22165096
Trained batch 3149 batch loss 1.28819609 epoch total loss 1.22167206
Trained batch 3150 batch loss 1.21691597 epoch total loss 1.22167051
Trained batch 3151 batch loss 1.28787529 epoch total loss 1.22169149
Trained batch 3152 batch loss 1.34665561 epoch total loss 1.22173107
Trained batch 3153 batch loss 1.00933576 epoch total loss 1.22166371
Trained batch 3154 batch loss 1.12488747 epoch total loss 1.22163308
Trained batch 3155 batch loss 1.38264453 epoch total loss 1.2216841
Trained batch 3156 batch loss 1.26383233 epoch total loss 1.22169745
Trained batch 3157 batch loss 1.21496916 epoch total loss 1.22169542
Trained batch 3158 batch loss 1.38833797 epoch total loss 1.22174823
Trained batch 3159 batch loss 1.05974483 epoch total loss 1.22169697
Trained batch 3160 batch loss 1.06547952 epoch total loss 1.2216475
Trained batch 3161 batch loss 1.25059962 epoch total loss 1.22165656
Trained batch 3162 batch loss 1.0465548 epoch total loss 1.22160125
Trained batch 3163 batch loss 1.3349793 epoch total loss 1.22163713
Trained batch 3164 batch loss 0.857943773 epoch total loss 1.22152209
Trained batch 3165 batch loss 1.18493533 epoch total loss 1.22151053
Trained batch 3166 batch loss 1.2616936 epoch total loss 1.22152317
Trained batch 3167 batch loss 1.35574603 epoch total loss 1.2215656
Trained batch 3168 batch loss 1.29991591 epoch total loss 1.22159028
Trained batch 3169 batch loss 1.16103899 epoch total loss 1.22157121
Trained batch 3170 batch loss 1.43910027 epoch total loss 1.22163987
Trained batch 3171 batch loss 1.23664176 epoch total loss 1.22164452
Trained batch 3172 batch loss 1.17381227 epoch total loss 1.2216295
Trained batch 3173 batch loss 1.23877144 epoch total loss 1.22163486
Trained batch 3174 batch loss 1.12055647 epoch total loss 1.22160304
Trained batch 3175 batch loss 1.07819319 epoch total loss 1.22155786
Trained batch 3176 batch loss 0.931234717 epoch total loss 1.22146642
Trained batch 3177 batch loss 1.08423066 epoch total loss 1.22142327
Trained batch 3178 batch loss 1.1477381 epoch total loss 1.2214
Trained batch 3179 batch loss 1.17029595 epoch total loss 1.22138405
Trained batch 3180 batch loss 1.23776019 epoch total loss 1.22138917
Trained batch 3181 batch loss 1.34254634 epoch total loss 1.2214272
Trained batch 3182 batch loss 1.26976883 epoch total loss 1.22144246
Trained batch 3183 batch loss 1.13877106 epoch total loss 1.22141647
Trained batch 3184 batch loss 1.35455275 epoch total loss 1.2214582
Trained batch 3185 batch loss 1.24829149 epoch total loss 1.22146666
Trained batch 3186 batch loss 1.35489047 epoch total loss 1.22150862
Trained batch 3187 batch loss 1.31079912 epoch total loss 1.22153664
Trained batch 3188 batch loss 0.991379201 epoch total loss 1.2214644
Trained batch 3189 batch loss 1.24837255 epoch total loss 1.22147286
Trained batch 3190 batch loss 1.30486691 epoch total loss 1.22149897
Trained batch 3191 batch loss 1.0850817 epoch total loss 1.22145617
Trained batch 3192 batch loss 1.38723278 epoch total loss 1.22150815
Trained batch 3193 batch loss 1.16023314 epoch total loss 1.22148895
Trained batch 3194 batch loss 1.29165351 epoch total loss 1.22151089
Trained batch 3195 batch loss 1.28337312 epoch total loss 1.22153032
Trained batch 3196 batch loss 1.27618277 epoch total loss 1.22154737
Trained batch 3197 batch loss 1.09329462 epoch total loss 1.22150731
Trained batch 3198 batch loss 1.15169096 epoch total loss 1.22148538
Trained batch 3199 batch loss 1.00197315 epoch total loss 1.22141683
Trained batch 3200 batch loss 0.958470285 epoch total loss 1.22133458
Trained batch 3201 batch loss 1.01600862 epoch total loss 1.22127044
Trained batch 3202 batch loss 0.865592599 epoch total loss 1.22115934
Trained batch 3203 batch loss 1.04778636 epoch total loss 1.22110522
Trained batch 3204 batch loss 1.39332342 epoch total loss 1.22115898
Trained batch 3205 batch loss 1.35281372 epoch total loss 1.22120011
Trained batch 3206 batch loss 1.38085926 epoch total loss 1.22124994
Trained batch 3207 batch loss 1.23981595 epoch total loss 1.22125566
Trained batch 3208 batch loss 1.26912653 epoch total loss 1.22127056
Trained batch 3209 batch loss 1.33541358 epoch total loss 1.22130609
Trained batch 3210 batch loss 1.27592468 epoch total loss 1.22132313
Trained batch 3211 batch loss 1.30791831 epoch total loss 1.22135007
Trained batch 3212 batch loss 1.30234778 epoch total loss 1.22137523
Trained batch 3213 batch loss 1.21401131 epoch total loss 1.22137296
Trained batch 3214 batch loss 1.19727945 epoch total loss 1.22136545
Trained batch 3215 batch loss 0.980991423 epoch total loss 1.22129071
Trained batch 3216 batch loss 1.14629173 epoch total loss 1.22126734
Trained batch 3217 batch loss 1.17923069 epoch total loss 1.22125435
Trained batch 3218 batch loss 1.18822241 epoch total loss 1.2212441
Trained batch 3219 batch loss 1.15373182 epoch total loss 1.22122312
Trained batch 3220 batch loss 1.36300325 epoch total loss 1.2212671
Trained batch 3221 batch loss 1.04936743 epoch total loss 1.22121382
Trained batch 3222 batch loss 1.55193973 epoch total loss 1.22131646
Trained batch 3223 batch loss 1.11880839 epoch total loss 1.22128463
Trained batch 3224 batch loss 1.46447039 epoch total loss 1.22136009
Trained batch 3225 batch loss 1.13882542 epoch total loss 1.22133446
Trained batch 3226 batch loss 1.13843155 epoch total loss 1.22130883
Trained batch 3227 batch loss 1.02913547 epoch total loss 1.22124922
Trained batch 3228 batch loss 1.306144 epoch total loss 1.22127557
Trained batch 3229 batch loss 1.25001502 epoch total loss 1.22128439
Trained batch 3230 batch loss 1.19598556 epoch total loss 1.22127664
Trained batch 3231 batch loss 1.16490197 epoch total loss 1.22125912
Trained batch 3232 batch loss 1.15547371 epoch total loss 1.22123873
Trained batch 3233 batch loss 1.1497885 epoch total loss 1.22121668
Trained batch 3234 batch loss 1.30495834 epoch total loss 1.22124255
Trained batch 3235 batch loss 1.21090388 epoch total loss 1.22123945
Trained batch 3236 batch loss 1.17068827 epoch total loss 1.22122383
Trained batch 3237 batch loss 1.33894777 epoch total loss 1.22126007
Trained batch 3238 batch loss 1.13332236 epoch total loss 1.22123301
Trained batch 3239 batch loss 1.25321078 epoch total loss 1.22124279
Trained batch 3240 batch loss 1.18865848 epoch total loss 1.22123277
Trained batch 3241 batch loss 1.40134335 epoch total loss 1.22128832
Trained batch 3242 batch loss 1.36308956 epoch total loss 1.22133207
Trained batch 3243 batch loss 1.5025537 epoch total loss 1.22141874
Trained batch 3244 batch loss 1.54428101 epoch total loss 1.22151828
Trained batch 3245 batch loss 1.35310292 epoch total loss 1.22155881
Trained batch 3246 batch loss 1.03893149 epoch total loss 1.22150254
Trained batch 3247 batch loss 1.04476547 epoch total loss 1.22144806
Trained batch 3248 batch loss 1.06831169 epoch total loss 1.22140086
Trained batch 3249 batch loss 0.9766379 epoch total loss 1.22132552
Trained batch 3250 batch loss 0.837436557 epoch total loss 1.22120738
Trained batch 3251 batch loss 1.03754795 epoch total loss 1.22115088
Trained batch 3252 batch loss 0.918058813 epoch total loss 1.22105765
Trained batch 3253 batch loss 0.91088438 epoch total loss 1.22096241
Trained batch 3254 batch loss 1.01289082 epoch total loss 1.22089839
Trained batch 3255 batch loss 0.941887617 epoch total loss 1.22081268
Trained batch 3256 batch loss 1.36995602 epoch total loss 1.22085845
Trained batch 3257 batch loss 1.11374438 epoch total loss 1.22082555
Trained batch 3258 batch loss 1.23111701 epoch total loss 1.22082877
Trained batch 3259 batch loss 1.23379362 epoch total loss 1.22083282
Trained batch 3260 batch loss 1.08542478 epoch total loss 1.22079122
Trained batch 3261 batch loss 1.34192848 epoch total loss 1.22082841
Trained batch 3262 batch loss 1.06568718 epoch total loss 1.22078085
Trained batch 3263 batch loss 1.05133784 epoch total loss 1.22072899
Trained batch 3264 batch loss 1.20020354 epoch total loss 1.22072268
Trained batch 3265 batch loss 1.06711626 epoch total loss 1.22067559
Trained batch 3266 batch loss 1.19773877 epoch total loss 1.22066855
Trained batch 3267 batch loss 1.01525593 epoch total loss 1.22060573
Trained batch 3268 batch loss 1.19276154 epoch total loss 1.22059715
Trained batch 3269 batch loss 1.26106191 epoch total loss 1.22060955
Trained batch 3270 batch loss 1.14406681 epoch total loss 1.22058618
Trained batch 3271 batch loss 1.16509414 epoch total loss 1.22056913
Trained batch 3272 batch loss 1.39058065 epoch total loss 1.22062111
Trained batch 3273 batch loss 1.15227413 epoch total loss 1.22060025
Trained batch 3274 batch loss 1.00640643 epoch total loss 1.2205348
Trained batch 3275 batch loss 1.33350539 epoch total loss 1.22056937
Trained batch 3276 batch loss 1.46886659 epoch total loss 1.22064507
Trained batch 3277 batch loss 1.12877274 epoch total loss 1.22061706
Trained batch 3278 batch loss 1.19647431 epoch total loss 1.22060966
Trained batch 3279 batch loss 1.26336277 epoch total loss 1.22062266
Trained batch 3280 batch loss 1.39966476 epoch total loss 1.22067726
Trained batch 3281 batch loss 1.3900547 epoch total loss 1.22072899
Trained batch 3282 batch loss 1.34732389 epoch total loss 1.2207675
Trained batch 3283 batch loss 1.31770766 epoch total loss 1.22079706
Trained batch 3284 batch loss 1.06652093 epoch total loss 1.22075009
Trained batch 3285 batch loss 1.11580539 epoch total loss 1.22071803
Trained batch 3286 batch loss 1.31911635 epoch total loss 1.22074795
Trained batch 3287 batch loss 1.14777303 epoch total loss 1.22072577
Trained batch 3288 batch loss 1.35617638 epoch total loss 1.22076702
Trained batch 3289 batch loss 1.44014156 epoch total loss 1.22083366
Trained batch 3290 batch loss 1.49516928 epoch total loss 1.22091711
Trained batch 3291 batch loss 1.39573479 epoch total loss 1.22097015
Trained batch 3292 batch loss 1.37094021 epoch total loss 1.22101569
Trained batch 3293 batch loss 1.42895103 epoch total loss 1.22107887
Trained batch 3294 batch loss 1.41641414 epoch total loss 1.22113824
Trained batch 3295 batch loss 1.54159844 epoch total loss 1.22123539
Trained batch 3296 batch loss 1.38959312 epoch total loss 1.22128654
Trained batch 3297 batch loss 1.20288491 epoch total loss 1.22128093
Trained batch 3298 batch loss 1.32370639 epoch total loss 1.22131205
Trained batch 3299 batch loss 1.19331908 epoch total loss 1.22130358
Trained batch 3300 batch loss 1.35228992 epoch total loss 1.22134316
Trained batch 3301 batch loss 1.27725911 epoch total loss 1.22136021
Trained batch 3302 batch loss 1.23578048 epoch total loss 1.22136462
Trained batch 3303 batch loss 1.14414561 epoch total loss 1.22134113
Trained batch 3304 batch loss 1.2954905 epoch total loss 1.22136354
Trained batch 3305 batch loss 1.12810564 epoch total loss 1.22133541
Trained batch 3306 batch loss 1.11305666 epoch total loss 1.22130263
Trained batch 3307 batch loss 1.24586833 epoch total loss 1.22131
Trained batch 3308 batch loss 1.23304474 epoch total loss 1.2213136
Trained batch 3309 batch loss 1.2100842 epoch total loss 1.22131026
Trained batch 3310 batch loss 1.0325942 epoch total loss 1.22125328
Trained batch 3311 batch loss 1.05927086 epoch total loss 1.2212044
Trained batch 3312 batch loss 1.07242739 epoch total loss 1.22115946
Trained batch 3313 batch loss 0.976062775 epoch total loss 1.22108555
Trained batch 3314 batch loss 0.91292119 epoch total loss 1.22099245
Trained batch 3315 batch loss 1.0508945 epoch total loss 1.22094119
Trained batch 3316 batch loss 0.964017034 epoch total loss 1.2208637
Trained batch 3317 batch loss 1.20316648 epoch total loss 1.22085834
Trained batch 3318 batch loss 1.1286422 epoch total loss 1.22083056
Trained batch 3319 batch loss 1.23476267 epoch total loss 1.22083485
Trained batch 3320 batch loss 1.35125399 epoch total loss 1.22087407
Trained batch 3321 batch loss 1.20989871 epoch total loss 1.22087085
Trained batch 3322 batch loss 1.23463821 epoch total loss 1.22087491
Trained batch 3323 batch loss 1.10067642 epoch total loss 1.22083879
Trained batch 3324 batch loss 1.05167675 epoch total loss 1.22078788
Trained batch 3325 batch loss 1.25706 epoch total loss 1.22079885
Trained batch 3326 batch loss 1.46418822 epoch total loss 1.22087193
Trained batch 3327 batch loss 1.4017179 epoch total loss 1.22092628
Trained batch 3328 batch loss 1.28210378 epoch total loss 1.22094464
Trained batch 3329 batch loss 1.37098956 epoch total loss 1.2209897
Trained batch 3330 batch loss 1.18483281 epoch total loss 1.22097886
Trained batch 3331 batch loss 1.22099197 epoch total loss 1.22097886
Trained batch 3332 batch loss 1.18545783 epoch total loss 1.22096825
Trained batch 3333 batch loss 1.18237555 epoch total loss 1.22095668
Trained batch 3334 batch loss 1.28784764 epoch total loss 1.22097671
Trained batch 3335 batch loss 1.25073683 epoch total loss 1.22098565
Trained batch 3336 batch loss 1.15003669 epoch total loss 1.22096443
Trained batch 3337 batch loss 1.13754058 epoch total loss 1.2209394
Trained batch 3338 batch loss 0.915463 epoch total loss 1.22084785
Trained batch 3339 batch loss 1.05390787 epoch total loss 1.2207979
Trained batch 3340 batch loss 1.15266991 epoch total loss 1.22077751
Trained batch 3341 batch loss 1.17800367 epoch total loss 1.22076464
Trained batch 3342 batch loss 1.36891401 epoch total loss 1.22080898
Trained batch 3343 batch loss 1.40288901 epoch total loss 1.22086346
Trained batch 3344 batch loss 1.37195063 epoch total loss 1.22090864
Trained batch 3345 batch loss 1.3671869 epoch total loss 1.22095239
Trained batch 3346 batch loss 1.36991549 epoch total loss 1.22099686
Trained batch 3347 batch loss 1.1461724 epoch total loss 1.22097456
Trained batch 3348 batch loss 1.11725318 epoch total loss 1.22094357
Trained batch 3349 batch loss 1.30715859 epoch total loss 1.22096932
Trained batch 3350 batch loss 1.26238334 epoch total loss 1.22098172
Trained batch 3351 batch loss 1.11277294 epoch total loss 1.22094941
Trained batch 3352 batch loss 1.3275758 epoch total loss 1.22098124
Trained batch 3353 batch loss 1.3373394 epoch total loss 1.22101593
Trained batch 3354 batch loss 1.18636024 epoch total loss 1.22100556
Trained batch 3355 batch loss 1.251194 epoch total loss 1.22101462
Trained batch 3356 batch loss 1.23019505 epoch total loss 1.22101724
Trained batch 3357 batch loss 1.28540993 epoch total loss 1.22103655
Trained batch 3358 batch loss 1.21921873 epoch total loss 1.22103596
Trained batch 3359 batch loss 1.31898248 epoch total loss 1.22106504
Trained batch 3360 batch loss 1.23091006 epoch total loss 1.22106802
Trained batch 3361 batch loss 1.17787433 epoch total loss 1.22105515
Trained batch 3362 batch loss 1.10246205 epoch total loss 1.22101986
Trained batch 3363 batch loss 1.17067766 epoch total loss 1.22100496
Trained batch 3364 batch loss 1.14688849 epoch total loss 1.22098303
Trained batch 3365 batch loss 1.04932177 epoch total loss 1.22093201
Trained batch 3366 batch loss 1.13518572 epoch total loss 1.2209065
Trained batch 3367 batch loss 1.0872252 epoch total loss 1.2208668
Trained batch 3368 batch loss 0.97597158 epoch total loss 1.2207942
Trained batch 3369 batch loss 1.06939 epoch total loss 1.22074926
Trained batch 3370 batch loss 1.16619992 epoch total loss 1.22073293
Trained batch 3371 batch loss 1.10421133 epoch total loss 1.22069836
Trained batch 3372 batch loss 1.08161128 epoch total loss 1.22065711
Trained batch 3373 batch loss 1.30662024 epoch total loss 1.22068262
Trained batch 3374 batch loss 1.27038777 epoch total loss 1.22069728
Trained batch 3375 batch loss 1.43641853 epoch total loss 1.2207613
Trained batch 3376 batch loss 1.28524983 epoch total loss 1.22078037
Trained batch 3377 batch loss 1.1866281 epoch total loss 1.22077024
Trained batch 3378 batch loss 1.03298604 epoch total loss 1.22071469
Trained batch 3379 batch loss 1.16965926 epoch total loss 1.22069955
Trained batch 3380 batch loss 1.26876879 epoch total loss 1.22071362
Trained batch 3381 batch loss 1.10698 epoch total loss 1.22068
Trained batch 3382 batch loss 1.24437249 epoch total loss 1.22068691
Trained batch 3383 batch loss 1.08709133 epoch total loss 1.22064745
Trained batch 3384 batch loss 1.25087237 epoch total loss 1.22065639
Trained batch 3385 batch loss 1.10677874 epoch total loss 1.22062278
Trained batch 3386 batch loss 1.07503092 epoch total loss 1.22057986
Trained batch 3387 batch loss 1.1753757 epoch total loss 1.22056651
Trained batch 3388 batch loss 1.24008751 epoch total loss 1.22057223
Trained batch 3389 batch loss 1.12613785 epoch total loss 1.22054434
Trained batch 3390 batch loss 1.12007976 epoch total loss 1.22051477
Trained batch 3391 batch loss 1.25255048 epoch total loss 1.22052419
Trained batch 3392 batch loss 1.23232675 epoch total loss 1.22052765
Trained batch 3393 batch loss 1.18167949 epoch total loss 1.2205162
Trained batch 3394 batch loss 1.21418524 epoch total loss 1.22051442
Trained batch 3395 batch loss 1.29586053 epoch total loss 1.22053659
Trained batch 3396 batch loss 1.32657242 epoch total loss 1.22056782
Trained batch 3397 batch loss 1.20952225 epoch total loss 1.2205646
Trained batch 3398 batch loss 1.04889631 epoch total loss 1.22051406
Trained batch 3399 batch loss 1.1208719 epoch total loss 1.22048473
Trained batch 3400 batch loss 1.32504034 epoch total loss 1.22051561
Trained batch 3401 batch loss 1.07713854 epoch total loss 1.22047341
Trained batch 3402 batch loss 1.24824452 epoch total loss 1.22048151
Trained batch 3403 batch loss 1.26610911 epoch total loss 1.22049499
Trained batch 3404 batch loss 1.09416127 epoch total loss 1.22045779
Trained batch 3405 batch loss 1.04404807 epoch total loss 1.22040606
Trained batch 3406 batch loss 1.31526101 epoch total loss 1.22043395
Trained batch 3407 batch loss 1.21523309 epoch total loss 1.2204324
Trained batch 3408 batch loss 1.1901952 epoch total loss 1.22042358
Trained batch 3409 batch loss 1.06555831 epoch total loss 1.22037816
Trained batch 3410 batch loss 1.1161778 epoch total loss 1.22034752
Trained batch 3411 batch loss 0.895408273 epoch total loss 1.22025239
Trained batch 3412 batch loss 1.24088335 epoch total loss 1.22025836
Trained batch 3413 batch loss 1.22463441 epoch total loss 1.22025967
Trained batch 3414 batch loss 1.03041863 epoch total loss 1.220204
Trained batch 3415 batch loss 1.33227634 epoch total loss 1.2202369
Trained batch 3416 batch loss 1.15861106 epoch total loss 1.2202189
Trained batch 3417 batch loss 1.33641922 epoch total loss 1.22025287
Trained batch 3418 batch loss 1.21268225 epoch total loss 1.22025073
Trained batch 3419 batch loss 1.28578687 epoch total loss 1.2202698
Trained batch 3420 batch loss 1.38419497 epoch total loss 1.22031784
Trained batch 3421 batch loss 1.24281502 epoch total loss 1.22032428
Trained batch 3422 batch loss 1.21284556 epoch total loss 1.22032213
Trained batch 3423 batch loss 1.26803446 epoch total loss 1.22033608
Trained batch 3424 batch loss 1.23954701 epoch total loss 1.2203418
Trained batch 3425 batch loss 1.50548756 epoch total loss 1.22042501
Trained batch 3426 batch loss 1.28717828 epoch total loss 1.22044444
Trained batch 3427 batch loss 1.21992993 epoch total loss 1.2204442
Trained batch 3428 batch loss 1.07256067 epoch total loss 1.22040117
Trained batch 3429 batch loss 1.08713329 epoch total loss 1.22036219
Trained batch 3430 batch loss 1.3373127 epoch total loss 1.2203964
Trained batch 3431 batch loss 1.16038454 epoch total loss 1.22037876
Trained batch 3432 batch loss 1.09061432 epoch total loss 1.22034109
Trained batch 3433 batch loss 1.08124137 epoch total loss 1.22030044
Trained batch 3434 batch loss 1.05117643 epoch total loss 1.2202512
Trained batch 3435 batch loss 1.14154339 epoch total loss 1.22022831
Trained batch 3436 batch loss 1.07991 epoch total loss 1.22018754
Trained batch 3437 batch loss 1.16884816 epoch total loss 1.22017264
Trained batch 3438 batch loss 1.07874477 epoch total loss 1.22013152
Trained batch 3439 batch loss 1.23754144 epoch total loss 1.22013652
Trained batch 3440 batch loss 1.24372339 epoch total loss 1.22014332
Trained batch 3441 batch loss 1.25359213 epoch total loss 1.22015297
Trained batch 3442 batch loss 1.30949616 epoch total loss 1.22017896
Trained batch 3443 batch loss 1.27626109 epoch total loss 1.22019529
Trained batch 3444 batch loss 1.34844518 epoch total loss 1.22023261
Trained batch 3445 batch loss 1.3504355 epoch total loss 1.2202704
Trained batch 3446 batch loss 1.36154 epoch total loss 1.22031128
Trained batch 3447 batch loss 1.24213839 epoch total loss 1.22031772
Trained batch 3448 batch loss 1.28852391 epoch total loss 1.22033751
Trained batch 3449 batch loss 1.05420613 epoch total loss 1.22028935
Trained batch 3450 batch loss 1.29442453 epoch total loss 1.22031081
Trained batch 3451 batch loss 1.43420553 epoch total loss 1.2203728
Trained batch 3452 batch loss 1.32645774 epoch total loss 1.22040355
Trained batch 3453 batch loss 1.44459677 epoch total loss 1.22046852
Trained batch 3454 batch loss 1.28571057 epoch total loss 1.22048736
Trained batch 3455 batch loss 1.37698579 epoch total loss 1.22053266
Trained batch 3456 batch loss 1.35135007 epoch total loss 1.22057056
Trained batch 3457 batch loss 1.38792384 epoch total loss 1.22061896
Trained batch 3458 batch loss 1.37400782 epoch total loss 1.22066331
Trained batch 3459 batch loss 1.29094315 epoch total loss 1.22068369
Trained batch 3460 batch loss 1.10161543 epoch total loss 1.22064924
Trained batch 3461 batch loss 1.38495588 epoch total loss 1.22069669
Trained batch 3462 batch loss 1.27342546 epoch total loss 1.22071183
Trained batch 3463 batch loss 1.37732279 epoch total loss 1.22075713
Trained batch 3464 batch loss 1.30230117 epoch total loss 1.22078061
Trained batch 3465 batch loss 1.34911609 epoch total loss 1.22081769
Trained batch 3466 batch loss 1.17165732 epoch total loss 1.22080362
Trained batch 3467 batch loss 1.09499836 epoch total loss 1.22076738
Trained batch 3468 batch loss 1.10499465 epoch total loss 1.220734
Trained batch 3469 batch loss 1.15296531 epoch total loss 1.22071433
Trained batch 3470 batch loss 1.17069244 epoch total loss 1.2207
Trained batch 3471 batch loss 1.29316604 epoch total loss 1.22072089
Trained batch 3472 batch loss 1.3305856 epoch total loss 1.22075248
Trained batch 3473 batch loss 1.26495194 epoch total loss 1.22076523
Trained batch 3474 batch loss 1.16420007 epoch total loss 1.2207489
Trained batch 3475 batch loss 1.22882497 epoch total loss 1.22075129
Trained batch 3476 batch loss 1.24766064 epoch total loss 1.22075903
Trained batch 3477 batch loss 0.930089116 epoch total loss 1.22067547
Trained batch 3478 batch loss 1.31251216 epoch total loss 1.22070181
Trained batch 3479 batch loss 1.17845988 epoch total loss 1.22068965
Trained batch 3480 batch loss 1.28793 epoch total loss 1.22070897
Trained batch 3481 batch loss 1.38245595 epoch total loss 1.22075546
Trained batch 3482 batch loss 1.30739832 epoch total loss 1.22078037
Trained batch 3483 batch loss 1.28835833 epoch total loss 1.2207998
Trained batch 3484 batch loss 1.19176757 epoch total loss 1.22079158
Trained batch 3485 batch loss 1.19698977 epoch total loss 1.22078466
Trained batch 3486 batch loss 1.26435447 epoch total loss 1.22079706
Trained batch 3487 batch loss 1.32676244 epoch total loss 1.22082746
Trained batch 3488 batch loss 1.25421572 epoch total loss 1.22083712
Trained batch 3489 batch loss 1.27206933 epoch total loss 1.22085178
Trained batch 3490 batch loss 1.30305791 epoch total loss 1.22087538
Trained batch 3491 batch loss 1.27405 epoch total loss 1.22089052
Trained batch 3492 batch loss 1.37912905 epoch total loss 1.22093582
Trained batch 3493 batch loss 1.20016587 epoch total loss 1.22092986
Trained batch 3494 batch loss 1.04271197 epoch total loss 1.22087884
Trained batch 3495 batch loss 1.4132334 epoch total loss 1.22093379
Trained batch 3496 batch loss 1.12977028 epoch total loss 1.22090769
Trained batch 3497 batch loss 1.12513351 epoch total loss 1.22088027
Trained batch 3498 batch loss 0.974736214 epoch total loss 1.22080994
Trained batch 3499 batch loss 0.890778661 epoch total loss 1.22071552
Trained batch 3500 batch loss 1.2790041 epoch total loss 1.22073209
Trained batch 3501 batch loss 1.34742665 epoch total loss 1.22076845
Trained batch 3502 batch loss 1.23145497 epoch total loss 1.22077143
Trained batch 3503 batch loss 1.07425833 epoch total loss 1.22072959
Trained batch 3504 batch loss 1.11145151 epoch total loss 1.22069836
Trained batch 3505 batch loss 0.972689509 epoch total loss 1.22062767
Trained batch 3506 batch loss 1.12782383 epoch total loss 1.2206012
Trained batch 3507 batch loss 1.13185954 epoch total loss 1.22057581
Trained batch 3508 batch loss 1.06277299 epoch total loss 1.22053099
Trained batch 3509 batch loss 1.03171277 epoch total loss 1.2204771
Trained batch 3510 batch loss 1.0081358 epoch total loss 1.22041667
Trained batch 3511 batch loss 1.05900633 epoch total loss 1.22037077
Trained batch 3512 batch loss 1.07802081 epoch total loss 1.22033024
Trained batch 3513 batch loss 1.13082457 epoch total loss 1.22030473
Trained batch 3514 batch loss 0.925367653 epoch total loss 1.2202208
Trained batch 3515 batch loss 1.37745881 epoch total loss 1.22026551
Trained batch 3516 batch loss 1.29547846 epoch total loss 1.22028697
Trained batch 3517 batch loss 1.06544089 epoch total loss 1.22024286
Trained batch 3518 batch loss 1.17905879 epoch total loss 1.22023118
Trained batch 3519 batch loss 1.11846781 epoch total loss 1.22020233
Trained batch 3520 batch loss 1.19932556 epoch total loss 1.22019637
Trained batch 3521 batch loss 1.19183254 epoch total loss 1.22018838
Trained batch 3522 batch loss 1.12481809 epoch total loss 1.22016132
Trained batch 3523 batch loss 1.36140108 epoch total loss 1.22020137
Trained batch 3524 batch loss 1.20893276 epoch total loss 1.22019827
Trained batch 3525 batch loss 1.18376613 epoch total loss 1.22018778
Trained batch 3526 batch loss 1.12297285 epoch total loss 1.22016025
Trained batch 3527 batch loss 0.981099069 epoch total loss 1.22009242
Trained batch 3528 batch loss 1.04371238 epoch total loss 1.22004259
Trained batch 3529 batch loss 1.14831066 epoch total loss 1.2200222
Trained batch 3530 batch loss 1.08396602 epoch total loss 1.2199837
Trained batch 3531 batch loss 1.13155687 epoch total loss 1.21995854
Trained batch 3532 batch loss 1.29000652 epoch total loss 1.21997845
Trained batch 3533 batch loss 1.07209408 epoch total loss 1.21993661
Trained batch 3534 batch loss 1.19022012 epoch total loss 1.21992826
Trained batch 3535 batch loss 1.17516303 epoch total loss 1.21991563
Trained batch 3536 batch loss 1.13284743 epoch total loss 1.21989107
Trained batch 3537 batch loss 0.897626519 epoch total loss 1.21979988
Trained batch 3538 batch loss 1.1476953 epoch total loss 1.21977937
Trained batch 3539 batch loss 1.2100929 epoch total loss 1.21977663
Trained batch 3540 batch loss 0.971960187 epoch total loss 1.21970665
Trained batch 3541 batch loss 1.21585786 epoch total loss 1.21970558
Trained batch 3542 batch loss 1.49574769 epoch total loss 1.21978354
Trained batch 3543 batch loss 1.20543468 epoch total loss 1.21977949
Trained batch 3544 batch loss 1.42203212 epoch total loss 1.21983647
Trained batch 3545 batch loss 1.30604267 epoch total loss 1.21986091
Trained batch 3546 batch loss 1.11522055 epoch total loss 1.21983135
Trained batch 3547 batch loss 1.30770802 epoch total loss 1.21985614
Trained batch 3548 batch loss 1.3123877 epoch total loss 1.21988225
Trained batch 3549 batch loss 1.38999 epoch total loss 1.21993017
Trained batch 3550 batch loss 1.28416228 epoch total loss 1.21994829
Trained batch 3551 batch loss 1.2994349 epoch total loss 1.21997058
Trained batch 3552 batch loss 1.19244266 epoch total loss 1.21996284
Trained batch 3553 batch loss 1.24821746 epoch total loss 1.21997082
Trained batch 3554 batch loss 1.20933235 epoch total loss 1.21996784
Trained batch 3555 batch loss 1.26988387 epoch total loss 1.21998191
Trained batch 3556 batch loss 1.20558906 epoch total loss 1.21997786
Trained batch 3557 batch loss 1.16946387 epoch total loss 1.21996367
Trained batch 3558 batch loss 0.975229263 epoch total loss 1.21989477
Trained batch 3559 batch loss 0.82629019 epoch total loss 1.21978414
Trained batch 3560 batch loss 0.890749753 epoch total loss 1.21969175
Trained batch 3561 batch loss 1.01850545 epoch total loss 1.21963525
Trained batch 3562 batch loss 1.15859556 epoch total loss 1.21961808
Trained batch 3563 batch loss 0.93981576 epoch total loss 1.21953964
Trained batch 3564 batch loss 0.981817722 epoch total loss 1.219473
Trained batch 3565 batch loss 0.913838267 epoch total loss 1.21938729
Trained batch 3566 batch loss 1.14339423 epoch total loss 1.21936607
Trained batch 3567 batch loss 1.11409092 epoch total loss 1.21933651
Trained batch 3568 batch loss 1.13576257 epoch total loss 1.21931314
Trained batch 3569 batch loss 1.28236234 epoch total loss 1.21933079
Trained batch 3570 batch loss 1.21602082 epoch total loss 1.21932983
Trained batch 3571 batch loss 1.00318074 epoch total loss 1.21926928
Trained batch 3572 batch loss 0.989854634 epoch total loss 1.21920502
Trained batch 3573 batch loss 1.06252503 epoch total loss 1.21916115
Trained batch 3574 batch loss 1.22727394 epoch total loss 1.21916342
Trained batch 3575 batch loss 1.12052083 epoch total loss 1.21913588
Trained batch 3576 batch loss 1.19382501 epoch total loss 1.21912873
Trained batch 3577 batch loss 1.18059862 epoch total loss 1.219118
Trained batch 3578 batch loss 1.24679637 epoch total loss 1.21912575
Trained batch 3579 batch loss 1.09373295 epoch total loss 1.2190907
Trained batch 3580 batch loss 1.09152067 epoch total loss 1.21905494
Trained batch 3581 batch loss 1.01419938 epoch total loss 1.21899772
Trained batch 3582 batch loss 1.1348983 epoch total loss 1.21897423
Trained batch 3583 batch loss 0.930653393 epoch total loss 1.21889377
Trained batch 3584 batch loss 0.938784838 epoch total loss 1.21881568
Trained batch 3585 batch loss 0.904623747 epoch total loss 1.21872807
Trained batch 3586 batch loss 1.33982086 epoch total loss 1.2187618
Trained batch 3587 batch loss 1.38397157 epoch total loss 1.21880782
Trained batch 3588 batch loss 0.996851444 epoch total loss 1.21874607
Trained batch 3589 batch loss 1.09136927 epoch total loss 1.21871054
Trained batch 3590 batch loss 1.43432164 epoch total loss 1.2187705
Trained batch 3591 batch loss 1.25791049 epoch total loss 1.21878135
Trained batch 3592 batch loss 1.20516109 epoch total loss 1.21877754
Trained batch 3593 batch loss 1.36112666 epoch total loss 1.21881723
Trained batch 3594 batch loss 1.0324049 epoch total loss 1.21876538
Trained batch 3595 batch loss 1.14081633 epoch total loss 1.21874356
Trained batch 3596 batch loss 1.10463834 epoch total loss 1.21871185
Trained batch 3597 batch loss 0.967442036 epoch total loss 1.218642
Trained batch 3598 batch loss 1.36383426 epoch total loss 1.21868229
Trained batch 3599 batch loss 1.55250978 epoch total loss 1.21877515
Trained batch 3600 batch loss 1.21153653 epoch total loss 1.21877301
Trained batch 3601 batch loss 1.23054647 epoch total loss 1.21877635
Trained batch 3602 batch loss 0.861885667 epoch total loss 1.21867716
Trained batch 3603 batch loss 1.16301215 epoch total loss 1.21866179
Trained batch 3604 batch loss 1.14085412 epoch total loss 1.21864009
Trained batch 3605 batch loss 0.903186917 epoch total loss 1.21855271
Trained batch 3606 batch loss 0.998184919 epoch total loss 1.21849155
Trained batch 3607 batch loss 1.00278461 epoch total loss 1.21843171
Trained batch 3608 batch loss 1.13579571 epoch total loss 1.21840882
Trained batch 3609 batch loss 1.19725275 epoch total loss 1.21840298
Trained batch 3610 batch loss 1.11469555 epoch total loss 1.21837425
Trained batch 3611 batch loss 1.14654064 epoch total loss 1.21835434
Trained batch 3612 batch loss 1.05287063 epoch total loss 1.21830845
Trained batch 3613 batch loss 1.07532954 epoch total loss 1.21826887
Trained batch 3614 batch loss 1.17584491 epoch total loss 1.21825707
Trained batch 3615 batch loss 1.06653225 epoch total loss 1.21821511
Trained batch 3616 batch loss 1.33449721 epoch total loss 1.21824729
Trained batch 3617 batch loss 1.29369152 epoch total loss 1.21826804
Trained batch 3618 batch loss 1.20756638 epoch total loss 1.21826506
Trained batch 3619 batch loss 1.22254539 epoch total loss 1.21826625
Trained batch 3620 batch loss 1.4278934 epoch total loss 1.21832418
Trained batch 3621 batch loss 1.16081679 epoch total loss 1.21830821
Trained batch 3622 batch loss 1.19501352 epoch total loss 1.21830177
Trained batch 3623 batch loss 1.44081926 epoch total loss 1.21836317
Trained batch 3624 batch loss 1.547665 epoch total loss 1.21845412
Trained batch 3625 batch loss 1.43160367 epoch total loss 1.21851289
Trained batch 3626 batch loss 1.5082823 epoch total loss 1.21859288
Trained batch 3627 batch loss 1.50598705 epoch total loss 1.21867204
Trained batch 3628 batch loss 1.31795454 epoch total loss 1.21869934
Trained batch 3629 batch loss 1.28810596 epoch total loss 1.21871853
Trained batch 3630 batch loss 1.38106847 epoch total loss 1.21876323
Trained batch 3631 batch loss 1.17968285 epoch total loss 1.21875238
Trained batch 3632 batch loss 1.17205238 epoch total loss 1.21873951
Trained batch 3633 batch loss 1.31333709 epoch total loss 1.21876562
Trained batch 3634 batch loss 1.07160401 epoch total loss 1.21872509
Trained batch 3635 batch loss 1.04725826 epoch total loss 1.218678
Trained batch 3636 batch loss 1.09948778 epoch total loss 1.21864522
Trained batch 3637 batch loss 1.28598738 epoch total loss 1.21866381
Trained batch 3638 batch loss 1.24434161 epoch total loss 1.21867085
Trained batch 3639 batch loss 1.17857397 epoch total loss 1.21865988
Trained batch 3640 batch loss 1.11427379 epoch total loss 1.21863115
Trained batch 3641 batch loss 0.971835494 epoch total loss 1.21856332
Trained batch 3642 batch loss 1.04177082 epoch total loss 1.2185148
Trained batch 3643 batch loss 1.28563094 epoch total loss 1.21853328
Trained batch 3644 batch loss 1.25135827 epoch total loss 1.21854234
Trained batch 3645 batch loss 1.15615058 epoch total loss 1.21852517
Trained batch 3646 batch loss 1.21146131 epoch total loss 1.21852326
Trained batch 3647 batch loss 1.44680214 epoch total loss 1.21858585
Trained batch 3648 batch loss 0.969807267 epoch total loss 1.21851766
Trained batch 3649 batch loss 1.31283331 epoch total loss 1.21854353
Trained batch 3650 batch loss 1.20853209 epoch total loss 1.21854079
Trained batch 3651 batch loss 1.3444531 epoch total loss 1.21857524
Trained batch 3652 batch loss 1.49768543 epoch total loss 1.21865165
Trained batch 3653 batch loss 1.1754353 epoch total loss 1.21863973
Trained batch 3654 batch loss 0.912004 epoch total loss 1.21855581
Trained batch 3655 batch loss 1.17175603 epoch total loss 1.21854305
Trained batch 3656 batch loss 1.1506871 epoch total loss 1.21852458
Trained batch 3657 batch loss 0.985677958 epoch total loss 1.21846092
Trained batch 3658 batch loss 0.979261458 epoch total loss 1.21839559
Trained batch 3659 batch loss 0.759126425 epoch total loss 1.21827018
Trained batch 3660 batch loss 0.974110723 epoch total loss 1.21820343
Trained batch 3661 batch loss 1.16735101 epoch total loss 1.2181896
Trained batch 3662 batch loss 1.00452256 epoch total loss 1.21813118
Trained batch 3663 batch loss 1.0140202 epoch total loss 1.21807551
Trained batch 3664 batch loss 1.16727912 epoch total loss 1.21806169
Trained batch 3665 batch loss 1.0121727 epoch total loss 1.21800554
Trained batch 3666 batch loss 1.12765 epoch total loss 1.21798086
Trained batch 3667 batch loss 1.28060055 epoch total loss 1.21799791
Trained batch 3668 batch loss 1.01161563 epoch total loss 1.21794164
Trained batch 3669 batch loss 1.23441136 epoch total loss 1.21794617
Trained batch 3670 batch loss 1.04853654 epoch total loss 1.21789992
Trained batch 3671 batch loss 1.36995721 epoch total loss 1.2179414
Trained batch 3672 batch loss 1.22309101 epoch total loss 1.21794283
Trained batch 3673 batch loss 1.15547764 epoch total loss 1.21792579
Trained batch 3674 batch loss 1.20982361 epoch total loss 1.21792364
Trained batch 3675 batch loss 1.14435601 epoch total loss 1.21790361
Trained batch 3676 batch loss 0.904873967 epoch total loss 1.2178185
Trained batch 3677 batch loss 1.40732551 epoch total loss 1.21787
Trained batch 3678 batch loss 1.30696654 epoch total loss 1.2178942
Trained batch 3679 batch loss 0.999945283 epoch total loss 1.21783507
Trained batch 3680 batch loss 1.05326104 epoch total loss 1.21779025
Trained batch 3681 batch loss 1.27843761 epoch total loss 1.2178067
Trained batch 3682 batch loss 1.33027017 epoch total loss 1.21783721
Trained batch 3683 batch loss 1.34468484 epoch total loss 1.21787167
Trained batch 3684 batch loss 1.28624773 epoch total loss 1.21789026
Trained batch 3685 batch loss 1.37008524 epoch total loss 1.21793151
Trained batch 3686 batch loss 1.43237889 epoch total loss 1.2179898
Trained batch 3687 batch loss 1.30529249 epoch total loss 1.21801341
Trained batch 3688 batch loss 1.22454309 epoch total loss 1.21801519
Trained batch 3689 batch loss 1.24608803 epoch total loss 1.21802282
Trained batch 3690 batch loss 1.02681017 epoch total loss 1.21797097
Trained batch 3691 batch loss 1.35017073 epoch total loss 1.21800685
Trained batch 3692 batch loss 1.36907685 epoch total loss 1.21804774
Trained batch 3693 batch loss 1.32381606 epoch total loss 1.21807635
Trained batch 3694 batch loss 1.3398807 epoch total loss 1.21810937
Trained batch 3695 batch loss 1.2831924 epoch total loss 1.21812689
Trained batch 3696 batch loss 1.5070926 epoch total loss 1.21820521
Trained batch 3697 batch loss 0.943744063 epoch total loss 1.21813095
Trained batch 3698 batch loss 1.03323412 epoch total loss 1.218081
Trained batch 3699 batch loss 0.938671827 epoch total loss 1.21800542
Trained batch 3700 batch loss 1.05319369 epoch total loss 1.21796083
Trained batch 3701 batch loss 1.00464129 epoch total loss 1.21790326
Trained batch 3702 batch loss 1.20329952 epoch total loss 1.21789932
Trained batch 3703 batch loss 1.15112758 epoch total loss 1.21788132
Trained batch 3704 batch loss 1.18822122 epoch total loss 1.21787322
Trained batch 3705 batch loss 1.13836145 epoch total loss 1.21785176
Trained batch 3706 batch loss 1.14759457 epoch total loss 1.21783268
Trained batch 3707 batch loss 1.22745872 epoch total loss 1.21783531
Trained batch 3708 batch loss 1.11964703 epoch total loss 1.21780884
Trained batch 3709 batch loss 1.25704765 epoch total loss 1.21781933
Trained batch 3710 batch loss 1.3751564 epoch total loss 1.21786177
Trained batch 3711 batch loss 1.30080533 epoch total loss 1.21788406
Trained batch 3712 batch loss 1.29158723 epoch total loss 1.21790397
Trained batch 3713 batch loss 1.38972592 epoch total loss 1.21795022
Trained batch 3714 batch loss 1.19867826 epoch total loss 1.21794498
Trained batch 3715 batch loss 1.44507623 epoch total loss 1.21800625
Trained batch 3716 batch loss 1.48226666 epoch total loss 1.21807742
Trained batch 3717 batch loss 1.32922363 epoch total loss 1.21810722
Trained batch 3718 batch loss 1.29368877 epoch total loss 1.21812749
Trained batch 3719 batch loss 1.17962122 epoch total loss 1.21811712
Trained batch 3720 batch loss 1.28103185 epoch total loss 1.21813416
Trained batch 3721 batch loss 1.23641777 epoch total loss 1.21813905
Trained batch 3722 batch loss 1.21364617 epoch total loss 1.21813786
Trained batch 3723 batch loss 1.33412671 epoch total loss 1.21816897
Trained batch 3724 batch loss 1.24273503 epoch total loss 1.21817553
Trained batch 3725 batch loss 1.09769404 epoch total loss 1.21814322
Trained batch 3726 batch loss 1.06390429 epoch total loss 1.21810186
Trained batch 3727 batch loss 1.12535679 epoch total loss 1.21807694
Trained batch 3728 batch loss 1.03737295 epoch total loss 1.21802855
Trained batch 3729 batch loss 1.04433036 epoch total loss 1.21798205
Trained batch 3730 batch loss 1.19301307 epoch total loss 1.21797526
Trained batch 3731 batch loss 1.29200161 epoch total loss 1.21799517
Trained batch 3732 batch loss 1.15718222 epoch total loss 1.21797884
Trained batch 3733 batch loss 1.43030214 epoch total loss 1.2180357
Trained batch 3734 batch loss 1.18817234 epoch total loss 1.21802759
Trained batch 3735 batch loss 1.11646843 epoch total loss 1.21800053
Trained batch 3736 batch loss 1.22229564 epoch total loss 1.2180016
Trained batch 3737 batch loss 1.14032471 epoch total loss 1.21798074
Trained batch 3738 batch loss 1.07707179 epoch total loss 1.21794307
Trained batch 3739 batch loss 1.28174043 epoch total loss 1.21796024
Trained batch 3740 batch loss 1.27950108 epoch total loss 1.21797657
Trained batch 3741 batch loss 1.17119467 epoch total loss 1.21796417
Trained batch 3742 batch loss 1.18208516 epoch total loss 1.21795452
Trained batch 3743 batch loss 1.34502745 epoch total loss 1.21798861
Trained batch 3744 batch loss 1.38191748 epoch total loss 1.21803236
Trained batch 3745 batch loss 1.25422239 epoch total loss 1.21804202
Trained batch 3746 batch loss 1.42972982 epoch total loss 1.21809852
Trained batch 3747 batch loss 1.09972429 epoch total loss 1.21806693
Trained batch 3748 batch loss 1.23263788 epoch total loss 1.21807075
Trained batch 3749 batch loss 0.955006421 epoch total loss 1.21800053
Trained batch 3750 batch loss 0.984930754 epoch total loss 1.21793842
Trained batch 3751 batch loss 1.15053463 epoch total loss 1.21792042
Trained batch 3752 batch loss 1.06873155 epoch total loss 1.21788073
Trained batch 3753 batch loss 1.11460686 epoch total loss 1.21785319
Trained batch 3754 batch loss 1.20316 epoch total loss 1.21784925
Trained batch 3755 batch loss 1.10275841 epoch total loss 1.21781862
Trained batch 3756 batch loss 1.34889483 epoch total loss 1.21785355
Trained batch 3757 batch loss 1.13037634 epoch total loss 1.21783018
Trained batch 3758 batch loss 1.13422132 epoch total loss 1.21780801
Trained batch 3759 batch loss 1.27002263 epoch total loss 1.21782184
Trained batch 3760 batch loss 1.07337391 epoch total loss 1.21778345
Trained batch 3761 batch loss 1.05721593 epoch total loss 1.21774077
Trained batch 3762 batch loss 1.08142543 epoch total loss 1.21770453
Trained batch 3763 batch loss 1.09017217 epoch total loss 1.21767068
Trained batch 3764 batch loss 1.23713624 epoch total loss 1.21767592
Trained batch 3765 batch loss 1.13582873 epoch total loss 1.21765411
Trained batch 3766 batch loss 1.04531467 epoch total loss 1.21760833
Trained batch 3767 batch loss 0.99048686 epoch total loss 1.21754813
Trained batch 3768 batch loss 0.949052811 epoch total loss 1.21747696
Trained batch 3769 batch loss 0.973206937 epoch total loss 1.21741211
Trained batch 3770 batch loss 0.987772107 epoch total loss 1.2173512
Trained batch 3771 batch loss 0.97393918 epoch total loss 1.21728671
Trained batch 3772 batch loss 0.998931885 epoch total loss 1.21722889
Trained batch 3773 batch loss 0.932180882 epoch total loss 1.21715331
Trained batch 3774 batch loss 1.31138408 epoch total loss 1.21717834
Trained batch 3775 batch loss 1.03043509 epoch total loss 1.21712875
Trained batch 3776 batch loss 0.937416613 epoch total loss 1.21705472
Trained batch 3777 batch loss 1.00165272 epoch total loss 1.21699762
Trained batch 3778 batch loss 1.35921597 epoch total loss 1.21703529
Trained batch 3779 batch loss 1.31911898 epoch total loss 1.21706235
Trained batch 3780 batch loss 1.18117213 epoch total loss 1.21705294
Trained batch 3781 batch loss 1.03795171 epoch total loss 1.21700561
Trained batch 3782 batch loss 1.10131288 epoch total loss 1.21697485
Trained batch 3783 batch loss 1.04377127 epoch total loss 1.2169292
Trained batch 3784 batch loss 1.11883712 epoch total loss 1.21690321
Trained batch 3785 batch loss 1.09351993 epoch total loss 1.21687067
Trained batch 3786 batch loss 0.97815454 epoch total loss 1.2168076
Trained batch 3787 batch loss 1.32742143 epoch total loss 1.21683681
Trained batch 3788 batch loss 1.09871054 epoch total loss 1.2168057
Trained batch 3789 batch loss 1.11652899 epoch total loss 1.21677923
Trained batch 3790 batch loss 1.06179404 epoch total loss 1.21673834
Trained batch 3791 batch loss 0.923767686 epoch total loss 1.2166611
Trained batch 3792 batch loss 1.27698624 epoch total loss 1.21667695
Trained batch 3793 batch loss 1.17164898 epoch total loss 1.21666515
Trained batch 3794 batch loss 1.26223183 epoch total loss 1.21667719
Trained batch 3795 batch loss 1.12568653 epoch total loss 1.21665311
Trained batch 3796 batch loss 1.06834698 epoch total loss 1.21661413
Trained batch 3797 batch loss 0.985161185 epoch total loss 1.21655321
Trained batch 3798 batch loss 1.03840899 epoch total loss 1.21650636
Trained batch 3799 batch loss 1.51620007 epoch total loss 1.21658516
Trained batch 3800 batch loss 1.28378189 epoch total loss 1.2166028
Trained batch 3801 batch loss 1.41211581 epoch total loss 1.2166543
Trained batch 3802 batch loss 1.18944466 epoch total loss 1.21664715
Trained batch 3803 batch loss 1.46727824 epoch total loss 1.21671307
Trained batch 3804 batch loss 1.28238869 epoch total loss 1.21673024
Trained batch 3805 batch loss 1.47194648 epoch total loss 1.21679735
Trained batch 3806 batch loss 1.33220649 epoch total loss 1.21682763
Trained batch 3807 batch loss 1.42472589 epoch total loss 1.21688235
Trained batch 3808 batch loss 1.24032211 epoch total loss 1.21688843
Trained batch 3809 batch loss 1.33638346 epoch total loss 1.21691978
Trained batch 3810 batch loss 1.22871017 epoch total loss 1.21692288
Trained batch 3811 batch loss 1.10944295 epoch total loss 1.21689463
Trained batch 3812 batch loss 1.3981024 epoch total loss 1.21694207
Trained batch 3813 batch loss 1.3303721 epoch total loss 1.21697187
Trained batch 3814 batch loss 1.39120519 epoch total loss 1.21701753
Trained batch 3815 batch loss 1.24602187 epoch total loss 1.21702516
Trained batch 3816 batch loss 1.21223688 epoch total loss 1.21702397
Trained batch 3817 batch loss 0.997400761 epoch total loss 1.21696651
Trained batch 3818 batch loss 1.41325223 epoch total loss 1.21701789
Trained batch 3819 batch loss 1.4252739 epoch total loss 1.21707237
Trained batch 3820 batch loss 1.28704381 epoch total loss 1.21709073
Trained batch 3821 batch loss 1.49947071 epoch total loss 1.21716464
Trained batch 3822 batch loss 1.33271706 epoch total loss 1.2171948
Trained batch 3823 batch loss 1.27050972 epoch total loss 1.21720874
Trained batch 3824 batch loss 1.21675682 epoch total loss 1.21720862
Trained batch 3825 batch loss 1.0860728 epoch total loss 1.21717441
Trained batch 3826 batch loss 1.06714284 epoch total loss 1.21713519
Trained batch 3827 batch loss 1.06677175 epoch total loss 1.21709597
Trained batch 3828 batch loss 1.37120271 epoch total loss 1.21713614
Trained batch 3829 batch loss 1.15347421 epoch total loss 1.21711946
Trained batch 3830 batch loss 1.21601963 epoch total loss 1.21711922
Trained batch 3831 batch loss 1.28293169 epoch total loss 1.21713626
Trained batch 3832 batch loss 1.20135903 epoch total loss 1.21713209
Trained batch 3833 batch loss 1.25615275 epoch total loss 1.21714234
Trained batch 3834 batch loss 1.08700347 epoch total loss 1.21710837
Trained batch 3835 batch loss 1.31270754 epoch total loss 1.21713328
Trained batch 3836 batch loss 1.17328346 epoch total loss 1.21712184
Trained batch 3837 batch loss 1.28923726 epoch total loss 1.21714056
Trained batch 3838 batch loss 1.33527207 epoch total loss 1.21717143
Trained batch 3839 batch loss 1.040097 epoch total loss 1.2171253
Trained batch 3840 batch loss 1.14017057 epoch total loss 1.21710527
Trained batch 3841 batch loss 1.31717372 epoch total loss 1.21713138
Trained batch 3842 batch loss 1.36939263 epoch total loss 1.21717107
Trained batch 3843 batch loss 1.28720176 epoch total loss 1.21718919
Trained batch 3844 batch loss 1.1936605 epoch total loss 1.21718311
Trained batch 3845 batch loss 1.35666835 epoch total loss 1.21721935
Trained batch 3846 batch loss 1.2168138 epoch total loss 1.21721923
Trained batch 3847 batch loss 1.32581019 epoch total loss 1.21724749
Trained batch 3848 batch loss 1.11033487 epoch total loss 1.21721971
Trained batch 3849 batch loss 1.1542902 epoch total loss 1.21720338
Trained batch 3850 batch loss 1.2581768 epoch total loss 1.21721399
Trained batch 3851 batch loss 1.42645621 epoch total loss 1.21726835
Trained batch 3852 batch loss 1.41821778 epoch total loss 1.21732056
Trained batch 3853 batch loss 1.30767512 epoch total loss 1.21734393
Trained batch 3854 batch loss 1.36610174 epoch total loss 1.21738255
Trained batch 3855 batch loss 1.25860143 epoch total loss 1.21739328
Trained batch 3856 batch loss 1.34167504 epoch total loss 1.21742558
Trained batch 3857 batch loss 1.31450498 epoch total loss 1.21745074
Trained batch 3858 batch loss 1.4440496 epoch total loss 1.21750939
Trained batch 3859 batch loss 1.35866559 epoch total loss 1.21754611
Trained batch 3860 batch loss 1.33631325 epoch total loss 1.21757686
Trained batch 3861 batch loss 1.15114021 epoch total loss 1.2175597
Trained batch 3862 batch loss 1.06710219 epoch total loss 1.21752071
Trained batch 3863 batch loss 1.36256194 epoch total loss 1.21755826
Trained batch 3864 batch loss 1.34719515 epoch total loss 1.21759188
Trained batch 3865 batch loss 1.45918798 epoch total loss 1.21765435
Trained batch 3866 batch loss 1.0516479 epoch total loss 1.21761143
Trained batch 3867 batch loss 1.26431775 epoch total loss 1.21762347
Trained batch 3868 batch loss 1.23509 epoch total loss 1.21762788
Trained batch 3869 batch loss 1.19076955 epoch total loss 1.21762097
Trained batch 3870 batch loss 1.22668695 epoch total loss 1.21762335
Trained batch 3871 batch loss 1.16163182 epoch total loss 1.21760881
Trained batch 3872 batch loss 1.20691121 epoch total loss 1.21760607
Trained batch 3873 batch loss 1.08097243 epoch total loss 1.21757078
Trained batch 3874 batch loss 1.09588873 epoch total loss 1.21753943
Trained batch 3875 batch loss 1.30184948 epoch total loss 1.21756113
Trained batch 3876 batch loss 1.40917921 epoch total loss 1.2176106
Trained batch 3877 batch loss 1.21976173 epoch total loss 1.21761107
Trained batch 3878 batch loss 1.2219584 epoch total loss 1.21761227
Trained batch 3879 batch loss 0.959245443 epoch total loss 1.21754575
Trained batch 3880 batch loss 1.13825274 epoch total loss 1.21752524
Trained batch 3881 batch loss 1.27860332 epoch total loss 1.2175411
Trained batch 3882 batch loss 1.18765259 epoch total loss 1.21753335
Trained batch 3883 batch loss 1.36045456 epoch total loss 1.21757007
Trained batch 3884 batch loss 1.28910208 epoch total loss 1.21758854
Trained batch 3885 batch loss 1.20891714 epoch total loss 1.21758628
Trained batch 3886 batch loss 1.07839489 epoch total loss 1.21755052
Trained batch 3887 batch loss 1.16888237 epoch total loss 1.217538
Trained batch 3888 batch loss 1.23396111 epoch total loss 1.21754229
Trained batch 3889 batch loss 1.15989232 epoch total loss 1.21752739
Trained batch 3890 batch loss 1.21537185 epoch total loss 1.21752679
Trained batch 3891 batch loss 1.20829082 epoch total loss 1.21752441
Trained batch 3892 batch loss 1.26878905 epoch total loss 1.21753752
Trained batch 3893 batch loss 1.29337168 epoch total loss 1.21755707
Trained batch 3894 batch loss 1.13269186 epoch total loss 1.21753526
Trained batch 3895 batch loss 1.03868008 epoch total loss 1.21748936
Trained batch 3896 batch loss 1.23791516 epoch total loss 1.21749461
Trained batch 3897 batch loss 1.17385387 epoch total loss 1.2174834
Trained batch 3898 batch loss 1.25219059 epoch total loss 1.21749222
Trained batch 3899 batch loss 1.19078755 epoch total loss 1.21748543
Trained batch 3900 batch loss 1.21519709 epoch total loss 1.21748483
Trained batch 3901 batch loss 1.11431015 epoch total loss 1.21745837
Trained batch 3902 batch loss 1.31681585 epoch total loss 1.21748388
Trained batch 3903 batch loss 1.20561016 epoch total loss 1.21748078
Trained batch 3904 batch loss 1.25807881 epoch total loss 1.21749127
Trained batch 3905 batch loss 1.16100013 epoch total loss 1.21747684
Trained batch 3906 batch loss 0.959896266 epoch total loss 1.21741092
Trained batch 3907 batch loss 1.22913861 epoch total loss 1.2174139
Trained batch 3908 batch loss 1.07079387 epoch total loss 1.21737635
Trained batch 3909 batch loss 1.11699963 epoch total loss 1.21735072
Trained batch 3910 batch loss 1.38395023 epoch total loss 1.21739328
Trained batch 3911 batch loss 1.47619653 epoch total loss 1.21745944
Trained batch 3912 batch loss 1.65304422 epoch total loss 1.21757078
Trained batch 3913 batch loss 1.44480205 epoch total loss 1.21762884
Trained batch 3914 batch loss 1.27663302 epoch total loss 1.21764398
Trained batch 3915 batch loss 1.21534991 epoch total loss 1.21764338
Trained batch 3916 batch loss 1.48460066 epoch total loss 1.21771145
Trained batch 3917 batch loss 1.36398578 epoch total loss 1.21774876
Trained batch 3918 batch loss 1.23959064 epoch total loss 1.21775436
Trained batch 3919 batch loss 1.32005739 epoch total loss 1.21778047
Trained batch 3920 batch loss 1.35075235 epoch total loss 1.21781433
Trained batch 3921 batch loss 1.40484381 epoch total loss 1.21786201
Trained batch 3922 batch loss 1.41119337 epoch total loss 1.21791124
Trained batch 3923 batch loss 1.3174355 epoch total loss 1.21793664
Trained batch 3924 batch loss 1.16694784 epoch total loss 1.21792364
Trained batch 3925 batch loss 1.35411501 epoch total loss 1.21795833
Trained batch 3926 batch loss 1.21594262 epoch total loss 1.21795774
Trained batch 3927 batch loss 1.14931989 epoch total loss 1.21794033
Trained batch 3928 batch loss 1.28717852 epoch total loss 1.21795785
Trained batch 3929 batch loss 1.23200119 epoch total loss 1.21796143
Trained batch 3930 batch loss 1.25858581 epoch total loss 1.2179718
Trained batch 3931 batch loss 1.18975472 epoch total loss 1.21796477
Trained batch 3932 batch loss 1.12402129 epoch total loss 1.21794081
Trained batch 3933 batch loss 1.31518126 epoch total loss 1.21796548
Trained batch 3934 batch loss 1.29659069 epoch total loss 1.21798539
Trained batch 3935 batch loss 1.18072844 epoch total loss 1.21797597
Trained batch 3936 batch loss 1.18125641 epoch total loss 1.21796656
Trained batch 3937 batch loss 1.21186781 epoch total loss 1.21796501
Trained batch 3938 batch loss 1.29212141 epoch total loss 1.21798384
Trained batch 3939 batch loss 1.33239532 epoch total loss 1.21801293
Trained batch 3940 batch loss 1.14481354 epoch total loss 1.21799445
Trained batch 3941 batch loss 1.29390335 epoch total loss 1.21801364
Trained batch 3942 batch loss 1.21137261 epoch total loss 1.21801198
Trained batch 3943 batch loss 1.3929373 epoch total loss 1.21805644
Trained batch 3944 batch loss 1.20723176 epoch total loss 1.21805358
Trained batch 3945 batch loss 1.08285046 epoch total loss 1.21801937
Trained batch 3946 batch loss 1.18464732 epoch total loss 1.2180109
Trained batch 3947 batch loss 1.13540912 epoch total loss 1.21798992
Trained batch 3948 batch loss 1.21317911 epoch total loss 1.21798873
Trained batch 3949 batch loss 1.33521819 epoch total loss 1.21801853
Trained batch 3950 batch loss 1.1735841 epoch total loss 1.21800733
Trained batch 3951 batch loss 1.3484273 epoch total loss 1.21804035
Trained batch 3952 batch loss 1.11226702 epoch total loss 1.21801364
Trained batch 3953 batch loss 1.15615964 epoch total loss 1.21799803
Trained batch 3954 batch loss 1.16757798 epoch total loss 1.21798527
Trained batch 3955 batch loss 1.26846981 epoch total loss 1.21799803
Trained batch 3956 batch loss 1.29862642 epoch total loss 1.21801841
Trained batch 3957 batch loss 1.13117695 epoch total loss 1.2179966
Trained batch 3958 batch loss 1.01718986 epoch total loss 1.21794581
Trained batch 3959 batch loss 1.04068255 epoch total loss 1.21790099
Trained batch 3960 batch loss 1.18873203 epoch total loss 1.2178936
Trained batch 3961 batch loss 1.07367015 epoch total loss 1.21785724
Trained batch 3962 batch loss 1.22617054 epoch total loss 1.21785939
Trained batch 3963 batch loss 1.19176733 epoch total loss 1.21785283
Trained batch 3964 batch loss 1.11037636 epoch total loss 1.21782565
Trained batch 3965 batch loss 1.08828807 epoch total loss 1.21779299
Trained batch 3966 batch loss 0.984791219 epoch total loss 1.21773434
Trained batch 3967 batch loss 1.08281231 epoch total loss 1.21770036
Trained batch 3968 batch loss 0.91977793 epoch total loss 1.21762526
Trained batch 3969 batch loss 0.934187174 epoch total loss 1.21755385
Trained batch 3970 batch loss 0.9261356 epoch total loss 1.21748042
Trained batch 3971 batch loss 0.967927098 epoch total loss 1.2174176
Trained batch 3972 batch loss 1.01610482 epoch total loss 1.21736693
Trained batch 3973 batch loss 0.935022414 epoch total loss 1.21729589
Trained batch 3974 batch loss 1.09536183 epoch total loss 1.21726513
Trained batch 3975 batch loss 1.17638373 epoch total loss 1.21725476
Trained batch 3976 batch loss 1.42248034 epoch total loss 1.21730638
Trained batch 3977 batch loss 1.32041574 epoch total loss 1.21733224
Trained batch 3978 batch loss 1.49794519 epoch total loss 1.21740282
Trained batch 3979 batch loss 1.25042546 epoch total loss 1.21741116
Trained batch 3980 batch loss 1.33514178 epoch total loss 1.21744072
Trained batch 3981 batch loss 1.25642455 epoch total loss 1.2174505
Trained batch 3982 batch loss 1.2372632 epoch total loss 1.21745551
Trained batch 3983 batch loss 1.2678299 epoch total loss 1.21746814
Trained batch 3984 batch loss 1.24656177 epoch total loss 1.21747553
Trained batch 3985 batch loss 1.5820601 epoch total loss 1.21756697
Trained batch 3986 batch loss 1.55663264 epoch total loss 1.21765208
Trained batch 3987 batch loss 1.44513416 epoch total loss 1.21770918
Trained batch 3988 batch loss 1.31931174 epoch total loss 1.21773458
Trained batch 3989 batch loss 1.09678328 epoch total loss 1.2177043
Trained batch 3990 batch loss 1.38090467 epoch total loss 1.21774518
Trained batch 3991 batch loss 1.06333232 epoch total loss 1.21770656
Trained batch 3992 batch loss 1.17858982 epoch total loss 1.21769679
Trained batch 3993 batch loss 1.26642776 epoch total loss 1.21770895
Trained batch 3994 batch loss 1.22519875 epoch total loss 1.21771085
Trained batch 3995 batch loss 1.18331504 epoch total loss 1.21770215
Trained batch 3996 batch loss 1.10565472 epoch total loss 1.21767414
Trained batch 3997 batch loss 1.19961691 epoch total loss 1.21766961
Trained batch 3998 batch loss 1.31618965 epoch total loss 1.21769428
Trained batch 3999 batch loss 1.07369936 epoch total loss 1.21765828
Trained batch 4000 batch loss 1.04833174 epoch total loss 1.21761596
Trained batch 4001 batch loss 1.17892396 epoch total loss 1.21760619
Trained batch 4002 batch loss 1.0184654 epoch total loss 1.21755648
Trained batch 4003 batch loss 1.04939508 epoch total loss 1.21751451
Trained batch 4004 batch loss 1.25802422 epoch total loss 1.21752453
Trained batch 4005 batch loss 1.11051214 epoch total loss 1.21749783
Trained batch 4006 batch loss 1.18097496 epoch total loss 1.21748877
Trained batch 4007 batch loss 1.14732432 epoch total loss 1.21747124
Trained batch 4008 batch loss 1.00742626 epoch total loss 1.21741879
Trained batch 4009 batch loss 1.1034261 epoch total loss 1.21739042
Trained batch 4010 batch loss 1.34450674 epoch total loss 1.21742213
Trained batch 4011 batch loss 1.35256016 epoch total loss 1.21745586
Trained batch 4012 batch loss 1.36990356 epoch total loss 1.21749389
Trained batch 4013 batch loss 1.2152195 epoch total loss 1.2174933
Trained batch 4014 batch loss 0.987272263 epoch total loss 1.21743596
Trained batch 4015 batch loss 1.36500168 epoch total loss 1.21747279
Trained batch 4016 batch loss 1.47596574 epoch total loss 1.21753716
Trained batch 4017 batch loss 1.55252957 epoch total loss 1.21762061
Trained batch 4018 batch loss 1.45438671 epoch total loss 1.21767962
Trained batch 4019 batch loss 1.2421279 epoch total loss 1.2176857
Trained batch 4020 batch loss 1.08527458 epoch total loss 1.2176528
Trained batch 4021 batch loss 1.5795598 epoch total loss 1.2177428
Trained batch 4022 batch loss 1.33856142 epoch total loss 1.21777284
Trained batch 4023 batch loss 1.361022 epoch total loss 1.21780837
Trained batch 4024 batch loss 1.13489902 epoch total loss 1.21778774
Trained batch 4025 batch loss 1.26578856 epoch total loss 1.21779966
Trained batch 4026 batch loss 1.29527271 epoch total loss 1.21781898
Trained batch 4027 batch loss 1.28919768 epoch total loss 1.21783662
Trained batch 4028 batch loss 1.30401456 epoch total loss 1.21785808
Trained batch 4029 batch loss 1.30177701 epoch total loss 1.21787882
Trained batch 4030 batch loss 1.21978116 epoch total loss 1.2178793
Trained batch 4031 batch loss 1.23895073 epoch total loss 1.21788454
Trained batch 4032 batch loss 1.11991131 epoch total loss 1.21786022
Trained batch 4033 batch loss 1.41812778 epoch total loss 1.21790993
Trained batch 4034 batch loss 1.31535757 epoch total loss 1.21793401
Trained batch 4035 batch loss 1.48459458 epoch total loss 1.218
Trained batch 4036 batch loss 1.31056476 epoch total loss 1.21802306
Trained batch 4037 batch loss 1.09293854 epoch total loss 1.21799195
Trained batch 4038 batch loss 1.22218239 epoch total loss 1.21799302
Trained batch 4039 batch loss 1.29586864 epoch total loss 1.21801233
Trained batch 4040 batch loss 1.16418922 epoch total loss 1.21799898
Trained batch 4041 batch loss 1.27415252 epoch total loss 1.21801281
Trained batch 4042 batch loss 1.16422558 epoch total loss 1.21799946
Trained batch 4043 batch loss 1.28825831 epoch total loss 1.21801674
Trained batch 4044 batch loss 0.944380522 epoch total loss 1.21794915
Trained batch 4045 batch loss 1.26065791 epoch total loss 1.21795964
Trained batch 4046 batch loss 1.34993052 epoch total loss 1.21799231
Trained batch 4047 batch loss 1.18287587 epoch total loss 1.21798372
Trained batch 4048 batch loss 1.15147686 epoch total loss 1.21796727
Trained batch 4049 batch loss 1.13725138 epoch total loss 1.21794736
Trained batch 4050 batch loss 1.24589205 epoch total loss 1.21795428
Trained batch 4051 batch loss 1.03386271 epoch total loss 1.21790874
Trained batch 4052 batch loss 1.09744918 epoch total loss 1.21787918
Trained batch 4053 batch loss 1.14455843 epoch total loss 1.21786106
Trained batch 4054 batch loss 1.24833834 epoch total loss 1.21786857
Trained batch 4055 batch loss 1.21588123 epoch total loss 1.21786809
Trained batch 4056 batch loss 1.24721694 epoch total loss 1.21787524
Trained batch 4057 batch loss 1.34963679 epoch total loss 1.21790779
Trained batch 4058 batch loss 1.37564456 epoch total loss 1.21794653
Trained batch 4059 batch loss 1.29865909 epoch total loss 1.21796656
Trained batch 4060 batch loss 1.14926052 epoch total loss 1.21794963
Trained batch 4061 batch loss 1.18609655 epoch total loss 1.21794176
Trained batch 4062 batch loss 1.13812923 epoch total loss 1.21792209
Trained batch 4063 batch loss 1.17718244 epoch total loss 1.21791208
Trained batch 4064 batch loss 1.2460705 epoch total loss 1.21791911
Trained batch 4065 batch loss 1.29636836 epoch total loss 1.2179383
Trained batch 4066 batch loss 1.05470085 epoch total loss 1.21789825
Trained batch 4067 batch loss 1.08152962 epoch total loss 1.21786463
Trained batch 4068 batch loss 1.1425221 epoch total loss 1.21784616
Trained batch 4069 batch loss 1.12035704 epoch total loss 1.21782219
Trained batch 4070 batch loss 1.06309235 epoch total loss 1.21778417
Trained batch 4071 batch loss 1.10211599 epoch total loss 1.21775568
Trained batch 4072 batch loss 1.36474252 epoch total loss 1.2177918
Trained batch 4073 batch loss 1.27981353 epoch total loss 1.21780705
Trained batch 4074 batch loss 1.12972546 epoch total loss 1.21778548
Trained batch 4075 batch loss 1.14583182 epoch total loss 1.21776783
Trained batch 4076 batch loss 1.05149293 epoch total loss 1.21772695
Trained batch 4077 batch loss 0.976865053 epoch total loss 1.21766794
Trained batch 4078 batch loss 1.22503948 epoch total loss 1.21766973
Trained batch 4079 batch loss 1.17025876 epoch total loss 1.21765816
Trained batch 4080 batch loss 1.22177219 epoch total loss 1.21765912
Trained batch 4081 batch loss 1.1112144 epoch total loss 1.21763313
Trained batch 4082 batch loss 1.24903142 epoch total loss 1.21764076
Trained batch 4083 batch loss 1.01702261 epoch total loss 1.21759164
Trained batch 4084 batch loss 1.12929177 epoch total loss 1.21757007
Trained batch 4085 batch loss 1.08473706 epoch total loss 1.21753764
Trained batch 4086 batch loss 1.15713811 epoch total loss 1.21752286
Trained batch 4087 batch loss 1.04173517 epoch total loss 1.21747983
Trained batch 4088 batch loss 1.2209667 epoch total loss 1.21748066
Trained batch 4089 batch loss 1.06229377 epoch total loss 1.21744275
Trained batch 4090 batch loss 1.26249802 epoch total loss 1.21745384
Trained batch 4091 batch loss 1.30705547 epoch total loss 1.21747577
Trained batch 4092 batch loss 1.11682844 epoch total loss 1.2174511
Trained batch 4093 batch loss 1.18017149 epoch total loss 1.21744204
Trained batch 4094 batch loss 1.11491084 epoch total loss 1.217417
Trained batch 4095 batch loss 1.09789979 epoch total loss 1.21738768
Trained batch 4096 batch loss 1.30853963 epoch total loss 1.21741
Trained batch 4097 batch loss 1.11570525 epoch total loss 1.21738517
Trained batch 4098 batch loss 1.03820539 epoch total loss 1.21734142
Trained batch 4099 batch loss 1.0127008 epoch total loss 1.21729147
Trained batch 4100 batch loss 1.2996366 epoch total loss 1.21731162
Trained batch 4101 batch loss 1.08694386 epoch total loss 1.21727979
Trained batch 4102 batch loss 1.34681249 epoch total loss 1.21731138
Trained batch 4103 batch loss 1.49037945 epoch total loss 1.2173779
Trained batch 4104 batch loss 1.2425983 epoch total loss 1.21738398
Trained batch 4105 batch loss 1.27790427 epoch total loss 1.21739876
Trained batch 4106 batch loss 1.37434077 epoch total loss 1.21743703
Trained batch 4107 batch loss 1.38818622 epoch total loss 1.21747863
Trained batch 4108 batch loss 1.3535018 epoch total loss 1.21751165
Trained batch 4109 batch loss 1.25780654 epoch total loss 1.21752155
Trained batch 4110 batch loss 1.30969191 epoch total loss 1.21754396
Trained batch 4111 batch loss 1.3681761 epoch total loss 1.21758056
Trained batch 4112 batch loss 1.1871779 epoch total loss 1.21757317
Trained batch 4113 batch loss 1.42194414 epoch total loss 1.21762276
Trained batch 4114 batch loss 1.41043472 epoch total loss 1.21766973
Trained batch 4115 batch loss 1.36295688 epoch total loss 1.21770501
Trained batch 4116 batch loss 1.06284833 epoch total loss 1.21766734
Trained batch 4117 batch loss 1.27950573 epoch total loss 1.21768236
Trained batch 4118 batch loss 1.16198993 epoch total loss 1.21766889
Trained batch 4119 batch loss 1.275002 epoch total loss 1.21768272
Trained batch 4120 batch loss 1.1066556 epoch total loss 1.21765578
Trained batch 4121 batch loss 1.1018151 epoch total loss 1.21762764
Trained batch 4122 batch loss 1.16620731 epoch total loss 1.21761513
Trained batch 4123 batch loss 1.35275924 epoch total loss 1.21764791
Trained batch 4124 batch loss 1.21091318 epoch total loss 1.21764624
Trained batch 4125 batch loss 1.11393023 epoch total loss 1.21762109
Trained batch 4126 batch loss 0.831008196 epoch total loss 1.21752739
Trained batch 4127 batch loss 0.880749464 epoch total loss 1.21744585
Trained batch 4128 batch loss 0.873069525 epoch total loss 1.2173624
Trained batch 4129 batch loss 1.12744355 epoch total loss 1.21734059
Trained batch 4130 batch loss 1.06078959 epoch total loss 1.21730268
Trained batch 4131 batch loss 1.15553522 epoch total loss 1.21728778
Trained batch 4132 batch loss 1.16225147 epoch total loss 1.21727443
Trained batch 4133 batch loss 1.16961 epoch total loss 1.21726286
Trained batch 4134 batch loss 1.34898043 epoch total loss 1.21729469
Trained batch 4135 batch loss 1.19913125 epoch total loss 1.2172904
Trained batch 4136 batch loss 1.1996088 epoch total loss 1.21728611
Trained batch 4137 batch loss 1.27284729 epoch total loss 1.21729958
Trained batch 4138 batch loss 1.33668709 epoch total loss 1.21732843
Trained batch 4139 batch loss 1.31951272 epoch total loss 1.21735311
Trained batch 4140 batch loss 1.3779459 epoch total loss 1.21739185
Trained batch 4141 batch loss 1.35425293 epoch total loss 1.21742499
Trained batch 4142 batch loss 1.30523944 epoch total loss 1.21744621
Trained batch 4143 batch loss 1.26658487 epoch total loss 1.21745801
Trained batch 4144 batch loss 1.23460448 epoch total loss 1.21746218
Trained batch 4145 batch loss 1.17675591 epoch total loss 1.21745229
Trained batch 4146 batch loss 1.25653791 epoch total loss 1.21746171
Trained batch 4147 batch loss 1.15220165 epoch total loss 1.21744597
Trained batch 4148 batch loss 1.13668919 epoch total loss 1.21742654
Trained batch 4149 batch loss 1.25590694 epoch total loss 1.21743584
Trained batch 4150 batch loss 1.0681994 epoch total loss 1.21739984
Trained batch 4151 batch loss 1.07595885 epoch total loss 1.21736586
Trained batch 4152 batch loss 1.29314053 epoch total loss 1.2173841
Trained batch 4153 batch loss 1.13952458 epoch total loss 1.21736538
Trained batch 4154 batch loss 1.12858462 epoch total loss 1.21734393
Trained batch 4155 batch loss 1.22305346 epoch total loss 1.21734536
Trained batch 4156 batch loss 1.17030287 epoch total loss 1.21733403
Trained batch 4157 batch loss 1.24037337 epoch total loss 1.21733952
Trained batch 4158 batch loss 1.32948029 epoch total loss 1.21736658
Trained batch 4159 batch loss 1.32430506 epoch total loss 1.21739221
Trained batch 4160 batch loss 1.11756885 epoch total loss 1.21736825
Trained batch 4161 batch loss 0.96039176 epoch total loss 1.21730649
Trained batch 4162 batch loss 0.976068079 epoch total loss 1.21724856
Trained batch 4163 batch loss 0.917861819 epoch total loss 1.21717668
Trained batch 4164 batch loss 0.95802629 epoch total loss 1.21711445
Trained batch 4165 batch loss 1.07838178 epoch total loss 1.21708119
Trained batch 4166 batch loss 1.08544064 epoch total loss 1.2170496
Trained batch 4167 batch loss 1.33655238 epoch total loss 1.21707821
Trained batch 4168 batch loss 1.44966638 epoch total loss 1.217134
Trained batch 4169 batch loss 1.36375284 epoch total loss 1.21716917
Trained batch 4170 batch loss 1.3120079 epoch total loss 1.21719193
Trained batch 4171 batch loss 1.45872426 epoch total loss 1.21724975
Trained batch 4172 batch loss 0.916051745 epoch total loss 1.21717763
Trained batch 4173 batch loss 0.726131678 epoch total loss 1.21706
Trained batch 4174 batch loss 1.19173 epoch total loss 1.21705389
Trained batch 4175 batch loss 1.35183239 epoch total loss 1.2170862
Trained batch 4176 batch loss 1.20744967 epoch total loss 1.21708393
Trained batch 4177 batch loss 1.30334163 epoch total loss 1.21710455
Trained batch 4178 batch loss 1.16670442 epoch total loss 1.21709239
Trained batch 4179 batch loss 1.32302773 epoch total loss 1.21711779
Trained batch 4180 batch loss 1.2755903 epoch total loss 1.21713173
Trained batch 4181 batch loss 1.25296223 epoch total loss 1.21714032
Trained batch 4182 batch loss 1.50618339 epoch total loss 1.21720946
Trained batch 4183 batch loss 1.3291285 epoch total loss 1.21723628
Trained batch 4184 batch loss 1.04385781 epoch total loss 1.2171948
Trained batch 4185 batch loss 0.96779573 epoch total loss 1.21713519
Trained batch 4186 batch loss 0.945398748 epoch total loss 1.21707034
Trained batch 4187 batch loss 0.939820111 epoch total loss 1.21700406
Trained batch 4188 batch loss 0.992551923 epoch total loss 1.21695054
Trained batch 4189 batch loss 1.07835221 epoch total loss 1.2169174
Trained batch 4190 batch loss 1.23418975 epoch total loss 1.21692157
Trained batch 4191 batch loss 1.51820374 epoch total loss 1.21699345
Trained batch 4192 batch loss 1.42821693 epoch total loss 1.21704376
Trained batch 4193 batch loss 1.31886792 epoch total loss 1.21706808
Trained batch 4194 batch loss 1.39133358 epoch total loss 1.21710956
Trained batch 4195 batch loss 1.37677 epoch total loss 1.21714771
Trained batch 4196 batch loss 1.50679219 epoch total loss 1.21721673
Trained batch 4197 batch loss 1.31911647 epoch total loss 1.21724105
Trained batch 4198 batch loss 1.33260489 epoch total loss 1.21726847
Trained batch 4199 batch loss 1.34775424 epoch total loss 1.21729958
Trained batch 4200 batch loss 1.08656812 epoch total loss 1.21726847
Trained batch 4201 batch loss 1.02162254 epoch total loss 1.21722186
Trained batch 4202 batch loss 1.05873919 epoch total loss 1.21718407
Trained batch 4203 batch loss 0.992502272 epoch total loss 1.21713066
Trained batch 4204 batch loss 0.982262313 epoch total loss 1.21707487
Trained batch 4205 batch loss 1.10213709 epoch total loss 1.21704745
Trained batch 4206 batch loss 1.04892755 epoch total loss 1.21700752
Trained batch 4207 batch loss 1.05553198 epoch total loss 1.21696913
Trained batch 4208 batch loss 0.931732059 epoch total loss 1.2169013
Trained batch 4209 batch loss 0.915317535 epoch total loss 1.21682966
Trained batch 4210 batch loss 1.02119946 epoch total loss 1.21678317
Trained batch 4211 batch loss 1.16279864 epoch total loss 1.21677029
Trained batch 4212 batch loss 1.03807247 epoch total loss 1.21672785
Trained batch 4213 batch loss 1.17057943 epoch total loss 1.21671689
Trained batch 4214 batch loss 1.05991983 epoch total loss 1.21667969
Trained batch 4215 batch loss 1.13055325 epoch total loss 1.21665931
Trained batch 4216 batch loss 1.02462494 epoch total loss 1.21661365
Trained batch 4217 batch loss 0.999735117 epoch total loss 1.21656215
Trained batch 4218 batch loss 1.1670773 epoch total loss 1.21655047
Trained batch 4219 batch loss 0.893013954 epoch total loss 1.2164737
Trained batch 4220 batch loss 1.02691031 epoch total loss 1.21642876
Trained batch 4221 batch loss 1.12106526 epoch total loss 1.21640623
Trained batch 4222 batch loss 1.22306228 epoch total loss 1.21640778
Trained batch 4223 batch loss 1.03413963 epoch total loss 1.21636462
Trained batch 4224 batch loss 0.891652822 epoch total loss 1.21628773
Trained batch 4225 batch loss 1.1873672 epoch total loss 1.21628094
Trained batch 4226 batch loss 1.11624873 epoch total loss 1.21625733
Trained batch 4227 batch loss 1.24742842 epoch total loss 1.21626472
Trained batch 4228 batch loss 1.03115571 epoch total loss 1.21622097
Trained batch 4229 batch loss 0.997746587 epoch total loss 1.21616924
Trained batch 4230 batch loss 1.03707635 epoch total loss 1.21612692
Trained batch 4231 batch loss 1.16870558 epoch total loss 1.21611571
Trained batch 4232 batch loss 1.33585334 epoch total loss 1.21614408
Trained batch 4233 batch loss 1.21315312 epoch total loss 1.21614337
Trained batch 4234 batch loss 1.10924017 epoch total loss 1.21611822
Trained batch 4235 batch loss 1.20685673 epoch total loss 1.21611607
Trained batch 4236 batch loss 0.97518003 epoch total loss 1.21605921
Trained batch 4237 batch loss 1.28413248 epoch total loss 1.21607518
Trained batch 4238 batch loss 1.18885565 epoch total loss 1.21606886
Trained batch 4239 batch loss 1.07056618 epoch total loss 1.21603453
Trained batch 4240 batch loss 1.39181614 epoch total loss 1.21607602
Trained batch 4241 batch loss 1.22516811 epoch total loss 1.21607804
Trained batch 4242 batch loss 1.20400643 epoch total loss 1.2160753
Trained batch 4243 batch loss 1.33960485 epoch total loss 1.21610439
Trained batch 4244 batch loss 1.31224585 epoch total loss 1.21612704
Trained batch 4245 batch loss 1.08477736 epoch total loss 1.21609616
Trained batch 4246 batch loss 1.22466886 epoch total loss 1.21609819
Trained batch 4247 batch loss 1.39011514 epoch total loss 1.21613908
Trained batch 4248 batch loss 1.1904763 epoch total loss 1.21613312
Trained batch 4249 batch loss 1.23663127 epoch total loss 1.21613789
Trained batch 4250 batch loss 1.14531159 epoch total loss 1.21612132
Trained batch 4251 batch loss 1.1907413 epoch total loss 1.21611536
Trained batch 4252 batch loss 1.07532609 epoch total loss 1.21608222
Trained batch 4253 batch loss 0.979380965 epoch total loss 1.21602666
Trained batch 4254 batch loss 0.995059729 epoch total loss 1.21597469
Trained batch 4255 batch loss 1.22337914 epoch total loss 1.21597636
Trained batch 4256 batch loss 1.16658354 epoch total loss 1.21596479
Trained batch 4257 batch loss 1.27883506 epoch total loss 1.21597958
Trained batch 4258 batch loss 1.30345988 epoch total loss 1.216
Trained batch 4259 batch loss 1.30777657 epoch total loss 1.21602154
Trained batch 4260 batch loss 1.38921833 epoch total loss 1.21606219
Trained batch 4261 batch loss 1.262784 epoch total loss 1.21607316
Trained batch 4262 batch loss 1.45827973 epoch total loss 1.21613
Trained batch 4263 batch loss 1.25061631 epoch total loss 1.21613801
Trained batch 4264 batch loss 1.32728815 epoch total loss 1.21616411
Trained batch 4265 batch loss 1.51921797 epoch total loss 1.21623504
Trained batch 4266 batch loss 1.40549231 epoch total loss 1.21627939
Trained batch 4267 batch loss 1.56644642 epoch total loss 1.2163614
Trained batch 4268 batch loss 1.49316072 epoch total loss 1.21642637
Trained batch 4269 batch loss 1.36753428 epoch total loss 1.21646178
Trained batch 4270 batch loss 1.47154558 epoch total loss 1.2165215
Trained batch 4271 batch loss 1.41869235 epoch total loss 1.21656883
Trained batch 4272 batch loss 1.36442518 epoch total loss 1.2166034
Trained batch 4273 batch loss 1.10384607 epoch total loss 1.21657705
Trained batch 4274 batch loss 1.07646608 epoch total loss 1.21654427
Trained batch 4275 batch loss 1.37401104 epoch total loss 1.21658111
Trained batch 4276 batch loss 1.40641761 epoch total loss 1.21662545
Trained batch 4277 batch loss 1.57684922 epoch total loss 1.21670961
Trained batch 4278 batch loss 1.2978555 epoch total loss 1.21672857
Trained batch 4279 batch loss 1.18733442 epoch total loss 1.21672177
Trained batch 4280 batch loss 1.44132805 epoch total loss 1.21677434
Trained batch 4281 batch loss 1.19817364 epoch total loss 1.21676993
Trained batch 4282 batch loss 1.16515183 epoch total loss 1.21675789
Trained batch 4283 batch loss 1.32662082 epoch total loss 1.21678352
Trained batch 4284 batch loss 1.19621098 epoch total loss 1.21677876
Trained batch 4285 batch loss 1.22513509 epoch total loss 1.21678066
Trained batch 4286 batch loss 1.20240974 epoch total loss 1.21677744
Trained batch 4287 batch loss 1.04818273 epoch total loss 1.2167381
Trained batch 4288 batch loss 1.14399385 epoch total loss 1.21672118
Trained batch 4289 batch loss 0.886308908 epoch total loss 1.21664405
Trained batch 4290 batch loss 1.02437019 epoch total loss 1.21659935
Trained batch 4291 batch loss 1.29542184 epoch total loss 1.2166177
Trained batch 4292 batch loss 1.21169901 epoch total loss 1.21661651
Trained batch 4293 batch loss 1.36938882 epoch total loss 1.21665215
Trained batch 4294 batch loss 1.145365 epoch total loss 1.21663558
Trained batch 4295 batch loss 1.21825767 epoch total loss 1.21663606
Trained batch 4296 batch loss 1.30883956 epoch total loss 1.21665752
Trained batch 4297 batch loss 1.19942081 epoch total loss 1.21665347
Trained batch 4298 batch loss 1.39627504 epoch total loss 1.21669531
Trained batch 4299 batch loss 1.46353436 epoch total loss 1.21675265
Trained batch 4300 batch loss 1.40055823 epoch total loss 1.21679544
Trained batch 4301 batch loss 1.40825 epoch total loss 1.21683991
Trained batch 4302 batch loss 1.33299088 epoch total loss 1.21686685
Trained batch 4303 batch loss 1.07258415 epoch total loss 1.21683347
Trained batch 4304 batch loss 1.10193074 epoch total loss 1.21680677
Trained batch 4305 batch loss 1.16405845 epoch total loss 1.21679449
Trained batch 4306 batch loss 1.18069398 epoch total loss 1.21678615
Trained batch 4307 batch loss 1.29284668 epoch total loss 1.21680379
Trained batch 4308 batch loss 1.11533368 epoch total loss 1.21678019
Trained batch 4309 batch loss 1.21556818 epoch total loss 1.21677983
Trained batch 4310 batch loss 1.02208388 epoch total loss 1.21673465
Trained batch 4311 batch loss 1.06201231 epoch total loss 1.21669877
Trained batch 4312 batch loss 1.16041958 epoch total loss 1.21668577
Trained batch 4313 batch loss 1.08528137 epoch total loss 1.21665537
Trained batch 4314 batch loss 1.1093061 epoch total loss 1.21663046
Trained batch 4315 batch loss 1.23140931 epoch total loss 1.21663392
Trained batch 4316 batch loss 1.04611075 epoch total loss 1.21659434
Trained batch 4317 batch loss 1.00204635 epoch total loss 1.21654463
Trained batch 4318 batch loss 1.07269382 epoch total loss 1.21651137
Trained batch 4319 batch loss 1.00485122 epoch total loss 1.21646237
Trained batch 4320 batch loss 1.10759568 epoch total loss 1.2164371
Trained batch 4321 batch loss 0.975316 epoch total loss 1.21638131
Trained batch 4322 batch loss 1.07016551 epoch total loss 1.21634746
Trained batch 4323 batch loss 1.15654778 epoch total loss 1.21633363
Trained batch 4324 batch loss 1.13385439 epoch total loss 1.21631455
Trained batch 4325 batch loss 1.19368553 epoch total loss 1.21630943
Trained batch 4326 batch loss 1.13212061 epoch total loss 1.21629
Trained batch 4327 batch loss 1.07509291 epoch total loss 1.21625733
Trained batch 4328 batch loss 1.20741403 epoch total loss 1.21625531
Trained batch 4329 batch loss 1.13587403 epoch total loss 1.21623671
Trained batch 4330 batch loss 0.979881644 epoch total loss 1.21618223
Trained batch 4331 batch loss 0.984334528 epoch total loss 1.21612871
Trained batch 4332 batch loss 0.963977873 epoch total loss 1.21607041
Trained batch 4333 batch loss 1.19523501 epoch total loss 1.21606565
Trained batch 4334 batch loss 1.16551185 epoch total loss 1.21605396
Trained batch 4335 batch loss 1.20337188 epoch total loss 1.2160511
Trained batch 4336 batch loss 1.16270399 epoch total loss 1.21603882
Trained batch 4337 batch loss 1.18939841 epoch total loss 1.21603262
Trained batch 4338 batch loss 1.34456718 epoch total loss 1.21606231
Trained batch 4339 batch loss 1.23935318 epoch total loss 1.21606767
Trained batch 4340 batch loss 1.36984396 epoch total loss 1.21610308
Trained batch 4341 batch loss 1.23279297 epoch total loss 1.21610689
Trained batch 4342 batch loss 1.05619729 epoch total loss 1.21607
Trained batch 4343 batch loss 1.07025552 epoch total loss 1.21603656
Trained batch 4344 batch loss 1.03822732 epoch total loss 1.21599555
Trained batch 4345 batch loss 1.10237646 epoch total loss 1.21596944
Trained batch 4346 batch loss 1.25743055 epoch total loss 1.21597898
Trained batch 4347 batch loss 1.38822567 epoch total loss 1.21601856
Trained batch 4348 batch loss 1.33889019 epoch total loss 1.21604681
Trained batch 4349 batch loss 1.05671 epoch total loss 1.21601021
Trained batch 4350 batch loss 1.46945059 epoch total loss 1.21606839
Trained batch 4351 batch loss 1.48563457 epoch total loss 1.21613038
Trained batch 4352 batch loss 1.54164767 epoch total loss 1.21620512
Trained batch 4353 batch loss 1.26728404 epoch total loss 1.2162168
Trained batch 4354 batch loss 1.37685466 epoch total loss 1.21625376
Trained batch 4355 batch loss 1.1343348 epoch total loss 1.21623492
Trained batch 4356 batch loss 0.993688464 epoch total loss 1.21618378
Trained batch 4357 batch loss 1.30687046 epoch total loss 1.21620464
Trained batch 4358 batch loss 1.1243279 epoch total loss 1.21618354
Trained batch 4359 batch loss 1.18831229 epoch total loss 1.21617723
Trained batch 4360 batch loss 1.12814021 epoch total loss 1.21615696
Trained batch 4361 batch loss 1.15659475 epoch total loss 1.21614337
Trained batch 4362 batch loss 1.15717602 epoch total loss 1.21612978
Trained batch 4363 batch loss 1.14337254 epoch total loss 1.21611321
Trained batch 4364 batch loss 1.17540467 epoch total loss 1.21610379
Trained batch 4365 batch loss 1.16765201 epoch total loss 1.21609271
Trained batch 4366 batch loss 1.00908327 epoch total loss 1.21604538
Trained batch 4367 batch loss 0.979222536 epoch total loss 1.21599102
Trained batch 4368 batch loss 1.13593292 epoch total loss 1.21597266
Trained batch 4369 batch loss 1.22782397 epoch total loss 1.2159754
Trained batch 4370 batch loss 0.925991654 epoch total loss 1.215909
Trained batch 4371 batch loss 0.985938311 epoch total loss 1.21585643
Trained batch 4372 batch loss 1.14763308 epoch total loss 1.2158407
Trained batch 4373 batch loss 1.06421304 epoch total loss 1.21580613
Trained batch 4374 batch loss 1.22236013 epoch total loss 1.21580756
Trained batch 4375 batch loss 1.24404454 epoch total loss 1.21581411
Trained batch 4376 batch loss 1.25613379 epoch total loss 1.21582329
Trained batch 4377 batch loss 1.17404699 epoch total loss 1.21581376
Trained batch 4378 batch loss 1.3221209 epoch total loss 1.21583807
Trained batch 4379 batch loss 1.23278666 epoch total loss 1.21584189
Trained batch 4380 batch loss 1.32598376 epoch total loss 1.21586716
Trained batch 4381 batch loss 1.2981813 epoch total loss 1.215886
Trained batch 4382 batch loss 1.11648893 epoch total loss 1.21586335
Trained batch 4383 batch loss 1.36601818 epoch total loss 1.21589768
Trained batch 4384 batch loss 1.16084409 epoch total loss 1.21588504
Trained batch 4385 batch loss 0.895969033 epoch total loss 1.21581209
Trained batch 4386 batch loss 1.12806058 epoch total loss 1.21579206
Trained batch 4387 batch loss 1.04871869 epoch total loss 1.21575403
Trained batch 4388 batch loss 1.12468135 epoch total loss 1.21573317
Trained batch 4389 batch loss 0.92912519 epoch total loss 1.21566784
Trained batch 4390 batch loss 1.17624521 epoch total loss 1.2156589
Trained batch 4391 batch loss 1.12943912 epoch total loss 1.21563923
Trained batch 4392 batch loss 0.98712492 epoch total loss 1.21558726
Trained batch 4393 batch loss 0.994522333 epoch total loss 1.21553695
Trained batch 4394 batch loss 0.987965107 epoch total loss 1.21548522
Trained batch 4395 batch loss 1.31320453 epoch total loss 1.21550739
Trained batch 4396 batch loss 1.33379626 epoch total loss 1.21553433
Trained batch 4397 batch loss 1.38903677 epoch total loss 1.21557379
Trained batch 4398 batch loss 1.31305337 epoch total loss 1.21559596
Trained batch 4399 batch loss 1.35303795 epoch total loss 1.21562719
Trained batch 4400 batch loss 1.64105713 epoch total loss 1.21572387
Trained batch 4401 batch loss 1.32890701 epoch total loss 1.21574962
Trained batch 4402 batch loss 1.22299886 epoch total loss 1.21575129
Trained batch 4403 batch loss 1.23350894 epoch total loss 1.21575534
Trained batch 4404 batch loss 1.128528 epoch total loss 1.21573555
Trained batch 4405 batch loss 1.1215322 epoch total loss 1.2157141
Trained batch 4406 batch loss 1.20577574 epoch total loss 1.21571183
Trained batch 4407 batch loss 1.16226649 epoch total loss 1.21569967
Trained batch 4408 batch loss 1.24030733 epoch total loss 1.21570528
Trained batch 4409 batch loss 1.2573241 epoch total loss 1.21571469
Trained batch 4410 batch loss 1.09076655 epoch total loss 1.21568632
Trained batch 4411 batch loss 1.09430194 epoch total loss 1.21565878
Trained batch 4412 batch loss 0.906885 epoch total loss 1.21558881
Trained batch 4413 batch loss 0.822638094 epoch total loss 1.21549976
Trained batch 4414 batch loss 0.959275424 epoch total loss 1.21544182
Trained batch 4415 batch loss 0.822979152 epoch total loss 1.21535277
Trained batch 4416 batch loss 0.810952544 epoch total loss 1.21526122
Trained batch 4417 batch loss 0.803691506 epoch total loss 1.21516812
Trained batch 4418 batch loss 0.870274425 epoch total loss 1.21509
Trained batch 4419 batch loss 0.715036452 epoch total loss 1.21497679
Trained batch 4420 batch loss 0.694284081 epoch total loss 1.21485901
Trained batch 4421 batch loss 1.10914302 epoch total loss 1.21483517
Trained batch 4422 batch loss 1.18581164 epoch total loss 1.21482861
Trained batch 4423 batch loss 0.865789235 epoch total loss 1.21474969
Trained batch 4424 batch loss 1.08015144 epoch total loss 1.2147193
Trained batch 4425 batch loss 0.917823672 epoch total loss 1.21465218
Trained batch 4426 batch loss 1.01035714 epoch total loss 1.21460605
Trained batch 4427 batch loss 1.27377772 epoch total loss 1.2146194
Trained batch 4428 batch loss 1.19498551 epoch total loss 1.21461499
Trained batch 4429 batch loss 1.24727106 epoch total loss 1.21462226
Trained batch 4430 batch loss 1.21096992 epoch total loss 1.21462142
Trained batch 4431 batch loss 1.31292105 epoch total loss 1.2146436
Trained batch 4432 batch loss 1.31285548 epoch total loss 1.21466577
Trained batch 4433 batch loss 1.30884886 epoch total loss 1.21468711
Trained batch 4434 batch loss 1.46825182 epoch total loss 1.21474433
Trained batch 4435 batch loss 1.48858058 epoch total loss 1.21480608
Trained batch 4436 batch loss 1.34675789 epoch total loss 1.21483588
Trained batch 4437 batch loss 1.22446871 epoch total loss 1.21483803
Trained batch 4438 batch loss 1.08323514 epoch total loss 1.21480834
Trained batch 4439 batch loss 1.11634445 epoch total loss 1.21478605
Trained batch 4440 batch loss 1.15219307 epoch total loss 1.21477211
Trained batch 4441 batch loss 1.05571175 epoch total loss 1.21473622
Trained batch 4442 batch loss 1.31214988 epoch total loss 1.21475816
Trained batch 4443 batch loss 1.39280653 epoch total loss 1.21479809
Trained batch 4444 batch loss 1.31799173 epoch total loss 1.21482134
Trained batch 4445 batch loss 1.38853884 epoch total loss 1.21486044
Trained batch 4446 batch loss 1.20878375 epoch total loss 1.21485913
Trained batch 4447 batch loss 1.36549139 epoch total loss 1.2148931
Trained batch 4448 batch loss 1.22385979 epoch total loss 1.21489501
Trained batch 4449 batch loss 1.12038374 epoch total loss 1.21487379
Trained batch 4450 batch loss 1.19563043 epoch total loss 1.2148695
Trained batch 4451 batch loss 1.3312037 epoch total loss 1.21489561
Trained batch 4452 batch loss 1.33372593 epoch total loss 1.21492231
Trained batch 4453 batch loss 1.24492455 epoch total loss 1.2149291
Trained batch 4454 batch loss 1.21994305 epoch total loss 1.21493018
Trained batch 4455 batch loss 1.17584944 epoch total loss 1.21492136
Trained batch 4456 batch loss 1.36148381 epoch total loss 1.21495426
Trained batch 4457 batch loss 1.51974273 epoch total loss 1.21502256
Trained batch 4458 batch loss 1.21297431 epoch total loss 1.21502209
Trained batch 4459 batch loss 1.21950376 epoch total loss 1.21502316
Trained batch 4460 batch loss 1.49784815 epoch total loss 1.21508658
Trained batch 4461 batch loss 1.47793376 epoch total loss 1.21514547
Trained batch 4462 batch loss 1.47148693 epoch total loss 1.21520305
Trained batch 4463 batch loss 1.4903357 epoch total loss 1.21526468
Trained batch 4464 batch loss 1.39558661 epoch total loss 1.21530497
Trained batch 4465 batch loss 1.32290196 epoch total loss 1.21532905
Trained batch 4466 batch loss 1.26917207 epoch total loss 1.21534109
Trained batch 4467 batch loss 1.17791259 epoch total loss 1.21533275
Trained batch 4468 batch loss 0.917848587 epoch total loss 1.21526611
Trained batch 4469 batch loss 1.01011813 epoch total loss 1.21522021
Trained batch 4470 batch loss 1.18714368 epoch total loss 1.21521389
Trained batch 4471 batch loss 1.36112785 epoch total loss 1.21524668
Trained batch 4472 batch loss 1.31763411 epoch total loss 1.21526957
Trained batch 4473 batch loss 1.31709361 epoch total loss 1.21529233
Trained batch 4474 batch loss 1.34549904 epoch total loss 1.21532142
Trained batch 4475 batch loss 1.38024175 epoch total loss 1.21535838
Trained batch 4476 batch loss 1.34946847 epoch total loss 1.2153883
Trained batch 4477 batch loss 1.29361963 epoch total loss 1.2154057
Trained batch 4478 batch loss 1.08204424 epoch total loss 1.21537602
Trained batch 4479 batch loss 1.16186094 epoch total loss 1.21536398
Trained batch 4480 batch loss 1.16032553 epoch total loss 1.2153517
Trained batch 4481 batch loss 1.38220549 epoch total loss 1.21538889
Trained batch 4482 batch loss 1.41879153 epoch total loss 1.21543431
Trained batch 4483 batch loss 1.25764537 epoch total loss 1.21544373
Trained batch 4484 batch loss 1.39569807 epoch total loss 1.2154839
Trained batch 4485 batch loss 1.20189464 epoch total loss 1.2154808
Trained batch 4486 batch loss 1.09330845 epoch total loss 1.21545362
Trained batch 4487 batch loss 1.32058191 epoch total loss 1.21547711
Trained batch 4488 batch loss 1.20885611 epoch total loss 1.21547568
Trained batch 4489 batch loss 1.27470303 epoch total loss 1.21548891
Trained batch 4490 batch loss 1.0736897 epoch total loss 1.21545732
Trained batch 4491 batch loss 1.19140899 epoch total loss 1.21545196
Trained batch 4492 batch loss 1.22559988 epoch total loss 1.21545422
Trained batch 4493 batch loss 1.03746486 epoch total loss 1.21541464
Trained batch 4494 batch loss 1.04186583 epoch total loss 1.21537602
Trained batch 4495 batch loss 1.5608809 epoch total loss 1.21545291
Trained batch 4496 batch loss 1.26744199 epoch total loss 1.21546447
Trained batch 4497 batch loss 1.18016803 epoch total loss 1.21545672
Trained batch 4498 batch loss 1.0478822 epoch total loss 1.21541941
Trained batch 4499 batch loss 0.962281823 epoch total loss 1.21536314
Trained batch 4500 batch loss 1.25082684 epoch total loss 1.21537113
Trained batch 4501 batch loss 1.28154945 epoch total loss 1.21538579
Trained batch 4502 batch loss 1.50654364 epoch total loss 1.21545053
Trained batch 4503 batch loss 1.42038524 epoch total loss 1.21549594
Trained batch 4504 batch loss 1.42488456 epoch total loss 1.21554244
Trained batch 4505 batch loss 1.11899805 epoch total loss 1.2155211
Trained batch 4506 batch loss 1.01916897 epoch total loss 1.21547747
Trained batch 4507 batch loss 1.10987663 epoch total loss 1.21545398
Trained batch 4508 batch loss 1.33951581 epoch total loss 1.21548152
Trained batch 4509 batch loss 1.33913612 epoch total loss 1.21550894
Trained batch 4510 batch loss 0.902538419 epoch total loss 1.21543956
Trained batch 4511 batch loss 0.967309713 epoch total loss 1.21538448
Trained batch 4512 batch loss 1.27314317 epoch total loss 1.21539724
Trained batch 4513 batch loss 1.15486646 epoch total loss 1.21538389
Trained batch 4514 batch loss 1.20864701 epoch total loss 1.21538234
Trained batch 4515 batch loss 1.14839768 epoch total loss 1.21536756
Trained batch 4516 batch loss 1.01799154 epoch total loss 1.21532381
Trained batch 4517 batch loss 1.32193661 epoch total loss 1.21534741
Trained batch 4518 batch loss 1.26060295 epoch total loss 1.21535742
Trained batch 4519 batch loss 1.28179121 epoch total loss 1.21537209
Trained batch 4520 batch loss 1.43565893 epoch total loss 1.21542084
Trained batch 4521 batch loss 1.5907799 epoch total loss 1.21550381
Trained batch 4522 batch loss 1.50596738 epoch total loss 1.21556807
Trained batch 4523 batch loss 1.50547886 epoch total loss 1.2156322
Trained batch 4524 batch loss 1.51748908 epoch total loss 1.21569884
Trained batch 4525 batch loss 1.19899583 epoch total loss 1.21569526
Trained batch 4526 batch loss 1.41583955 epoch total loss 1.21573949
Trained batch 4527 batch loss 1.40829241 epoch total loss 1.21578205
Trained batch 4528 batch loss 1.07696855 epoch total loss 1.21575141
Trained batch 4529 batch loss 1.25424147 epoch total loss 1.21576
Trained batch 4530 batch loss 1.39998972 epoch total loss 1.21580064
Trained batch 4531 batch loss 1.27002478 epoch total loss 1.21581256
Trained batch 4532 batch loss 1.17095447 epoch total loss 1.21580267
Trained batch 4533 batch loss 1.21630025 epoch total loss 1.21580279
Trained batch 4534 batch loss 1.35982895 epoch total loss 1.2158345
Trained batch 4535 batch loss 1.37829614 epoch total loss 1.21587038
Trained batch 4536 batch loss 1.13560033 epoch total loss 1.21585274
Trained batch 4537 batch loss 1.02687669 epoch total loss 1.21581101
Trained batch 4538 batch loss 1.03369617 epoch total loss 1.21577096
Trained batch 4539 batch loss 1.24536669 epoch total loss 1.21577752
Trained batch 4540 batch loss 1.37324858 epoch total loss 1.21581209
Trained batch 4541 batch loss 1.2242806 epoch total loss 1.21581399
Trained batch 4542 batch loss 1.33386469 epoch total loss 1.21584
Trained batch 4543 batch loss 1.25146 epoch total loss 1.21584785
Trained batch 4544 batch loss 1.00192451 epoch total loss 1.21580076
Trained batch 4545 batch loss 0.849064 epoch total loss 1.21572
Trained batch 4546 batch loss 1.1233573 epoch total loss 1.21569979
Trained batch 4547 batch loss 1.19220161 epoch total loss 1.21569467
Trained batch 4548 batch loss 1.44792318 epoch total loss 1.21574569
Trained batch 4549 batch loss 1.36876225 epoch total loss 1.2157793
Trained batch 4550 batch loss 1.21777618 epoch total loss 1.21577978
Trained batch 4551 batch loss 1.19849491 epoch total loss 1.21577597
Trained batch 4552 batch loss 1.10646951 epoch total loss 1.21575201
Trained batch 4553 batch loss 1.15560794 epoch total loss 1.21573877
Trained batch 4554 batch loss 1.47277904 epoch total loss 1.21579528
Trained batch 4555 batch loss 1.05676126 epoch total loss 1.21576023
Trained batch 4556 batch loss 1.07116139 epoch total loss 1.21572852
Trained batch 4557 batch loss 0.965424955 epoch total loss 1.21567357
Trained batch 4558 batch loss 0.844219863 epoch total loss 1.21559215
Trained batch 4559 batch loss 1.13332534 epoch total loss 1.21557403
Trained batch 4560 batch loss 1.13974965 epoch total loss 1.21555746
Trained batch 4561 batch loss 1.12505007 epoch total loss 1.21553755
Trained batch 4562 batch loss 0.897066712 epoch total loss 1.21546769
Trained batch 4563 batch loss 0.947398782 epoch total loss 1.21540892
Trained batch 4564 batch loss 0.907206774 epoch total loss 1.21534145
Trained batch 4565 batch loss 1.03657794 epoch total loss 1.21530235
Trained batch 4566 batch loss 1.06830657 epoch total loss 1.21527016
Trained batch 4567 batch loss 0.874259949 epoch total loss 1.21519542
Trained batch 4568 batch loss 1.08275914 epoch total loss 1.21516633
Trained batch 4569 batch loss 0.873039842 epoch total loss 1.21509147
Trained batch 4570 batch loss 0.987715244 epoch total loss 1.21504176
Trained batch 4571 batch loss 0.908644259 epoch total loss 1.21497476
Trained batch 4572 batch loss 1.19338059 epoch total loss 1.21497
Trained batch 4573 batch loss 1.30310786 epoch total loss 1.2149893
Trained batch 4574 batch loss 1.49189925 epoch total loss 1.21504974
Trained batch 4575 batch loss 1.3691169 epoch total loss 1.21508348
Trained batch 4576 batch loss 1.43239951 epoch total loss 1.21513104
Trained batch 4577 batch loss 1.48359179 epoch total loss 1.21518958
Trained batch 4578 batch loss 1.58887267 epoch total loss 1.21527123
Trained batch 4579 batch loss 1.56409168 epoch total loss 1.21534741
Trained batch 4580 batch loss 1.37966835 epoch total loss 1.21538329
Trained batch 4581 batch loss 1.25614858 epoch total loss 1.21539223
Trained batch 4582 batch loss 1.26164949 epoch total loss 1.21540236
Trained batch 4583 batch loss 1.57646298 epoch total loss 1.21548116
Trained batch 4584 batch loss 1.50647116 epoch total loss 1.2155447
Trained batch 4585 batch loss 1.39221764 epoch total loss 1.21558321
Trained batch 4586 batch loss 1.38634253 epoch total loss 1.2156204
Trained batch 4587 batch loss 1.31649494 epoch total loss 1.21564233
Trained batch 4588 batch loss 1.15150487 epoch total loss 1.21562827
Trained batch 4589 batch loss 1.11118805 epoch total loss 1.21560562
Trained batch 4590 batch loss 1.57021308 epoch total loss 1.21568286
Trained batch 4591 batch loss 1.36854911 epoch total loss 1.21571624
Trained batch 4592 batch loss 1.30895853 epoch total loss 1.21573651
Trained batch 4593 batch loss 1.15361869 epoch total loss 1.21572304
Trained batch 4594 batch loss 1.47813606 epoch total loss 1.21578014
Trained batch 4595 batch loss 1.38717628 epoch total loss 1.21581745
Trained batch 4596 batch loss 1.3787396 epoch total loss 1.21585298
Trained batch 4597 batch loss 1.47108889 epoch total loss 1.21590853
Trained batch 4598 batch loss 1.21968353 epoch total loss 1.21590936
Trained batch 4599 batch loss 1.26602364 epoch total loss 1.21592021
Trained batch 4600 batch loss 1.19313979 epoch total loss 1.21591532
Trained batch 4601 batch loss 1.03200054 epoch total loss 1.21587539
Trained batch 4602 batch loss 1.05725968 epoch total loss 1.21584094
Trained batch 4603 batch loss 1.04835176 epoch total loss 1.21580446
Trained batch 4604 batch loss 1.01828575 epoch total loss 1.21576154
Trained batch 4605 batch loss 1.08242178 epoch total loss 1.21573257
Trained batch 4606 batch loss 1.22000551 epoch total loss 1.21573365
Trained batch 4607 batch loss 1.11115336 epoch total loss 1.21571088
Trained batch 4608 batch loss 0.974688232 epoch total loss 1.21565866
Trained batch 4609 batch loss 1.19435465 epoch total loss 1.21565402
Trained batch 4610 batch loss 1.22813046 epoch total loss 1.21565664
Trained batch 4611 batch loss 1.00152779 epoch total loss 1.21561027
Trained batch 4612 batch loss 1.23700619 epoch total loss 1.2156148
Trained batch 4613 batch loss 1.16149771 epoch total loss 1.21560311
Trained batch 4614 batch loss 1.2270534 epoch total loss 1.21560562
Trained batch 4615 batch loss 1.30111969 epoch total loss 1.21562409
Trained batch 4616 batch loss 1.25966311 epoch total loss 1.21563375
Trained batch 4617 batch loss 1.46954799 epoch total loss 1.21568871
Trained batch 4618 batch loss 1.16255927 epoch total loss 1.21567726
Trained batch 4619 batch loss 1.1826241 epoch total loss 1.21567011
Trained batch 4620 batch loss 0.997898161 epoch total loss 1.21562302
Trained batch 4621 batch loss 1.3388586 epoch total loss 1.2156496
Trained batch 4622 batch loss 0.981185734 epoch total loss 1.21559894
Trained batch 4623 batch loss 1.35800016 epoch total loss 1.2156297
Trained batch 4624 batch loss 1.3962338 epoch total loss 1.21566868
Trained batch 4625 batch loss 1.3794446 epoch total loss 1.21570408
Trained batch 4626 batch loss 1.26418614 epoch total loss 1.21571457
Trained batch 4627 batch loss 1.40760016 epoch total loss 1.21575606
Trained batch 4628 batch loss 1.24701476 epoch total loss 1.21576285
Trained batch 4629 batch loss 1.19872069 epoch total loss 1.21575916
Trained batch 4630 batch loss 1.24618638 epoch total loss 1.21576571
Trained batch 4631 batch loss 1.47326887 epoch total loss 1.21582127
Trained batch 4632 batch loss 1.43368506 epoch total loss 1.21586823
Trained batch 4633 batch loss 1.04523969 epoch total loss 1.21583152
Trained batch 4634 batch loss 0.939414561 epoch total loss 1.21577179
Trained batch 4635 batch loss 1.13315701 epoch total loss 1.21575403
Trained batch 4636 batch loss 1.43515682 epoch total loss 1.21580136
Trained batch 4637 batch loss 1.22751617 epoch total loss 1.21580386
Trained batch 4638 batch loss 1.39364481 epoch total loss 1.21584225
Trained batch 4639 batch loss 1.38531899 epoch total loss 1.21587873
Trained batch 4640 batch loss 0.980343282 epoch total loss 1.21582794
Trained batch 4641 batch loss 1.22886157 epoch total loss 1.2158308
Trained batch 4642 batch loss 1.21393073 epoch total loss 1.21583045
Trained batch 4643 batch loss 1.09247684 epoch total loss 1.21580374
Trained batch 4644 batch loss 1.17723823 epoch total loss 1.21579552
Trained batch 4645 batch loss 1.14900327 epoch total loss 1.21578109
Trained batch 4646 batch loss 1.17583609 epoch total loss 1.21577251
Trained batch 4647 batch loss 1.13241 epoch total loss 1.21575451
Trained batch 4648 batch loss 1.14944863 epoch total loss 1.2157402
Trained batch 4649 batch loss 1.33501124 epoch total loss 1.21576595
Trained batch 4650 batch loss 1.21084619 epoch total loss 1.21576488
Trained batch 4651 batch loss 1.29616165 epoch total loss 1.21578217
Trained batch 4652 batch loss 1.35596836 epoch total loss 1.21581233
Trained batch 4653 batch loss 1.34366536 epoch total loss 1.21583986
Trained batch 4654 batch loss 1.2871474 epoch total loss 1.21585512
Trained batch 4655 batch loss 1.40736544 epoch total loss 1.21589625
Trained batch 4656 batch loss 1.19859338 epoch total loss 1.21589255
Trained batch 4657 batch loss 1.28784788 epoch total loss 1.21590805
Trained batch 4658 batch loss 1.22227204 epoch total loss 1.21590936
Trained batch 4659 batch loss 1.36789584 epoch total loss 1.21594203
Trained batch 4660 batch loss 1.41629755 epoch total loss 1.21598506
Trained batch 4661 batch loss 1.05245161 epoch total loss 1.21594989
Trained batch 4662 batch loss 0.917911768 epoch total loss 1.215886
Trained batch 4663 batch loss 1.05735946 epoch total loss 1.2158519
Trained batch 4664 batch loss 1.24124765 epoch total loss 1.21585739
Trained batch 4665 batch loss 1.13836384 epoch total loss 1.2158407
Trained batch 4666 batch loss 1.20066905 epoch total loss 1.21583748
Trained batch 4667 batch loss 1.36575806 epoch total loss 1.21586955
Trained batch 4668 batch loss 1.31508577 epoch total loss 1.21589077
Trained batch 4669 batch loss 1.32366478 epoch total loss 1.21591389
Trained batch 4670 batch loss 1.28316498 epoch total loss 1.21592832
Trained batch 4671 batch loss 1.36538172 epoch total loss 1.21596026
Trained batch 4672 batch loss 1.3264029 epoch total loss 1.21598387
Trained batch 4673 batch loss 1.3005985 epoch total loss 1.21600199
Trained batch 4674 batch loss 1.41333604 epoch total loss 1.21604431
Trained batch 4675 batch loss 1.40380812 epoch total loss 1.21608448
Trained batch 4676 batch loss 1.30783248 epoch total loss 1.21610403
Trained batch 4677 batch loss 1.27268505 epoch total loss 1.21611607
Trained batch 4678 batch loss 1.27753782 epoch total loss 1.21612918
Trained batch 4679 batch loss 1.01029897 epoch total loss 1.2160852
Trained batch 4680 batch loss 1.03544664 epoch total loss 1.21604657
Trained batch 4681 batch loss 1.08247697 epoch total loss 1.21601808
Trained batch 4682 batch loss 1.05540097 epoch total loss 1.21598375
Trained batch 4683 batch loss 1.29727042 epoch total loss 1.21600115
Trained batch 4684 batch loss 1.39306474 epoch total loss 1.21603894
Trained batch 4685 batch loss 1.14542425 epoch total loss 1.2160238
Trained batch 4686 batch loss 1.27265501 epoch total loss 1.21603584
Trained batch 4687 batch loss 1.16412878 epoch total loss 1.21602476
Trained batch 4688 batch loss 0.987445354 epoch total loss 1.215976
Trained batch 4689 batch loss 1.23390913 epoch total loss 1.21597981
Trained batch 4690 batch loss 1.13253975 epoch total loss 1.21596205
Trained batch 4691 batch loss 1.12044907 epoch total loss 1.21594167
Trained batch 4692 batch loss 1.32537532 epoch total loss 1.21596491
Trained batch 4693 batch loss 1.31077456 epoch total loss 1.21598506
Trained batch 4694 batch loss 1.34304547 epoch total loss 1.21601224
Trained batch 4695 batch loss 1.17927897 epoch total loss 1.21600437
Trained batch 4696 batch loss 1.3853097 epoch total loss 1.21604049
Trained batch 4697 batch loss 1.20889783 epoch total loss 1.21603894
Trained batch 4698 batch loss 1.08831191 epoch total loss 1.21601176
Trained batch 4699 batch loss 1.2141856 epoch total loss 1.2160114
Trained batch 4700 batch loss 1.29636657 epoch total loss 1.21602845
Trained batch 4701 batch loss 1.30955172 epoch total loss 1.21604836
Trained batch 4702 batch loss 1.42559242 epoch total loss 1.21609306
Trained batch 4703 batch loss 1.57233441 epoch total loss 1.21616876
Trained batch 4704 batch loss 1.35123909 epoch total loss 1.21619737
Trained batch 4705 batch loss 1.37335873 epoch total loss 1.21623087
Trained batch 4706 batch loss 1.48147202 epoch total loss 1.21628726
Trained batch 4707 batch loss 1.30385876 epoch total loss 1.21630585
Trained batch 4708 batch loss 1.3067435 epoch total loss 1.21632493
Trained batch 4709 batch loss 1.32681918 epoch total loss 1.21634841
Trained batch 4710 batch loss 1.51076937 epoch total loss 1.21641088
Trained batch 4711 batch loss 1.54358947 epoch total loss 1.21648037
Trained batch 4712 batch loss 1.4417 epoch total loss 1.21652818
Trained batch 4713 batch loss 1.50249648 epoch total loss 1.21658885
Trained batch 4714 batch loss 1.4118576 epoch total loss 1.21663022
Trained batch 4715 batch loss 1.27398634 epoch total loss 1.21664238
Trained batch 4716 batch loss 1.264992 epoch total loss 1.21665263
Trained batch 4717 batch loss 0.999605775 epoch total loss 1.21660662
Trained batch 4718 batch loss 0.966492534 epoch total loss 1.21655357
Trained batch 4719 batch loss 0.984147608 epoch total loss 1.21650434
Trained batch 4720 batch loss 0.941782355 epoch total loss 1.21644616
Trained batch 4721 batch loss 0.911795855 epoch total loss 1.21638167
Trained batch 4722 batch loss 1.05751908 epoch total loss 1.21634793
Trained batch 4723 batch loss 1.14554417 epoch total loss 1.21633303
Trained batch 4724 batch loss 1.2613349 epoch total loss 1.21634245
Trained batch 4725 batch loss 1.47612667 epoch total loss 1.21639752
Trained batch 4726 batch loss 1.20031452 epoch total loss 1.21639407
Trained batch 4727 batch loss 1.04228401 epoch total loss 1.21635723
Trained batch 4728 batch loss 1.38993168 epoch total loss 1.21639395
Trained batch 4729 batch loss 1.17418933 epoch total loss 1.21638513
Trained batch 4730 batch loss 1.16190231 epoch total loss 1.21637368
Trained batch 4731 batch loss 1.01877785 epoch total loss 1.21633184
Trained batch 4732 batch loss 1.06092536 epoch total loss 1.21629894
Trained batch 4733 batch loss 1.06951034 epoch total loss 1.21626794
Trained batch 4734 batch loss 0.893229067 epoch total loss 1.21619964
Trained batch 4735 batch loss 0.942727804 epoch total loss 1.21614194
Trained batch 4736 batch loss 1.08064151 epoch total loss 1.21611333
Trained batch 4737 batch loss 1.04198909 epoch total loss 1.21607661
Trained batch 4738 batch loss 0.899545133 epoch total loss 1.21600974
Trained batch 4739 batch loss 1.01112759 epoch total loss 1.21596646
Trained batch 4740 batch loss 1.17920852 epoch total loss 1.21595871
Trained batch 4741 batch loss 1.09532404 epoch total loss 1.21593332
Trained batch 4742 batch loss 0.798726618 epoch total loss 1.21584535
Trained batch 4743 batch loss 1.23983526 epoch total loss 1.21585035
Trained batch 4744 batch loss 1.25669265 epoch total loss 1.21585906
Trained batch 4745 batch loss 0.97577405 epoch total loss 1.21580839
Trained batch 4746 batch loss 1.05654287 epoch total loss 1.21577489
Trained batch 4747 batch loss 0.950663924 epoch total loss 1.21571898
Trained batch 4748 batch loss 1.03152704 epoch total loss 1.21568024
Trained batch 4749 batch loss 0.902112424 epoch total loss 1.21561432
Trained batch 4750 batch loss 0.912336826 epoch total loss 1.21555042
Trained batch 4751 batch loss 1.00948882 epoch total loss 1.21550691
Trained batch 4752 batch loss 1.01047027 epoch total loss 1.21546376
Trained batch 4753 batch loss 1.12423944 epoch total loss 1.21544456
Trained batch 4754 batch loss 0.920110464 epoch total loss 1.21538234
Trained batch 4755 batch loss 1.01074958 epoch total loss 1.2153393
Trained batch 4756 batch loss 1.27528989 epoch total loss 1.21535194
Trained batch 4757 batch loss 1.30875945 epoch total loss 1.21537161
Trained batch 4758 batch loss 1.12119162 epoch total loss 1.2153517
Trained batch 4759 batch loss 1.09018362 epoch total loss 1.21532547
Trained batch 4760 batch loss 1.33723545 epoch total loss 1.2153511
Trained batch 4761 batch loss 1.49814928 epoch total loss 1.21541047
Trained batch 4762 batch loss 1.0504936 epoch total loss 1.21537578
Trained batch 4763 batch loss 0.973921895 epoch total loss 1.21532512
Trained batch 4764 batch loss 1.04468429 epoch total loss 1.21528935
Trained batch 4765 batch loss 0.8370049 epoch total loss 1.21521
Trained batch 4766 batch loss 1.03299141 epoch total loss 1.21517181
Trained batch 4767 batch loss 0.935466349 epoch total loss 1.21511316
Trained batch 4768 batch loss 1.04835963 epoch total loss 1.21507812
Trained batch 4769 batch loss 1.05076647 epoch total loss 1.21504366
Trained batch 4770 batch loss 1.11426568 epoch total loss 1.21502256
Trained batch 4771 batch loss 1.11172473 epoch total loss 1.21500099
Trained batch 4772 batch loss 1.18411577 epoch total loss 1.21499443
Trained batch 4773 batch loss 1.19543648 epoch total loss 1.21499038
Trained batch 4774 batch loss 1.17445374 epoch total loss 1.21498179
Trained batch 4775 batch loss 1.49697423 epoch total loss 1.21504092
Trained batch 4776 batch loss 1.46002746 epoch total loss 1.21509218
Trained batch 4777 batch loss 1.39450145 epoch total loss 1.21512973
Trained batch 4778 batch loss 1.20128953 epoch total loss 1.21512687
Trained batch 4779 batch loss 1.22754812 epoch total loss 1.21512938
Trained batch 4780 batch loss 1.00190485 epoch total loss 1.21508479
Trained batch 4781 batch loss 1.22453034 epoch total loss 1.21508682
Trained batch 4782 batch loss 1.10231757 epoch total loss 1.21506333
Trained batch 4783 batch loss 1.44387066 epoch total loss 1.21511114
Trained batch 4784 batch loss 1.30805969 epoch total loss 1.21513057
Trained batch 4785 batch loss 1.40806401 epoch total loss 1.21517086
Trained batch 4786 batch loss 1.2295785 epoch total loss 1.21517384
Trained batch 4787 batch loss 1.06802559 epoch total loss 1.21514308
Trained batch 4788 batch loss 1.32419229 epoch total loss 1.21516585
Trained batch 4789 batch loss 1.20306528 epoch total loss 1.21516335
Trained batch 4790 batch loss 1.23774374 epoch total loss 1.21516812
Trained batch 4791 batch loss 1.19294548 epoch total loss 1.21516347
Trained batch 4792 batch loss 1.39365983 epoch total loss 1.21520066
Trained batch 4793 batch loss 1.33468509 epoch total loss 1.21522558
Trained batch 4794 batch loss 1.24543297 epoch total loss 1.2152319
Trained batch 4795 batch loss 1.2635057 epoch total loss 1.21524203
Trained batch 4796 batch loss 1.27542973 epoch total loss 1.21525455
Trained batch 4797 batch loss 1.20138526 epoch total loss 1.21525156
Trained batch 4798 batch loss 1.15071368 epoch total loss 1.21523821
Trained batch 4799 batch loss 1.22896183 epoch total loss 1.21524107
Trained batch 4800 batch loss 1.08988416 epoch total loss 1.21521497
Trained batch 4801 batch loss 1.28480303 epoch total loss 1.21522939
Trained batch 4802 batch loss 1.23429537 epoch total loss 1.21523345
Trained batch 4803 batch loss 1.20227242 epoch total loss 1.2152307
Trained batch 4804 batch loss 1.10507655 epoch total loss 1.2152077
Trained batch 4805 batch loss 0.958305597 epoch total loss 1.21515429
Trained batch 4806 batch loss 1.08405519 epoch total loss 1.21512699
Trained batch 4807 batch loss 1.19970632 epoch total loss 1.21512377
Trained batch 4808 batch loss 1.12672567 epoch total loss 1.21510541
Trained batch 4809 batch loss 1.08297217 epoch total loss 1.215078
Trained batch 4810 batch loss 0.948434 epoch total loss 1.21502256
Trained batch 4811 batch loss 1.22666359 epoch total loss 1.21502495
Trained batch 4812 batch loss 1.28161407 epoch total loss 1.21503878
Trained batch 4813 batch loss 1.23863077 epoch total loss 1.21504366
Trained batch 4814 batch loss 1.43050051 epoch total loss 1.21508849
Trained batch 4815 batch loss 1.27880454 epoch total loss 1.21510172
Trained batch 4816 batch loss 1.18417144 epoch total loss 1.21509528
Trained batch 4817 batch loss 1.23195946 epoch total loss 1.21509874
Trained batch 4818 batch loss 1.32900405 epoch total loss 1.21512246
Trained batch 4819 batch loss 1.45277548 epoch total loss 1.21517169
Trained batch 4820 batch loss 1.45587564 epoch total loss 1.21522176
Trained batch 4821 batch loss 1.26416636 epoch total loss 1.2152319
Trained batch 4822 batch loss 1.2906642 epoch total loss 1.21524751
Trained batch 4823 batch loss 1.1758213 epoch total loss 1.21523929
Trained batch 4824 batch loss 1.29254079 epoch total loss 1.21525526
Trained batch 4825 batch loss 1.20623267 epoch total loss 1.21525335
Trained batch 4826 batch loss 1.10071433 epoch total loss 1.21522963
Trained batch 4827 batch loss 1.29234242 epoch total loss 1.2152456
Trained batch 4828 batch loss 1.06752479 epoch total loss 1.21521497
Trained batch 4829 batch loss 1.0936861 epoch total loss 1.21518981
Trained batch 4830 batch loss 1.39654803 epoch total loss 1.21522737
Trained batch 4831 batch loss 1.09212613 epoch total loss 1.21520197
Trained batch 4832 batch loss 1.43805909 epoch total loss 1.21524811
Trained batch 4833 batch loss 1.09652376 epoch total loss 1.21522355
Trained batch 4834 batch loss 1.11353052 epoch total loss 1.21520257
Trained batch 4835 batch loss 1.11093187 epoch total loss 1.21518099
Trained batch 4836 batch loss 1.35949 epoch total loss 1.2152108
Trained batch 4837 batch loss 1.35551476 epoch total loss 1.21523976
Trained batch 4838 batch loss 1.1783427 epoch total loss 1.21523213
Trained batch 4839 batch loss 1.12549138 epoch total loss 1.21521354
Trained batch 4840 batch loss 0.986612678 epoch total loss 1.21516633
Trained batch 4841 batch loss 1.0238148 epoch total loss 1.21512687
Trained batch 4842 batch loss 0.916871667 epoch total loss 1.21506536
Trained batch 4843 batch loss 0.854682 epoch total loss 1.21499085
Trained batch 4844 batch loss 1.29311776 epoch total loss 1.21500695
Trained batch 4845 batch loss 1.19044161 epoch total loss 1.21500182
Trained batch 4846 batch loss 1.2318114 epoch total loss 1.2150054
Trained batch 4847 batch loss 1.36219358 epoch total loss 1.2150358
Trained batch 4848 batch loss 1.49059 epoch total loss 1.21509266
Trained batch 4849 batch loss 1.1577127 epoch total loss 1.21508074
Trained batch 4850 batch loss 1.45099545 epoch total loss 1.21512949
Trained batch 4851 batch loss 1.3792274 epoch total loss 1.21516335
Trained batch 4852 batch loss 1.35382247 epoch total loss 1.21519196
Trained batch 4853 batch loss 1.20213449 epoch total loss 1.21518922
Trained batch 4854 batch loss 1.36024165 epoch total loss 1.21521914
Trained batch 4855 batch loss 1.26341164 epoch total loss 1.21522903
Trained batch 4856 batch loss 1.19707036 epoch total loss 1.21522534
Trained batch 4857 batch loss 1.23204589 epoch total loss 1.2152288
Trained batch 4858 batch loss 1.36432183 epoch total loss 1.21525943
Trained batch 4859 batch loss 1.42118418 epoch total loss 1.21530187
Trained batch 4860 batch loss 1.55725694 epoch total loss 1.2153722
Trained batch 4861 batch loss 1.24242711 epoch total loss 1.21537769
Trained batch 4862 batch loss 1.25374413 epoch total loss 1.21538568
Trained batch 4863 batch loss 1.35072875 epoch total loss 1.21541345
Trained batch 4864 batch loss 1.37035251 epoch total loss 1.21544528
Trained batch 4865 batch loss 1.26831031 epoch total loss 1.21545613
Trained batch 4866 batch loss 1.03865886 epoch total loss 1.21541977
Trained batch 4867 batch loss 1.05901432 epoch total loss 1.21538758
Trained batch 4868 batch loss 1.15559793 epoch total loss 1.2153753
Trained batch 4869 batch loss 1.07502007 epoch total loss 1.21534657
Trained batch 4870 batch loss 1.11403441 epoch total loss 1.21532583
Trained batch 4871 batch loss 1.07233119 epoch total loss 1.21529639
Trained batch 4872 batch loss 0.830941141 epoch total loss 1.21521759
Trained batch 4873 batch loss 0.900372088 epoch total loss 1.21515298
Trained batch 4874 batch loss 0.997770309 epoch total loss 1.21510828
Trained batch 4875 batch loss 1.0653069 epoch total loss 1.21507764
Trained batch 4876 batch loss 1.11536217 epoch total loss 1.21505713
Trained batch 4877 batch loss 1.31873202 epoch total loss 1.21507847
Trained batch 4878 batch loss 1.46216679 epoch total loss 1.21512914
Trained batch 4879 batch loss 1.28329134 epoch total loss 1.21514308
Trained batch 4880 batch loss 1.39709723 epoch total loss 1.2151804
Trained batch 4881 batch loss 1.3112433 epoch total loss 1.2152
Trained batch 4882 batch loss 1.21383142 epoch total loss 1.21519971
Trained batch 4883 batch loss 1.29288161 epoch total loss 1.21521568
Trained batch 4884 batch loss 1.3369956 epoch total loss 1.2152406
Trained batch 4885 batch loss 1.36713 epoch total loss 1.21527171
Trained batch 4886 batch loss 1.0710057 epoch total loss 1.21524215
Trained batch 4887 batch loss 1.29067779 epoch total loss 1.21525753
Trained batch 4888 batch loss 1.1206435 epoch total loss 1.21523809
Trained batch 4889 batch loss 1.30685663 epoch total loss 1.21525681
Trained batch 4890 batch loss 1.20055449 epoch total loss 1.21525383
Trained batch 4891 batch loss 1.31849813 epoch total loss 1.21527493
Trained batch 4892 batch loss 1.15200388 epoch total loss 1.21526194
Trained batch 4893 batch loss 1.34973156 epoch total loss 1.21528947
Trained batch 4894 batch loss 1.23476171 epoch total loss 1.21529341
Trained batch 4895 batch loss 1.09486651 epoch total loss 1.21526873
Trained batch 4896 batch loss 1.28886914 epoch total loss 1.21528387
Trained batch 4897 batch loss 1.34122086 epoch total loss 1.21530962
Trained batch 4898 batch loss 1.34079099 epoch total loss 1.21533525
Trained batch 4899 batch loss 1.32841635 epoch total loss 1.21535838
Trained batch 4900 batch loss 1.1325295 epoch total loss 1.21534145
Trained batch 4901 batch loss 1.16329098 epoch total loss 1.21533072
Trained batch 4902 batch loss 1.12462687 epoch total loss 1.21531224
Trained batch 4903 batch loss 1.18260431 epoch total loss 1.21530557
Trained batch 4904 batch loss 1.21654868 epoch total loss 1.21530569
Trained batch 4905 batch loss 1.07628298 epoch total loss 1.21527743
Trained batch 4906 batch loss 1.25380647 epoch total loss 1.2152853
Trained batch 4907 batch loss 1.21424878 epoch total loss 1.21528506
Trained batch 4908 batch loss 1.55355442 epoch total loss 1.21535397
Trained batch 4909 batch loss 1.12977791 epoch total loss 1.21533656
Trained batch 4910 batch loss 1.27282166 epoch total loss 1.21534836
Trained batch 4911 batch loss 1.12133431 epoch total loss 1.21532917
Trained batch 4912 batch loss 1.31860304 epoch total loss 1.21535015
Trained batch 4913 batch loss 1.01476 epoch total loss 1.21530926
Trained batch 4914 batch loss 1.17934299 epoch total loss 1.21530187
Trained batch 4915 batch loss 1.15382504 epoch total loss 1.21528935
Trained batch 4916 batch loss 1.14864445 epoch total loss 1.21527576
Trained batch 4917 batch loss 1.20938683 epoch total loss 1.21527469
Trained batch 4918 batch loss 1.30025625 epoch total loss 1.21529198
Trained batch 4919 batch loss 1.28544378 epoch total loss 1.21530628
Trained batch 4920 batch loss 1.1255703 epoch total loss 1.21528792
Trained batch 4921 batch loss 1.25877404 epoch total loss 1.21529686
Trained batch 4922 batch loss 1.16244245 epoch total loss 1.21528614
Trained batch 4923 batch loss 1.27419591 epoch total loss 1.21529806
Trained batch 4924 batch loss 1.28309655 epoch total loss 1.21531188
Trained batch 4925 batch loss 1.26453555 epoch total loss 1.2153219
Trained batch 4926 batch loss 1.23205888 epoch total loss 1.21532524
Trained batch 4927 batch loss 1.12285733 epoch total loss 1.21530652
Trained batch 4928 batch loss 1.28770018 epoch total loss 1.21532118
Trained batch 4929 batch loss 1.14241958 epoch total loss 1.21530652
Trained batch 4930 batch loss 1.2633028 epoch total loss 1.21531618
Trained batch 4931 batch loss 1.27870202 epoch total loss 1.21532905
Trained batch 4932 batch loss 1.21381903 epoch total loss 1.21532881
Trained batch 4933 batch loss 1.16140079 epoch total loss 1.21531785
Trained batch 4934 batch loss 1.20354974 epoch total loss 1.21531546
Trained batch 4935 batch loss 1.1973983 epoch total loss 1.21531188
Trained batch 4936 batch loss 1.29325771 epoch total loss 1.21532762
Trained batch 4937 batch loss 1.21370173 epoch total loss 1.21532738
Trained batch 4938 batch loss 1.35526454 epoch total loss 1.21535575
Trained batch 4939 batch loss 1.43202567 epoch total loss 1.21539962
Trained batch 4940 batch loss 1.25999701 epoch total loss 1.21540868
Trained batch 4941 batch loss 1.11462677 epoch total loss 1.2153883
Trained batch 4942 batch loss 1.29460812 epoch total loss 1.21540427
Trained batch 4943 batch loss 1.08072209 epoch total loss 1.21537697
Trained batch 4944 batch loss 1.26857865 epoch total loss 1.2153877
Trained batch 4945 batch loss 1.24626517 epoch total loss 1.2153939
Trained batch 4946 batch loss 1.31370211 epoch total loss 1.21541381
Trained batch 4947 batch loss 1.49180734 epoch total loss 1.2154696
Trained batch 4948 batch loss 1.45213282 epoch total loss 1.2155174
Trained batch 4949 batch loss 1.32686973 epoch total loss 1.21553993
Trained batch 4950 batch loss 1.30660844 epoch total loss 1.21555829
Trained batch 4951 batch loss 1.44984782 epoch total loss 1.21560562
Trained batch 4952 batch loss 1.31826174 epoch total loss 1.21562636
Trained batch 4953 batch loss 1.27958083 epoch total loss 1.21563935
Trained batch 4954 batch loss 1.15191925 epoch total loss 1.21562648
Trained batch 4955 batch loss 1.08077884 epoch total loss 1.21559918
Trained batch 4956 batch loss 1.2231307 epoch total loss 1.21560073
Trained batch 4957 batch loss 0.883873463 epoch total loss 1.21553373
Trained batch 4958 batch loss 1.13503432 epoch total loss 1.21551752
Trained batch 4959 batch loss 0.924478471 epoch total loss 1.21545887
Trained batch 4960 batch loss 0.824067593 epoch total loss 1.21538
Trained batch 4961 batch loss 0.93115896 epoch total loss 1.21532273
Trained batch 4962 batch loss 1.07050061 epoch total loss 1.21529341
Trained batch 4963 batch loss 1.17510223 epoch total loss 1.21528542
Trained batch 4964 batch loss 1.27895081 epoch total loss 1.21529818
Trained batch 4965 batch loss 1.10266948 epoch total loss 1.21527553
Trained batch 4966 batch loss 1.25397515 epoch total loss 1.21528327
Trained batch 4967 batch loss 1.11626053 epoch total loss 1.21526337
Trained batch 4968 batch loss 1.01809669 epoch total loss 1.21522367
Trained batch 4969 batch loss 0.997587919 epoch total loss 1.2151798
Trained batch 4970 batch loss 1.0743072 epoch total loss 1.21515143
Trained batch 4971 batch loss 1.13176203 epoch total loss 1.21513474
Trained batch 4972 batch loss 1.15556502 epoch total loss 1.2151227
Trained batch 4973 batch loss 1.08140349 epoch total loss 1.21509588
Trained batch 4974 batch loss 1.20269108 epoch total loss 1.21509337
Trained batch 4975 batch loss 1.13192153 epoch total loss 1.21507668
Trained batch 4976 batch loss 1.01699924 epoch total loss 1.21503687
Trained batch 4977 batch loss 1.24520707 epoch total loss 1.21504295
Trained batch 4978 batch loss 1.13366473 epoch total loss 1.21502662
Trained batch 4979 batch loss 1.31657147 epoch total loss 1.215047
Trained batch 4980 batch loss 1.43223453 epoch total loss 1.21509051
Trained batch 4981 batch loss 1.26352692 epoch total loss 1.21510029
Trained batch 4982 batch loss 1.37940657 epoch total loss 1.21513331
Trained batch 4983 batch loss 1.33122182 epoch total loss 1.21515656
Trained batch 4984 batch loss 0.975715041 epoch total loss 1.21510851
Trained batch 4985 batch loss 0.992566288 epoch total loss 1.21506381
Trained batch 4986 batch loss 1.02320552 epoch total loss 1.21502542
Trained batch 4987 batch loss 1.1487999 epoch total loss 1.21501219
Trained batch 4988 batch loss 1.38205636 epoch total loss 1.21504557
Trained batch 4989 batch loss 1.22935021 epoch total loss 1.21504855
Trained batch 4990 batch loss 1.27016866 epoch total loss 1.21505952
Trained batch 4991 batch loss 1.35923648 epoch total loss 1.21508849
Trained batch 4992 batch loss 1.3853507 epoch total loss 1.21512246
Trained batch 4993 batch loss 1.3450743 epoch total loss 1.21514857
Trained batch 4994 batch loss 1.15924263 epoch total loss 1.21513736
Trained batch 4995 batch loss 1.1929214 epoch total loss 1.21513295
Trained batch 4996 batch loss 1.19343174 epoch total loss 1.21512854
Trained batch 4997 batch loss 1.3772223 epoch total loss 1.21516109
Trained batch 4998 batch loss 1.38444471 epoch total loss 1.21519482
Trained batch 4999 batch loss 1.49122751 epoch total loss 1.21525013
Trained batch 5000 batch loss 1.44853759 epoch total loss 1.21529675
Trained batch 5001 batch loss 1.51244164 epoch total loss 1.21535611
Trained batch 5002 batch loss 1.63574898 epoch total loss 1.21544015
Trained batch 5003 batch loss 1.36017251 epoch total loss 1.21546912
Trained batch 5004 batch loss 1.54481578 epoch total loss 1.21553504
Trained batch 5005 batch loss 1.2122376 epoch total loss 1.21553433
Trained batch 5006 batch loss 1.50656092 epoch total loss 1.2155925
Trained batch 5007 batch loss 1.58865166 epoch total loss 1.21566701
Trained batch 5008 batch loss 1.37037873 epoch total loss 1.215698
Trained batch 5009 batch loss 1.34734941 epoch total loss 1.21572423
Trained batch 5010 batch loss 1.0889467 epoch total loss 1.21569884
Trained batch 5011 batch loss 1.1610744 epoch total loss 1.21568799
Trained batch 5012 batch loss 1.0400902 epoch total loss 1.21565294
Trained batch 5013 batch loss 0.982222438 epoch total loss 1.21560645
Trained batch 5014 batch loss 1.06995082 epoch total loss 1.21557736
Trained batch 5015 batch loss 0.966164768 epoch total loss 1.21552765
Trained batch 5016 batch loss 0.978158 epoch total loss 1.21548033
Trained batch 5017 batch loss 0.849447131 epoch total loss 1.21540737
Trained batch 5018 batch loss 1.28732347 epoch total loss 1.21542168
Trained batch 5019 batch loss 1.54448986 epoch total loss 1.21548724
Trained batch 5020 batch loss 1.32631302 epoch total loss 1.2155093
Trained batch 5021 batch loss 1.38468671 epoch total loss 1.21554291
Trained batch 5022 batch loss 1.44142079 epoch total loss 1.21558797
Trained batch 5023 batch loss 1.33309674 epoch total loss 1.21561134
Trained batch 5024 batch loss 1.47708368 epoch total loss 1.21566331
Trained batch 5025 batch loss 1.54520726 epoch total loss 1.215729
Trained batch 5026 batch loss 1.28934264 epoch total loss 1.21574366
Trained batch 5027 batch loss 1.31534827 epoch total loss 1.21576345
Trained batch 5028 batch loss 1.27188146 epoch total loss 1.21577466
Trained batch 5029 batch loss 1.34841192 epoch total loss 1.21580112
Trained batch 5030 batch loss 1.23177505 epoch total loss 1.21580434
Trained batch 5031 batch loss 1.28686225 epoch total loss 1.21581841
Trained batch 5032 batch loss 1.36741066 epoch total loss 1.21584845
Trained batch 5033 batch loss 1.406322 epoch total loss 1.21588624
Trained batch 5034 batch loss 1.43449759 epoch total loss 1.21592975
Trained batch 5035 batch loss 1.48625088 epoch total loss 1.21598339
Trained batch 5036 batch loss 1.27391946 epoch total loss 1.21599495
Trained batch 5037 batch loss 1.31196785 epoch total loss 1.21601403
Trained batch 5038 batch loss 1.31752229 epoch total loss 1.21603417
Trained batch 5039 batch loss 1.30823076 epoch total loss 1.21605241
Trained batch 5040 batch loss 1.08906817 epoch total loss 1.21602714
Trained batch 5041 batch loss 1.17403126 epoch total loss 1.2160188
Trained batch 5042 batch loss 1.28574634 epoch total loss 1.21603262
Trained batch 5043 batch loss 1.33225965 epoch total loss 1.21605563
Trained batch 5044 batch loss 1.45131946 epoch total loss 1.21610224
Trained batch 5045 batch loss 1.19110298 epoch total loss 1.21609724
Trained batch 5046 batch loss 0.984433413 epoch total loss 1.21605134
Trained batch 5047 batch loss 1.0386138 epoch total loss 1.21601617
Trained batch 5048 batch loss 1.08547568 epoch total loss 1.2159903
Trained batch 5049 batch loss 1.0671016 epoch total loss 1.21596074
Trained batch 5050 batch loss 1.16080952 epoch total loss 1.21594977
Trained batch 5051 batch loss 1.38533759 epoch total loss 1.21598327
Trained batch 5052 batch loss 1.16436 epoch total loss 1.21597314
Trained batch 5053 batch loss 1.03807569 epoch total loss 1.21593797
Trained batch 5054 batch loss 1.36106896 epoch total loss 1.21596658
Trained batch 5055 batch loss 1.2446636 epoch total loss 1.2159723
Trained batch 5056 batch loss 1.22289646 epoch total loss 1.21597362
Trained batch 5057 batch loss 1.3646462 epoch total loss 1.21600294
Trained batch 5058 batch loss 1.26580572 epoch total loss 1.21601284
Trained batch 5059 batch loss 1.21156645 epoch total loss 1.21601188
Trained batch 5060 batch loss 1.11398172 epoch total loss 1.21599174
Trained batch 5061 batch loss 0.938103795 epoch total loss 1.21593678
Trained batch 5062 batch loss 1.01055837 epoch total loss 1.21589625
Trained batch 5063 batch loss 1.04112124 epoch total loss 1.21586168
Trained batch 5064 batch loss 0.986538529 epoch total loss 1.21581638
Trained batch 5065 batch loss 0.960386276 epoch total loss 1.21576595
Trained batch 5066 batch loss 1.03832269 epoch total loss 1.21573091
Trained batch 5067 batch loss 0.835570753 epoch total loss 1.2156558
Trained batch 5068 batch loss 1.02413523 epoch total loss 1.21561801
Trained batch 5069 batch loss 0.888660371 epoch total loss 1.21555352
Trained batch 5070 batch loss 0.927199 epoch total loss 1.21549666
Trained batch 5071 batch loss 1.15079331 epoch total loss 1.2154839
Trained batch 5072 batch loss 0.991919518 epoch total loss 1.2154398
Trained batch 5073 batch loss 1.13177538 epoch total loss 1.21542323
Trained batch 5074 batch loss 1.36792326 epoch total loss 1.21545339
Trained batch 5075 batch loss 1.26617861 epoch total loss 1.2154634
Trained batch 5076 batch loss 1.08720982 epoch total loss 1.21543813
Trained batch 5077 batch loss 1.33246958 epoch total loss 1.21546113
Trained batch 5078 batch loss 1.1277529 epoch total loss 1.21544397
Trained batch 5079 batch loss 0.921061456 epoch total loss 1.21538591
Trained batch 5080 batch loss 0.985425 epoch total loss 1.21534073
Trained batch 5081 batch loss 0.972284436 epoch total loss 1.21529281
Trained batch 5082 batch loss 1.05221438 epoch total loss 1.21526074
Trained batch 5083 batch loss 1.00804794 epoch total loss 1.21522
Trained batch 5084 batch loss 1.26627767 epoch total loss 1.21523
Trained batch 5085 batch loss 1.20124769 epoch total loss 1.21522713
Trained batch 5086 batch loss 1.19311905 epoch total loss 1.21522284
Trained batch 5087 batch loss 1.24189281 epoch total loss 1.21522808
Trained batch 5088 batch loss 1.15682459 epoch total loss 1.21521664
Trained batch 5089 batch loss 1.27111912 epoch total loss 1.21522748
Trained batch 5090 batch loss 1.08499575 epoch total loss 1.21520197
Trained batch 5091 batch loss 1.22418475 epoch total loss 1.21520376
Trained batch 5092 batch loss 1.21930099 epoch total loss 1.21520448
Trained batch 5093 batch loss 1.24083376 epoch total loss 1.21520948
Trained batch 5094 batch loss 1.28764379 epoch total loss 1.21522367
Trained batch 5095 batch loss 1.22626591 epoch total loss 1.21522582
Trained batch 5096 batch loss 1.49628353 epoch total loss 1.21528101
Trained batch 5097 batch loss 0.983735442 epoch total loss 1.21523559
Trained batch 5098 batch loss 0.958196 epoch total loss 1.21518517
Trained batch 5099 batch loss 1.1304493 epoch total loss 1.21516848
Trained batch 5100 batch loss 1.09401298 epoch total loss 1.21514475
Trained batch 5101 batch loss 1.11318278 epoch total loss 1.21512485
Trained batch 5102 batch loss 1.07877159 epoch total loss 1.21509802
Trained batch 5103 batch loss 0.991246462 epoch total loss 1.21505415
Trained batch 5104 batch loss 1.00910294 epoch total loss 1.21501386
Trained batch 5105 batch loss 1.45606494 epoch total loss 1.21506107
Trained batch 5106 batch loss 1.30521345 epoch total loss 1.21507871
Trained batch 5107 batch loss 1.23440802 epoch total loss 1.21508253
Trained batch 5108 batch loss 1.49950671 epoch total loss 1.2151382
Trained batch 5109 batch loss 1.34619904 epoch total loss 1.21516383
Trained batch 5110 batch loss 1.45357084 epoch total loss 1.21521044
Trained batch 5111 batch loss 1.27671051 epoch total loss 1.2152226
Trained batch 5112 batch loss 1.26719379 epoch total loss 1.21523273
Trained batch 5113 batch loss 1.44396257 epoch total loss 1.21527743
Trained batch 5114 batch loss 1.139884 epoch total loss 1.21526265
Trained batch 5115 batch loss 1.18124747 epoch total loss 1.21525598
Trained batch 5116 batch loss 1.26702428 epoch total loss 1.21526611
Trained batch 5117 batch loss 1.14873 epoch total loss 1.21525311
Trained batch 5118 batch loss 1.15022635 epoch total loss 1.21524048
Trained batch 5119 batch loss 1.08457947 epoch total loss 1.21521485
Trained batch 5120 batch loss 1.15011692 epoch total loss 1.21520209
Trained batch 5121 batch loss 1.16023648 epoch total loss 1.21519136
Trained batch 5122 batch loss 1.11190748 epoch total loss 1.21517122
Trained batch 5123 batch loss 1.31158137 epoch total loss 1.21519
Trained batch 5124 batch loss 1.29961705 epoch total loss 1.2152065
Trained batch 5125 batch loss 1.11141038 epoch total loss 1.21518624
Trained batch 5126 batch loss 1.37702799 epoch total loss 1.21521783
Trained batch 5127 batch loss 1.30250382 epoch total loss 1.21523488
Trained batch 5128 batch loss 1.17169595 epoch total loss 1.21522641
Trained batch 5129 batch loss 1.32881916 epoch total loss 1.21524858
Trained batch 5130 batch loss 1.36202168 epoch total loss 1.21527708
Trained batch 5131 batch loss 1.27676606 epoch total loss 1.21528912
Trained batch 5132 batch loss 1.21648669 epoch total loss 1.21528935
Trained batch 5133 batch loss 1.32052016 epoch total loss 1.21530974
Trained batch 5134 batch loss 1.1013124 epoch total loss 1.21528757
Trained batch 5135 batch loss 1.18964553 epoch total loss 1.21528244
Trained batch 5136 batch loss 1.46286976 epoch total loss 1.21533072
Trained batch 5137 batch loss 1.46298933 epoch total loss 1.21537888
Trained batch 5138 batch loss 1.66510928 epoch total loss 1.21546638
Trained batch 5139 batch loss 1.55716801 epoch total loss 1.2155329
Trained batch 5140 batch loss 1.46073222 epoch total loss 1.21558058
Trained batch 5141 batch loss 1.34404624 epoch total loss 1.21560562
Trained batch 5142 batch loss 1.29835761 epoch total loss 1.21562171
Trained batch 5143 batch loss 1.53841472 epoch total loss 1.21568453
Trained batch 5144 batch loss 1.47421432 epoch total loss 1.21573484
Trained batch 5145 batch loss 1.10626209 epoch total loss 1.2157135
Trained batch 5146 batch loss 1.0641793 epoch total loss 1.21568406
Trained batch 5147 batch loss 1.1375258 epoch total loss 1.21566892
Trained batch 5148 batch loss 1.2416451 epoch total loss 1.21567392
Trained batch 5149 batch loss 1.15468764 epoch total loss 1.21566212
Trained batch 5150 batch loss 1.18859804 epoch total loss 1.21565688
Trained batch 5151 batch loss 1.21892619 epoch total loss 1.21565747
Trained batch 5152 batch loss 1.1557703 epoch total loss 1.21564579
Trained batch 5153 batch loss 1.07384956 epoch total loss 1.21561825
Trained batch 5154 batch loss 0.992074847 epoch total loss 1.21557498
Trained batch 5155 batch loss 0.855450213 epoch total loss 1.21550512
Trained batch 5156 batch loss 1.00253046 epoch total loss 1.21546376
Trained batch 5157 batch loss 0.850876212 epoch total loss 1.21539307
Trained batch 5158 batch loss 0.74059689 epoch total loss 1.21530104
Trained batch 5159 batch loss 0.883328795 epoch total loss 1.21523666
Trained batch 5160 batch loss 0.923599839 epoch total loss 1.21518028
Trained batch 5161 batch loss 1.17826855 epoch total loss 1.21517313
Trained batch 5162 batch loss 1.35426807 epoch total loss 1.21520007
Trained batch 5163 batch loss 1.09425044 epoch total loss 1.2151767
Trained batch 5164 batch loss 1.17178881 epoch total loss 1.21516824
Trained batch 5165 batch loss 1.42924619 epoch total loss 1.21520972
Trained batch 5166 batch loss 1.27037334 epoch total loss 1.21522045
Trained batch 5167 batch loss 1.1044395 epoch total loss 1.21519899
Trained batch 5168 batch loss 0.916420937 epoch total loss 1.21514118
Trained batch 5169 batch loss 0.811521947 epoch total loss 1.2150631
Trained batch 5170 batch loss 0.769197226 epoch total loss 1.21497679
Trained batch 5171 batch loss 0.875568688 epoch total loss 1.21491122
Trained batch 5172 batch loss 0.808082 epoch total loss 1.21483254
Trained batch 5173 batch loss 0.839292705 epoch total loss 1.21476
Trained batch 5174 batch loss 0.822215557 epoch total loss 1.21468413
Trained batch 5175 batch loss 1.08699226 epoch total loss 1.21465933
Trained batch 5176 batch loss 0.830266118 epoch total loss 1.21458507
Trained batch 5177 batch loss 0.949363589 epoch total loss 1.21453381
Trained batch 5178 batch loss 0.96434468 epoch total loss 1.21448553
Trained batch 5179 batch loss 1.0119282 epoch total loss 1.21444631
Trained batch 5180 batch loss 0.930337667 epoch total loss 1.21439147
Trained batch 5181 batch loss 0.998379469 epoch total loss 1.21434987
Trained batch 5182 batch loss 1.28225088 epoch total loss 1.21436286
Trained batch 5183 batch loss 1.07287979 epoch total loss 1.21433556
Trained batch 5184 batch loss 1.11712539 epoch total loss 1.21431684
Trained batch 5185 batch loss 1.11648262 epoch total loss 1.21429801
Trained batch 5186 batch loss 1.37433803 epoch total loss 1.21432889
Trained batch 5187 batch loss 1.22386408 epoch total loss 1.21433067
Trained batch 5188 batch loss 1.14046264 epoch total loss 1.21431649
Trained batch 5189 batch loss 1.09755874 epoch total loss 1.21429408
Trained batch 5190 batch loss 1.14032221 epoch total loss 1.21427977
Trained batch 5191 batch loss 1.37457979 epoch total loss 1.21431065
Trained batch 5192 batch loss 1.4479661 epoch total loss 1.21435559
Trained batch 5193 batch loss 1.23850083 epoch total loss 1.21436012
Trained batch 5194 batch loss 1.25188076 epoch total loss 1.21436739
Trained batch 5195 batch loss 1.28239417 epoch total loss 1.2143805
Trained batch 5196 batch loss 1.07563233 epoch total loss 1.2143538
Trained batch 5197 batch loss 1.31671143 epoch total loss 1.21437347
Trained batch 5198 batch loss 1.1143285 epoch total loss 1.21435428
Trained batch 5199 batch loss 1.39475882 epoch total loss 1.21438885
Trained batch 5200 batch loss 1.28925037 epoch total loss 1.21440327
Trained batch 5201 batch loss 1.15430641 epoch total loss 1.21439171
Trained batch 5202 batch loss 1.45033455 epoch total loss 1.21443701
Trained batch 5203 batch loss 1.35296643 epoch total loss 1.21446371
Trained batch 5204 batch loss 1.29749823 epoch total loss 1.21447957
Trained batch 5205 batch loss 1.24395585 epoch total loss 1.21448529
Trained batch 5206 batch loss 1.21748972 epoch total loss 1.21448588
Trained batch 5207 batch loss 1.06874156 epoch total loss 1.21445787
Trained batch 5208 batch loss 1.15736151 epoch total loss 1.2144469
Trained batch 5209 batch loss 1.24491715 epoch total loss 1.21445274
Trained batch 5210 batch loss 1.13042378 epoch total loss 1.21443665
Trained batch 5211 batch loss 1.01478338 epoch total loss 1.21439826
Trained batch 5212 batch loss 1.04964328 epoch total loss 1.21436667
Trained batch 5213 batch loss 1.18946958 epoch total loss 1.21436191
Trained batch 5214 batch loss 1.18167889 epoch total loss 1.21435571
Trained batch 5215 batch loss 1.21817899 epoch total loss 1.21435642
Trained batch 5216 batch loss 1.26545107 epoch total loss 1.2143662
Trained batch 5217 batch loss 1.19278288 epoch total loss 1.21436214
Trained batch 5218 batch loss 1.06031919 epoch total loss 1.21433258
Trained batch 5219 batch loss 1.20555913 epoch total loss 1.21433091
Trained batch 5220 batch loss 1.17314959 epoch total loss 1.21432316
Trained batch 5221 batch loss 1.14644516 epoch total loss 1.21431017
Trained batch 5222 batch loss 1.19517386 epoch total loss 1.21430647
Trained batch 5223 batch loss 1.28323197 epoch total loss 1.21431971
Trained batch 5224 batch loss 1.24442101 epoch total loss 1.21432543
Trained batch 5225 batch loss 1.3081001 epoch total loss 1.21434343
Trained batch 5226 batch loss 1.21933615 epoch total loss 1.21434438
Trained batch 5227 batch loss 1.34467816 epoch total loss 1.2143693
Trained batch 5228 batch loss 1.20318305 epoch total loss 1.21436715
Trained batch 5229 batch loss 1.27504921 epoch total loss 1.21437871
Trained batch 5230 batch loss 1.30744016 epoch total loss 1.2143966
Trained batch 5231 batch loss 1.32644141 epoch total loss 1.21441805
Trained batch 5232 batch loss 1.23233485 epoch total loss 1.21442139
Trained batch 5233 batch loss 1.06392646 epoch total loss 1.21439266
Trained batch 5234 batch loss 1.16374075 epoch total loss 1.21438301
Trained batch 5235 batch loss 1.33688831 epoch total loss 1.21440637
Trained batch 5236 batch loss 1.29354596 epoch total loss 1.21442151
Trained batch 5237 batch loss 1.17143869 epoch total loss 1.21441329
Trained batch 5238 batch loss 1.16835117 epoch total loss 1.21440446
Trained batch 5239 batch loss 1.48141146 epoch total loss 1.21445549
Trained batch 5240 batch loss 1.5641011 epoch total loss 1.21452212
Trained batch 5241 batch loss 1.18302739 epoch total loss 1.21451616
Trained batch 5242 batch loss 1.22625661 epoch total loss 1.21451843
Trained batch 5243 batch loss 1.29710436 epoch total loss 1.21453404
Trained batch 5244 batch loss 1.15008 epoch total loss 1.21452177
Trained batch 5245 batch loss 1.32209563 epoch total loss 1.21454227
Trained batch 5246 batch loss 1.21490741 epoch total loss 1.21454239
Trained batch 5247 batch loss 1.35340977 epoch total loss 1.21456885
Trained batch 5248 batch loss 1.42069638 epoch total loss 1.21460819
Trained batch 5249 batch loss 1.37967706 epoch total loss 1.21463966
Trained batch 5250 batch loss 1.41552985 epoch total loss 1.21467793
Trained batch 5251 batch loss 1.20450687 epoch total loss 1.21467602
Trained batch 5252 batch loss 1.11499906 epoch total loss 1.21465707
Trained batch 5253 batch loss 1.06127048 epoch total loss 1.21462786
Trained batch 5254 batch loss 1.19066811 epoch total loss 1.21462321
Trained batch 5255 batch loss 1.18692052 epoch total loss 1.21461797
Trained batch 5256 batch loss 1.2985754 epoch total loss 1.21463394
Trained batch 5257 batch loss 1.05453587 epoch total loss 1.21460342
Trained batch 5258 batch loss 1.09693098 epoch total loss 1.21458113
Trained batch 5259 batch loss 1.09175062 epoch total loss 1.21455777
Trained batch 5260 batch loss 1.12673855 epoch total loss 1.21454108
Trained batch 5261 batch loss 1.01371634 epoch total loss 1.21450293
Trained batch 5262 batch loss 1.04510021 epoch total loss 1.21447074
Trained batch 5263 batch loss 1.08253717 epoch total loss 1.21444559
Trained batch 5264 batch loss 1.34713268 epoch total loss 1.21447086
Trained batch 5265 batch loss 1.27841353 epoch total loss 1.21448302
Trained batch 5266 batch loss 1.31175983 epoch total loss 1.21450138
Trained batch 5267 batch loss 1.35317373 epoch total loss 1.21452773
Trained batch 5268 batch loss 1.2279923 epoch total loss 1.21453023
Trained batch 5269 batch loss 0.99277252 epoch total loss 1.21448815
Trained batch 5270 batch loss 1.06552029 epoch total loss 1.2144599
Trained batch 5271 batch loss 1.37107062 epoch total loss 1.21448958
Trained batch 5272 batch loss 1.3832171 epoch total loss 1.21452165
Trained batch 5273 batch loss 1.55628562 epoch total loss 1.21458638
Trained batch 5274 batch loss 1.46482062 epoch total loss 1.21463382
Trained batch 5275 batch loss 1.34823179 epoch total loss 1.21465921
Trained batch 5276 batch loss 1.27888334 epoch total loss 1.21467137
Trained batch 5277 batch loss 1.36150479 epoch total loss 1.21469915
Trained batch 5278 batch loss 1.25802684 epoch total loss 1.21470726
Trained batch 5279 batch loss 1.31897902 epoch total loss 1.21472704
Trained batch 5280 batch loss 1.26254904 epoch total loss 1.2147361
Trained batch 5281 batch loss 1.37670958 epoch total loss 1.21476686
Trained batch 5282 batch loss 1.39679265 epoch total loss 1.21480131
Trained batch 5283 batch loss 1.03287315 epoch total loss 1.21476686
Trained batch 5284 batch loss 0.868930399 epoch total loss 1.21470141
Trained batch 5285 batch loss 0.934197307 epoch total loss 1.21464837
Trained batch 5286 batch loss 0.892797828 epoch total loss 1.21458745
Trained batch 5287 batch loss 1.24829841 epoch total loss 1.21459389
Trained batch 5288 batch loss 1.34190881 epoch total loss 1.21461785
Trained batch 5289 batch loss 1.35303092 epoch total loss 1.21464407
Trained batch 5290 batch loss 1.14222789 epoch total loss 1.21463037
Trained batch 5291 batch loss 1.36712098 epoch total loss 1.21465921
Trained batch 5292 batch loss 1.37854576 epoch total loss 1.21469009
Trained batch 5293 batch loss 1.47760928 epoch total loss 1.2147398
Trained batch 5294 batch loss 1.37373364 epoch total loss 1.21476972
Trained batch 5295 batch loss 1.16762602 epoch total loss 1.2147609
Trained batch 5296 batch loss 1.27250183 epoch total loss 1.21477175
Trained batch 5297 batch loss 1.2904284 epoch total loss 1.21478605
Trained batch 5298 batch loss 1.30597579 epoch total loss 1.21480334
Trained batch 5299 batch loss 1.20630288 epoch total loss 1.21480179
Trained batch 5300 batch loss 1.13494492 epoch total loss 1.21478665
Trained batch 5301 batch loss 1.32805657 epoch total loss 1.21480799
Trained batch 5302 batch loss 1.21106482 epoch total loss 1.21480727
Trained batch 5303 batch loss 1.36708224 epoch total loss 1.214836
Trained batch 5304 batch loss 1.25428247 epoch total loss 1.21484351
Trained batch 5305 batch loss 1.21555328 epoch total loss 1.21484351
Trained batch 5306 batch loss 1.24560881 epoch total loss 1.21484935
Trained batch 5307 batch loss 1.16057849 epoch total loss 1.2148391
Trained batch 5308 batch loss 1.14999223 epoch total loss 1.21482694
Trained batch 5309 batch loss 1.15145624 epoch total loss 1.21481502
Trained batch 5310 batch loss 1.34513164 epoch total loss 1.21483958
Trained batch 5311 batch loss 1.42012775 epoch total loss 1.21487808
Trained batch 5312 batch loss 1.56530344 epoch total loss 1.21494412
Trained batch 5313 batch loss 1.41201472 epoch total loss 1.2149812
Trained batch 5314 batch loss 1.46378016 epoch total loss 1.21502805
Trained batch 5315 batch loss 1.36752927 epoch total loss 1.21505678
Trained batch 5316 batch loss 1.28211308 epoch total loss 1.21506941
Trained batch 5317 batch loss 1.21858382 epoch total loss 1.21507013
Trained batch 5318 batch loss 1.11162663 epoch total loss 1.2150507
Trained batch 5319 batch loss 0.892017961 epoch total loss 1.21499
Trained batch 5320 batch loss 1.27701235 epoch total loss 1.21500158
Trained batch 5321 batch loss 1.11728 epoch total loss 1.21498322
Trained batch 5322 batch loss 1.04971445 epoch total loss 1.21495223
Trained batch 5323 batch loss 1.45493603 epoch total loss 1.21499729
Trained batch 5324 batch loss 1.37690187 epoch total loss 1.21502769
Trained batch 5325 batch loss 1.536726 epoch total loss 1.21508813
Trained batch 5326 batch loss 1.19492745 epoch total loss 1.21508431
Trained batch 5327 batch loss 1.51564026 epoch total loss 1.2151407
Trained batch 5328 batch loss 1.3784132 epoch total loss 1.21517134
Trained batch 5329 batch loss 1.25576425 epoch total loss 1.21517897
Trained batch 5330 batch loss 1.33061719 epoch total loss 1.21520066
Trained batch 5331 batch loss 1.22469246 epoch total loss 1.21520245
Trained batch 5332 batch loss 1.30530345 epoch total loss 1.21521926
Trained batch 5333 batch loss 1.39310825 epoch total loss 1.21525264
Trained batch 5334 batch loss 1.083776 epoch total loss 1.21522808
Trained batch 5335 batch loss 1.16775286 epoch total loss 1.21521914
Trained batch 5336 batch loss 1.1960156 epoch total loss 1.21521556
Trained batch 5337 batch loss 1.37701952 epoch total loss 1.21524584
Trained batch 5338 batch loss 1.1541605 epoch total loss 1.2152344
Trained batch 5339 batch loss 1.21164107 epoch total loss 1.21523368
Trained batch 5340 batch loss 1.1023711 epoch total loss 1.21521258
Trained batch 5341 batch loss 1.16845834 epoch total loss 1.21520388
Trained batch 5342 batch loss 1.09990764 epoch total loss 1.2151823
Trained batch 5343 batch loss 1.02084088 epoch total loss 1.21514595
Trained batch 5344 batch loss 1.02832508 epoch total loss 1.21511102
Trained batch 5345 batch loss 0.871761143 epoch total loss 1.21504676
Trained batch 5346 batch loss 1.10013115 epoch total loss 1.21502519
Trained batch 5347 batch loss 1.19892359 epoch total loss 1.21502221
Trained batch 5348 batch loss 1.28530073 epoch total loss 1.21503532
Trained batch 5349 batch loss 1.32126009 epoch total loss 1.21505511
Trained batch 5350 batch loss 1.23046255 epoch total loss 1.21505809
Trained batch 5351 batch loss 1.23351502 epoch total loss 1.21506143
Trained batch 5352 batch loss 1.23199 epoch total loss 1.21506464
Trained batch 5353 batch loss 1.28688788 epoch total loss 1.21507812
Trained batch 5354 batch loss 1.12058425 epoch total loss 1.21506047
Trained batch 5355 batch loss 1.13419235 epoch total loss 1.21504533
Trained batch 5356 batch loss 1.17858362 epoch total loss 1.21503854
Trained batch 5357 batch loss 1.33261108 epoch total loss 1.21506047
Trained batch 5358 batch loss 1.22324705 epoch total loss 1.21506202
Trained batch 5359 batch loss 1.35643435 epoch total loss 1.21508837
Trained batch 5360 batch loss 1.26914787 epoch total loss 1.2150985
Trained batch 5361 batch loss 1.167171 epoch total loss 1.21508944
Trained batch 5362 batch loss 1.14629436 epoch total loss 1.21507668
Trained batch 5363 batch loss 0.968276322 epoch total loss 1.21503067
Trained batch 5364 batch loss 1.12950063 epoch total loss 1.2150147
Trained batch 5365 batch loss 1.10789013 epoch total loss 1.21499479
Trained batch 5366 batch loss 1.19062018 epoch total loss 1.21499014
Trained batch 5367 batch loss 1.03259754 epoch total loss 1.21495616
Trained batch 5368 batch loss 1.13833153 epoch total loss 1.21494186
Trained batch 5369 batch loss 1.45038617 epoch total loss 1.21498573
Trained batch 5370 batch loss 1.11807203 epoch total loss 1.21496773
Trained batch 5371 batch loss 1.06765854 epoch total loss 1.21494031
Trained batch 5372 batch loss 1.01397789 epoch total loss 1.21490288
Trained batch 5373 batch loss 1.3285538 epoch total loss 1.2149241
Trained batch 5374 batch loss 1.06212306 epoch total loss 1.21489561
Trained batch 5375 batch loss 1.16531 epoch total loss 1.21488643
Trained batch 5376 batch loss 1.16788459 epoch total loss 1.21487772
Trained batch 5377 batch loss 1.05431175 epoch total loss 1.2148478
Trained batch 5378 batch loss 1.19792306 epoch total loss 1.2148447
Trained batch 5379 batch loss 1.2929424 epoch total loss 1.21485913
Trained batch 5380 batch loss 1.24806809 epoch total loss 1.21486533
Trained batch 5381 batch loss 1.0934633 epoch total loss 1.2148428
Trained batch 5382 batch loss 1.40230048 epoch total loss 1.21487761
Trained batch 5383 batch loss 1.0533191 epoch total loss 1.21484756
Trained batch 5384 batch loss 1.27532315 epoch total loss 1.21485877
Trained batch 5385 batch loss 1.02747011 epoch total loss 1.21482396
Trained batch 5386 batch loss 1.18396401 epoch total loss 1.21481824
Trained batch 5387 batch loss 1.15625072 epoch total loss 1.21480739
Trained batch 5388 batch loss 1.07881141 epoch total loss 1.21478212
Trained batch 5389 batch loss 1.31115246 epoch total loss 1.2148
Trained batch 5390 batch loss 1.23465633 epoch total loss 1.2148037
Trained batch 5391 batch loss 1.22551453 epoch total loss 1.21480572
Trained batch 5392 batch loss 1.20390034 epoch total loss 1.2148037
Trained batch 5393 batch loss 1.22401738 epoch total loss 1.21480548
Trained batch 5394 batch loss 1.08597744 epoch total loss 1.21478152
Trained batch 5395 batch loss 1.14653873 epoch total loss 1.21476889
Trained batch 5396 batch loss 1.18656778 epoch total loss 1.21476364
Trained batch 5397 batch loss 1.13380444 epoch total loss 1.21474862
Trained batch 5398 batch loss 1.25715876 epoch total loss 1.21475661
Trained batch 5399 batch loss 1.2893393 epoch total loss 1.21477044
Trained batch 5400 batch loss 1.17688251 epoch total loss 1.2147634
Trained batch 5401 batch loss 1.05941939 epoch total loss 1.21473467
Trained batch 5402 batch loss 1.32105219 epoch total loss 1.21475434
Trained batch 5403 batch loss 1.57443273 epoch total loss 1.21482086
Trained batch 5404 batch loss 1.1899333 epoch total loss 1.21481633
Trained batch 5405 batch loss 1.31978309 epoch total loss 1.21483576
Trained batch 5406 batch loss 1.41121519 epoch total loss 1.214872
Trained batch 5407 batch loss 1.18892884 epoch total loss 1.21486723
Trained batch 5408 batch loss 1.43849969 epoch total loss 1.2149086
Trained batch 5409 batch loss 1.49404907 epoch total loss 1.21496022
Trained batch 5410 batch loss 1.25634 epoch total loss 1.21496785
Trained batch 5411 batch loss 0.878471494 epoch total loss 1.21490562
Trained batch 5412 batch loss 1.06975412 epoch total loss 1.2148788
Trained batch 5413 batch loss 1.07418919 epoch total loss 1.21485281
Trained batch 5414 batch loss 1.08804107 epoch total loss 1.21482944
Trained batch 5415 batch loss 1.19868147 epoch total loss 1.21482646
Trained batch 5416 batch loss 1.26504695 epoch total loss 1.21483576
Trained batch 5417 batch loss 1.20563507 epoch total loss 1.21483397
Trained batch 5418 batch loss 1.38872051 epoch total loss 1.21486604
Trained batch 5419 batch loss 1.21346986 epoch total loss 1.2148658
Trained batch 5420 batch loss 1.11202633 epoch total loss 1.21484685
Trained batch 5421 batch loss 1.34453392 epoch total loss 1.21487081
Trained batch 5422 batch loss 1.26979804 epoch total loss 1.21488094
Trained batch 5423 batch loss 1.16529727 epoch total loss 1.21487188
Trained batch 5424 batch loss 1.1444397 epoch total loss 1.21485889
Trained batch 5425 batch loss 1.22172499 epoch total loss 1.21486008
Trained batch 5426 batch loss 1.16406977 epoch total loss 1.21485078
Trained batch 5427 batch loss 1.24809718 epoch total loss 1.21485686
Trained batch 5428 batch loss 1.37665391 epoch total loss 1.21488667
Trained batch 5429 batch loss 1.32018352 epoch total loss 1.2149061
Trained batch 5430 batch loss 1.16816854 epoch total loss 1.21489739
Trained batch 5431 batch loss 1.15111911 epoch total loss 1.21488559
Trained batch 5432 batch loss 1.17255044 epoch total loss 1.21487784
Trained batch 5433 batch loss 1.11665082 epoch total loss 1.21485972
Trained batch 5434 batch loss 1.22599971 epoch total loss 1.21486187
Trained batch 5435 batch loss 1.17477369 epoch total loss 1.21485448
Trained batch 5436 batch loss 1.02686822 epoch total loss 1.21481991
Trained batch 5437 batch loss 1.23349881 epoch total loss 1.21482325
Trained batch 5438 batch loss 1.33338451 epoch total loss 1.21484506
Trained batch 5439 batch loss 1.24239111 epoch total loss 1.21485007
Trained batch 5440 batch loss 1.44588661 epoch total loss 1.21489263
Trained batch 5441 batch loss 1.35707033 epoch total loss 1.21491873
Trained batch 5442 batch loss 1.25416279 epoch total loss 1.21492589
Trained batch 5443 batch loss 1.23235214 epoch total loss 1.2149291
Trained batch 5444 batch loss 1.25296247 epoch total loss 1.21493614
Trained batch 5445 batch loss 1.30451798 epoch total loss 1.21495259
Trained batch 5446 batch loss 1.52372479 epoch total loss 1.21500933
Trained batch 5447 batch loss 1.34602451 epoch total loss 1.21503341
Trained batch 5448 batch loss 1.21168733 epoch total loss 1.21503282
Trained batch 5449 batch loss 1.03526676 epoch total loss 1.21499979
Trained batch 5450 batch loss 1.25855255 epoch total loss 1.2150079
Trained batch 5451 batch loss 1.27740312 epoch total loss 1.21501935
Trained batch 5452 batch loss 1.23084235 epoch total loss 1.21502221
Trained batch 5453 batch loss 1.41417372 epoch total loss 1.2150588
Trained batch 5454 batch loss 1.26753545 epoch total loss 1.21506834
Trained batch 5455 batch loss 1.24138451 epoch total loss 1.21507311
Trained batch 5456 batch loss 1.30917096 epoch total loss 1.21509039
Trained batch 5457 batch loss 1.2123158 epoch total loss 1.21508992
Trained batch 5458 batch loss 1.12059331 epoch total loss 1.21507263
Trained batch 5459 batch loss 1.44383931 epoch total loss 1.21511447
Trained batch 5460 batch loss 1.28548598 epoch total loss 1.21512747
Trained batch 5461 batch loss 1.20031226 epoch total loss 1.21512473
Trained batch 5462 batch loss 1.41886139 epoch total loss 1.21516204
Trained batch 5463 batch loss 1.31288981 epoch total loss 1.21517992
Trained batch 5464 batch loss 1.04107356 epoch total loss 1.21514809
Trained batch 5465 batch loss 0.908068 epoch total loss 1.21509182
Trained batch 5466 batch loss 1.37820339 epoch total loss 1.21512175
Trained batch 5467 batch loss 1.53707409 epoch total loss 1.21518064
Trained batch 5468 batch loss 1.43835735 epoch total loss 1.21522152
Trained batch 5469 batch loss 1.4499048 epoch total loss 1.21526432
Trained batch 5470 batch loss 1.62166512 epoch total loss 1.21533859
Trained batch 5471 batch loss 1.30739522 epoch total loss 1.21535552
Trained batch 5472 batch loss 1.4654454 epoch total loss 1.21540117
Trained batch 5473 batch loss 1.60260797 epoch total loss 1.21547186
Trained batch 5474 batch loss 1.45271683 epoch total loss 1.21551526
Trained batch 5475 batch loss 1.38687623 epoch total loss 1.21554649
Trained batch 5476 batch loss 1.22352028 epoch total loss 1.21554804
Trained batch 5477 batch loss 0.988903165 epoch total loss 1.21550655
Trained batch 5478 batch loss 1.03883 epoch total loss 1.21547437
Trained batch 5479 batch loss 1.02327847 epoch total loss 1.21543932
Trained batch 5480 batch loss 1.19437361 epoch total loss 1.2154355
Trained batch 5481 batch loss 1.14056611 epoch total loss 1.2154218
Trained batch 5482 batch loss 1.30155241 epoch total loss 1.21543753
Trained batch 5483 batch loss 1.10565305 epoch total loss 1.2154175
Trained batch 5484 batch loss 1.20188975 epoch total loss 1.215415
Trained batch 5485 batch loss 1.06297433 epoch total loss 1.21538723
Trained batch 5486 batch loss 1.11151433 epoch total loss 1.21536827
Trained batch 5487 batch loss 0.971384168 epoch total loss 1.21532381
Trained batch 5488 batch loss 1.20370746 epoch total loss 1.21532166
Trained batch 5489 batch loss 1.6087383 epoch total loss 1.2153933
Trained batch 5490 batch loss 1.25079119 epoch total loss 1.21539986
Trained batch 5491 batch loss 1.12569094 epoch total loss 1.21538341
Trained batch 5492 batch loss 1.16042459 epoch total loss 1.21537352
Trained batch 5493 batch loss 1.2785356 epoch total loss 1.21538496
Trained batch 5494 batch loss 1.34674454 epoch total loss 1.2154088
Trained batch 5495 batch loss 1.15763175 epoch total loss 1.21539831
Trained batch 5496 batch loss 1.3067193 epoch total loss 1.21541488
Trained batch 5497 batch loss 1.16791892 epoch total loss 1.2154063
Trained batch 5498 batch loss 1.12391925 epoch total loss 1.21538973
Trained batch 5499 batch loss 1.21051741 epoch total loss 1.21538877
Trained batch 5500 batch loss 1.30644059 epoch total loss 1.21540534
Trained batch 5501 batch loss 1.32647562 epoch total loss 1.21542561
Trained batch 5502 batch loss 1.19915652 epoch total loss 1.21542263
Trained batch 5503 batch loss 1.22843611 epoch total loss 1.21542501
Trained batch 5504 batch loss 1.20316315 epoch total loss 1.21542275
Trained batch 5505 batch loss 1.35843754 epoch total loss 1.21544874
Trained batch 5506 batch loss 1.4762243 epoch total loss 1.21549606
Trained batch 5507 batch loss 1.49169815 epoch total loss 1.21554625
Trained batch 5508 batch loss 1.17928 epoch total loss 1.21553969
Trained batch 5509 batch loss 1.43442619 epoch total loss 1.21557939
Trained batch 5510 batch loss 1.40788054 epoch total loss 1.21561432
Trained batch 5511 batch loss 1.36072206 epoch total loss 1.21564066
Trained batch 5512 batch loss 1.34811521 epoch total loss 1.21566463
Trained batch 5513 batch loss 1.60328162 epoch total loss 1.21573508
Trained batch 5514 batch loss 1.34421086 epoch total loss 1.21575832
Trained batch 5515 batch loss 1.12404025 epoch total loss 1.21574163
Trained batch 5516 batch loss 1.28115535 epoch total loss 1.21575356
Trained batch 5517 batch loss 1.13273919 epoch total loss 1.21573853
Trained batch 5518 batch loss 1.20625412 epoch total loss 1.21573675
Trained batch 5519 batch loss 1.206918 epoch total loss 1.2157352
Trained batch 5520 batch loss 1.22045946 epoch total loss 1.21573615
Trained batch 5521 batch loss 1.2588532 epoch total loss 1.2157439
Trained batch 5522 batch loss 1.24939203 epoch total loss 1.21575
Trained batch 5523 batch loss 1.19683576 epoch total loss 1.21574652
Trained batch 5524 batch loss 1.0256238 epoch total loss 1.21571207
Trained batch 5525 batch loss 1.11058259 epoch total loss 1.215693
Trained batch 5526 batch loss 1.19152617 epoch total loss 1.21568871
Trained batch 5527 batch loss 1.03412843 epoch total loss 1.2156558
Trained batch 5528 batch loss 1.17632151 epoch total loss 1.21564865
Trained batch 5529 batch loss 1.34799 epoch total loss 1.21567261
Trained batch 5530 batch loss 1.30200672 epoch total loss 1.21568835
Trained batch 5531 batch loss 1.27301466 epoch total loss 1.21569872
Trained batch 5532 batch loss 1.43591392 epoch total loss 1.21573853
Trained batch 5533 batch loss 1.27158451 epoch total loss 1.21574855
Trained batch 5534 batch loss 1.16489792 epoch total loss 1.21573937
Trained batch 5535 batch loss 1.18576288 epoch total loss 1.215734
Trained batch 5536 batch loss 1.08989358 epoch total loss 1.21571124
Trained batch 5537 batch loss 1.19924247 epoch total loss 1.21570826
Trained batch 5538 batch loss 1.28517866 epoch total loss 1.21572077
Trained batch 5539 batch loss 1.19914579 epoch total loss 1.21571779
Trained batch 5540 batch loss 1.18922234 epoch total loss 1.21571302
Trained batch 5541 batch loss 1.23345065 epoch total loss 1.21571624
Trained batch 5542 batch loss 1.10047901 epoch total loss 1.2156955
Trained batch 5543 batch loss 1.17363822 epoch total loss 1.21568787
Trained batch 5544 batch loss 1.13567853 epoch total loss 1.21567345
Trained batch 5545 batch loss 1.07947338 epoch total loss 1.21564901
Trained batch 5546 batch loss 1.3496542 epoch total loss 1.21567309
Trained batch 5547 batch loss 1.04228377 epoch total loss 1.21564186
Trained batch 5548 batch loss 1.00871992 epoch total loss 1.21560454
Trained batch 5549 batch loss 1.27050877 epoch total loss 1.21561444
Trained batch 5550 batch loss 1.1570096 epoch total loss 1.21560395
Trained batch 5551 batch loss 1.10461104 epoch total loss 1.21558392
Trained batch 5552 batch loss 1.24374378 epoch total loss 1.21558905
Epoch 2 train loss 1.2155890464782715
Validated batch 1 batch loss 1.10000587
Validated batch 2 batch loss 1.32039618
Validated batch 3 batch loss 1.17658353
Validated batch 4 batch loss 1.29757261
Validated batch 5 batch loss 1.25022
Validated batch 6 batch loss 1.13316798
Validated batch 7 batch loss 1.3249191
Validated batch 8 batch loss 1.10433555
Validated batch 9 batch loss 1.20486236
Validated batch 10 batch loss 1.26518118
Validated batch 11 batch loss 1.09858251
Validated batch 12 batch loss 0.973498702
Validated batch 13 batch loss 1.27122247
Validated batch 14 batch loss 1.23668242
Validated batch 15 batch loss 1.21232116
Validated batch 16 batch loss 1.4024
Validated batch 17 batch loss 1.23409557
Validated batch 18 batch loss 1.26922357
Validated batch 19 batch loss 1.13819742
Validated batch 20 batch loss 1.31416583
Validated batch 21 batch loss 1.19904709
Validated batch 22 batch loss 1.27323878
Validated batch 23 batch loss 1.33619595
Validated batch 24 batch loss 1.31207991
Validated batch 25 batch loss 1.29685736
Validated batch 26 batch loss 1.19196844
Validated batch 27 batch loss 1.42020273
Validated batch 28 batch loss 1.33673477
Validated batch 29 batch loss 1.07505226
Validated batch 30 batch loss 1.44440758
Validated batch 31 batch loss 1.31853771
Validated batch 32 batch loss 1.23013306
Validated batch 33 batch loss 1.23143411
Validated batch 34 batch loss 1.37460065
Validated batch 35 batch loss 1.26062012
Validated batch 36 batch loss 1.18897128
Validated batch 37 batch loss 1.20493412
Validated batch 38 batch loss 1.25031471
Validated batch 39 batch loss 1.1614095
Validated batch 40 batch loss 1.30795479
Validated batch 41 batch loss 1.26511383
Validated batch 42 batch loss 1.14684343
Validated batch 43 batch loss 1.33572328
Validated batch 44 batch loss 1.45505404
Validated batch 45 batch loss 1.30696988
Validated batch 46 batch loss 1.09185886
Validated batch 47 batch loss 1.26826239
Validated batch 48 batch loss 1.28488016
Validated batch 49 batch loss 0.98754257
Validated batch 50 batch loss 1.32824492
Validated batch 51 batch loss 1.35539579
Validated batch 52 batch loss 1.27049673
Validated batch 53 batch loss 1.46742582
Validated batch 54 batch loss 1.05646968
Validated batch 55 batch loss 1.41071796
Validated batch 56 batch loss 1.32637835
Validated batch 57 batch loss 1.36707819
Validated batch 58 batch loss 1.35239577
Validated batch 59 batch loss 1.11288738
Validated batch 60 batch loss 1.34780693
Validated batch 61 batch loss 1.15025246
Validated batch 62 batch loss 1.26917517
Validated batch 63 batch loss 1.34449661
Validated batch 64 batch loss 1.10625052
Validated batch 65 batch loss 1.26483011
Validated batch 66 batch loss 1.30368853
Validated batch 67 batch loss 1.75700092
Validated batch 68 batch loss 1.16373682
Validated batch 69 batch loss 1.04589343
Validated batch 70 batch loss 1.06455183
Validated batch 71 batch loss 1.02373052
Validated batch 72 batch loss 1.22007656
Validated batch 73 batch loss 1.36713982
Validated batch 74 batch loss 1.07317317
Validated batch 75 batch loss 1.30220318
Validated batch 76 batch loss 1.38577008
Validated batch 77 batch loss 1.15258896
Validated batch 78 batch loss 1.03097034
Validated batch 79 batch loss 1.09561992
Validated batch 80 batch loss 1.07921219
Validated batch 81 batch loss 0.997870207
Validated batch 82 batch loss 1.14992523
Validated batch 83 batch loss 1.30304205
Validated batch 84 batch loss 1.39340401
Validated batch 85 batch loss 1.26552832
Validated batch 86 batch loss 1.27837789
Validated batch 87 batch loss 1.37140179
Validated batch 88 batch loss 1.32086253
Validated batch 89 batch loss 1.02132833
Validated batch 90 batch loss 1.08888507
Validated batch 91 batch loss 1.15579593
Validated batch 92 batch loss 1.23761177
Validated batch 93 batch loss 1.26769865
Validated batch 94 batch loss 1.14946485
Validated batch 95 batch loss 1.17043483
Validated batch 96 batch loss 1.21350574
Validated batch 97 batch loss 1.07577145
Validated batch 98 batch loss 0.989106774
Validated batch 99 batch loss 1.16186833
Validated batch 100 batch loss 1.15902352
Validated batch 101 batch loss 1.20715261
Validated batch 102 batch loss 1.19912171
Validated batch 103 batch loss 1.2398715
Validated batch 104 batch loss 1.23522043
Validated batch 105 batch loss 1.17027211
Validated batch 106 batch loss 1.09031916
Validated batch 107 batch loss 1.04566956
Validated batch 108 batch loss 1.22361231
Validated batch 109 batch loss 1.29442978
Validated batch 110 batch loss 1.11711681
Validated batch 111 batch loss 1.02551889
Validated batch 112 batch loss 1.34190214
Validated batch 113 batch loss 1.12984431
Validated batch 114 batch loss 1.37997842
Validated batch 115 batch loss 1.36880398
Validated batch 116 batch loss 1.20737374
Validated batch 117 batch loss 1.0796957
Validated batch 118 batch loss 1.26387239
Validated batch 119 batch loss 1.26925337
Validated batch 120 batch loss 1.20244145
Validated batch 121 batch loss 1.23260069
Validated batch 122 batch loss 1.2900362
Validated batch 123 batch loss 1.3223809
Validated batch 124 batch loss 1.52744472
Validated batch 125 batch loss 1.22852039
Validated batch 126 batch loss 1.18166852
Validated batch 127 batch loss 1.24415684
Validated batch 128 batch loss 1.47420835
Validated batch 129 batch loss 1.363958
Validated batch 130 batch loss 1.20596504
Validated batch 131 batch loss 1.22111726
Validated batch 132 batch loss 1.15845692
Validated batch 133 batch loss 1.29304063
Validated batch 134 batch loss 1.23932695
Validated batch 135 batch loss 1.15716183
Validated batch 136 batch loss 1.32391357
Validated batch 137 batch loss 1.32428789
Validated batch 138 batch loss 1.37579441
Validated batch 139 batch loss 1.53601813
Validated batch 140 batch loss 0.984484792
Validated batch 141 batch loss 1.35620952
Validated batch 142 batch loss 1.31508815
Validated batch 143 batch loss 1.21811843
Validated batch 144 batch loss 1.36066473
Validated batch 145 batch loss 1.39234138
Validated batch 146 batch loss 1.24673724
Validated batch 147 batch loss 1.2598381
Validated batch 148 batch loss 1.3785671
Validated batch 149 batch loss 1.19303262
Validated batch 150 batch loss 1.3107717
Validated batch 151 batch loss 1.28612113
Validated batch 152 batch loss 1.26201749
Validated batch 153 batch loss 1.46749949
Validated batch 154 batch loss 1.32511675
Validated batch 155 batch loss 1.31001568
Validated batch 156 batch loss 1.15055716
Validated batch 157 batch loss 1.42916703
Validated batch 158 batch loss 1.33983052
Validated batch 159 batch loss 1.18324566
Validated batch 160 batch loss 1.17362428
Validated batch 161 batch loss 1.31397867
Validated batch 162 batch loss 0.985121
Validated batch 163 batch loss 1.03316104
Validated batch 164 batch loss 1.17941248
Validated batch 165 batch loss 1.13793921
Validated batch 166 batch loss 1.13861573
Validated batch 167 batch loss 1.38568509
Validated batch 168 batch loss 1.21572208
Validated batch 169 batch loss 1.28889954
Validated batch 170 batch loss 1.24989438
Validated batch 171 batch loss 1.22575045
Validated batch 172 batch loss 1.38536859
Validated batch 173 batch loss 1.28700435
Validated batch 174 batch loss 1.23173821
Validated batch 175 batch loss 1.20354438
Validated batch 176 batch loss 1.11903954
Validated batch 177 batch loss 1.15397692
Validated batch 178 batch loss 1.1765244
Validated batch 179 batch loss 1.22501719
Validated batch 180 batch loss 1.2588011
Validated batch 181 batch loss 1.28322768
Validated batch 182 batch loss 1.30218148
Validated batch 183 batch loss 0.998484433
Validated batch 184 batch loss 1.19116461
Validated batch 185 batch loss 1.22858846
Validated batch 186 batch loss 1.17571902
Validated batch 187 batch loss 1.2057209
Validated batch 188 batch loss 1.31101334
Validated batch 189 batch loss 1.29162
Validated batch 190 batch loss 1.16178417
Validated batch 191 batch loss 1.0946486
Validated batch 192 batch loss 1.29133046
Validated batch 193 batch loss 1.19734299
Validated batch 194 batch loss 1.14957082
Validated batch 195 batch loss 1.17134428
Validated batch 196 batch loss 1.11931908
Validated batch 197 batch loss 1.2541095
Validated batch 198 batch loss 0.904349446
Validated batch 199 batch loss 1.35915828
Validated batch 200 batch loss 1.13231444
Validated batch 201 batch loss 1.14498591
Validated batch 202 batch loss 1.28807378
Validated batch 203 batch loss 1.29566324
Validated batch 204 batch loss 1.13668537
Validated batch 205 batch loss 1.5174911
Validated batch 206 batch loss 1.51508689
Validated batch 207 batch loss 1.23992932
Validated batch 208 batch loss 1.18114781
Validated batch 209 batch loss 1.15262508
Validated batch 210 batch loss 1.0411638
Validated batch 211 batch loss 1.16616869
Validated batch 212 batch loss 1.1389643
Validated batch 213 batch loss 1.12016785
Validated batch 214 batch loss 1.31282246
Validated batch 215 batch loss 1.33545506
Validated batch 216 batch loss 1.20709229
Validated batch 217 batch loss 1.08006287
Validated batch 218 batch loss 1.13057446
Validated batch 219 batch loss 1.07800722
Validated batch 220 batch loss 1.41303825
Validated batch 221 batch loss 1.30672073
Validated batch 222 batch loss 1.18148148
Validated batch 223 batch loss 1.20211399
Validated batch 224 batch loss 1.24965036
Validated batch 225 batch loss 1.15646
Validated batch 226 batch loss 1.19621873
Validated batch 227 batch loss 1.1647675
Validated batch 228 batch loss 1.21523952
Validated batch 229 batch loss 1.09956563
Validated batch 230 batch loss 1.2039597
Validated batch 231 batch loss 0.974501371
Validated batch 232 batch loss 1.07952833
Validated batch 233 batch loss 1.32357287
Validated batch 234 batch loss 1.08043325
Validated batch 235 batch loss 1.51062572
Validated batch 236 batch loss 1.50630236
Validated batch 237 batch loss 1.33645058
Validated batch 238 batch loss 1.15796208
Validated batch 239 batch loss 0.864272714
Validated batch 240 batch loss 1.24308324
Validated batch 241 batch loss 1.1958493
Validated batch 242 batch loss 1.34547186
Validated batch 243 batch loss 1.28253961
Validated batch 244 batch loss 1.23946953
Validated batch 245 batch loss 1.04106605
Validated batch 246 batch loss 1.21311164
Validated batch 247 batch loss 1.35963166
Validated batch 248 batch loss 1.05566299
Validated batch 249 batch loss 1.34375191
Validated batch 250 batch loss 1.29672146
Validated batch 251 batch loss 1.20591307
Validated batch 252 batch loss 1.33083868
Validated batch 253 batch loss 1.40018523
Validated batch 254 batch loss 1.11933243
Validated batch 255 batch loss 0.868018508
Validated batch 256 batch loss 0.986339
Validated batch 257 batch loss 1.11591244
Validated batch 258 batch loss 1.32336807
Validated batch 259 batch loss 1.10302377
Validated batch 260 batch loss 1.28585076
Validated batch 261 batch loss 1.23723602
Validated batch 262 batch loss 1.13858259
Validated batch 263 batch loss 1.13768983
Validated batch 264 batch loss 1.07629848
Validated batch 265 batch loss 1.13663876
Validated batch 266 batch loss 1.34008968
Validated batch 267 batch loss 1.10662353
Validated batch 268 batch loss 1.12687254
Validated batch 269 batch loss 1.40788949
Validated batch 270 batch loss 1.11661887
Validated batch 271 batch loss 1.21265042
Validated batch 272 batch loss 1.38719237
Validated batch 273 batch loss 1.31051707
Validated batch 274 batch loss 1.03426886
Validated batch 275 batch loss 1.21454048
Validated batch 276 batch loss 1.27217865
Validated batch 277 batch loss 1.44004536
Validated batch 278 batch loss 1.041116
Validated batch 279 batch loss 1.26748705
Validated batch 280 batch loss 1.20697904
Validated batch 281 batch loss 1.16287553
Validated batch 282 batch loss 1.20715213
Validated batch 283 batch loss 1.03553474
Validated batch 284 batch loss 1.12109292
Validated batch 285 batch loss 1.23808718
Validated batch 286 batch loss 1.23481309
Validated batch 287 batch loss 1.1851263
Validated batch 288 batch loss 1.12432671
Validated batch 289 batch loss 1.11273193
Validated batch 290 batch loss 1.30470979
Validated batch 291 batch loss 1.08675265
Validated batch 292 batch loss 1.00975907
Validated batch 293 batch loss 1.15644515
Validated batch 294 batch loss 1.31406546
Validated batch 295 batch loss 0.978347659
Validated batch 296 batch loss 1.2627399
Validated batch 297 batch loss 1.24076807
Validated batch 298 batch loss 1.20974135
Validated batch 299 batch loss 1.37411296
Validated batch 300 batch loss 1.09118319
Validated batch 301 batch loss 1.24636769
Validated batch 302 batch loss 1.24655437
Validated batch 303 batch loss 0.979134083
Validated batch 304 batch loss 1.48893976
Validated batch 305 batch loss 1.11313057
Validated batch 306 batch loss 1.22312975
Validated batch 307 batch loss 1.19411039
Validated batch 308 batch loss 1.29781842
Validated batch 309 batch loss 1.35349798
Validated batch 310 batch loss 1.24646139
Validated batch 311 batch loss 1.28463483
Validated batch 312 batch loss 0.927767277
Validated batch 313 batch loss 1.11571121
Validated batch 314 batch loss 1.08044159
Validated batch 315 batch loss 1.18940067
Validated batch 316 batch loss 1.25999641
Validated batch 317 batch loss 1.43578744
Validated batch 318 batch loss 1.32267404
Validated batch 319 batch loss 1.13909435
Validated batch 320 batch loss 1.06317449
Validated batch 321 batch loss 1.33643174
Validated batch 322 batch loss 1.510813
Validated batch 323 batch loss 1.09249878
Validated batch 324 batch loss 1.08286369
Validated batch 325 batch loss 1.01824725
Validated batch 326 batch loss 1.04306459
Validated batch 327 batch loss 1.24836874
Validated batch 328 batch loss 1.33153844
Validated batch 329 batch loss 1.37538266
Validated batch 330 batch loss 1.06988049
Validated batch 331 batch loss 1.18034387
Validated batch 332 batch loss 1.15702152
Validated batch 333 batch loss 1.40508699
Validated batch 334 batch loss 1.14209974
Validated batch 335 batch loss 1.15224445
Validated batch 336 batch loss 1.13202107
Validated batch 337 batch loss 1.26703048
Validated batch 338 batch loss 1.07810402
Validated batch 339 batch loss 1.12022269
Validated batch 340 batch loss 1.21719241
Validated batch 341 batch loss 1.34785819
Validated batch 342 batch loss 1.42116725
Validated batch 343 batch loss 1.27188873
Validated batch 344 batch loss 1.38811922
Validated batch 345 batch loss 1.09764266
Validated batch 346 batch loss 1.02268696
Validated batch 347 batch loss 1.20451903
Validated batch 348 batch loss 1.4269619
Validated batch 349 batch loss 1.37692106
Validated batch 350 batch loss 1.18386292
Validated batch 351 batch loss 1.1162163
Validated batch 352 batch loss 0.901104391
Validated batch 353 batch loss 1.17423224
Validated batch 354 batch loss 1.32670236
Validated batch 355 batch loss 1.08707631
Validated batch 356 batch loss 1.41959143
Validated batch 357 batch loss 1.21930981
Validated batch 358 batch loss 1.17655993
Validated batch 359 batch loss 1.31513882
Validated batch 360 batch loss 1.19437623
Validated batch 361 batch loss 1.22287166
Validated batch 362 batch loss 1.34786177
Validated batch 363 batch loss 1.09076619
Validated batch 364 batch loss 0.967564225
Validated batch 365 batch loss 1.15975285
Validated batch 366 batch loss 1.29359567
Validated batch 367 batch loss 1.18302274
Validated batch 368 batch loss 1.2701726
Validated batch 369 batch loss 1.22009122
Validated batch 370 batch loss 1.27925885
Validated batch 371 batch loss 1.51217568
Validated batch 372 batch loss 1.37510943
Validated batch 373 batch loss 1.17124975
Validated batch 374 batch loss 1.19635737
Validated batch 375 batch loss 1.05976057
Validated batch 376 batch loss 1.30860531
Validated batch 377 batch loss 1.40664291
Validated batch 378 batch loss 1.23314929
Validated batch 379 batch loss 1.06863594
Validated batch 380 batch loss 1.08509517
Validated batch 381 batch loss 1.31551957
Validated batch 382 batch loss 1.06738687
Validated batch 383 batch loss 1.25269198
Validated batch 384 batch loss 1.19814277
Validated batch 385 batch loss 1.25907993
Validated batch 386 batch loss 1.03846
Validated batch 387 batch loss 1.0837326
Validated batch 388 batch loss 1.22375441
Validated batch 389 batch loss 1.19439983
Validated batch 390 batch loss 1.37365174
Validated batch 391 batch loss 1.33397746
Validated batch 392 batch loss 1.14170551
Validated batch 393 batch loss 1.23173642
Validated batch 394 batch loss 1.2811451
Validated batch 395 batch loss 1.29614353
Validated batch 396 batch loss 1.17868364
Validated batch 397 batch loss 1.31381989
Validated batch 398 batch loss 1.07985
Validated batch 399 batch loss 1.07449949
Validated batch 400 batch loss 1.15223503
Validated batch 401 batch loss 1.12743092
Validated batch 402 batch loss 1.07584214
Validated batch 403 batch loss 1.19475508
Validated batch 404 batch loss 1.29844785
Validated batch 405 batch loss 1.38810444
Validated batch 406 batch loss 1.11502433
Validated batch 407 batch loss 1.26292014
Validated batch 408 batch loss 1.10641861
Validated batch 409 batch loss 1.26338458
Validated batch 410 batch loss 1.32559025
Validated batch 411 batch loss 1.10104918
Validated batch 412 batch loss 1.27654517
Validated batch 413 batch loss 1.36347151
Validated batch 414 batch loss 1.34862
Validated batch 415 batch loss 1.1716603
Validated batch 416 batch loss 1.3764708
Validated batch 417 batch loss 0.95168221
Validated batch 418 batch loss 1.3718071
Validated batch 419 batch loss 1.24484074
Validated batch 420 batch loss 1.19564962
Validated batch 421 batch loss 1.12218666
Validated batch 422 batch loss 0.933601141
Validated batch 423 batch loss 1.20005012
Validated batch 424 batch loss 1.23045897
Validated batch 425 batch loss 1.27348757
Validated batch 426 batch loss 1.20061851
Validated batch 427 batch loss 1.12250257
Validated batch 428 batch loss 0.944167
Validated batch 429 batch loss 1.23994231
Validated batch 430 batch loss 1.35942531
Validated batch 431 batch loss 1.16789889
Validated batch 432 batch loss 1.15130639
Validated batch 433 batch loss 1.17946
Validated batch 434 batch loss 1.07898974
Validated batch 435 batch loss 1.2893672
Validated batch 436 batch loss 1.13852394
Validated batch 437 batch loss 1.13568103
Validated batch 438 batch loss 1.29433203
Validated batch 439 batch loss 1.33071315
Validated batch 440 batch loss 1.19239807
Validated batch 441 batch loss 1.24379706
Validated batch 442 batch loss 1.18982244
Validated batch 443 batch loss 1.24432206
Validated batch 444 batch loss 1.35307455
Validated batch 445 batch loss 1.38956571
Validated batch 446 batch loss 1.38589454
Validated batch 447 batch loss 1.48235095
Validated batch 448 batch loss 1.52865767
Validated batch 449 batch loss 1.52006221
Validated batch 450 batch loss 1.44476223
Validated batch 451 batch loss 1.22943401
Validated batch 452 batch loss 1.26109672
Validated batch 453 batch loss 1.22666931
Validated batch 454 batch loss 1.0906527
Validated batch 455 batch loss 1.33652139
Validated batch 456 batch loss 1.28355551
Validated batch 457 batch loss 1.23124373
Validated batch 458 batch loss 1.05244303
Validated batch 459 batch loss 1.0339992
Validated batch 460 batch loss 1.27734113
Validated batch 461 batch loss 1.04139733
Validated batch 462 batch loss 0.959296286
Validated batch 463 batch loss 1.16911519
Validated batch 464 batch loss 1.31961894
Validated batch 465 batch loss 1.14325476
Validated batch 466 batch loss 1.17420077
Validated batch 467 batch loss 1.33257222
Validated batch 468 batch loss 1.14926839
Validated batch 469 batch loss 0.945578933
Validated batch 470 batch loss 1.37288594
Validated batch 471 batch loss 1.24225879
Validated batch 472 batch loss 1.11715925
Validated batch 473 batch loss 0.899957418
Validated batch 474 batch loss 1.04057741
Validated batch 475 batch loss 1.07375669
Validated batch 476 batch loss 1.28357053
Validated batch 477 batch loss 1.13096392
Validated batch 478 batch loss 1.18509912
Validated batch 479 batch loss 1.21691394
Validated batch 480 batch loss 0.953961849
Validated batch 481 batch loss 1.14505279
Validated batch 482 batch loss 1.35091591
Validated batch 483 batch loss 1.65460253
Validated batch 484 batch loss 1.14630806
Validated batch 485 batch loss 0.966715097
Validated batch 486 batch loss 1.37439084
Validated batch 487 batch loss 1.05332661
Validated batch 488 batch loss 1.11976314
Validated batch 489 batch loss 1.35248435
Validated batch 490 batch loss 1.23444152
Validated batch 491 batch loss 0.953807116
Validated batch 492 batch loss 0.945704818
Validated batch 493 batch loss 1.23800814
Validated batch 494 batch loss 1.05308867
Validated batch 495 batch loss 1.0717752
Validated batch 496 batch loss 1.28580678
Validated batch 497 batch loss 1.08277822
Validated batch 498 batch loss 1.21250224
Validated batch 499 batch loss 1.26023126
Validated batch 500 batch loss 1.11294162
Validated batch 501 batch loss 1.00697827
Validated batch 502 batch loss 1.16102529
Validated batch 503 batch loss 1.11610579
Validated batch 504 batch loss 1.08080482
Validated batch 505 batch loss 1.22607291
Validated batch 506 batch loss 1.29410851
Validated batch 507 batch loss 1.2991221
Validated batch 508 batch loss 1.10335493
Validated batch 509 batch loss 0.972019076
Validated batch 510 batch loss 1.24746609
Validated batch 511 batch loss 1.01375389
Validated batch 512 batch loss 1.46064281
Validated batch 513 batch loss 1.10547805
Validated batch 514 batch loss 1.21684337
Validated batch 515 batch loss 1.05909705
Validated batch 516 batch loss 1.1326555
Validated batch 517 batch loss 1.31745863
Validated batch 518 batch loss 1.27525115
Validated batch 519 batch loss 1.29845643
Validated batch 520 batch loss 1.1431632
Validated batch 521 batch loss 1.36018121
Validated batch 522 batch loss 1.39760661
Validated batch 523 batch loss 1.28333557
Validated batch 524 batch loss 1.40384543
Validated batch 525 batch loss 1.15976214
Validated batch 526 batch loss 1.13173425
Validated batch 527 batch loss 1.15961933
Validated batch 528 batch loss 1.03465629
Validated batch 529 batch loss 1.3859278
Validated batch 530 batch loss 1.34750962
Validated batch 531 batch loss 1.33781946
Validated batch 532 batch loss 1.21787405
Validated batch 533 batch loss 1.16906869
Validated batch 534 batch loss 0.960314631
Validated batch 535 batch loss 1.09290957
Validated batch 536 batch loss 0.905226588
Validated batch 537 batch loss 1.22212458
Validated batch 538 batch loss 1.11079228
Validated batch 539 batch loss 0.964798808
Validated batch 540 batch loss 1.29537606
Validated batch 541 batch loss 1.28301764
Validated batch 542 batch loss 1.23208475
Validated batch 543 batch loss 1.04778671
Validated batch 544 batch loss 0.949311256
Validated batch 545 batch loss 1.06672382
Validated batch 546 batch loss 1.16537142
Validated batch 547 batch loss 1.22553432
Validated batch 548 batch loss 1.3003912
Validated batch 549 batch loss 1.22921729
Validated batch 550 batch loss 1.4040451
Validated batch 551 batch loss 1.50728059
Validated batch 552 batch loss 1.18269849
Validated batch 553 batch loss 1.34863222
Validated batch 554 batch loss 1.20188975
Validated batch 555 batch loss 1.13029
Validated batch 556 batch loss 1.3068037
Validated batch 557 batch loss 1.34823918
Validated batch 558 batch loss 1.37489462
Validated batch 559 batch loss 1.32280552
Validated batch 560 batch loss 1.01118231
Validated batch 561 batch loss 1.1934917
Validated batch 562 batch loss 1.00091767
Validated batch 563 batch loss 1.00222421
Validated batch 564 batch loss 1.38583541
Validated batch 565 batch loss 1.20962667
Validated batch 566 batch loss 1.2862004
Validated batch 567 batch loss 1.19159019
Validated batch 568 batch loss 1.06449485
Validated batch 569 batch loss 1.13032663
Validated batch 570 batch loss 1.16879463
Validated batch 571 batch loss 1.29359376
Validated batch 572 batch loss 1.23307204
Validated batch 573 batch loss 1.14305592
Validated batch 574 batch loss 1.05142069
Validated batch 575 batch loss 1.33692265
Validated batch 576 batch loss 1.27942944
Validated batch 577 batch loss 1.15554953
Validated batch 578 batch loss 1.18112659
Validated batch 579 batch loss 1.34201193
Validated batch 580 batch loss 1.06224179
Validated batch 581 batch loss 1.14509976
Validated batch 582 batch loss 1.16958809
Validated batch 583 batch loss 1.13791525
Validated batch 584 batch loss 1.39490008
Validated batch 585 batch loss 1.06504202
Validated batch 586 batch loss 0.893775761
Validated batch 587 batch loss 1.09158027
Validated batch 588 batch loss 1.35895276
Validated batch 589 batch loss 1.40337443
Validated batch 590 batch loss 1.48404527
Validated batch 591 batch loss 1.1888442
Validated batch 592 batch loss 1.21598458
Validated batch 593 batch loss 1.26993692
Validated batch 594 batch loss 1.21612144
Validated batch 595 batch loss 1.09442425
Validated batch 596 batch loss 1.04859757
Validated batch 597 batch loss 1.0789535
Validated batch 598 batch loss 1.07536829
Validated batch 599 batch loss 1.11634684
Validated batch 600 batch loss 1.02976823
Validated batch 601 batch loss 1.17018676
Validated batch 602 batch loss 1.22634757
Validated batch 603 batch loss 1.26065564
Validated batch 604 batch loss 1.09208179
Validated batch 605 batch loss 1.45365679
Validated batch 606 batch loss 1.17340446
Validated batch 607 batch loss 1.30740631
Validated batch 608 batch loss 1.39915454
Validated batch 609 batch loss 1.15133989
Validated batch 610 batch loss 1.0937742
Validated batch 611 batch loss 1.40623212
Validated batch 612 batch loss 1.38503408
Validated batch 613 batch loss 1.34491587
Validated batch 614 batch loss 1.3397541
Validated batch 615 batch loss 1.2739377
Validated batch 616 batch loss 1.25937223
Validated batch 617 batch loss 1.31861091
Validated batch 618 batch loss 1.19252563
Validated batch 619 batch loss 1.08704019
Validated batch 620 batch loss 1.17280829
Validated batch 621 batch loss 1.36875951
Validated batch 622 batch loss 1.44807971
Validated batch 623 batch loss 1.36025262
Validated batch 624 batch loss 1.22752392
Validated batch 625 batch loss 1.32936978
Validated batch 626 batch loss 1.12359047
Validated batch 627 batch loss 1.16109514
Validated batch 628 batch loss 1.16140282
Validated batch 629 batch loss 1.32761276
Validated batch 630 batch loss 1.56864691
Validated batch 631 batch loss 1.32123446
Validated batch 632 batch loss 1.03276777
Validated batch 633 batch loss 1.1559341
Validated batch 634 batch loss 1.28809011
Validated batch 635 batch loss 1.27285504
Validated batch 636 batch loss 1.34928894
Validated batch 637 batch loss 1.15030229
Validated batch 638 batch loss 1.04651856
Validated batch 639 batch loss 1.01975083
Validated batch 640 batch loss 0.810760915
Validated batch 641 batch loss 1.07345843
Validated batch 642 batch loss 1.10344458
Validated batch 643 batch loss 1.16803885
Validated batch 644 batch loss 1.30332661
Validated batch 645 batch loss 1.34117854
Validated batch 646 batch loss 1.26165438
Validated batch 647 batch loss 1.16995525
Validated batch 648 batch loss 1.01011801
Validated batch 649 batch loss 0.865698099
Validated batch 650 batch loss 1.33239126
Validated batch 651 batch loss 1.03280401
Validated batch 652 batch loss 1.3704195
Validated batch 653 batch loss 1.15962625
Validated batch 654 batch loss 1.21836495
Validated batch 655 batch loss 1.39379525
Validated batch 656 batch loss 1.16060758
Validated batch 657 batch loss 1.10783792
Validated batch 658 batch loss 1.23077774
Validated batch 659 batch loss 1.13706017
Validated batch 660 batch loss 1.11554074
Validated batch 661 batch loss 0.990916729
Validated batch 662 batch loss 1.34661222
Validated batch 663 batch loss 1.14228153
Validated batch 664 batch loss 1.30751622
Validated batch 665 batch loss 1.29201734
Validated batch 666 batch loss 1.44568586
Validated batch 667 batch loss 1.47730827
Validated batch 668 batch loss 1.36025226
Validated batch 669 batch loss 1.30421472
Validated batch 670 batch loss 1.17524052
Validated batch 671 batch loss 1.06780827
Validated batch 672 batch loss 0.942076802
Validated batch 673 batch loss 1.14067018
Validated batch 674 batch loss 1.30129313
Validated batch 675 batch loss 1.24967051
Validated batch 676 batch loss 1.16395
Validated batch 677 batch loss 1.17639911
Validated batch 678 batch loss 1.2987349
Validated batch 679 batch loss 1.27825785
Validated batch 680 batch loss 0.994908273
Validated batch 681 batch loss 1.10429955
Validated batch 682 batch loss 1.27300167
Validated batch 683 batch loss 1.3084662
Validated batch 684 batch loss 1.3150425
Validated batch 685 batch loss 1.303514
Validated batch 686 batch loss 1.15015519
Validated batch 687 batch loss 1.27180767
Validated batch 688 batch loss 1.2181251
Validated batch 689 batch loss 1.21849346
Validated batch 690 batch loss 1.03855431
Validated batch 691 batch loss 1.13834465
Validated batch 692 batch loss 1.2430259
Validated batch 693 batch loss 0.976012051
Validated batch 694 batch loss 0.842689037
Validated batch 695 batch loss 0.919331789
Validated batch 696 batch loss 1.07655358
Validated batch 697 batch loss 1.2643137
Validated batch 698 batch loss 1.28301311
Validated batch 699 batch loss 1.18644524
Validated batch 700 batch loss 1.17498517
Validated batch 701 batch loss 1.06370044
Validated batch 702 batch loss 1.16741681
Validated batch 703 batch loss 1.22274673
Validated batch 704 batch loss 1.04174185
Validated batch 705 batch loss 1.27087474
Validated batch 706 batch loss 1.09102583
Validated batch 707 batch loss 1.2622155
Validated batch 708 batch loss 1.06919849
Validated batch 709 batch loss 1.21358299
Validated batch 710 batch loss 1.30151141
Validated batch 711 batch loss 1.32676256
Validated batch 712 batch loss 1.2075808
Validated batch 713 batch loss 1.12113655
Validated batch 714 batch loss 1.20641136
Validated batch 715 batch loss 1.11981249
Validated batch 716 batch loss 0.959628701
Validated batch 717 batch loss 1.19672418
Validated batch 718 batch loss 1.26809633
Validated batch 719 batch loss 1.26274276
Validated batch 720 batch loss 1.18968821
Validated batch 721 batch loss 1.07002378
Validated batch 722 batch loss 1.36179292
Validated batch 723 batch loss 1.40448606
Validated batch 724 batch loss 1.42311788
Validated batch 725 batch loss 1.10928369
Validated batch 726 batch loss 1.27246439
Validated batch 727 batch loss 1.34577358
Validated batch 728 batch loss 1.24397242
Validated batch 729 batch loss 1.20030355
Validated batch 730 batch loss 1.28627872
Validated batch 731 batch loss 1.30881143
Validated batch 732 batch loss 1.10080838
Validated batch 733 batch loss 1.16320348
Validated batch 734 batch loss 1.14299536
Validated batch 735 batch loss 1.05911934
Validated batch 736 batch loss 1.03193271
Validated batch 737 batch loss 1.14914155
Validated batch 738 batch loss 1.21611655
Epoch 2 val loss 1.2123668193817139
Start epoch 3 with learning rate 0.0003
Start distributed traininng...
Trained batch 1 batch loss 0.973996162 epoch total loss 0.973996162
Trained batch 2 batch loss 0.922633946 epoch total loss 0.948315
Trained batch 3 batch loss 1.1220603 epoch total loss 1.00623012
Trained batch 4 batch loss 1.3241924 epoch total loss 1.08572066
Trained batch 5 batch loss 1.28245628 epoch total loss 1.12506783
Trained batch 6 batch loss 1.15028501 epoch total loss 1.12927067
Trained batch 7 batch loss 1.2381779 epoch total loss 1.14482892
Trained batch 8 batch loss 1.2856425 epoch total loss 1.16243064
Trained batch 9 batch loss 1.40233064 epoch total loss 1.1890862
Trained batch 10 batch loss 1.35827136 epoch total loss 1.20600474
Trained batch 11 batch loss 1.16119289 epoch total loss 1.20193088
Trained batch 12 batch loss 1.41298485 epoch total loss 1.21951878
Trained batch 13 batch loss 1.15348196 epoch total loss 1.21443892
Trained batch 14 batch loss 1.07880723 epoch total loss 1.20475101
Trained batch 15 batch loss 1.15856874 epoch total loss 1.2016722
Trained batch 16 batch loss 1.03037953 epoch total loss 1.19096649
Trained batch 17 batch loss 1.15548384 epoch total loss 1.18887925
Trained batch 18 batch loss 1.17346323 epoch total loss 1.18802285
Trained batch 19 batch loss 1.32190752 epoch total loss 1.19506931
Trained batch 20 batch loss 1.1615324 epoch total loss 1.19339252
Trained batch 21 batch loss 1.29438674 epoch total loss 1.19820178
Trained batch 22 batch loss 1.12284899 epoch total loss 1.19477665
Trained batch 23 batch loss 1.29653978 epoch total loss 1.19920111
Trained batch 24 batch loss 1.10875595 epoch total loss 1.19543254
Trained batch 25 batch loss 1.0682528 epoch total loss 1.19034529
Trained batch 26 batch loss 1.28668165 epoch total loss 1.19405055
Trained batch 27 batch loss 1.20179951 epoch total loss 1.19433761
Trained batch 28 batch loss 1.14094782 epoch total loss 1.19243085
Trained batch 29 batch loss 1.08140051 epoch total loss 1.18860233
Trained batch 30 batch loss 1.1986258 epoch total loss 1.18893647
Trained batch 31 batch loss 1.14315701 epoch total loss 1.18745971
Trained batch 32 batch loss 1.27485442 epoch total loss 1.19019079
Trained batch 33 batch loss 1.29298592 epoch total loss 1.19330573
Trained batch 34 batch loss 1.26648784 epoch total loss 1.19545817
Trained batch 35 batch loss 1.29482412 epoch total loss 1.19829714
Trained batch 36 batch loss 1.39831817 epoch total loss 1.20385325
Trained batch 37 batch loss 1.3499459 epoch total loss 1.2078017
Trained batch 38 batch loss 1.34301233 epoch total loss 1.21136
Trained batch 39 batch loss 1.41848052 epoch total loss 1.21667075
Trained batch 40 batch loss 1.21579099 epoch total loss 1.2166487
Trained batch 41 batch loss 1.3537823 epoch total loss 1.21999335
Trained batch 42 batch loss 1.14113474 epoch total loss 1.21811581
Trained batch 43 batch loss 0.97360146 epoch total loss 1.21242952
Trained batch 44 batch loss 0.846048355 epoch total loss 1.20410264
Trained batch 45 batch loss 1.08253849 epoch total loss 1.20140123
Trained batch 46 batch loss 1.10692596 epoch total loss 1.19934738
Trained batch 47 batch loss 1.21667027 epoch total loss 1.19971597
Trained batch 48 batch loss 1.43503952 epoch total loss 1.20461857
Trained batch 49 batch loss 1.25471902 epoch total loss 1.20564103
Trained batch 50 batch loss 1.27519381 epoch total loss 1.20703197
Trained batch 51 batch loss 1.18979561 epoch total loss 1.20669401
Trained batch 52 batch loss 1.18336678 epoch total loss 1.20624542
Trained batch 53 batch loss 1.30426562 epoch total loss 1.20809495
Trained batch 54 batch loss 1.03165174 epoch total loss 1.20482743
Trained batch 55 batch loss 0.977449238 epoch total loss 1.20069325
Trained batch 56 batch loss 1.20403981 epoch total loss 1.20075309
Trained batch 57 batch loss 1.42296529 epoch total loss 1.20465159
Trained batch 58 batch loss 1.2635324 epoch total loss 1.20566678
Trained batch 59 batch loss 1.36904621 epoch total loss 1.20843601
Trained batch 60 batch loss 0.994268537 epoch total loss 1.20486653
Trained batch 61 batch loss 0.999527037 epoch total loss 1.2015003
Trained batch 62 batch loss 1.29423165 epoch total loss 1.20299602
Trained batch 63 batch loss 1.20194411 epoch total loss 1.20297933
Trained batch 64 batch loss 1.28278875 epoch total loss 1.20422637
Trained batch 65 batch loss 1.10331893 epoch total loss 1.20267391
Trained batch 66 batch loss 1.11635399 epoch total loss 1.20136607
Trained batch 67 batch loss 1.12314165 epoch total loss 1.20019853
Trained batch 68 batch loss 1.0872165 epoch total loss 1.19853699
Trained batch 69 batch loss 1.0603497 epoch total loss 1.19653428
Trained batch 70 batch loss 1.16131651 epoch total loss 1.19603121
Trained batch 71 batch loss 1.22258663 epoch total loss 1.19640517
Trained batch 72 batch loss 1.24863315 epoch total loss 1.19713068
Trained batch 73 batch loss 1.03416955 epoch total loss 1.19489837
Trained batch 74 batch loss 1.09802651 epoch total loss 1.19358933
Trained batch 75 batch loss 1.08162582 epoch total loss 1.19209647
Trained batch 76 batch loss 1.37213099 epoch total loss 1.19446528
Trained batch 77 batch loss 1.2748878 epoch total loss 1.19550979
Trained batch 78 batch loss 1.34433854 epoch total loss 1.19741786
Trained batch 79 batch loss 1.46288311 epoch total loss 1.20077813
Trained batch 80 batch loss 1.02700448 epoch total loss 1.19860601
Trained batch 81 batch loss 1.15890431 epoch total loss 1.19811583
Trained batch 82 batch loss 1.15618968 epoch total loss 1.19760454
Trained batch 83 batch loss 1.13755226 epoch total loss 1.19688106
Trained batch 84 batch loss 1.25778699 epoch total loss 1.19760609
Trained batch 85 batch loss 1.12006688 epoch total loss 1.1966939
Trained batch 86 batch loss 1.07513356 epoch total loss 1.19528043
Trained batch 87 batch loss 0.877453327 epoch total loss 1.19162726
Trained batch 88 batch loss 0.854570627 epoch total loss 1.18779707
Trained batch 89 batch loss 0.736598492 epoch total loss 1.18272734
Trained batch 90 batch loss 0.776612759 epoch total loss 1.17821491
Trained batch 91 batch loss 1.07604051 epoch total loss 1.17709219
Trained batch 92 batch loss 0.657730162 epoch total loss 1.17144692
Trained batch 93 batch loss 1.03211796 epoch total loss 1.16994882
Trained batch 94 batch loss 0.916743517 epoch total loss 1.16725504
Trained batch 95 batch loss 0.928895533 epoch total loss 1.16474605
Trained batch 96 batch loss 1.23807859 epoch total loss 1.16550982
Trained batch 97 batch loss 1.29256988 epoch total loss 1.16681981
Trained batch 98 batch loss 1.07956362 epoch total loss 1.16592944
Trained batch 99 batch loss 1.36927402 epoch total loss 1.16798341
Trained batch 100 batch loss 0.968374252 epoch total loss 1.16598737
Trained batch 101 batch loss 0.955906093 epoch total loss 1.16390729
Trained batch 102 batch loss 1.12470675 epoch total loss 1.16352308
Trained batch 103 batch loss 1.03838956 epoch total loss 1.16230822
Trained batch 104 batch loss 1.14180732 epoch total loss 1.16211104
Trained batch 105 batch loss 1.14028454 epoch total loss 1.16190314
Trained batch 106 batch loss 1.11873829 epoch total loss 1.16149592
Trained batch 107 batch loss 1.11301148 epoch total loss 1.16104281
Trained batch 108 batch loss 1.18112063 epoch total loss 1.16122878
Trained batch 109 batch loss 1.11574268 epoch total loss 1.16081142
Trained batch 110 batch loss 0.945301116 epoch total loss 1.15885234
Trained batch 111 batch loss 1.01369786 epoch total loss 1.15754461
Trained batch 112 batch loss 1.15494752 epoch total loss 1.15752149
Trained batch 113 batch loss 0.941899061 epoch total loss 1.1556133
Trained batch 114 batch loss 0.85201323 epoch total loss 1.15295017
Trained batch 115 batch loss 1.01090705 epoch total loss 1.15171504
Trained batch 116 batch loss 1.26559067 epoch total loss 1.15269685
Trained batch 117 batch loss 1.09824753 epoch total loss 1.15223145
Trained batch 118 batch loss 1.14772117 epoch total loss 1.15219319
Trained batch 119 batch loss 1.14466572 epoch total loss 1.15213
Trained batch 120 batch loss 1.29345429 epoch total loss 1.15330768
Trained batch 121 batch loss 1.28669274 epoch total loss 1.15441012
Trained batch 122 batch loss 1.28491843 epoch total loss 1.15547979
Trained batch 123 batch loss 0.981189609 epoch total loss 1.15406275
Trained batch 124 batch loss 1.06576335 epoch total loss 1.15335071
Trained batch 125 batch loss 0.953266799 epoch total loss 1.15175
Trained batch 126 batch loss 1.10697079 epoch total loss 1.15139461
Trained batch 127 batch loss 1.07404208 epoch total loss 1.15078545
Trained batch 128 batch loss 1.3686471 epoch total loss 1.15248752
Trained batch 129 batch loss 1.3832 epoch total loss 1.15427589
Trained batch 130 batch loss 1.24790275 epoch total loss 1.15499616
Trained batch 131 batch loss 0.962983131 epoch total loss 1.15353048
Trained batch 132 batch loss 0.95013 epoch total loss 1.15198958
Trained batch 133 batch loss 0.769638896 epoch total loss 1.14911473
Trained batch 134 batch loss 0.986302733 epoch total loss 1.14789963
Trained batch 135 batch loss 0.934013844 epoch total loss 1.14631546
Trained batch 136 batch loss 0.866882801 epoch total loss 1.14426076
Trained batch 137 batch loss 1.11074376 epoch total loss 1.14401615
Trained batch 138 batch loss 1.24456358 epoch total loss 1.14474475
Trained batch 139 batch loss 1.01019025 epoch total loss 1.14377677
Trained batch 140 batch loss 0.970396161 epoch total loss 1.14253831
Trained batch 141 batch loss 1.06182623 epoch total loss 1.14196599
Trained batch 142 batch loss 1.14359975 epoch total loss 1.14197743
Trained batch 143 batch loss 1.07352567 epoch total loss 1.1414988
Trained batch 144 batch loss 1.03060102 epoch total loss 1.14072859
Trained batch 145 batch loss 1.21014524 epoch total loss 1.14120734
Trained batch 146 batch loss 1.03261805 epoch total loss 1.14046359
Trained batch 147 batch loss 1.17155623 epoch total loss 1.14067519
Trained batch 148 batch loss 1.34173203 epoch total loss 1.1420337
Trained batch 149 batch loss 1.1938889 epoch total loss 1.14238167
Trained batch 150 batch loss 1.32049227 epoch total loss 1.14356911
Trained batch 151 batch loss 1.12769079 epoch total loss 1.14346397
Trained batch 152 batch loss 1.16721654 epoch total loss 1.14362025
Trained batch 153 batch loss 1.41090608 epoch total loss 1.14536715
Trained batch 154 batch loss 1.54703903 epoch total loss 1.14797544
Trained batch 155 batch loss 1.34971201 epoch total loss 1.14927697
Trained batch 156 batch loss 1.19391501 epoch total loss 1.14956307
Trained batch 157 batch loss 1.46300781 epoch total loss 1.15155959
Trained batch 158 batch loss 1.29298568 epoch total loss 1.15245473
Trained batch 159 batch loss 1.31586123 epoch total loss 1.15348244
Trained batch 160 batch loss 1.14698887 epoch total loss 1.15344179
Trained batch 161 batch loss 1.3985734 epoch total loss 1.15496433
Trained batch 162 batch loss 0.983477771 epoch total loss 1.15390575
Trained batch 163 batch loss 1.24192691 epoch total loss 1.15444577
Trained batch 164 batch loss 1.02177978 epoch total loss 1.15363681
Trained batch 165 batch loss 0.956490934 epoch total loss 1.1524421
Trained batch 166 batch loss 0.991190612 epoch total loss 1.15147066
Trained batch 167 batch loss 1.08700287 epoch total loss 1.15108466
Trained batch 168 batch loss 1.25455213 epoch total loss 1.1517005
Trained batch 169 batch loss 1.3671155 epoch total loss 1.15297508
Trained batch 170 batch loss 0.669050276 epoch total loss 1.15012848
Trained batch 171 batch loss 1.09490502 epoch total loss 1.14980567
Trained batch 172 batch loss 1.05180693 epoch total loss 1.14923584
Trained batch 173 batch loss 1.27808285 epoch total loss 1.14998055
Trained batch 174 batch loss 1.1447258 epoch total loss 1.14995039
Trained batch 175 batch loss 1.42319357 epoch total loss 1.15151179
Trained batch 176 batch loss 1.21554899 epoch total loss 1.15187562
Trained batch 177 batch loss 1.28012776 epoch total loss 1.15260017
Trained batch 178 batch loss 1.17426884 epoch total loss 1.15272188
Trained batch 179 batch loss 1.02629817 epoch total loss 1.15201557
Trained batch 180 batch loss 1.08969378 epoch total loss 1.15166926
Trained batch 181 batch loss 1.25253308 epoch total loss 1.15222657
Trained batch 182 batch loss 1.07787752 epoch total loss 1.15181804
Trained batch 183 batch loss 1.10523689 epoch total loss 1.15156353
Trained batch 184 batch loss 1.33195639 epoch total loss 1.1525439
Trained batch 185 batch loss 1.1359061 epoch total loss 1.15245402
Trained batch 186 batch loss 1.11075842 epoch total loss 1.15222991
Trained batch 187 batch loss 1.20074129 epoch total loss 1.1524893
Trained batch 188 batch loss 1.32871008 epoch total loss 1.15342665
Trained batch 189 batch loss 1.31721747 epoch total loss 1.1542933
Trained batch 190 batch loss 1.24144065 epoch total loss 1.1547519
Trained batch 191 batch loss 0.960814714 epoch total loss 1.15373659
Trained batch 192 batch loss 0.819802046 epoch total loss 1.15199733
Trained batch 193 batch loss 1.10133469 epoch total loss 1.15173483
Trained batch 194 batch loss 1.0912149 epoch total loss 1.15142286
Trained batch 195 batch loss 1.08922291 epoch total loss 1.15110385
Trained batch 196 batch loss 1.03686547 epoch total loss 1.15052104
Trained batch 197 batch loss 1.1761775 epoch total loss 1.15065122
Trained batch 198 batch loss 1.16055739 epoch total loss 1.15070128
Trained batch 199 batch loss 1.29150975 epoch total loss 1.15140879
Trained batch 200 batch loss 1.12739539 epoch total loss 1.15128875
Trained batch 201 batch loss 1.05880415 epoch total loss 1.1508286
Trained batch 202 batch loss 1.29277587 epoch total loss 1.15153134
Trained batch 203 batch loss 0.976616681 epoch total loss 1.15066969
Trained batch 204 batch loss 0.977874577 epoch total loss 1.14982271
Trained batch 205 batch loss 1.19865203 epoch total loss 1.15006089
Trained batch 206 batch loss 0.96167767 epoch total loss 1.14914644
Trained batch 207 batch loss 1.14069891 epoch total loss 1.14910567
Trained batch 208 batch loss 1.02891183 epoch total loss 1.14852786
Trained batch 209 batch loss 0.9628039 epoch total loss 1.14763916
Trained batch 210 batch loss 0.915652275 epoch total loss 1.14653444
Trained batch 211 batch loss 0.956545353 epoch total loss 1.14563406
Trained batch 212 batch loss 0.997683823 epoch total loss 1.14493608
Trained batch 213 batch loss 1.05141687 epoch total loss 1.14449704
Trained batch 214 batch loss 0.890376 epoch total loss 1.14330959
Trained batch 215 batch loss 0.7964921 epoch total loss 1.14169657
Trained batch 216 batch loss 0.95076263 epoch total loss 1.14081252
Trained batch 217 batch loss 0.918630302 epoch total loss 1.13978863
Trained batch 218 batch loss 1.27416182 epoch total loss 1.14040506
Trained batch 219 batch loss 0.934629738 epoch total loss 1.13946545
Trained batch 220 batch loss 1.0450958 epoch total loss 1.13903642
Trained batch 221 batch loss 1.1172328 epoch total loss 1.13893771
Trained batch 222 batch loss 1.39575529 epoch total loss 1.14009464
Trained batch 223 batch loss 1.22790742 epoch total loss 1.14048839
Trained batch 224 batch loss 1.07852697 epoch total loss 1.1402117
Trained batch 225 batch loss 0.991132498 epoch total loss 1.13954914
Trained batch 226 batch loss 0.998308301 epoch total loss 1.13892424
Trained batch 227 batch loss 1.03415155 epoch total loss 1.13846266
Trained batch 228 batch loss 1.09099984 epoch total loss 1.13825452
Trained batch 229 batch loss 0.945567369 epoch total loss 1.13741302
Trained batch 230 batch loss 1.25908566 epoch total loss 1.13794208
Trained batch 231 batch loss 0.951516032 epoch total loss 1.13713503
Trained batch 232 batch loss 1.04403615 epoch total loss 1.13673377
Trained batch 233 batch loss 0.978069067 epoch total loss 1.13605273
Trained batch 234 batch loss 1.23721337 epoch total loss 1.1364851
Trained batch 235 batch loss 1.03367162 epoch total loss 1.13604748
Trained batch 236 batch loss 1.04349327 epoch total loss 1.13565528
Trained batch 237 batch loss 1.30223644 epoch total loss 1.13635826
Trained batch 238 batch loss 0.997421622 epoch total loss 1.13577449
Trained batch 239 batch loss 0.937618 epoch total loss 1.13494539
Trained batch 240 batch loss 1.03516054 epoch total loss 1.13452959
Trained batch 241 batch loss 1.00186908 epoch total loss 1.13397908
Trained batch 242 batch loss 1.25309229 epoch total loss 1.1344713
Trained batch 243 batch loss 1.42312133 epoch total loss 1.13565922
Trained batch 244 batch loss 1.30508554 epoch total loss 1.13635349
Trained batch 245 batch loss 1.23557055 epoch total loss 1.13675845
Trained batch 246 batch loss 1.34507751 epoch total loss 1.13760519
Trained batch 247 batch loss 1.32040513 epoch total loss 1.13834536
Trained batch 248 batch loss 1.24483085 epoch total loss 1.13877475
Trained batch 249 batch loss 1.32631469 epoch total loss 1.13952792
Trained batch 250 batch loss 1.09713125 epoch total loss 1.1393584
Trained batch 251 batch loss 1.43059254 epoch total loss 1.14051878
Trained batch 252 batch loss 1.14675283 epoch total loss 1.14054346
Trained batch 253 batch loss 1.1441952 epoch total loss 1.14055789
Trained batch 254 batch loss 1.08801699 epoch total loss 1.14035106
Trained batch 255 batch loss 1.28238189 epoch total loss 1.140908
Trained batch 256 batch loss 1.32761109 epoch total loss 1.14163733
Trained batch 257 batch loss 1.26261675 epoch total loss 1.14210796
Trained batch 258 batch loss 1.42199135 epoch total loss 1.14319289
Trained batch 259 batch loss 1.34897244 epoch total loss 1.1439873
Trained batch 260 batch loss 1.14908814 epoch total loss 1.14400697
Trained batch 261 batch loss 1.15062141 epoch total loss 1.14403236
Trained batch 262 batch loss 1.46042407 epoch total loss 1.14524
Trained batch 263 batch loss 1.39922333 epoch total loss 1.14620566
Trained batch 264 batch loss 1.37887561 epoch total loss 1.14708698
Trained batch 265 batch loss 1.49699259 epoch total loss 1.14840734
Trained batch 266 batch loss 1.37638712 epoch total loss 1.14926434
Trained batch 267 batch loss 1.47567511 epoch total loss 1.15048683
Trained batch 268 batch loss 1.3861655 epoch total loss 1.15136623
Trained batch 269 batch loss 1.30344653 epoch total loss 1.15193164
Trained batch 270 batch loss 1.37244356 epoch total loss 1.15274823
Trained batch 271 batch loss 1.29138696 epoch total loss 1.15325987
Trained batch 272 batch loss 0.986502051 epoch total loss 1.15264678
Trained batch 273 batch loss 0.920803666 epoch total loss 1.15179753
Trained batch 274 batch loss 1.07567739 epoch total loss 1.15151978
Trained batch 275 batch loss 1.05253935 epoch total loss 1.15115988
Trained batch 276 batch loss 1.23315275 epoch total loss 1.15145695
Trained batch 277 batch loss 1.15370321 epoch total loss 1.15146518
Trained batch 278 batch loss 1.12373924 epoch total loss 1.1513654
Trained batch 279 batch loss 0.970109582 epoch total loss 1.15071583
Trained batch 280 batch loss 0.999073207 epoch total loss 1.15017426
Trained batch 281 batch loss 1.08440518 epoch total loss 1.14994025
Trained batch 282 batch loss 0.808758497 epoch total loss 1.1487304
Trained batch 283 batch loss 1.24205351 epoch total loss 1.14906013
Trained batch 284 batch loss 1.35634351 epoch total loss 1.14979
Trained batch 285 batch loss 1.24452734 epoch total loss 1.15012252
Trained batch 286 batch loss 1.16958523 epoch total loss 1.15019059
Trained batch 287 batch loss 1.13489377 epoch total loss 1.15013719
Trained batch 288 batch loss 1.26349759 epoch total loss 1.15053082
Trained batch 289 batch loss 1.1490922 epoch total loss 1.15052581
Trained batch 290 batch loss 1.03836918 epoch total loss 1.15013897
Trained batch 291 batch loss 1.34819269 epoch total loss 1.15081966
Trained batch 292 batch loss 1.15904665 epoch total loss 1.15084791
Trained batch 293 batch loss 1.17785585 epoch total loss 1.15094006
Trained batch 294 batch loss 1.12917435 epoch total loss 1.15086603
Trained batch 295 batch loss 1.03820944 epoch total loss 1.15048409
Trained batch 296 batch loss 1.32296515 epoch total loss 1.1510669
Trained batch 297 batch loss 1.14904523 epoch total loss 1.1510601
Trained batch 298 batch loss 1.07688642 epoch total loss 1.15081108
Trained batch 299 batch loss 1.3151449 epoch total loss 1.15136075
Trained batch 300 batch loss 1.36032188 epoch total loss 1.15205729
Trained batch 301 batch loss 1.46430683 epoch total loss 1.15309465
Trained batch 302 batch loss 1.36185217 epoch total loss 1.15378582
Trained batch 303 batch loss 1.19153178 epoch total loss 1.1539104
Trained batch 304 batch loss 1.33482826 epoch total loss 1.15450561
Trained batch 305 batch loss 1.41504955 epoch total loss 1.15535975
Trained batch 306 batch loss 1.08992755 epoch total loss 1.155146
Trained batch 307 batch loss 1.34684205 epoch total loss 1.15577042
Trained batch 308 batch loss 1.44276083 epoch total loss 1.15670216
Trained batch 309 batch loss 1.45543885 epoch total loss 1.15766895
Trained batch 310 batch loss 1.30839682 epoch total loss 1.1581552
Trained batch 311 batch loss 1.27594244 epoch total loss 1.15853393
Trained batch 312 batch loss 1.0515132 epoch total loss 1.15819085
Trained batch 313 batch loss 1.13754666 epoch total loss 1.15812492
Trained batch 314 batch loss 1.32679677 epoch total loss 1.15866208
Trained batch 315 batch loss 1.18006015 epoch total loss 1.15872991
Trained batch 316 batch loss 1.15591025 epoch total loss 1.15872109
Trained batch 317 batch loss 0.95058012 epoch total loss 1.15806448
Trained batch 318 batch loss 1.14466858 epoch total loss 1.15802228
Trained batch 319 batch loss 1.00431228 epoch total loss 1.15754044
Trained batch 320 batch loss 0.969677567 epoch total loss 1.15695333
Trained batch 321 batch loss 1.08961153 epoch total loss 1.15674353
Trained batch 322 batch loss 1.02131486 epoch total loss 1.15632284
Trained batch 323 batch loss 1.31091952 epoch total loss 1.15680146
Trained batch 324 batch loss 1.2818433 epoch total loss 1.15718734
Trained batch 325 batch loss 1.19345927 epoch total loss 1.15729892
Trained batch 326 batch loss 1.25190783 epoch total loss 1.1575892
Trained batch 327 batch loss 1.19117928 epoch total loss 1.15769196
Trained batch 328 batch loss 1.02016091 epoch total loss 1.1572727
Trained batch 329 batch loss 1.29434502 epoch total loss 1.15768933
Trained batch 330 batch loss 1.04799008 epoch total loss 1.15735698
Trained batch 331 batch loss 1.05288744 epoch total loss 1.15704131
Trained batch 332 batch loss 1.06197953 epoch total loss 1.15675497
Trained batch 333 batch loss 1.22283626 epoch total loss 1.15695345
Trained batch 334 batch loss 1.1594 epoch total loss 1.15696073
Trained batch 335 batch loss 1.12427282 epoch total loss 1.15686321
Trained batch 336 batch loss 1.13220239 epoch total loss 1.15678978
Trained batch 337 batch loss 1.0390923 epoch total loss 1.1564405
Trained batch 338 batch loss 1.15120959 epoch total loss 1.15642512
Trained batch 339 batch loss 0.987224817 epoch total loss 1.15592587
Trained batch 340 batch loss 1.23802149 epoch total loss 1.15616739
Trained batch 341 batch loss 1.00043106 epoch total loss 1.15571058
Trained batch 342 batch loss 0.979267597 epoch total loss 1.15519476
Trained batch 343 batch loss 1.08385336 epoch total loss 1.15498674
Trained batch 344 batch loss 1.01682329 epoch total loss 1.15458512
Trained batch 345 batch loss 1.1768961 epoch total loss 1.15464985
Trained batch 346 batch loss 0.950077593 epoch total loss 1.15405858
Trained batch 347 batch loss 1.166646 epoch total loss 1.15409482
Trained batch 348 batch loss 1.21020913 epoch total loss 1.15425611
Trained batch 349 batch loss 1.29080379 epoch total loss 1.15464735
Trained batch 350 batch loss 1.11460614 epoch total loss 1.15453291
Trained batch 351 batch loss 1.22704089 epoch total loss 1.1547395
Trained batch 352 batch loss 1.26477766 epoch total loss 1.15505207
Trained batch 353 batch loss 1.19974625 epoch total loss 1.15517867
Trained batch 354 batch loss 1.15681934 epoch total loss 1.15518332
Trained batch 355 batch loss 1.17893171 epoch total loss 1.15525019
Trained batch 356 batch loss 1.15217113 epoch total loss 1.15524149
Trained batch 357 batch loss 1.19199026 epoch total loss 1.15534449
Trained batch 358 batch loss 1.2929399 epoch total loss 1.15572882
Trained batch 359 batch loss 1.15122271 epoch total loss 1.15571618
Trained batch 360 batch loss 1.29256737 epoch total loss 1.15609634
Trained batch 361 batch loss 1.25078177 epoch total loss 1.15635872
Trained batch 362 batch loss 1.0730207 epoch total loss 1.15612853
Trained batch 363 batch loss 0.941707134 epoch total loss 1.15553784
Trained batch 364 batch loss 1.08184195 epoch total loss 1.15533543
Trained batch 365 batch loss 1.19046664 epoch total loss 1.15543163
Trained batch 366 batch loss 1.24976015 epoch total loss 1.15568936
Trained batch 367 batch loss 1.59635222 epoch total loss 1.15689
Trained batch 368 batch loss 1.49315941 epoch total loss 1.15780377
Trained batch 369 batch loss 1.40346432 epoch total loss 1.15846956
Trained batch 370 batch loss 1.30382 epoch total loss 1.15886247
Trained batch 371 batch loss 1.19780362 epoch total loss 1.15896749
Trained batch 372 batch loss 1.3753159 epoch total loss 1.159549
Trained batch 373 batch loss 1.01727128 epoch total loss 1.15916753
Trained batch 374 batch loss 0.909526765 epoch total loss 1.15850008
Trained batch 375 batch loss 0.84379077 epoch total loss 1.15766084
Trained batch 376 batch loss 1.43469071 epoch total loss 1.15839756
Trained batch 377 batch loss 0.834208071 epoch total loss 1.1575377
Trained batch 378 batch loss 1.41483438 epoch total loss 1.15821826
Trained batch 379 batch loss 1.43105912 epoch total loss 1.15893817
Trained batch 380 batch loss 1.14838552 epoch total loss 1.15891039
Trained batch 381 batch loss 1.39702559 epoch total loss 1.15953541
Trained batch 382 batch loss 1.31427276 epoch total loss 1.15994048
Trained batch 383 batch loss 1.41830802 epoch total loss 1.16061509
Trained batch 384 batch loss 1.27910495 epoch total loss 1.1609236
Trained batch 385 batch loss 1.14367604 epoch total loss 1.1608789
Trained batch 386 batch loss 1.16088247 epoch total loss 1.1608789
Trained batch 387 batch loss 1.05516171 epoch total loss 1.16060579
Trained batch 388 batch loss 1.30195522 epoch total loss 1.16097
Trained batch 389 batch loss 1.07942152 epoch total loss 1.16076028
Trained batch 390 batch loss 0.943634629 epoch total loss 1.16020358
Trained batch 391 batch loss 1.15462279 epoch total loss 1.16018939
Trained batch 392 batch loss 1.22053337 epoch total loss 1.16034329
Trained batch 393 batch loss 1.17182755 epoch total loss 1.16037238
Trained batch 394 batch loss 1.07283604 epoch total loss 1.16015029
Trained batch 395 batch loss 1.18218732 epoch total loss 1.16020608
Trained batch 396 batch loss 0.990515053 epoch total loss 1.15977752
Trained batch 397 batch loss 1.03202868 epoch total loss 1.15945578
Trained batch 398 batch loss 0.905489206 epoch total loss 1.15881765
Trained batch 399 batch loss 1.1813916 epoch total loss 1.15887427
Trained batch 400 batch loss 0.962392688 epoch total loss 1.15838313
Trained batch 401 batch loss 1.12055206 epoch total loss 1.15828872
Trained batch 402 batch loss 1.11589146 epoch total loss 1.15818334
Trained batch 403 batch loss 1.02026641 epoch total loss 1.15784109
Trained batch 404 batch loss 1.24732494 epoch total loss 1.15806258
Trained batch 405 batch loss 1.15822649 epoch total loss 1.15806293
Trained batch 406 batch loss 1.25216627 epoch total loss 1.1582948
Trained batch 407 batch loss 1.07880723 epoch total loss 1.15809941
Trained batch 408 batch loss 1.0958451 epoch total loss 1.15794683
Trained batch 409 batch loss 1.16260052 epoch total loss 1.15795827
Trained batch 410 batch loss 1.09892964 epoch total loss 1.15781426
Trained batch 411 batch loss 1.02773261 epoch total loss 1.15749776
Trained batch 412 batch loss 1.15270782 epoch total loss 1.1574862
Trained batch 413 batch loss 1.2901721 epoch total loss 1.15780747
Trained batch 414 batch loss 1.20673084 epoch total loss 1.15792561
Trained batch 415 batch loss 1.1555202 epoch total loss 1.15791976
Trained batch 416 batch loss 1.09992433 epoch total loss 1.15778041
Trained batch 417 batch loss 0.905624807 epoch total loss 1.15717566
Trained batch 418 batch loss 0.846425712 epoch total loss 1.15643227
Trained batch 419 batch loss 1.13202834 epoch total loss 1.15637398
Trained batch 420 batch loss 1.36494923 epoch total loss 1.15687072
Trained batch 421 batch loss 0.938446641 epoch total loss 1.1563518
Trained batch 422 batch loss 1.00971138 epoch total loss 1.15600431
Trained batch 423 batch loss 1.33513498 epoch total loss 1.15642786
Trained batch 424 batch loss 1.08698058 epoch total loss 1.15626407
Trained batch 425 batch loss 1.30922842 epoch total loss 1.15662396
Trained batch 426 batch loss 0.887748122 epoch total loss 1.15599287
Trained batch 427 batch loss 1.08850121 epoch total loss 1.15583479
Trained batch 428 batch loss 1.13178122 epoch total loss 1.15577853
Trained batch 429 batch loss 1.04726982 epoch total loss 1.15552557
Trained batch 430 batch loss 1.21048689 epoch total loss 1.15565336
Trained batch 431 batch loss 1.05605435 epoch total loss 1.15542233
Trained batch 432 batch loss 1.08766651 epoch total loss 1.15526557
Trained batch 433 batch loss 1.10670066 epoch total loss 1.15515339
Trained batch 434 batch loss 1.05827427 epoch total loss 1.15493011
Trained batch 435 batch loss 0.968805373 epoch total loss 1.15450227
Trained batch 436 batch loss 1.32508802 epoch total loss 1.15489352
Trained batch 437 batch loss 1.15695202 epoch total loss 1.15489817
Trained batch 438 batch loss 1.04505241 epoch total loss 1.15464735
Trained batch 439 batch loss 1.31882787 epoch total loss 1.15502143
Trained batch 440 batch loss 1.11804736 epoch total loss 1.15493739
Trained batch 441 batch loss 1.06926155 epoch total loss 1.15474308
Trained batch 442 batch loss 1.01802874 epoch total loss 1.15443385
Trained batch 443 batch loss 1.06889129 epoch total loss 1.15424061
Trained batch 444 batch loss 0.985816479 epoch total loss 1.1538614
Trained batch 445 batch loss 1.00616586 epoch total loss 1.15352952
Trained batch 446 batch loss 1.03016686 epoch total loss 1.15325284
Trained batch 447 batch loss 1.10411191 epoch total loss 1.15314293
Trained batch 448 batch loss 1.1118865 epoch total loss 1.15305078
Trained batch 449 batch loss 1.13863444 epoch total loss 1.15301871
Trained batch 450 batch loss 1.1554358 epoch total loss 1.15302408
Trained batch 451 batch loss 1.0549736 epoch total loss 1.15280676
Trained batch 452 batch loss 0.997301519 epoch total loss 1.15246272
Trained batch 453 batch loss 1.11084676 epoch total loss 1.15237081
Trained batch 454 batch loss 0.97076416 epoch total loss 1.15197086
Trained batch 455 batch loss 1.27801037 epoch total loss 1.15224779
Trained batch 456 batch loss 1.05588 epoch total loss 1.15203655
Trained batch 457 batch loss 0.898965836 epoch total loss 1.15148282
Trained batch 458 batch loss 0.895473063 epoch total loss 1.15092385
Trained batch 459 batch loss 0.934657037 epoch total loss 1.15045261
Trained batch 460 batch loss 0.858299494 epoch total loss 1.14981747
Trained batch 461 batch loss 1.1348722 epoch total loss 1.14978504
Trained batch 462 batch loss 1.27255547 epoch total loss 1.15005088
Trained batch 463 batch loss 1.25493658 epoch total loss 1.15027738
Trained batch 464 batch loss 1.01806056 epoch total loss 1.14999247
Trained batch 465 batch loss 1.01080561 epoch total loss 1.14969313
Trained batch 466 batch loss 1.07248747 epoch total loss 1.14952743
Trained batch 467 batch loss 1.17248082 epoch total loss 1.14957666
Trained batch 468 batch loss 1.16261983 epoch total loss 1.14960444
Trained batch 469 batch loss 1.05404007 epoch total loss 1.14940071
Trained batch 470 batch loss 1.0933404 epoch total loss 1.14928138
Trained batch 471 batch loss 0.929818392 epoch total loss 1.14881539
Trained batch 472 batch loss 0.958871484 epoch total loss 1.14841294
Trained batch 473 batch loss 1.07913494 epoch total loss 1.14826655
Trained batch 474 batch loss 1.17076802 epoch total loss 1.148314
Trained batch 475 batch loss 0.946680129 epoch total loss 1.14788949
Trained batch 476 batch loss 0.990454495 epoch total loss 1.14755881
Trained batch 477 batch loss 1.02850378 epoch total loss 1.14730918
Trained batch 478 batch loss 0.870256 epoch total loss 1.14672959
Trained batch 479 batch loss 1.15318799 epoch total loss 1.14674306
Trained batch 480 batch loss 1.22624016 epoch total loss 1.14690864
Trained batch 481 batch loss 1.13073719 epoch total loss 1.14687502
Trained batch 482 batch loss 1.04701447 epoch total loss 1.14666784
Trained batch 483 batch loss 1.12566233 epoch total loss 1.14662445
Trained batch 484 batch loss 0.994525194 epoch total loss 1.14631009
Trained batch 485 batch loss 1.01819539 epoch total loss 1.14604592
Trained batch 486 batch loss 1.24093378 epoch total loss 1.14624107
Trained batch 487 batch loss 1.18790197 epoch total loss 1.14632666
Trained batch 488 batch loss 1.28437328 epoch total loss 1.14660954
Trained batch 489 batch loss 1.4699862 epoch total loss 1.1472708
Trained batch 490 batch loss 1.34350014 epoch total loss 1.14767134
Trained batch 491 batch loss 1.64827859 epoch total loss 1.14869082
Trained batch 492 batch loss 1.41734457 epoch total loss 1.14923692
Trained batch 493 batch loss 1.40920889 epoch total loss 1.14976418
Trained batch 494 batch loss 1.20925355 epoch total loss 1.14988458
Trained batch 495 batch loss 1.19006276 epoch total loss 1.14996576
Trained batch 496 batch loss 1.09161782 epoch total loss 1.1498481
Trained batch 497 batch loss 1.18403256 epoch total loss 1.14991689
Trained batch 498 batch loss 0.883967638 epoch total loss 1.14938283
Trained batch 499 batch loss 1.27165079 epoch total loss 1.14962792
Trained batch 500 batch loss 1.15309691 epoch total loss 1.14963472
Trained batch 501 batch loss 1.25417829 epoch total loss 1.14984334
Trained batch 502 batch loss 1.42327392 epoch total loss 1.15038812
Trained batch 503 batch loss 1.45782161 epoch total loss 1.15099931
Trained batch 504 batch loss 1.24000955 epoch total loss 1.15117586
Trained batch 505 batch loss 1.28742862 epoch total loss 1.15144563
Trained batch 506 batch loss 1.32884 epoch total loss 1.15179622
Trained batch 507 batch loss 1.19884038 epoch total loss 1.15188909
Trained batch 508 batch loss 1.13717842 epoch total loss 1.15186012
Trained batch 509 batch loss 1.16031086 epoch total loss 1.15187681
Trained batch 510 batch loss 1.29330277 epoch total loss 1.15215409
Trained batch 511 batch loss 1.12955904 epoch total loss 1.15210986
Trained batch 512 batch loss 1.22569919 epoch total loss 1.15225363
Trained batch 513 batch loss 1.30737019 epoch total loss 1.15255606
Trained batch 514 batch loss 1.10025895 epoch total loss 1.15245426
Trained batch 515 batch loss 1.351156 epoch total loss 1.15284014
Trained batch 516 batch loss 1.1909554 epoch total loss 1.15291405
Trained batch 517 batch loss 1.03330493 epoch total loss 1.15268266
Trained batch 518 batch loss 1.12620378 epoch total loss 1.15263164
Trained batch 519 batch loss 0.975658298 epoch total loss 1.15229058
Trained batch 520 batch loss 1.06353855 epoch total loss 1.15211987
Trained batch 521 batch loss 1.10407376 epoch total loss 1.15202773
Trained batch 522 batch loss 1.09382164 epoch total loss 1.15191615
Trained batch 523 batch loss 1.21788573 epoch total loss 1.15204227
Trained batch 524 batch loss 1.25926471 epoch total loss 1.15224695
Trained batch 525 batch loss 1.33895993 epoch total loss 1.15260267
Trained batch 526 batch loss 1.19502616 epoch total loss 1.15268326
Trained batch 527 batch loss 1.06123567 epoch total loss 1.15250969
Trained batch 528 batch loss 1.34005237 epoch total loss 1.15286481
Trained batch 529 batch loss 1.32706857 epoch total loss 1.15319419
Trained batch 530 batch loss 1.24612033 epoch total loss 1.15336943
Trained batch 531 batch loss 1.4157393 epoch total loss 1.15386355
Trained batch 532 batch loss 1.18366289 epoch total loss 1.15391958
Trained batch 533 batch loss 1.25632906 epoch total loss 1.15411174
Trained batch 534 batch loss 1.27197647 epoch total loss 1.1543324
Trained batch 535 batch loss 1.10747898 epoch total loss 1.1542449
Trained batch 536 batch loss 0.989545643 epoch total loss 1.15393758
Trained batch 537 batch loss 1.00534582 epoch total loss 1.15366089
Trained batch 538 batch loss 1.12641966 epoch total loss 1.15361023
Trained batch 539 batch loss 1.15462279 epoch total loss 1.15361214
Trained batch 540 batch loss 1.1659255 epoch total loss 1.15363503
Trained batch 541 batch loss 1.03917551 epoch total loss 1.15342343
Trained batch 542 batch loss 1.13127589 epoch total loss 1.15338254
Trained batch 543 batch loss 1.26889765 epoch total loss 1.15359533
Trained batch 544 batch loss 1.35062194 epoch total loss 1.15395761
Trained batch 545 batch loss 1.09230661 epoch total loss 1.15384448
Trained batch 546 batch loss 0.951616645 epoch total loss 1.15347397
Trained batch 547 batch loss 1.05417013 epoch total loss 1.15329254
Trained batch 548 batch loss 1.07798636 epoch total loss 1.15315509
Trained batch 549 batch loss 1.07332563 epoch total loss 1.15300965
Trained batch 550 batch loss 0.993026853 epoch total loss 1.15271878
Trained batch 551 batch loss 0.942315936 epoch total loss 1.15233696
Trained batch 552 batch loss 1.34988451 epoch total loss 1.15269494
Trained batch 553 batch loss 1.10504174 epoch total loss 1.15260875
Trained batch 554 batch loss 1.20372665 epoch total loss 1.15270102
Trained batch 555 batch loss 1.26456094 epoch total loss 1.1529026
Trained batch 556 batch loss 1.19541359 epoch total loss 1.15297914
Trained batch 557 batch loss 1.13780117 epoch total loss 1.15295196
Trained batch 558 batch loss 1.19378972 epoch total loss 1.15302503
Trained batch 559 batch loss 1.19356883 epoch total loss 1.15309763
Trained batch 560 batch loss 1.1226548 epoch total loss 1.15304327
Trained batch 561 batch loss 1.03998864 epoch total loss 1.15284169
Trained batch 562 batch loss 1.04982936 epoch total loss 1.15265834
Trained batch 563 batch loss 0.982671261 epoch total loss 1.15235639
Trained batch 564 batch loss 1.14709604 epoch total loss 1.15234709
Trained batch 565 batch loss 1.30071688 epoch total loss 1.15260971
Trained batch 566 batch loss 1.22634149 epoch total loss 1.15273988
Trained batch 567 batch loss 1.050102 epoch total loss 1.15255892
Trained batch 568 batch loss 1.05678844 epoch total loss 1.15239024
Trained batch 569 batch loss 1.05807817 epoch total loss 1.15222454
Trained batch 570 batch loss 1.32211852 epoch total loss 1.15252268
Trained batch 571 batch loss 1.11489582 epoch total loss 1.15245676
Trained batch 572 batch loss 1.03437865 epoch total loss 1.15225029
Trained batch 573 batch loss 1.10799456 epoch total loss 1.15217304
Trained batch 574 batch loss 0.919722259 epoch total loss 1.15176809
Trained batch 575 batch loss 1.01435244 epoch total loss 1.15152907
Trained batch 576 batch loss 1.13112235 epoch total loss 1.15149355
Trained batch 577 batch loss 1.21388233 epoch total loss 1.15160167
Trained batch 578 batch loss 1.2892431 epoch total loss 1.15183985
Trained batch 579 batch loss 1.16029346 epoch total loss 1.1518544
Trained batch 580 batch loss 1.14023614 epoch total loss 1.15183437
Trained batch 581 batch loss 1.06086683 epoch total loss 1.15167785
Trained batch 582 batch loss 1.20327759 epoch total loss 1.15176654
Trained batch 583 batch loss 1.25266743 epoch total loss 1.15193963
Trained batch 584 batch loss 1.04638743 epoch total loss 1.15175891
Trained batch 585 batch loss 1.05363262 epoch total loss 1.15159118
Trained batch 586 batch loss 1.20164299 epoch total loss 1.15167665
Trained batch 587 batch loss 1.29749274 epoch total loss 1.15192509
Trained batch 588 batch loss 1.02953529 epoch total loss 1.15171695
Trained batch 589 batch loss 0.910352767 epoch total loss 1.15130711
Trained batch 590 batch loss 1.05449438 epoch total loss 1.15114295
Trained batch 591 batch loss 1.16875267 epoch total loss 1.15117288
Trained batch 592 batch loss 0.995919645 epoch total loss 1.15091062
Trained batch 593 batch loss 1.22729468 epoch total loss 1.15103936
Trained batch 594 batch loss 1.03294635 epoch total loss 1.15084052
Trained batch 595 batch loss 1.25299847 epoch total loss 1.1510123
Trained batch 596 batch loss 1.07746351 epoch total loss 1.1508888
Trained batch 597 batch loss 1.21018147 epoch total loss 1.15098822
Trained batch 598 batch loss 1.07118082 epoch total loss 1.15085471
Trained batch 599 batch loss 0.896149218 epoch total loss 1.15042961
Trained batch 600 batch loss 1.24736965 epoch total loss 1.15059114
Trained batch 601 batch loss 1.15147889 epoch total loss 1.15059257
Trained batch 602 batch loss 1.20595479 epoch total loss 1.1506846
Trained batch 603 batch loss 1.19656277 epoch total loss 1.15076053
Trained batch 604 batch loss 1.15571928 epoch total loss 1.15076876
Trained batch 605 batch loss 1.54007518 epoch total loss 1.15141225
Trained batch 606 batch loss 1.18739259 epoch total loss 1.15147161
Trained batch 607 batch loss 1.23693538 epoch total loss 1.1516124
Trained batch 608 batch loss 1.21020627 epoch total loss 1.15170884
Trained batch 609 batch loss 0.950238585 epoch total loss 1.15137804
Trained batch 610 batch loss 1.03218293 epoch total loss 1.15118253
Trained batch 611 batch loss 1.15155721 epoch total loss 1.15118313
Trained batch 612 batch loss 1.08704305 epoch total loss 1.15107834
Trained batch 613 batch loss 1.39694262 epoch total loss 1.15147948
Trained batch 614 batch loss 1.41571259 epoch total loss 1.15190983
Trained batch 615 batch loss 1.55231535 epoch total loss 1.15256095
Trained batch 616 batch loss 1.38322 epoch total loss 1.15293539
Trained batch 617 batch loss 1.45631468 epoch total loss 1.153427
Trained batch 618 batch loss 1.03432775 epoch total loss 1.15323424
Trained batch 619 batch loss 1.28997755 epoch total loss 1.15345526
Trained batch 620 batch loss 1.37925601 epoch total loss 1.15381944
Trained batch 621 batch loss 1.21609378 epoch total loss 1.1539197
Trained batch 622 batch loss 1.28198826 epoch total loss 1.15412557
Trained batch 623 batch loss 1.2863 epoch total loss 1.15433776
Trained batch 624 batch loss 1.41114604 epoch total loss 1.15474927
Trained batch 625 batch loss 1.33786654 epoch total loss 1.15504229
Trained batch 626 batch loss 1.46037126 epoch total loss 1.1555301
Trained batch 627 batch loss 1.20725906 epoch total loss 1.15561259
Trained batch 628 batch loss 1.33502674 epoch total loss 1.15589821
Trained batch 629 batch loss 1.32058549 epoch total loss 1.15616
Trained batch 630 batch loss 1.21195436 epoch total loss 1.15624869
Trained batch 631 batch loss 1.11968589 epoch total loss 1.15619075
Trained batch 632 batch loss 1.31078291 epoch total loss 1.15643537
Trained batch 633 batch loss 1.21273911 epoch total loss 1.1565243
Trained batch 634 batch loss 1.27839351 epoch total loss 1.15671647
Trained batch 635 batch loss 1.073982 epoch total loss 1.15658617
Trained batch 636 batch loss 1.27391589 epoch total loss 1.15677071
Trained batch 637 batch loss 1.14235735 epoch total loss 1.15674806
Trained batch 638 batch loss 1.04763579 epoch total loss 1.15657699
Trained batch 639 batch loss 1.03195906 epoch total loss 1.15638196
Trained batch 640 batch loss 1.36613417 epoch total loss 1.15670979
Trained batch 641 batch loss 1.12587261 epoch total loss 1.15666163
Trained batch 642 batch loss 1.24346662 epoch total loss 1.15679681
Trained batch 643 batch loss 1.16192651 epoch total loss 1.1568048
Trained batch 644 batch loss 1.22194207 epoch total loss 1.15690589
Trained batch 645 batch loss 1.15947413 epoch total loss 1.15691
Trained batch 646 batch loss 1.3325069 epoch total loss 1.15718174
Trained batch 647 batch loss 1.36187 epoch total loss 1.15749812
Trained batch 648 batch loss 1.30104041 epoch total loss 1.15771961
Trained batch 649 batch loss 1.16577923 epoch total loss 1.15773201
Trained batch 650 batch loss 1.05567408 epoch total loss 1.15757501
Trained batch 651 batch loss 1.12934828 epoch total loss 1.15753162
Trained batch 652 batch loss 1.30926311 epoch total loss 1.15776432
Trained batch 653 batch loss 1.24393153 epoch total loss 1.1578964
Trained batch 654 batch loss 1.15990567 epoch total loss 1.1578995
Trained batch 655 batch loss 1.07976508 epoch total loss 1.15778017
Trained batch 656 batch loss 1.05418897 epoch total loss 1.15762222
Trained batch 657 batch loss 1.20652604 epoch total loss 1.15769672
Trained batch 658 batch loss 1.27559268 epoch total loss 1.1578759
Trained batch 659 batch loss 1.1926856 epoch total loss 1.15792871
Trained batch 660 batch loss 1.1475879 epoch total loss 1.15791297
Trained batch 661 batch loss 1.15040445 epoch total loss 1.15790164
Trained batch 662 batch loss 0.969252586 epoch total loss 1.15761662
Trained batch 663 batch loss 0.965798855 epoch total loss 1.15732741
Trained batch 664 batch loss 1.10842705 epoch total loss 1.15725362
Trained batch 665 batch loss 1.11301231 epoch total loss 1.15718722
Trained batch 666 batch loss 1.29159582 epoch total loss 1.15738904
Trained batch 667 batch loss 1.17918479 epoch total loss 1.15742171
Trained batch 668 batch loss 1.03734207 epoch total loss 1.15724206
Trained batch 669 batch loss 0.847774446 epoch total loss 1.15677941
Trained batch 670 batch loss 1.08174 epoch total loss 1.15666735
Trained batch 671 batch loss 1.04231179 epoch total loss 1.156497
Trained batch 672 batch loss 0.847135842 epoch total loss 1.15603662
Trained batch 673 batch loss 0.970459104 epoch total loss 1.15576077
Trained batch 674 batch loss 0.834199548 epoch total loss 1.15528381
Trained batch 675 batch loss 1.00888443 epoch total loss 1.15506697
Trained batch 676 batch loss 0.921624899 epoch total loss 1.15472162
Trained batch 677 batch loss 1.01730037 epoch total loss 1.1545186
Trained batch 678 batch loss 1.06414104 epoch total loss 1.15438533
Trained batch 679 batch loss 1.49145532 epoch total loss 1.15488172
Trained batch 680 batch loss 1.28261852 epoch total loss 1.15506947
Trained batch 681 batch loss 1.1945343 epoch total loss 1.15512741
Trained batch 682 batch loss 1.31520188 epoch total loss 1.15536213
Trained batch 683 batch loss 1.19043422 epoch total loss 1.15541351
Trained batch 684 batch loss 1.1815052 epoch total loss 1.15545166
Trained batch 685 batch loss 1.09896326 epoch total loss 1.15536916
Trained batch 686 batch loss 1.16995692 epoch total loss 1.15539038
Trained batch 687 batch loss 1.36512685 epoch total loss 1.15569568
Trained batch 688 batch loss 1.3638432 epoch total loss 1.15599823
Trained batch 689 batch loss 1.40749764 epoch total loss 1.15636325
Trained batch 690 batch loss 1.42051709 epoch total loss 1.15674603
Trained batch 691 batch loss 1.15654433 epoch total loss 1.15674579
Trained batch 692 batch loss 1.1768477 epoch total loss 1.15677476
Trained batch 693 batch loss 1.28255892 epoch total loss 1.15695632
Trained batch 694 batch loss 1.06671953 epoch total loss 1.15682626
Trained batch 695 batch loss 1.16644692 epoch total loss 1.15684009
Trained batch 696 batch loss 1.19666052 epoch total loss 1.15689731
Trained batch 697 batch loss 1.11241889 epoch total loss 1.15683341
Trained batch 698 batch loss 1.09942269 epoch total loss 1.15675128
Trained batch 699 batch loss 1.3574084 epoch total loss 1.15703833
Trained batch 700 batch loss 1.3996923 epoch total loss 1.15738499
Trained batch 701 batch loss 1.26439977 epoch total loss 1.1575377
Trained batch 702 batch loss 1.14861703 epoch total loss 1.15752494
Trained batch 703 batch loss 1.26929379 epoch total loss 1.15768397
Trained batch 704 batch loss 1.196944 epoch total loss 1.15773976
Trained batch 705 batch loss 1.29436898 epoch total loss 1.15793347
Trained batch 706 batch loss 1.18657947 epoch total loss 1.15797412
Trained batch 707 batch loss 1.05241847 epoch total loss 1.15782487
Trained batch 708 batch loss 1.51137328 epoch total loss 1.15832412
Trained batch 709 batch loss 1.09389651 epoch total loss 1.15823328
Trained batch 710 batch loss 0.97402072 epoch total loss 1.15797377
Trained batch 711 batch loss 1.26869917 epoch total loss 1.15812945
Trained batch 712 batch loss 1.51688802 epoch total loss 1.15863335
Trained batch 713 batch loss 1.61316657 epoch total loss 1.15927088
Trained batch 714 batch loss 1.35898519 epoch total loss 1.15955055
Trained batch 715 batch loss 1.55678451 epoch total loss 1.16010618
Trained batch 716 batch loss 1.34973216 epoch total loss 1.16037095
Trained batch 717 batch loss 1.23112869 epoch total loss 1.16046965
Trained batch 718 batch loss 1.29397821 epoch total loss 1.16065562
Trained batch 719 batch loss 1.60421312 epoch total loss 1.16127253
Trained batch 720 batch loss 1.33404434 epoch total loss 1.16151249
Trained batch 721 batch loss 0.964154422 epoch total loss 1.16123879
Trained batch 722 batch loss 1.17396557 epoch total loss 1.16125643
Trained batch 723 batch loss 1.16873169 epoch total loss 1.16126668
Trained batch 724 batch loss 1.04274464 epoch total loss 1.16110301
Trained batch 725 batch loss 1.27010918 epoch total loss 1.16125333
Trained batch 726 batch loss 1.19638205 epoch total loss 1.16130173
Trained batch 727 batch loss 1.22034955 epoch total loss 1.16138291
Trained batch 728 batch loss 1.12185633 epoch total loss 1.16132855
Trained batch 729 batch loss 1.09207749 epoch total loss 1.16123366
Trained batch 730 batch loss 0.947866 epoch total loss 1.16094136
Trained batch 731 batch loss 0.943148077 epoch total loss 1.16064346
Trained batch 732 batch loss 0.851992 epoch total loss 1.16022182
Trained batch 733 batch loss 0.846837878 epoch total loss 1.15979433
Trained batch 734 batch loss 0.713834643 epoch total loss 1.15918672
Trained batch 735 batch loss 0.775219858 epoch total loss 1.15866423
Trained batch 736 batch loss 1.04419303 epoch total loss 1.15850866
Trained batch 737 batch loss 1.07122254 epoch total loss 1.15839028
Trained batch 738 batch loss 1.0857358 epoch total loss 1.15829182
Trained batch 739 batch loss 1.11919403 epoch total loss 1.15823901
Trained batch 740 batch loss 1.25385618 epoch total loss 1.15836811
Trained batch 741 batch loss 1.32649851 epoch total loss 1.15859509
Trained batch 742 batch loss 1.16275167 epoch total loss 1.15860069
Trained batch 743 batch loss 1.02536488 epoch total loss 1.1584214
Trained batch 744 batch loss 0.819607377 epoch total loss 1.1579659
Trained batch 745 batch loss 0.8171857 epoch total loss 1.15750861
Trained batch 746 batch loss 0.664925 epoch total loss 1.15684819
Trained batch 747 batch loss 0.847579837 epoch total loss 1.1564343
Trained batch 748 batch loss 0.810418606 epoch total loss 1.15597165
Trained batch 749 batch loss 0.744438291 epoch total loss 1.15542221
Trained batch 750 batch loss 0.863309145 epoch total loss 1.15503275
Trained batch 751 batch loss 0.946624398 epoch total loss 1.15475512
Trained batch 752 batch loss 0.835849941 epoch total loss 1.15433109
Trained batch 753 batch loss 0.853446841 epoch total loss 1.1539315
Trained batch 754 batch loss 1.02992094 epoch total loss 1.15376711
Trained batch 755 batch loss 0.929886937 epoch total loss 1.15347052
Trained batch 756 batch loss 1.02334833 epoch total loss 1.15329838
Trained batch 757 batch loss 1.2029078 epoch total loss 1.15336394
Trained batch 758 batch loss 0.9077667 epoch total loss 1.15303993
Trained batch 759 batch loss 0.980140567 epoch total loss 1.15281212
Trained batch 760 batch loss 1.12124062 epoch total loss 1.15277064
Trained batch 761 batch loss 1.34195924 epoch total loss 1.15301919
Trained batch 762 batch loss 1.24144483 epoch total loss 1.1531353
Trained batch 763 batch loss 0.944376945 epoch total loss 1.15286171
Trained batch 764 batch loss 0.912051439 epoch total loss 1.15254653
Trained batch 765 batch loss 0.933192432 epoch total loss 1.15225971
Trained batch 766 batch loss 1.20240831 epoch total loss 1.15232515
Trained batch 767 batch loss 1.41995287 epoch total loss 1.1526742
Trained batch 768 batch loss 1.1295557 epoch total loss 1.15264404
Trained batch 769 batch loss 1.15176082 epoch total loss 1.15264285
Trained batch 770 batch loss 1.36762953 epoch total loss 1.15292203
Trained batch 771 batch loss 1.04949141 epoch total loss 1.15278792
Trained batch 772 batch loss 1.0625875 epoch total loss 1.1526711
Trained batch 773 batch loss 1.29454708 epoch total loss 1.15285456
Trained batch 774 batch loss 1.03752267 epoch total loss 1.15270567
Trained batch 775 batch loss 1.14114821 epoch total loss 1.15269077
Trained batch 776 batch loss 1.21362233 epoch total loss 1.15276921
Trained batch 777 batch loss 1.15263367 epoch total loss 1.15276909
Trained batch 778 batch loss 1.17897081 epoch total loss 1.15280282
Trained batch 779 batch loss 1.20331764 epoch total loss 1.15286756
Trained batch 780 batch loss 1.2814765 epoch total loss 1.15303254
Trained batch 781 batch loss 0.910801291 epoch total loss 1.15272236
Trained batch 782 batch loss 1.09677601 epoch total loss 1.15265083
Trained batch 783 batch loss 1.09784842 epoch total loss 1.15258086
Trained batch 784 batch loss 1.04102671 epoch total loss 1.15243852
Trained batch 785 batch loss 1.13904572 epoch total loss 1.15242147
Trained batch 786 batch loss 1.02023554 epoch total loss 1.15225339
Trained batch 787 batch loss 1.06926537 epoch total loss 1.15214789
Trained batch 788 batch loss 0.820476055 epoch total loss 1.15172708
Trained batch 789 batch loss 1.30677438 epoch total loss 1.15192354
Trained batch 790 batch loss 1.15601707 epoch total loss 1.15192866
Trained batch 791 batch loss 1.23756063 epoch total loss 1.15203691
Trained batch 792 batch loss 1.12241101 epoch total loss 1.15199959
Trained batch 793 batch loss 1.31288671 epoch total loss 1.15220249
Trained batch 794 batch loss 1.18066633 epoch total loss 1.15223825
Trained batch 795 batch loss 1.29767346 epoch total loss 1.15242124
Trained batch 796 batch loss 1.16513705 epoch total loss 1.15243721
Trained batch 797 batch loss 1.26209497 epoch total loss 1.15257478
Trained batch 798 batch loss 1.1479454 epoch total loss 1.15256906
Trained batch 799 batch loss 0.953807831 epoch total loss 1.15232027
Trained batch 800 batch loss 1.24003756 epoch total loss 1.15242994
Trained batch 801 batch loss 1.13573027 epoch total loss 1.15240908
Trained batch 802 batch loss 1.15447664 epoch total loss 1.15241158
Trained batch 803 batch loss 1.19608021 epoch total loss 1.15246606
Trained batch 804 batch loss 1.25354958 epoch total loss 1.15259171
Trained batch 805 batch loss 1.37639165 epoch total loss 1.15286982
Trained batch 806 batch loss 0.99288106 epoch total loss 1.15267122
Trained batch 807 batch loss 1.20501244 epoch total loss 1.15273619
Trained batch 808 batch loss 1.11565316 epoch total loss 1.15269029
Trained batch 809 batch loss 1.02297378 epoch total loss 1.15252984
Trained batch 810 batch loss 1.08827639 epoch total loss 1.15245056
Trained batch 811 batch loss 1.09820521 epoch total loss 1.15238369
Trained batch 812 batch loss 0.979514837 epoch total loss 1.15217066
Trained batch 813 batch loss 1.13047659 epoch total loss 1.15214407
Trained batch 814 batch loss 1.12807047 epoch total loss 1.15211451
Trained batch 815 batch loss 1.23215115 epoch total loss 1.15221274
Trained batch 816 batch loss 1.33782649 epoch total loss 1.15244019
Trained batch 817 batch loss 1.16669595 epoch total loss 1.15245759
Trained batch 818 batch loss 1.15565801 epoch total loss 1.15246153
Trained batch 819 batch loss 1.24507403 epoch total loss 1.15257454
Trained batch 820 batch loss 1.30616021 epoch total loss 1.15276182
Trained batch 821 batch loss 1.16827106 epoch total loss 1.15278077
Trained batch 822 batch loss 1.06146336 epoch total loss 1.15266967
Trained batch 823 batch loss 1.24335384 epoch total loss 1.15277982
Trained batch 824 batch loss 1.08126712 epoch total loss 1.15269303
Trained batch 825 batch loss 1.06425214 epoch total loss 1.15258586
Trained batch 826 batch loss 1.05641079 epoch total loss 1.1524694
Trained batch 827 batch loss 0.928075671 epoch total loss 1.15219808
Trained batch 828 batch loss 1.07486737 epoch total loss 1.15210474
Trained batch 829 batch loss 1.03758454 epoch total loss 1.15196657
Trained batch 830 batch loss 0.990991235 epoch total loss 1.15177262
Trained batch 831 batch loss 0.926048696 epoch total loss 1.15150094
Trained batch 832 batch loss 1.11828637 epoch total loss 1.15146101
Trained batch 833 batch loss 1.23641121 epoch total loss 1.15156293
Trained batch 834 batch loss 1.2488234 epoch total loss 1.15167964
Trained batch 835 batch loss 1.3231833 epoch total loss 1.15188503
Trained batch 836 batch loss 1.22890961 epoch total loss 1.15197706
Trained batch 837 batch loss 0.946117401 epoch total loss 1.15173113
Trained batch 838 batch loss 1.51709116 epoch total loss 1.15216708
Trained batch 839 batch loss 1.09994781 epoch total loss 1.15210497
Trained batch 840 batch loss 1.26503897 epoch total loss 1.15223932
Trained batch 841 batch loss 1.11796331 epoch total loss 1.15219855
Trained batch 842 batch loss 1.31241202 epoch total loss 1.15238893
Trained batch 843 batch loss 1.20874703 epoch total loss 1.15245581
Trained batch 844 batch loss 1.25947165 epoch total loss 1.15258253
Trained batch 845 batch loss 1.13383913 epoch total loss 1.15256035
Trained batch 846 batch loss 1.11114931 epoch total loss 1.15251136
Trained batch 847 batch loss 1.09531832 epoch total loss 1.15244389
Trained batch 848 batch loss 1.09785378 epoch total loss 1.15237951
Trained batch 849 batch loss 1.09102738 epoch total loss 1.15230727
Trained batch 850 batch loss 1.09147787 epoch total loss 1.15223563
Trained batch 851 batch loss 0.871655107 epoch total loss 1.15190601
Trained batch 852 batch loss 0.938619077 epoch total loss 1.15165555
Trained batch 853 batch loss 0.823912442 epoch total loss 1.15127134
Trained batch 854 batch loss 1.08691812 epoch total loss 1.151196
Trained batch 855 batch loss 0.9127056 epoch total loss 1.15091705
Trained batch 856 batch loss 0.935339689 epoch total loss 1.15066528
Trained batch 857 batch loss 0.977691293 epoch total loss 1.15046346
Trained batch 858 batch loss 1.03479147 epoch total loss 1.15032864
Trained batch 859 batch loss 0.799151659 epoch total loss 1.14991975
Trained batch 860 batch loss 0.796608746 epoch total loss 1.14950895
Trained batch 861 batch loss 0.866850078 epoch total loss 1.14918065
Trained batch 862 batch loss 0.962433696 epoch total loss 1.14896405
Trained batch 863 batch loss 0.959139287 epoch total loss 1.14874411
Trained batch 864 batch loss 0.881642044 epoch total loss 1.148435
Trained batch 865 batch loss 1.24468184 epoch total loss 1.14854622
Trained batch 866 batch loss 1.0964 epoch total loss 1.14848602
Trained batch 867 batch loss 0.827934 epoch total loss 1.14811623
Trained batch 868 batch loss 1.02161741 epoch total loss 1.14797056
Trained batch 869 batch loss 1.10084188 epoch total loss 1.14791632
Trained batch 870 batch loss 1.17073047 epoch total loss 1.14794254
Trained batch 871 batch loss 1.17193818 epoch total loss 1.14797008
Trained batch 872 batch loss 1.21953869 epoch total loss 1.1480521
Trained batch 873 batch loss 1.07031131 epoch total loss 1.14796305
Trained batch 874 batch loss 1.05857193 epoch total loss 1.14786077
Trained batch 875 batch loss 1.01534975 epoch total loss 1.14770937
Trained batch 876 batch loss 1.03871846 epoch total loss 1.14758492
Trained batch 877 batch loss 1.10957932 epoch total loss 1.14754152
Trained batch 878 batch loss 1.03451896 epoch total loss 1.14741278
Trained batch 879 batch loss 1.03592181 epoch total loss 1.14728606
Trained batch 880 batch loss 1.22835016 epoch total loss 1.14737809
Trained batch 881 batch loss 0.983446956 epoch total loss 1.14719212
Trained batch 882 batch loss 1.17822337 epoch total loss 1.14722729
Trained batch 883 batch loss 1.14256024 epoch total loss 1.14722192
Trained batch 884 batch loss 1.007779 epoch total loss 1.14706421
Trained batch 885 batch loss 1.01280284 epoch total loss 1.14691257
Trained batch 886 batch loss 1.25328279 epoch total loss 1.14703262
Trained batch 887 batch loss 1.2446959 epoch total loss 1.14714265
Trained batch 888 batch loss 1.34549665 epoch total loss 1.14736605
Trained batch 889 batch loss 1.4662199 epoch total loss 1.14772475
Trained batch 890 batch loss 1.23005629 epoch total loss 1.14781725
Trained batch 891 batch loss 0.843008876 epoch total loss 1.14747524
Trained batch 892 batch loss 1.43324685 epoch total loss 1.14779556
Trained batch 893 batch loss 1.59269953 epoch total loss 1.14829373
Trained batch 894 batch loss 1.24812734 epoch total loss 1.14840543
Trained batch 895 batch loss 1.43736672 epoch total loss 1.14872825
Trained batch 896 batch loss 1.37934351 epoch total loss 1.14898574
Trained batch 897 batch loss 1.15826845 epoch total loss 1.14899611
Trained batch 898 batch loss 1.28389633 epoch total loss 1.14914644
Trained batch 899 batch loss 1.49131942 epoch total loss 1.14952707
Trained batch 900 batch loss 1.15238881 epoch total loss 1.14953017
Trained batch 901 batch loss 1.31126785 epoch total loss 1.1497097
Trained batch 902 batch loss 1.19321084 epoch total loss 1.14975798
Trained batch 903 batch loss 1.21387434 epoch total loss 1.14982891
Trained batch 904 batch loss 1.19139481 epoch total loss 1.14987493
Trained batch 905 batch loss 1.228652 epoch total loss 1.14996195
Trained batch 906 batch loss 1.20108855 epoch total loss 1.15001833
Trained batch 907 batch loss 1.28251767 epoch total loss 1.15016437
Trained batch 908 batch loss 1.1923275 epoch total loss 1.15021086
Trained batch 909 batch loss 0.990925908 epoch total loss 1.15003574
Trained batch 910 batch loss 1.24910736 epoch total loss 1.15014458
Trained batch 911 batch loss 1.39139915 epoch total loss 1.15040934
Trained batch 912 batch loss 1.34348214 epoch total loss 1.15062106
Trained batch 913 batch loss 1.31998241 epoch total loss 1.15080655
Trained batch 914 batch loss 1.0398711 epoch total loss 1.15068519
Trained batch 915 batch loss 1.13186729 epoch total loss 1.15066469
Trained batch 916 batch loss 1.2495718 epoch total loss 1.15077257
Trained batch 917 batch loss 1.13791811 epoch total loss 1.15075862
Trained batch 918 batch loss 1.17334437 epoch total loss 1.15078318
Trained batch 919 batch loss 1.07025814 epoch total loss 1.15069556
Trained batch 920 batch loss 0.998664498 epoch total loss 1.15053034
Trained batch 921 batch loss 1.15108514 epoch total loss 1.15053093
Trained batch 922 batch loss 1.27735651 epoch total loss 1.1506685
Trained batch 923 batch loss 1.2864244 epoch total loss 1.15081561
Trained batch 924 batch loss 1.1708864 epoch total loss 1.1508373
Trained batch 925 batch loss 0.968996108 epoch total loss 1.15064073
Trained batch 926 batch loss 1.15902 epoch total loss 1.15064979
Trained batch 927 batch loss 0.962807417 epoch total loss 1.15044713
Trained batch 928 batch loss 1.05382621 epoch total loss 1.15034306
Trained batch 929 batch loss 0.952383459 epoch total loss 1.15012991
Trained batch 930 batch loss 1.35202336 epoch total loss 1.15034699
Trained batch 931 batch loss 1.05698705 epoch total loss 1.15024674
Trained batch 932 batch loss 1.15337312 epoch total loss 1.15025008
Trained batch 933 batch loss 1.25618029 epoch total loss 1.15036368
Trained batch 934 batch loss 1.47763681 epoch total loss 1.15071404
Trained batch 935 batch loss 1.20253491 epoch total loss 1.15076947
Trained batch 936 batch loss 1.18175113 epoch total loss 1.15080261
Trained batch 937 batch loss 1.15323853 epoch total loss 1.15080512
Trained batch 938 batch loss 1.09408152 epoch total loss 1.15074468
Trained batch 939 batch loss 0.954305351 epoch total loss 1.15053558
Trained batch 940 batch loss 1.16147983 epoch total loss 1.15054727
Trained batch 941 batch loss 1.19456041 epoch total loss 1.150594
Trained batch 942 batch loss 1.25000954 epoch total loss 1.15069962
Trained batch 943 batch loss 1.07444608 epoch total loss 1.15061867
Trained batch 944 batch loss 1.12405324 epoch total loss 1.15059054
Trained batch 945 batch loss 1.09030223 epoch total loss 1.15052676
Trained batch 946 batch loss 1.09405684 epoch total loss 1.15046716
Trained batch 947 batch loss 0.917684495 epoch total loss 1.15022135
Trained batch 948 batch loss 1.04463112 epoch total loss 1.15011
Trained batch 949 batch loss 1.23160434 epoch total loss 1.15019584
Trained batch 950 batch loss 1.09131873 epoch total loss 1.15013385
Trained batch 951 batch loss 1.04778993 epoch total loss 1.1500262
Trained batch 952 batch loss 1.16673672 epoch total loss 1.15004373
Trained batch 953 batch loss 1.12837911 epoch total loss 1.15002108
Trained batch 954 batch loss 0.953797 epoch total loss 1.14981544
Trained batch 955 batch loss 1.32038307 epoch total loss 1.14999413
Trained batch 956 batch loss 1.42290163 epoch total loss 1.15027952
Trained batch 957 batch loss 1.35233915 epoch total loss 1.15049064
Trained batch 958 batch loss 1.07107103 epoch total loss 1.15040767
Trained batch 959 batch loss 1.64890885 epoch total loss 1.15092754
Trained batch 960 batch loss 1.49233413 epoch total loss 1.15128314
Trained batch 961 batch loss 1.08974743 epoch total loss 1.15121913
Trained batch 962 batch loss 1.10646045 epoch total loss 1.15117252
Trained batch 963 batch loss 1.17235112 epoch total loss 1.15119457
Trained batch 964 batch loss 1.3543483 epoch total loss 1.15140533
Trained batch 965 batch loss 1.15247154 epoch total loss 1.15140641
Trained batch 966 batch loss 1.48375571 epoch total loss 1.15175045
Trained batch 967 batch loss 1.32116485 epoch total loss 1.15192568
Trained batch 968 batch loss 1.10991311 epoch total loss 1.15188217
Trained batch 969 batch loss 0.946773648 epoch total loss 1.15167058
Trained batch 970 batch loss 0.980003715 epoch total loss 1.15149355
Trained batch 971 batch loss 1.10637927 epoch total loss 1.15144706
Trained batch 972 batch loss 0.970655143 epoch total loss 1.15126109
Trained batch 973 batch loss 1.08578777 epoch total loss 1.15119386
Trained batch 974 batch loss 1.00086093 epoch total loss 1.15103948
Trained batch 975 batch loss 1.12731969 epoch total loss 1.15101516
Trained batch 976 batch loss 1.20038319 epoch total loss 1.15106571
Trained batch 977 batch loss 1.24747181 epoch total loss 1.15116441
Trained batch 978 batch loss 1.07899237 epoch total loss 1.15109062
Trained batch 979 batch loss 1.06340241 epoch total loss 1.15100098
Trained batch 980 batch loss 1.19594479 epoch total loss 1.15104687
Trained batch 981 batch loss 1.00237191 epoch total loss 1.15089524
Trained batch 982 batch loss 0.697904766 epoch total loss 1.1504339
Trained batch 983 batch loss 1.08829451 epoch total loss 1.1503706
Trained batch 984 batch loss 1.27214086 epoch total loss 1.15049434
Trained batch 985 batch loss 1.29315686 epoch total loss 1.15063918
Trained batch 986 batch loss 1.3101933 epoch total loss 1.15080106
Trained batch 987 batch loss 1.19858909 epoch total loss 1.15084946
Trained batch 988 batch loss 1.28031254 epoch total loss 1.15098047
Trained batch 989 batch loss 1.1102221 epoch total loss 1.15093923
Trained batch 990 batch loss 1.15130866 epoch total loss 1.1509397
Trained batch 991 batch loss 1.15789711 epoch total loss 1.15094662
Trained batch 992 batch loss 1.28045332 epoch total loss 1.15107715
Trained batch 993 batch loss 1.16628361 epoch total loss 1.15109241
Trained batch 994 batch loss 1.16955447 epoch total loss 1.15111101
Trained batch 995 batch loss 1.10571527 epoch total loss 1.15106535
Trained batch 996 batch loss 1.14383173 epoch total loss 1.15105808
Trained batch 997 batch loss 1.23239362 epoch total loss 1.15113974
Trained batch 998 batch loss 1.08342743 epoch total loss 1.15107179
Trained batch 999 batch loss 1.14977753 epoch total loss 1.15107048
Trained batch 1000 batch loss 1.22767794 epoch total loss 1.15114713
Trained batch 1001 batch loss 1.17304111 epoch total loss 1.15116906
Trained batch 1002 batch loss 0.988066375 epoch total loss 1.15100622
Trained batch 1003 batch loss 1.18096447 epoch total loss 1.15103602
Trained batch 1004 batch loss 1.11913252 epoch total loss 1.15100431
Trained batch 1005 batch loss 1.13018298 epoch total loss 1.15098345
Trained batch 1006 batch loss 1.2520591 epoch total loss 1.15108395
Trained batch 1007 batch loss 1.0796932 epoch total loss 1.15101314
Trained batch 1008 batch loss 1.24603355 epoch total loss 1.15110743
Trained batch 1009 batch loss 1.17730546 epoch total loss 1.1511333
Trained batch 1010 batch loss 1.28762317 epoch total loss 1.15126848
Trained batch 1011 batch loss 1.18280017 epoch total loss 1.1512996
Trained batch 1012 batch loss 1.27934837 epoch total loss 1.15142608
Trained batch 1013 batch loss 1.03037763 epoch total loss 1.15130663
Trained batch 1014 batch loss 1.0877378 epoch total loss 1.15124393
Trained batch 1015 batch loss 0.961792707 epoch total loss 1.15105724
Trained batch 1016 batch loss 0.803458452 epoch total loss 1.15071511
Trained batch 1017 batch loss 0.973274648 epoch total loss 1.15054071
Trained batch 1018 batch loss 1.02423859 epoch total loss 1.15041661
Trained batch 1019 batch loss 1.37832475 epoch total loss 1.15064025
Trained batch 1020 batch loss 1.26939368 epoch total loss 1.15075672
Trained batch 1021 batch loss 1.40064788 epoch total loss 1.15100145
Trained batch 1022 batch loss 1.15598702 epoch total loss 1.15100634
Trained batch 1023 batch loss 1.05661356 epoch total loss 1.15091407
Trained batch 1024 batch loss 1.21314871 epoch total loss 1.15097487
Trained batch 1025 batch loss 1.0696578 epoch total loss 1.1508956
Trained batch 1026 batch loss 1.24865794 epoch total loss 1.15099084
Trained batch 1027 batch loss 1.21762347 epoch total loss 1.15105581
Trained batch 1028 batch loss 1.08604896 epoch total loss 1.15099251
Trained batch 1029 batch loss 1.36262071 epoch total loss 1.15119827
Trained batch 1030 batch loss 1.10742807 epoch total loss 1.15115571
Trained batch 1031 batch loss 1.11824107 epoch total loss 1.15112388
Trained batch 1032 batch loss 1.13415051 epoch total loss 1.15110743
Trained batch 1033 batch loss 1.09225106 epoch total loss 1.15105045
Trained batch 1034 batch loss 1.15497267 epoch total loss 1.15105438
Trained batch 1035 batch loss 1.15275145 epoch total loss 1.15105593
Trained batch 1036 batch loss 1.04138052 epoch total loss 1.15095007
Trained batch 1037 batch loss 0.978003144 epoch total loss 1.1507833
Trained batch 1038 batch loss 1.01725471 epoch total loss 1.15065467
Trained batch 1039 batch loss 1.01373625 epoch total loss 1.15052295
Trained batch 1040 batch loss 1.02258062 epoch total loss 1.15039992
Trained batch 1041 batch loss 0.899500132 epoch total loss 1.15015888
Trained batch 1042 batch loss 1.39039898 epoch total loss 1.15038943
Trained batch 1043 batch loss 1.27057123 epoch total loss 1.15050471
Trained batch 1044 batch loss 1.26653409 epoch total loss 1.15061581
Trained batch 1045 batch loss 1.24181867 epoch total loss 1.15070307
Trained batch 1046 batch loss 1.15293908 epoch total loss 1.15070522
Trained batch 1047 batch loss 1.27431023 epoch total loss 1.15082324
Trained batch 1048 batch loss 1.41239429 epoch total loss 1.15107286
Trained batch 1049 batch loss 1.22815669 epoch total loss 1.15114629
Trained batch 1050 batch loss 1.16715848 epoch total loss 1.15116155
Trained batch 1051 batch loss 1.09962511 epoch total loss 1.15111244
Trained batch 1052 batch loss 1.00952196 epoch total loss 1.15097785
Trained batch 1053 batch loss 1.25745511 epoch total loss 1.15107894
Trained batch 1054 batch loss 1.13023055 epoch total loss 1.15105927
Trained batch 1055 batch loss 1.20989609 epoch total loss 1.15111494
Trained batch 1056 batch loss 1.0889163 epoch total loss 1.15105605
Trained batch 1057 batch loss 1.30983472 epoch total loss 1.15120625
Trained batch 1058 batch loss 1.25911272 epoch total loss 1.15130818
Trained batch 1059 batch loss 1.08080161 epoch total loss 1.15124166
Trained batch 1060 batch loss 1.31769228 epoch total loss 1.15139878
Trained batch 1061 batch loss 1.44116139 epoch total loss 1.15167189
Trained batch 1062 batch loss 1.31544399 epoch total loss 1.15182602
Trained batch 1063 batch loss 1.14772904 epoch total loss 1.15182221
Trained batch 1064 batch loss 1.14745927 epoch total loss 1.15181804
Trained batch 1065 batch loss 0.941133 epoch total loss 1.15162027
Trained batch 1066 batch loss 1.15053153 epoch total loss 1.1516192
Trained batch 1067 batch loss 1.0737958 epoch total loss 1.15154636
Trained batch 1068 batch loss 1.31123567 epoch total loss 1.15169597
Trained batch 1069 batch loss 1.09622717 epoch total loss 1.15164399
Trained batch 1070 batch loss 1.24020886 epoch total loss 1.15172672
Trained batch 1071 batch loss 1.21650696 epoch total loss 1.15178728
Trained batch 1072 batch loss 0.96677947 epoch total loss 1.15161479
Trained batch 1073 batch loss 1.20791698 epoch total loss 1.15166724
Trained batch 1074 batch loss 0.954765081 epoch total loss 1.15148377
Trained batch 1075 batch loss 1.14876938 epoch total loss 1.15148127
Trained batch 1076 batch loss 1.23175657 epoch total loss 1.15155602
Trained batch 1077 batch loss 1.16431427 epoch total loss 1.15156782
Trained batch 1078 batch loss 1.14603 epoch total loss 1.15156269
Trained batch 1079 batch loss 1.28353405 epoch total loss 1.151685
Trained batch 1080 batch loss 1.09234488 epoch total loss 1.15162992
Trained batch 1081 batch loss 0.892635942 epoch total loss 1.15139031
Trained batch 1082 batch loss 1.08676958 epoch total loss 1.15133059
Trained batch 1083 batch loss 1.1658901 epoch total loss 1.15134406
Trained batch 1084 batch loss 1.20907354 epoch total loss 1.15139735
Trained batch 1085 batch loss 1.08835626 epoch total loss 1.15133929
Trained batch 1086 batch loss 1.11291802 epoch total loss 1.15130389
Trained batch 1087 batch loss 1.12413788 epoch total loss 1.15127897
Trained batch 1088 batch loss 1.10914683 epoch total loss 1.15124023
Trained batch 1089 batch loss 1.16934013 epoch total loss 1.1512568
Trained batch 1090 batch loss 1.13317049 epoch total loss 1.15124023
Trained batch 1091 batch loss 1.00070333 epoch total loss 1.15110219
Trained batch 1092 batch loss 1.3266325 epoch total loss 1.151263
Trained batch 1093 batch loss 1.38244534 epoch total loss 1.15147448
Trained batch 1094 batch loss 1.38553822 epoch total loss 1.15168846
Trained batch 1095 batch loss 1.40759373 epoch total loss 1.15192211
Trained batch 1096 batch loss 1.19618273 epoch total loss 1.15196252
Trained batch 1097 batch loss 1.40873981 epoch total loss 1.15219653
Trained batch 1098 batch loss 1.39227855 epoch total loss 1.15241528
Trained batch 1099 batch loss 1.61162186 epoch total loss 1.15283298
Trained batch 1100 batch loss 1.27397096 epoch total loss 1.15294313
Trained batch 1101 batch loss 1.31569886 epoch total loss 1.15309095
Trained batch 1102 batch loss 1.41916585 epoch total loss 1.15333235
Trained batch 1103 batch loss 1.34512782 epoch total loss 1.15350628
Trained batch 1104 batch loss 1.27205729 epoch total loss 1.15361369
Trained batch 1105 batch loss 1.33375144 epoch total loss 1.15377665
Trained batch 1106 batch loss 1.30438423 epoch total loss 1.1539129
Trained batch 1107 batch loss 1.13230026 epoch total loss 1.15389335
Trained batch 1108 batch loss 1.36413097 epoch total loss 1.15408313
Trained batch 1109 batch loss 1.51887465 epoch total loss 1.15441215
Trained batch 1110 batch loss 1.02845013 epoch total loss 1.15429866
Trained batch 1111 batch loss 1.0084784 epoch total loss 1.15416729
Trained batch 1112 batch loss 1.04737806 epoch total loss 1.15407133
Trained batch 1113 batch loss 0.943718731 epoch total loss 1.15388227
Trained batch 1114 batch loss 0.926343918 epoch total loss 1.15367806
Trained batch 1115 batch loss 0.869314313 epoch total loss 1.15342295
Trained batch 1116 batch loss 1.05070877 epoch total loss 1.15333092
Trained batch 1117 batch loss 1.08502591 epoch total loss 1.15326977
Trained batch 1118 batch loss 1.08531594 epoch total loss 1.15320909
Trained batch 1119 batch loss 0.905050278 epoch total loss 1.15298724
Trained batch 1120 batch loss 0.832790673 epoch total loss 1.15270138
Trained batch 1121 batch loss 0.849447489 epoch total loss 1.15243089
Trained batch 1122 batch loss 0.771379709 epoch total loss 1.15209126
Trained batch 1123 batch loss 0.998798609 epoch total loss 1.15195477
Trained batch 1124 batch loss 0.791685283 epoch total loss 1.1516341
Trained batch 1125 batch loss 0.917613685 epoch total loss 1.15142608
Trained batch 1126 batch loss 0.908002555 epoch total loss 1.15120983
Trained batch 1127 batch loss 0.98768723 epoch total loss 1.15106475
Trained batch 1128 batch loss 1.21503067 epoch total loss 1.1511215
Trained batch 1129 batch loss 0.998384356 epoch total loss 1.15098631
Trained batch 1130 batch loss 1.11197424 epoch total loss 1.15095174
Trained batch 1131 batch loss 1.31381226 epoch total loss 1.15109575
Trained batch 1132 batch loss 1.25665355 epoch total loss 1.15118909
Trained batch 1133 batch loss 1.46107578 epoch total loss 1.15146255
Trained batch 1134 batch loss 1.38368416 epoch total loss 1.15166736
Trained batch 1135 batch loss 1.11225486 epoch total loss 1.15163267
Trained batch 1136 batch loss 1.33303761 epoch total loss 1.15179229
Trained batch 1137 batch loss 1.15821743 epoch total loss 1.15179789
Trained batch 1138 batch loss 1.06916702 epoch total loss 1.15172541
Trained batch 1139 batch loss 1.11332166 epoch total loss 1.15169156
Trained batch 1140 batch loss 1.16651654 epoch total loss 1.15170455
Trained batch 1141 batch loss 1.12573099 epoch total loss 1.15168178
Trained batch 1142 batch loss 0.908643544 epoch total loss 1.15146911
Trained batch 1143 batch loss 1.29143643 epoch total loss 1.15159142
Trained batch 1144 batch loss 1.11123753 epoch total loss 1.15155613
Trained batch 1145 batch loss 0.946686685 epoch total loss 1.1513772
Trained batch 1146 batch loss 1.14883554 epoch total loss 1.15137494
Trained batch 1147 batch loss 1.08240402 epoch total loss 1.15131485
Trained batch 1148 batch loss 1.08545065 epoch total loss 1.1512574
Trained batch 1149 batch loss 1.00600696 epoch total loss 1.15113103
Trained batch 1150 batch loss 1.18780756 epoch total loss 1.15116298
Trained batch 1151 batch loss 1.22775877 epoch total loss 1.1512295
Trained batch 1152 batch loss 1.26488435 epoch total loss 1.15132821
Trained batch 1153 batch loss 1.16281319 epoch total loss 1.15133822
Trained batch 1154 batch loss 1.14634132 epoch total loss 1.15133381
Trained batch 1155 batch loss 1.30823779 epoch total loss 1.15146971
Trained batch 1156 batch loss 1.19735038 epoch total loss 1.1515094
Trained batch 1157 batch loss 1.207654 epoch total loss 1.15155792
Trained batch 1158 batch loss 1.1141367 epoch total loss 1.15152562
Trained batch 1159 batch loss 1.11366558 epoch total loss 1.15149295
Trained batch 1160 batch loss 1.37279582 epoch total loss 1.15168369
Trained batch 1161 batch loss 1.11921632 epoch total loss 1.15165579
Trained batch 1162 batch loss 1.10936713 epoch total loss 1.15161943
Trained batch 1163 batch loss 1.18993378 epoch total loss 1.15165234
Trained batch 1164 batch loss 1.45669818 epoch total loss 1.15191436
Trained batch 1165 batch loss 1.13604355 epoch total loss 1.15190077
Trained batch 1166 batch loss 1.23002505 epoch total loss 1.15196764
Trained batch 1167 batch loss 1.15421867 epoch total loss 1.15196955
Trained batch 1168 batch loss 1.24447465 epoch total loss 1.15204883
Trained batch 1169 batch loss 1.35942459 epoch total loss 1.15222621
Trained batch 1170 batch loss 1.30641353 epoch total loss 1.15235794
Trained batch 1171 batch loss 1.35507572 epoch total loss 1.15253103
Trained batch 1172 batch loss 1.3578012 epoch total loss 1.15270627
Trained batch 1173 batch loss 1.11970568 epoch total loss 1.15267813
Trained batch 1174 batch loss 1.42244971 epoch total loss 1.15290797
Trained batch 1175 batch loss 1.25069189 epoch total loss 1.15299118
Trained batch 1176 batch loss 1.41602564 epoch total loss 1.15321481
Trained batch 1177 batch loss 1.1698662 epoch total loss 1.153229
Trained batch 1178 batch loss 1.14991045 epoch total loss 1.15322626
Trained batch 1179 batch loss 1.29231691 epoch total loss 1.15334427
Trained batch 1180 batch loss 1.28338194 epoch total loss 1.15345442
Trained batch 1181 batch loss 1.42240095 epoch total loss 1.15368211
Trained batch 1182 batch loss 1.26480961 epoch total loss 1.15377605
Trained batch 1183 batch loss 1.38542819 epoch total loss 1.15397179
Trained batch 1184 batch loss 1.33067751 epoch total loss 1.15412104
Trained batch 1185 batch loss 1.51780629 epoch total loss 1.15442801
Trained batch 1186 batch loss 1.42331314 epoch total loss 1.15465474
Trained batch 1187 batch loss 1.11309147 epoch total loss 1.15461969
Trained batch 1188 batch loss 1.1702069 epoch total loss 1.15463281
Trained batch 1189 batch loss 0.945142627 epoch total loss 1.15445662
Trained batch 1190 batch loss 1.179515 epoch total loss 1.15447772
Trained batch 1191 batch loss 1.06104136 epoch total loss 1.15439928
Trained batch 1192 batch loss 0.967020631 epoch total loss 1.15424204
Trained batch 1193 batch loss 1.07092726 epoch total loss 1.1541723
Trained batch 1194 batch loss 1.00301254 epoch total loss 1.1540457
Trained batch 1195 batch loss 1.15151322 epoch total loss 1.15404356
Trained batch 1196 batch loss 1.39757025 epoch total loss 1.15424716
Trained batch 1197 batch loss 1.31008852 epoch total loss 1.15437734
Trained batch 1198 batch loss 1.1744597 epoch total loss 1.15439403
Trained batch 1199 batch loss 1.06701589 epoch total loss 1.15432119
Trained batch 1200 batch loss 1.07305884 epoch total loss 1.15425348
Trained batch 1201 batch loss 0.982651174 epoch total loss 1.15411055
Trained batch 1202 batch loss 1.18380165 epoch total loss 1.15413535
Trained batch 1203 batch loss 1.07019877 epoch total loss 1.15406549
Trained batch 1204 batch loss 1.09095919 epoch total loss 1.15401304
Trained batch 1205 batch loss 1.13128817 epoch total loss 1.15399432
Trained batch 1206 batch loss 0.936142743 epoch total loss 1.1538136
Trained batch 1207 batch loss 1.04821825 epoch total loss 1.15372622
Trained batch 1208 batch loss 0.910022378 epoch total loss 1.1535244
Trained batch 1209 batch loss 1.28684449 epoch total loss 1.15363467
Trained batch 1210 batch loss 1.13231754 epoch total loss 1.15361714
Trained batch 1211 batch loss 1.28051805 epoch total loss 1.15372193
Trained batch 1212 batch loss 1.15244126 epoch total loss 1.15372086
Trained batch 1213 batch loss 1.02196121 epoch total loss 1.15361226
Trained batch 1214 batch loss 1.24204731 epoch total loss 1.15368509
Trained batch 1215 batch loss 1.11708593 epoch total loss 1.15365493
Trained batch 1216 batch loss 1.194309 epoch total loss 1.15368843
Trained batch 1217 batch loss 1.13448572 epoch total loss 1.1536727
Trained batch 1218 batch loss 1.03096259 epoch total loss 1.15357196
Trained batch 1219 batch loss 1.05323362 epoch total loss 1.15348959
Trained batch 1220 batch loss 1.08684897 epoch total loss 1.15343499
Trained batch 1221 batch loss 0.998915434 epoch total loss 1.15330839
Trained batch 1222 batch loss 0.944047749 epoch total loss 1.15313721
Trained batch 1223 batch loss 1.00542092 epoch total loss 1.15301633
Trained batch 1224 batch loss 1.12428594 epoch total loss 1.15299284
Trained batch 1225 batch loss 1.21675277 epoch total loss 1.15304494
Trained batch 1226 batch loss 1.02797687 epoch total loss 1.1529429
Trained batch 1227 batch loss 1.00668693 epoch total loss 1.15282381
Trained batch 1228 batch loss 1.02369237 epoch total loss 1.15271866
Trained batch 1229 batch loss 1.03190899 epoch total loss 1.15262032
Trained batch 1230 batch loss 1.2719481 epoch total loss 1.15271735
Trained batch 1231 batch loss 1.30279422 epoch total loss 1.15283918
Trained batch 1232 batch loss 1.23105931 epoch total loss 1.15290272
Trained batch 1233 batch loss 1.28716326 epoch total loss 1.15301156
Trained batch 1234 batch loss 1.24998403 epoch total loss 1.15309012
Trained batch 1235 batch loss 1.07800674 epoch total loss 1.15302932
Trained batch 1236 batch loss 1.23094893 epoch total loss 1.15309238
Trained batch 1237 batch loss 1.2683568 epoch total loss 1.15318549
Trained batch 1238 batch loss 1.20037532 epoch total loss 1.15322363
Trained batch 1239 batch loss 1.28375471 epoch total loss 1.15332901
Trained batch 1240 batch loss 1.34529972 epoch total loss 1.15348387
Trained batch 1241 batch loss 1.05037642 epoch total loss 1.15340078
Trained batch 1242 batch loss 1.14329684 epoch total loss 1.15339267
Trained batch 1243 batch loss 1.08115327 epoch total loss 1.1533345
Trained batch 1244 batch loss 1.13232613 epoch total loss 1.15331769
Trained batch 1245 batch loss 1.26525474 epoch total loss 1.15340757
Trained batch 1246 batch loss 1.1817317 epoch total loss 1.15343034
Trained batch 1247 batch loss 1.13648176 epoch total loss 1.15341675
Trained batch 1248 batch loss 0.921096563 epoch total loss 1.15323067
Trained batch 1249 batch loss 0.889216304 epoch total loss 1.15301919
Trained batch 1250 batch loss 1.05687642 epoch total loss 1.1529423
Trained batch 1251 batch loss 1.07520175 epoch total loss 1.15288019
Trained batch 1252 batch loss 1.09694552 epoch total loss 1.15283549
Trained batch 1253 batch loss 1.16741681 epoch total loss 1.15284705
Trained batch 1254 batch loss 0.939916134 epoch total loss 1.1526773
Trained batch 1255 batch loss 1.06900072 epoch total loss 1.15261054
Trained batch 1256 batch loss 1.20103645 epoch total loss 1.15264916
Trained batch 1257 batch loss 1.17953503 epoch total loss 1.1526705
Trained batch 1258 batch loss 1.16642928 epoch total loss 1.15268147
Trained batch 1259 batch loss 1.12184882 epoch total loss 1.15265691
Trained batch 1260 batch loss 1.0555321 epoch total loss 1.1525799
Trained batch 1261 batch loss 1.09143209 epoch total loss 1.15253139
Trained batch 1262 batch loss 1.2729733 epoch total loss 1.15262675
Trained batch 1263 batch loss 1.27567375 epoch total loss 1.15272415
Trained batch 1264 batch loss 1.3304466 epoch total loss 1.15286481
Trained batch 1265 batch loss 1.2748065 epoch total loss 1.15296113
Trained batch 1266 batch loss 1.3505621 epoch total loss 1.1531173
Trained batch 1267 batch loss 1.17757332 epoch total loss 1.15313661
Trained batch 1268 batch loss 1.33833635 epoch total loss 1.15328264
Trained batch 1269 batch loss 1.22809029 epoch total loss 1.15334165
Trained batch 1270 batch loss 1.37657011 epoch total loss 1.15351748
Trained batch 1271 batch loss 1.14239287 epoch total loss 1.15350866
Trained batch 1272 batch loss 1.19774413 epoch total loss 1.15354347
Trained batch 1273 batch loss 1.19668651 epoch total loss 1.15357733
Trained batch 1274 batch loss 1.30092978 epoch total loss 1.15369296
Trained batch 1275 batch loss 1.21817493 epoch total loss 1.15374351
Trained batch 1276 batch loss 1.12618375 epoch total loss 1.15372193
Trained batch 1277 batch loss 1.14498734 epoch total loss 1.15371513
Trained batch 1278 batch loss 1.21661425 epoch total loss 1.15376437
Trained batch 1279 batch loss 1.11156881 epoch total loss 1.15373135
Trained batch 1280 batch loss 1.06727421 epoch total loss 1.15366387
Trained batch 1281 batch loss 1.43671703 epoch total loss 1.15388489
Trained batch 1282 batch loss 1.06358075 epoch total loss 1.15381444
Trained batch 1283 batch loss 1.236449 epoch total loss 1.15387881
Trained batch 1284 batch loss 1.34815 epoch total loss 1.15403008
Trained batch 1285 batch loss 1.34675169 epoch total loss 1.15418017
Trained batch 1286 batch loss 1.0956322 epoch total loss 1.15413451
Trained batch 1287 batch loss 1.14857066 epoch total loss 1.15413022
Trained batch 1288 batch loss 1.03491879 epoch total loss 1.15403771
Trained batch 1289 batch loss 1.22157896 epoch total loss 1.15409
Trained batch 1290 batch loss 1.37108135 epoch total loss 1.15425825
Trained batch 1291 batch loss 1.19461966 epoch total loss 1.15428948
Trained batch 1292 batch loss 1.1744796 epoch total loss 1.1543051
Trained batch 1293 batch loss 1.14648521 epoch total loss 1.15429902
Trained batch 1294 batch loss 1.17616 epoch total loss 1.15431595
Trained batch 1295 batch loss 1.25012636 epoch total loss 1.15438986
Trained batch 1296 batch loss 1.21652794 epoch total loss 1.1544379
Trained batch 1297 batch loss 1.04998791 epoch total loss 1.15435743
Trained batch 1298 batch loss 1.18691468 epoch total loss 1.15438247
Trained batch 1299 batch loss 1.36670423 epoch total loss 1.1545459
Trained batch 1300 batch loss 1.14424086 epoch total loss 1.15453804
Trained batch 1301 batch loss 1.35005069 epoch total loss 1.15468836
Trained batch 1302 batch loss 1.49457073 epoch total loss 1.15494943
Trained batch 1303 batch loss 1.38194752 epoch total loss 1.15512359
Trained batch 1304 batch loss 1.23433483 epoch total loss 1.15518439
Trained batch 1305 batch loss 1.25562811 epoch total loss 1.1552614
Trained batch 1306 batch loss 1.4142133 epoch total loss 1.15545964
Trained batch 1307 batch loss 1.40855515 epoch total loss 1.15565324
Trained batch 1308 batch loss 1.37359715 epoch total loss 1.15582
Trained batch 1309 batch loss 1.42011595 epoch total loss 1.15602195
Trained batch 1310 batch loss 1.26226974 epoch total loss 1.15610301
Trained batch 1311 batch loss 1.11599159 epoch total loss 1.15607238
Trained batch 1312 batch loss 1.22577953 epoch total loss 1.15612555
Trained batch 1313 batch loss 1.21398044 epoch total loss 1.15616965
Trained batch 1314 batch loss 1.31708455 epoch total loss 1.1562922
Trained batch 1315 batch loss 1.26510823 epoch total loss 1.15637493
Trained batch 1316 batch loss 1.33886492 epoch total loss 1.15651357
Trained batch 1317 batch loss 1.10709929 epoch total loss 1.15647602
Trained batch 1318 batch loss 1.01057732 epoch total loss 1.15636539
Trained batch 1319 batch loss 1.09356892 epoch total loss 1.15631783
Trained batch 1320 batch loss 1.14676452 epoch total loss 1.15631056
Trained batch 1321 batch loss 1.29899061 epoch total loss 1.15641856
Trained batch 1322 batch loss 1.20981288 epoch total loss 1.15645897
Trained batch 1323 batch loss 1.1157918 epoch total loss 1.15642822
Trained batch 1324 batch loss 1.29063511 epoch total loss 1.15652966
Trained batch 1325 batch loss 1.09928477 epoch total loss 1.15648639
Trained batch 1326 batch loss 1.06081676 epoch total loss 1.15641427
Trained batch 1327 batch loss 1.23662889 epoch total loss 1.15647459
Trained batch 1328 batch loss 1.1975745 epoch total loss 1.15650558
Trained batch 1329 batch loss 1.28365493 epoch total loss 1.15660131
Trained batch 1330 batch loss 1.21706951 epoch total loss 1.15664673
Trained batch 1331 batch loss 0.85257709 epoch total loss 1.15641832
Trained batch 1332 batch loss 1.44928336 epoch total loss 1.15663826
Trained batch 1333 batch loss 1.20445395 epoch total loss 1.15667403
Trained batch 1334 batch loss 1.17478359 epoch total loss 1.15668774
Trained batch 1335 batch loss 1.0921098 epoch total loss 1.15663934
Trained batch 1336 batch loss 1.18429041 epoch total loss 1.15666008
Trained batch 1337 batch loss 1.20329285 epoch total loss 1.15669489
Trained batch 1338 batch loss 1.32222605 epoch total loss 1.15681863
Trained batch 1339 batch loss 1.3232609 epoch total loss 1.15694296
Trained batch 1340 batch loss 1.24981916 epoch total loss 1.15701234
Trained batch 1341 batch loss 1.40720868 epoch total loss 1.15719891
Trained batch 1342 batch loss 1.40168917 epoch total loss 1.15738106
Trained batch 1343 batch loss 1.21515179 epoch total loss 1.15742421
Trained batch 1344 batch loss 1.01620233 epoch total loss 1.15731907
Trained batch 1345 batch loss 1.0116868 epoch total loss 1.15721083
Trained batch 1346 batch loss 1.21642375 epoch total loss 1.15725482
Trained batch 1347 batch loss 1.07134461 epoch total loss 1.15719104
Trained batch 1348 batch loss 1.20402336 epoch total loss 1.15722573
Trained batch 1349 batch loss 1.17394876 epoch total loss 1.15723813
Trained batch 1350 batch loss 1.25611305 epoch total loss 1.15731132
Trained batch 1351 batch loss 1.32173944 epoch total loss 1.15743315
Trained batch 1352 batch loss 1.16703773 epoch total loss 1.15744019
Trained batch 1353 batch loss 1.30532837 epoch total loss 1.1575495
Trained batch 1354 batch loss 1.22169673 epoch total loss 1.15759683
Trained batch 1355 batch loss 1.13754153 epoch total loss 1.15758204
Trained batch 1356 batch loss 1.14843309 epoch total loss 1.15757525
Trained batch 1357 batch loss 1.0203135 epoch total loss 1.15747416
Trained batch 1358 batch loss 0.96690762 epoch total loss 1.15733385
Trained batch 1359 batch loss 0.86426568 epoch total loss 1.1571182
Trained batch 1360 batch loss 1.11391544 epoch total loss 1.15708637
Trained batch 1361 batch loss 1.01947451 epoch total loss 1.15698528
Trained batch 1362 batch loss 1.05372298 epoch total loss 1.15690947
Trained batch 1363 batch loss 1.23365343 epoch total loss 1.15696573
Trained batch 1364 batch loss 1.27125144 epoch total loss 1.15704954
Trained batch 1365 batch loss 1.1618036 epoch total loss 1.15705299
Trained batch 1366 batch loss 1.2630024 epoch total loss 1.1571306
Trained batch 1367 batch loss 1.05450773 epoch total loss 1.15705562
Trained batch 1368 batch loss 1.15413928 epoch total loss 1.15705347
Trained batch 1369 batch loss 1.13271475 epoch total loss 1.15703571
Trained batch 1370 batch loss 1.10910916 epoch total loss 1.15700066
Trained batch 1371 batch loss 1.0528028 epoch total loss 1.15692472
Trained batch 1372 batch loss 0.931456089 epoch total loss 1.15676033
Trained batch 1373 batch loss 1.10060716 epoch total loss 1.15671945
Trained batch 1374 batch loss 0.948059738 epoch total loss 1.15656757
Trained batch 1375 batch loss 0.986050308 epoch total loss 1.1564436
Trained batch 1376 batch loss 1.06351113 epoch total loss 1.156376
Trained batch 1377 batch loss 0.93570888 epoch total loss 1.15621579
Trained batch 1378 batch loss 1.12272203 epoch total loss 1.15619147
Trained batch 1379 batch loss 1.21514666 epoch total loss 1.15623415
Trained batch 1380 batch loss 1.21660829 epoch total loss 1.15627789
Trained batch 1381 batch loss 1.00071132 epoch total loss 1.15616524
Trained batch 1382 batch loss 1.12787771 epoch total loss 1.15614486
Trained batch 1383 batch loss 1.14416873 epoch total loss 1.15613616
Trained batch 1384 batch loss 1.1322341 epoch total loss 1.15611887
Trained batch 1385 batch loss 1.34049463 epoch total loss 1.15625191
Trained batch 1386 batch loss 1.34409404 epoch total loss 1.15638745
Trained batch 1387 batch loss 1.35962152 epoch total loss 1.15653396
Trained batch 1388 batch loss 1.24435306 epoch total loss 1.15659726
Trained batch 1389 batch loss 1.24773097 epoch total loss 1.15666282
Trained batch 1390 batch loss 1.15502441 epoch total loss 1.15666175
Trained batch 1391 batch loss 1.05200911 epoch total loss 1.15658641
Trained batch 1392 batch loss 1.1295898 epoch total loss 1.1565671
Trained batch 1393 batch loss 1.15970302 epoch total loss 1.15656936
Trained batch 1394 batch loss 1.16670942 epoch total loss 1.15657663
Trained batch 1395 batch loss 1.17776299 epoch total loss 1.15659177
Trained batch 1396 batch loss 1.34020686 epoch total loss 1.15672338
Trained batch 1397 batch loss 1.0408926 epoch total loss 1.15664041
Trained batch 1398 batch loss 0.864549339 epoch total loss 1.15643144
Trained batch 1399 batch loss 1.00481617 epoch total loss 1.15632308
Trained batch 1400 batch loss 1.15508127 epoch total loss 1.15632212
Trained batch 1401 batch loss 1.28591037 epoch total loss 1.15641463
Trained batch 1402 batch loss 1.32453215 epoch total loss 1.15653455
Trained batch 1403 batch loss 1.27615011 epoch total loss 1.15661979
Trained batch 1404 batch loss 1.36364913 epoch total loss 1.15676725
Trained batch 1405 batch loss 1.29350269 epoch total loss 1.15686452
Trained batch 1406 batch loss 1.16889882 epoch total loss 1.15687311
Trained batch 1407 batch loss 1.10819781 epoch total loss 1.15683854
Trained batch 1408 batch loss 1.18943071 epoch total loss 1.15686166
Trained batch 1409 batch loss 1.14141738 epoch total loss 1.1568507
Trained batch 1410 batch loss 1.08784127 epoch total loss 1.1568017
Trained batch 1411 batch loss 1.23864985 epoch total loss 1.15685976
Trained batch 1412 batch loss 1.26073956 epoch total loss 1.15693331
Trained batch 1413 batch loss 0.960823894 epoch total loss 1.15679455
Trained batch 1414 batch loss 0.913066506 epoch total loss 1.15662217
Trained batch 1415 batch loss 1.11800098 epoch total loss 1.15659487
Trained batch 1416 batch loss 0.94708693 epoch total loss 1.15644693
Trained batch 1417 batch loss 1.07491589 epoch total loss 1.15638947
Trained batch 1418 batch loss 1.02839804 epoch total loss 1.15629923
Trained batch 1419 batch loss 1.25991571 epoch total loss 1.15637219
Trained batch 1420 batch loss 1.16122293 epoch total loss 1.15637565
Trained batch 1421 batch loss 1.28719079 epoch total loss 1.1564678
Trained batch 1422 batch loss 1.25909233 epoch total loss 1.15653992
Trained batch 1423 batch loss 1.18044865 epoch total loss 1.15655673
Trained batch 1424 batch loss 1.0575583 epoch total loss 1.15648723
Trained batch 1425 batch loss 1.02584255 epoch total loss 1.15639555
Trained batch 1426 batch loss 1.20511866 epoch total loss 1.15642965
Trained batch 1427 batch loss 1.23380065 epoch total loss 1.15648389
Trained batch 1428 batch loss 1.44608676 epoch total loss 1.15668666
Trained batch 1429 batch loss 1.28657901 epoch total loss 1.15677762
Trained batch 1430 batch loss 1.26819944 epoch total loss 1.15685546
Trained batch 1431 batch loss 1.10443521 epoch total loss 1.15681887
Trained batch 1432 batch loss 1.20618224 epoch total loss 1.15685332
Trained batch 1433 batch loss 1.19042778 epoch total loss 1.1568768
Trained batch 1434 batch loss 1.2144351 epoch total loss 1.15691698
Trained batch 1435 batch loss 0.981480241 epoch total loss 1.15679467
Trained batch 1436 batch loss 0.946677208 epoch total loss 1.1566484
Trained batch 1437 batch loss 1.0586884 epoch total loss 1.15658021
Trained batch 1438 batch loss 1.00446415 epoch total loss 1.15647447
Trained batch 1439 batch loss 1.02938914 epoch total loss 1.15638614
Trained batch 1440 batch loss 1.26857352 epoch total loss 1.1564641
Trained batch 1441 batch loss 1.12764931 epoch total loss 1.15644407
Trained batch 1442 batch loss 1.25037742 epoch total loss 1.15650916
Trained batch 1443 batch loss 1.21417212 epoch total loss 1.1565491
Trained batch 1444 batch loss 1.06073427 epoch total loss 1.15648282
Trained batch 1445 batch loss 1.14621615 epoch total loss 1.15647578
Trained batch 1446 batch loss 1.19716096 epoch total loss 1.1565038
Trained batch 1447 batch loss 1.18327856 epoch total loss 1.15652227
Trained batch 1448 batch loss 1.27388453 epoch total loss 1.15660346
Trained batch 1449 batch loss 1.14276552 epoch total loss 1.15659392
Trained batch 1450 batch loss 1.06506062 epoch total loss 1.15653074
Trained batch 1451 batch loss 1.11382461 epoch total loss 1.15650129
Trained batch 1452 batch loss 1.18367147 epoch total loss 1.15652
Trained batch 1453 batch loss 1.24917841 epoch total loss 1.15658379
Trained batch 1454 batch loss 1.27227139 epoch total loss 1.1566633
Trained batch 1455 batch loss 1.26952386 epoch total loss 1.1567409
Trained batch 1456 batch loss 1.22123599 epoch total loss 1.15678513
Trained batch 1457 batch loss 1.33991313 epoch total loss 1.1569109
Trained batch 1458 batch loss 1.16920185 epoch total loss 1.15691924
Trained batch 1459 batch loss 1.13493156 epoch total loss 1.15690422
Trained batch 1460 batch loss 0.938610077 epoch total loss 1.15675461
Trained batch 1461 batch loss 1.11880684 epoch total loss 1.15672863
Trained batch 1462 batch loss 1.04532385 epoch total loss 1.15665245
Trained batch 1463 batch loss 1.12885284 epoch total loss 1.1566335
Trained batch 1464 batch loss 1.08593202 epoch total loss 1.15658522
Trained batch 1465 batch loss 1.20194376 epoch total loss 1.15661609
Trained batch 1466 batch loss 1.00516605 epoch total loss 1.15651274
Trained batch 1467 batch loss 0.981208146 epoch total loss 1.15639329
Trained batch 1468 batch loss 1.02661455 epoch total loss 1.15630484
Trained batch 1469 batch loss 1.20165038 epoch total loss 1.15633571
Trained batch 1470 batch loss 1.18388104 epoch total loss 1.15635443
Trained batch 1471 batch loss 1.31057632 epoch total loss 1.15645933
Trained batch 1472 batch loss 1.23563743 epoch total loss 1.15651309
Trained batch 1473 batch loss 0.930016458 epoch total loss 1.15635931
Trained batch 1474 batch loss 0.945708752 epoch total loss 1.15621638
Trained batch 1475 batch loss 1.08546376 epoch total loss 1.15616834
Trained batch 1476 batch loss 1.01495838 epoch total loss 1.15607274
Trained batch 1477 batch loss 0.997625172 epoch total loss 1.15596557
Trained batch 1478 batch loss 1.21972513 epoch total loss 1.15600872
Trained batch 1479 batch loss 1.07556462 epoch total loss 1.15595424
Trained batch 1480 batch loss 1.2276504 epoch total loss 1.15600276
Trained batch 1481 batch loss 1.17719126 epoch total loss 1.15601707
Trained batch 1482 batch loss 1.20737875 epoch total loss 1.15605175
Trained batch 1483 batch loss 1.10386801 epoch total loss 1.15601659
Trained batch 1484 batch loss 1.23319077 epoch total loss 1.15606856
Trained batch 1485 batch loss 1.29621398 epoch total loss 1.15616298
Trained batch 1486 batch loss 1.25733471 epoch total loss 1.15623105
Trained batch 1487 batch loss 1.29440939 epoch total loss 1.15632391
Trained batch 1488 batch loss 1.2428937 epoch total loss 1.1563822
Trained batch 1489 batch loss 1.28551173 epoch total loss 1.15646887
Trained batch 1490 batch loss 1.33530164 epoch total loss 1.15658891
Trained batch 1491 batch loss 1.09799 epoch total loss 1.15654969
Trained batch 1492 batch loss 1.12909389 epoch total loss 1.15653133
Trained batch 1493 batch loss 1.15772486 epoch total loss 1.15653205
Trained batch 1494 batch loss 1.12622547 epoch total loss 1.15651178
Trained batch 1495 batch loss 1.20717788 epoch total loss 1.15654564
Trained batch 1496 batch loss 1.30262351 epoch total loss 1.15664327
Trained batch 1497 batch loss 1.03517938 epoch total loss 1.15656209
Trained batch 1498 batch loss 1.26880026 epoch total loss 1.15663707
Trained batch 1499 batch loss 1.25673389 epoch total loss 1.15670383
Trained batch 1500 batch loss 1.2532227 epoch total loss 1.1567682
Trained batch 1501 batch loss 1.45700443 epoch total loss 1.15696824
Trained batch 1502 batch loss 1.23312116 epoch total loss 1.1570189
Trained batch 1503 batch loss 1.04603338 epoch total loss 1.15694511
Trained batch 1504 batch loss 1.00985765 epoch total loss 1.15684724
Trained batch 1505 batch loss 1.40701437 epoch total loss 1.15701354
Trained batch 1506 batch loss 1.34695303 epoch total loss 1.15713954
Trained batch 1507 batch loss 1.31687558 epoch total loss 1.15724564
Trained batch 1508 batch loss 1.36672401 epoch total loss 1.15738451
Trained batch 1509 batch loss 1.16038859 epoch total loss 1.15738654
Trained batch 1510 batch loss 1.28162253 epoch total loss 1.1574688
Trained batch 1511 batch loss 1.23857927 epoch total loss 1.15752244
Trained batch 1512 batch loss 1.22439408 epoch total loss 1.15756667
Trained batch 1513 batch loss 1.22918355 epoch total loss 1.15761387
Trained batch 1514 batch loss 1.26592267 epoch total loss 1.1576854
Trained batch 1515 batch loss 1.07284355 epoch total loss 1.15762949
Trained batch 1516 batch loss 1.00305796 epoch total loss 1.15752745
Trained batch 1517 batch loss 0.976174533 epoch total loss 1.15740788
Trained batch 1518 batch loss 1.17072177 epoch total loss 1.1574167
Trained batch 1519 batch loss 1.33408082 epoch total loss 1.15753305
Trained batch 1520 batch loss 1.44345593 epoch total loss 1.15772116
Trained batch 1521 batch loss 1.19109297 epoch total loss 1.1577431
Trained batch 1522 batch loss 1.37068403 epoch total loss 1.15788305
Trained batch 1523 batch loss 1.23502254 epoch total loss 1.15793371
Trained batch 1524 batch loss 1.53182817 epoch total loss 1.15817904
Trained batch 1525 batch loss 1.39641571 epoch total loss 1.15833521
Trained batch 1526 batch loss 1.10566628 epoch total loss 1.15830076
Trained batch 1527 batch loss 1.20051432 epoch total loss 1.15832841
Trained batch 1528 batch loss 1.31105459 epoch total loss 1.15842831
Trained batch 1529 batch loss 1.30202413 epoch total loss 1.15852225
Trained batch 1530 batch loss 1.20761287 epoch total loss 1.15855432
Trained batch 1531 batch loss 1.04957747 epoch total loss 1.15848315
Trained batch 1532 batch loss 1.27861392 epoch total loss 1.15856147
Trained batch 1533 batch loss 1.22282124 epoch total loss 1.15860343
Trained batch 1534 batch loss 1.25137043 epoch total loss 1.15866387
Trained batch 1535 batch loss 1.35290432 epoch total loss 1.15879047
Trained batch 1536 batch loss 1.102211 epoch total loss 1.15875351
Trained batch 1537 batch loss 1.12757182 epoch total loss 1.15873325
Trained batch 1538 batch loss 0.837524235 epoch total loss 1.15852439
Trained batch 1539 batch loss 0.889303684 epoch total loss 1.15834951
Trained batch 1540 batch loss 0.887607336 epoch total loss 1.15817368
Trained batch 1541 batch loss 0.97483027 epoch total loss 1.15805471
Trained batch 1542 batch loss 0.959764481 epoch total loss 1.15792608
Trained batch 1543 batch loss 0.938226 epoch total loss 1.15778363
Trained batch 1544 batch loss 0.986504078 epoch total loss 1.15767276
Trained batch 1545 batch loss 1.1741823 epoch total loss 1.15768337
Trained batch 1546 batch loss 1.1746242 epoch total loss 1.15769434
Trained batch 1547 batch loss 1.03030992 epoch total loss 1.15761209
Trained batch 1548 batch loss 0.982651949 epoch total loss 1.15749896
Trained batch 1549 batch loss 1.3248086 epoch total loss 1.15760708
Trained batch 1550 batch loss 1.10637796 epoch total loss 1.15757394
Trained batch 1551 batch loss 1.10153365 epoch total loss 1.15753782
Trained batch 1552 batch loss 0.961939454 epoch total loss 1.15741181
Trained batch 1553 batch loss 1.17800701 epoch total loss 1.15742505
Trained batch 1554 batch loss 1.25226116 epoch total loss 1.15748608
Trained batch 1555 batch loss 1.35490251 epoch total loss 1.15761304
Trained batch 1556 batch loss 1.29345143 epoch total loss 1.1577003
Trained batch 1557 batch loss 1.40857267 epoch total loss 1.15786147
Trained batch 1558 batch loss 1.1846844 epoch total loss 1.15787864
Trained batch 1559 batch loss 1.08008432 epoch total loss 1.15782881
Trained batch 1560 batch loss 1.29758525 epoch total loss 1.15791833
Trained batch 1561 batch loss 1.2869103 epoch total loss 1.15800095
Trained batch 1562 batch loss 1.33924091 epoch total loss 1.15811706
Trained batch 1563 batch loss 1.18195724 epoch total loss 1.15813231
Trained batch 1564 batch loss 1.12045 epoch total loss 1.15810823
Trained batch 1565 batch loss 1.40819335 epoch total loss 1.15826797
Trained batch 1566 batch loss 1.3203367 epoch total loss 1.15837145
Trained batch 1567 batch loss 1.40548134 epoch total loss 1.15852916
Trained batch 1568 batch loss 1.22674286 epoch total loss 1.15857267
Trained batch 1569 batch loss 1.01497817 epoch total loss 1.15848124
Trained batch 1570 batch loss 1.10666418 epoch total loss 1.15844822
Trained batch 1571 batch loss 0.962985873 epoch total loss 1.15832376
Trained batch 1572 batch loss 1.14030778 epoch total loss 1.15831232
Trained batch 1573 batch loss 1.29852939 epoch total loss 1.15840149
Trained batch 1574 batch loss 1.34266388 epoch total loss 1.15851855
Trained batch 1575 batch loss 1.22135413 epoch total loss 1.15855837
Trained batch 1576 batch loss 1.41082096 epoch total loss 1.15871847
Trained batch 1577 batch loss 1.16486049 epoch total loss 1.1587224
Trained batch 1578 batch loss 1.09016299 epoch total loss 1.15867901
Trained batch 1579 batch loss 1.25123405 epoch total loss 1.15873754
Trained batch 1580 batch loss 1.15060544 epoch total loss 1.15873241
Trained batch 1581 batch loss 1.24319279 epoch total loss 1.15878582
Trained batch 1582 batch loss 1.08842254 epoch total loss 1.15874135
Trained batch 1583 batch loss 1.31202078 epoch total loss 1.15883815
Trained batch 1584 batch loss 1.42813456 epoch total loss 1.15900815
Trained batch 1585 batch loss 1.14371443 epoch total loss 1.15899849
Trained batch 1586 batch loss 1.15960991 epoch total loss 1.15899885
Trained batch 1587 batch loss 1.20520175 epoch total loss 1.15902805
Trained batch 1588 batch loss 1.17313278 epoch total loss 1.15903687
Trained batch 1589 batch loss 1.2116524 epoch total loss 1.15907
Trained batch 1590 batch loss 1.21796155 epoch total loss 1.15910709
Trained batch 1591 batch loss 1.04235816 epoch total loss 1.15903366
Trained batch 1592 batch loss 1.17501771 epoch total loss 1.15904379
Trained batch 1593 batch loss 1.19440365 epoch total loss 1.15906596
Trained batch 1594 batch loss 1.05045795 epoch total loss 1.15899777
Trained batch 1595 batch loss 0.848604441 epoch total loss 1.15880322
Trained batch 1596 batch loss 1.17360222 epoch total loss 1.15881252
Trained batch 1597 batch loss 1.01961088 epoch total loss 1.15872538
Trained batch 1598 batch loss 1.08538699 epoch total loss 1.15867937
Trained batch 1599 batch loss 1.09414697 epoch total loss 1.15863907
Trained batch 1600 batch loss 1.1198523 epoch total loss 1.15861475
Trained batch 1601 batch loss 0.878095 epoch total loss 1.15843952
Trained batch 1602 batch loss 1.29250884 epoch total loss 1.1585232
Trained batch 1603 batch loss 1.20003319 epoch total loss 1.15854919
Trained batch 1604 batch loss 1.40548158 epoch total loss 1.15870309
Trained batch 1605 batch loss 1.23797536 epoch total loss 1.15875244
Trained batch 1606 batch loss 1.10562551 epoch total loss 1.15871942
Trained batch 1607 batch loss 1.29247046 epoch total loss 1.15880263
Trained batch 1608 batch loss 1.12942123 epoch total loss 1.15878427
Trained batch 1609 batch loss 1.41797137 epoch total loss 1.15894544
Trained batch 1610 batch loss 1.38481617 epoch total loss 1.15908563
Trained batch 1611 batch loss 1.3253088 epoch total loss 1.15918887
Trained batch 1612 batch loss 1.12896729 epoch total loss 1.15917015
Trained batch 1613 batch loss 1.00100291 epoch total loss 1.15907204
Trained batch 1614 batch loss 1.2845335 epoch total loss 1.15914977
Trained batch 1615 batch loss 1.26349115 epoch total loss 1.1592145
Trained batch 1616 batch loss 1.18365455 epoch total loss 1.15922952
Trained batch 1617 batch loss 1.29978681 epoch total loss 1.15931642
Trained batch 1618 batch loss 1.09285569 epoch total loss 1.15927541
Trained batch 1619 batch loss 1.16464329 epoch total loss 1.15927875
Trained batch 1620 batch loss 1.16714 epoch total loss 1.15928364
Trained batch 1621 batch loss 1.28513336 epoch total loss 1.15936124
Trained batch 1622 batch loss 1.29710054 epoch total loss 1.15944624
Trained batch 1623 batch loss 1.09320319 epoch total loss 1.15940535
Trained batch 1624 batch loss 1.26135242 epoch total loss 1.15946817
Trained batch 1625 batch loss 1.22112715 epoch total loss 1.15950608
Trained batch 1626 batch loss 1.20759213 epoch total loss 1.15953565
Trained batch 1627 batch loss 1.41437685 epoch total loss 1.15969241
Trained batch 1628 batch loss 1.25147414 epoch total loss 1.15974867
Trained batch 1629 batch loss 1.00174642 epoch total loss 1.15965176
Trained batch 1630 batch loss 1.09587502 epoch total loss 1.15961254
Trained batch 1631 batch loss 0.835926294 epoch total loss 1.15941405
Trained batch 1632 batch loss 0.86201787 epoch total loss 1.1592319
Trained batch 1633 batch loss 0.999181509 epoch total loss 1.15913391
Trained batch 1634 batch loss 1.1396246 epoch total loss 1.15912199
Trained batch 1635 batch loss 1.14882541 epoch total loss 1.15911567
Trained batch 1636 batch loss 1.23458087 epoch total loss 1.15916181
Trained batch 1637 batch loss 1.26553655 epoch total loss 1.15922678
Trained batch 1638 batch loss 1.38367033 epoch total loss 1.15936375
Trained batch 1639 batch loss 1.32766092 epoch total loss 1.15946639
Trained batch 1640 batch loss 1.2005465 epoch total loss 1.15949154
Trained batch 1641 batch loss 1.30841923 epoch total loss 1.15958226
Trained batch 1642 batch loss 1.34047556 epoch total loss 1.15969241
Trained batch 1643 batch loss 1.26588798 epoch total loss 1.15975702
Trained batch 1644 batch loss 1.16110456 epoch total loss 1.15975785
Trained batch 1645 batch loss 1.26134467 epoch total loss 1.1598196
Trained batch 1646 batch loss 1.14756918 epoch total loss 1.15981221
Trained batch 1647 batch loss 1.16722405 epoch total loss 1.15981674
Trained batch 1648 batch loss 1.0651629 epoch total loss 1.15975928
Trained batch 1649 batch loss 1.48382592 epoch total loss 1.15995586
Trained batch 1650 batch loss 1.48431182 epoch total loss 1.16015244
Trained batch 1651 batch loss 1.30527091 epoch total loss 1.16024029
Trained batch 1652 batch loss 1.32329226 epoch total loss 1.160339
Trained batch 1653 batch loss 1.28900445 epoch total loss 1.16041684
Trained batch 1654 batch loss 1.31339121 epoch total loss 1.16050935
Trained batch 1655 batch loss 1.30437207 epoch total loss 1.16059625
Trained batch 1656 batch loss 1.2110672 epoch total loss 1.16062665
Trained batch 1657 batch loss 0.900503337 epoch total loss 1.16046977
Trained batch 1658 batch loss 1.10023 epoch total loss 1.16043341
Trained batch 1659 batch loss 1.00786686 epoch total loss 1.16034138
Trained batch 1660 batch loss 0.943734765 epoch total loss 1.16021085
Trained batch 1661 batch loss 1.01312971 epoch total loss 1.16012239
Trained batch 1662 batch loss 0.969375134 epoch total loss 1.1600076
Trained batch 1663 batch loss 0.923553824 epoch total loss 1.15986538
Trained batch 1664 batch loss 0.968913138 epoch total loss 1.1597507
Trained batch 1665 batch loss 1.02560592 epoch total loss 1.15967011
Trained batch 1666 batch loss 0.963165343 epoch total loss 1.1595521
Trained batch 1667 batch loss 1.39154589 epoch total loss 1.15969133
Trained batch 1668 batch loss 1.25474906 epoch total loss 1.15974832
Trained batch 1669 batch loss 1.27921045 epoch total loss 1.15981984
Trained batch 1670 batch loss 1.29073524 epoch total loss 1.15989828
Trained batch 1671 batch loss 1.24818671 epoch total loss 1.15995109
Trained batch 1672 batch loss 1.36781597 epoch total loss 1.16007543
Trained batch 1673 batch loss 1.18040752 epoch total loss 1.16008759
Trained batch 1674 batch loss 1.37810671 epoch total loss 1.16021776
Trained batch 1675 batch loss 1.21666527 epoch total loss 1.1602515
Trained batch 1676 batch loss 1.14716971 epoch total loss 1.16024375
Trained batch 1677 batch loss 1.23667336 epoch total loss 1.16028929
Trained batch 1678 batch loss 1.12521386 epoch total loss 1.16026843
Trained batch 1679 batch loss 1.30114532 epoch total loss 1.16035235
Trained batch 1680 batch loss 1.16572022 epoch total loss 1.16035557
Trained batch 1681 batch loss 1.22688484 epoch total loss 1.16039515
Trained batch 1682 batch loss 1.20541167 epoch total loss 1.16042197
Trained batch 1683 batch loss 1.08877766 epoch total loss 1.16037941
Trained batch 1684 batch loss 1.07862067 epoch total loss 1.16033077
Trained batch 1685 batch loss 1.20310485 epoch total loss 1.16035616
Trained batch 1686 batch loss 1.28368711 epoch total loss 1.16042936
Trained batch 1687 batch loss 1.26150751 epoch total loss 1.1604892
Trained batch 1688 batch loss 1.21159494 epoch total loss 1.16051948
Trained batch 1689 batch loss 1.17672634 epoch total loss 1.16052914
Trained batch 1690 batch loss 1.27138758 epoch total loss 1.1605947
Trained batch 1691 batch loss 1.17987442 epoch total loss 1.16060615
Trained batch 1692 batch loss 1.20048761 epoch total loss 1.16062963
Trained batch 1693 batch loss 1.06696844 epoch total loss 1.16057432
Trained batch 1694 batch loss 1.05088353 epoch total loss 1.16050959
Trained batch 1695 batch loss 1.10985923 epoch total loss 1.16047978
Trained batch 1696 batch loss 1.21633327 epoch total loss 1.16051269
Trained batch 1697 batch loss 1.32753325 epoch total loss 1.16061103
Trained batch 1698 batch loss 0.933685601 epoch total loss 1.1604774
Trained batch 1699 batch loss 1.32507849 epoch total loss 1.16057432
Trained batch 1700 batch loss 1.31549287 epoch total loss 1.16066551
Trained batch 1701 batch loss 1.11788225 epoch total loss 1.16064036
Trained batch 1702 batch loss 1.06205738 epoch total loss 1.16058242
Trained batch 1703 batch loss 1.28382194 epoch total loss 1.16065478
Trained batch 1704 batch loss 1.04726171 epoch total loss 1.16058826
Trained batch 1705 batch loss 1.13856351 epoch total loss 1.16057527
Trained batch 1706 batch loss 1.16777909 epoch total loss 1.16057944
Trained batch 1707 batch loss 1.08883739 epoch total loss 1.16053748
Trained batch 1708 batch loss 1.14308584 epoch total loss 1.16052723
Trained batch 1709 batch loss 1.19295037 epoch total loss 1.1605463
Trained batch 1710 batch loss 1.14678478 epoch total loss 1.1605382
Trained batch 1711 batch loss 1.31844425 epoch total loss 1.16063046
Trained batch 1712 batch loss 1.10019398 epoch total loss 1.16059518
Trained batch 1713 batch loss 1.23253489 epoch total loss 1.16063714
Trained batch 1714 batch loss 1.24801862 epoch total loss 1.16068816
Trained batch 1715 batch loss 1.1220603 epoch total loss 1.16066563
Trained batch 1716 batch loss 1.1015172 epoch total loss 1.16063118
Trained batch 1717 batch loss 1.21484292 epoch total loss 1.16066277
Trained batch 1718 batch loss 1.17814493 epoch total loss 1.1606729
Trained batch 1719 batch loss 1.15047407 epoch total loss 1.16066706
Trained batch 1720 batch loss 1.21041298 epoch total loss 1.16069603
Trained batch 1721 batch loss 1.27608275 epoch total loss 1.16076303
Trained batch 1722 batch loss 1.16883302 epoch total loss 1.16076779
Trained batch 1723 batch loss 1.32832611 epoch total loss 1.16086495
Trained batch 1724 batch loss 1.10053277 epoch total loss 1.16083
Trained batch 1725 batch loss 1.18377 epoch total loss 1.16084325
Trained batch 1726 batch loss 1.35088 epoch total loss 1.1609534
Trained batch 1727 batch loss 1.23410487 epoch total loss 1.16099572
Trained batch 1728 batch loss 1.3191843 epoch total loss 1.16108727
Trained batch 1729 batch loss 1.27841651 epoch total loss 1.16115522
Trained batch 1730 batch loss 1.21688032 epoch total loss 1.16118741
Trained batch 1731 batch loss 1.21035719 epoch total loss 1.16121578
Trained batch 1732 batch loss 1.18361759 epoch total loss 1.16122878
Trained batch 1733 batch loss 1.1634059 epoch total loss 1.16123
Trained batch 1734 batch loss 1.30845773 epoch total loss 1.16131496
Trained batch 1735 batch loss 1.26556289 epoch total loss 1.16137493
Trained batch 1736 batch loss 1.23069477 epoch total loss 1.16141498
Trained batch 1737 batch loss 1.02269137 epoch total loss 1.16133511
Trained batch 1738 batch loss 1.00207686 epoch total loss 1.16124344
Trained batch 1739 batch loss 1.20363045 epoch total loss 1.16126776
Trained batch 1740 batch loss 1.15292525 epoch total loss 1.16126299
Trained batch 1741 batch loss 1.16729462 epoch total loss 1.16126645
Trained batch 1742 batch loss 1.40849626 epoch total loss 1.16140831
Trained batch 1743 batch loss 1.32936382 epoch total loss 1.16150475
Trained batch 1744 batch loss 1.2467072 epoch total loss 1.1615535
Trained batch 1745 batch loss 1.42024243 epoch total loss 1.1617018
Trained batch 1746 batch loss 1.11349607 epoch total loss 1.16167426
Trained batch 1747 batch loss 1.21937108 epoch total loss 1.16170728
Trained batch 1748 batch loss 1.38113081 epoch total loss 1.16183281
Trained batch 1749 batch loss 1.27229476 epoch total loss 1.16189599
Trained batch 1750 batch loss 1.37018561 epoch total loss 1.16201496
Trained batch 1751 batch loss 1.41977692 epoch total loss 1.16216218
Trained batch 1752 batch loss 1.48187304 epoch total loss 1.16234469
Trained batch 1753 batch loss 1.42327225 epoch total loss 1.16249359
Trained batch 1754 batch loss 1.38244498 epoch total loss 1.16261899
Trained batch 1755 batch loss 1.34955859 epoch total loss 1.16272545
Trained batch 1756 batch loss 1.21385372 epoch total loss 1.16275465
Trained batch 1757 batch loss 1.22069025 epoch total loss 1.16278756
Trained batch 1758 batch loss 1.02823842 epoch total loss 1.16271102
Trained batch 1759 batch loss 1.14008665 epoch total loss 1.16269827
Trained batch 1760 batch loss 1.40422273 epoch total loss 1.16283536
Trained batch 1761 batch loss 1.65818238 epoch total loss 1.16311669
Trained batch 1762 batch loss 1.21355855 epoch total loss 1.16314542
Trained batch 1763 batch loss 1.3457489 epoch total loss 1.1632489
Trained batch 1764 batch loss 1.19018066 epoch total loss 1.16326416
Trained batch 1765 batch loss 1.39780641 epoch total loss 1.16339707
Trained batch 1766 batch loss 0.997824192 epoch total loss 1.16330326
Trained batch 1767 batch loss 1.25415421 epoch total loss 1.16335464
Trained batch 1768 batch loss 1.33567953 epoch total loss 1.16345215
Trained batch 1769 batch loss 0.915808 epoch total loss 1.16331208
Trained batch 1770 batch loss 1.17980671 epoch total loss 1.16332138
Trained batch 1771 batch loss 1.24766135 epoch total loss 1.16336894
Trained batch 1772 batch loss 0.90303576 epoch total loss 1.16322207
Trained batch 1773 batch loss 0.935415745 epoch total loss 1.16309357
Trained batch 1774 batch loss 0.931126654 epoch total loss 1.16296279
Trained batch 1775 batch loss 1.01330304 epoch total loss 1.16287839
Trained batch 1776 batch loss 1.23607326 epoch total loss 1.16291964
Trained batch 1777 batch loss 1.2333703 epoch total loss 1.16295922
Trained batch 1778 batch loss 1.22960234 epoch total loss 1.16299665
Trained batch 1779 batch loss 1.1965096 epoch total loss 1.16301548
Trained batch 1780 batch loss 1.20600724 epoch total loss 1.16303968
Trained batch 1781 batch loss 1.28431797 epoch total loss 1.16310787
Trained batch 1782 batch loss 1.26820064 epoch total loss 1.16316688
Trained batch 1783 batch loss 1.23737597 epoch total loss 1.16320848
Trained batch 1784 batch loss 1.3393904 epoch total loss 1.16330719
Trained batch 1785 batch loss 1.36551511 epoch total loss 1.16342044
Trained batch 1786 batch loss 1.33043385 epoch total loss 1.1635139
Trained batch 1787 batch loss 0.999766231 epoch total loss 1.16342235
Trained batch 1788 batch loss 1.25008011 epoch total loss 1.16347075
Trained batch 1789 batch loss 1.05909038 epoch total loss 1.16341233
Trained batch 1790 batch loss 1.22564363 epoch total loss 1.16344714
Trained batch 1791 batch loss 1.15009129 epoch total loss 1.16343963
Trained batch 1792 batch loss 1.13628483 epoch total loss 1.16342449
Trained batch 1793 batch loss 1.16198254 epoch total loss 1.16342366
Trained batch 1794 batch loss 0.939845085 epoch total loss 1.16329908
Trained batch 1795 batch loss 1.03094864 epoch total loss 1.16322529
Trained batch 1796 batch loss 0.823298752 epoch total loss 1.16303611
Trained batch 1797 batch loss 1.08594632 epoch total loss 1.16299319
Trained batch 1798 batch loss 1.2492435 epoch total loss 1.16304111
Trained batch 1799 batch loss 1.1453855 epoch total loss 1.16303122
Trained batch 1800 batch loss 1.0097537 epoch total loss 1.16294611
Trained batch 1801 batch loss 0.96296066 epoch total loss 1.162835
Trained batch 1802 batch loss 0.943294644 epoch total loss 1.16271317
Trained batch 1803 batch loss 0.799532413 epoch total loss 1.16251183
Trained batch 1804 batch loss 1.01017904 epoch total loss 1.16242743
Trained batch 1805 batch loss 0.930235207 epoch total loss 1.16229868
Trained batch 1806 batch loss 1.05545235 epoch total loss 1.16223955
Trained batch 1807 batch loss 1.10902238 epoch total loss 1.16221011
Trained batch 1808 batch loss 1.12093461 epoch total loss 1.16218734
Trained batch 1809 batch loss 1.10452533 epoch total loss 1.16215539
Trained batch 1810 batch loss 1.10156894 epoch total loss 1.16212189
Trained batch 1811 batch loss 1.23552847 epoch total loss 1.16216254
Trained batch 1812 batch loss 1.03744006 epoch total loss 1.16209364
Trained batch 1813 batch loss 1.06119084 epoch total loss 1.16203797
Trained batch 1814 batch loss 1.05597687 epoch total loss 1.16197956
Trained batch 1815 batch loss 0.86150825 epoch total loss 1.16181397
Trained batch 1816 batch loss 1.05050099 epoch total loss 1.1617527
Trained batch 1817 batch loss 1.06791496 epoch total loss 1.16170108
Trained batch 1818 batch loss 1.10013485 epoch total loss 1.16166711
Trained batch 1819 batch loss 1.04685807 epoch total loss 1.16160405
Trained batch 1820 batch loss 1.12644613 epoch total loss 1.16158473
Trained batch 1821 batch loss 1.17567086 epoch total loss 1.16159248
Trained batch 1822 batch loss 1.03895354 epoch total loss 1.16152525
Trained batch 1823 batch loss 1.05732906 epoch total loss 1.16146815
Trained batch 1824 batch loss 1.05807 epoch total loss 1.16141152
Trained batch 1825 batch loss 1.0588069 epoch total loss 1.16135526
Trained batch 1826 batch loss 0.983573437 epoch total loss 1.16125798
Trained batch 1827 batch loss 0.905901849 epoch total loss 1.16111827
Trained batch 1828 batch loss 0.892376423 epoch total loss 1.16097116
Trained batch 1829 batch loss 0.9849 epoch total loss 1.16087496
Trained batch 1830 batch loss 1.18054748 epoch total loss 1.16088569
Trained batch 1831 batch loss 1.05154407 epoch total loss 1.16082597
Trained batch 1832 batch loss 0.894498587 epoch total loss 1.16068065
Trained batch 1833 batch loss 1.11382103 epoch total loss 1.16065502
Trained batch 1834 batch loss 1.19832182 epoch total loss 1.16067553
Trained batch 1835 batch loss 1.06868207 epoch total loss 1.16062534
Trained batch 1836 batch loss 0.882374406 epoch total loss 1.16047382
Trained batch 1837 batch loss 1.10977292 epoch total loss 1.16044629
Trained batch 1838 batch loss 1.18025136 epoch total loss 1.16045702
Trained batch 1839 batch loss 1.29776406 epoch total loss 1.16053164
Trained batch 1840 batch loss 1.09220469 epoch total loss 1.16049457
Trained batch 1841 batch loss 1.1004529 epoch total loss 1.1604619
Trained batch 1842 batch loss 1.22529125 epoch total loss 1.16049719
Trained batch 1843 batch loss 1.32916439 epoch total loss 1.16058862
Trained batch 1844 batch loss 1.07214808 epoch total loss 1.1605407
Trained batch 1845 batch loss 1.24044442 epoch total loss 1.16058409
Trained batch 1846 batch loss 1.04865289 epoch total loss 1.16052341
Trained batch 1847 batch loss 1.19498551 epoch total loss 1.16054213
Trained batch 1848 batch loss 1.25049686 epoch total loss 1.16059077
Trained batch 1849 batch loss 1.4029243 epoch total loss 1.16072178
Trained batch 1850 batch loss 1.29823983 epoch total loss 1.16079617
Trained batch 1851 batch loss 1.19976664 epoch total loss 1.16081715
Trained batch 1852 batch loss 1.10072756 epoch total loss 1.16078484
Trained batch 1853 batch loss 1.28420711 epoch total loss 1.16085136
Trained batch 1854 batch loss 1.27625489 epoch total loss 1.16091371
Trained batch 1855 batch loss 1.3915745 epoch total loss 1.16103804
Trained batch 1856 batch loss 1.19228172 epoch total loss 1.16105497
Trained batch 1857 batch loss 1.16826391 epoch total loss 1.16105878
Trained batch 1858 batch loss 0.940162897 epoch total loss 1.16093993
Trained batch 1859 batch loss 1.0716598 epoch total loss 1.16089201
Trained batch 1860 batch loss 1.3380785 epoch total loss 1.16098726
Trained batch 1861 batch loss 1.31908464 epoch total loss 1.16107225
Trained batch 1862 batch loss 1.09676421 epoch total loss 1.16103756
Trained batch 1863 batch loss 1.37518 epoch total loss 1.1611526
Trained batch 1864 batch loss 1.0812397 epoch total loss 1.16110981
Trained batch 1865 batch loss 1.15851772 epoch total loss 1.16110837
Trained batch 1866 batch loss 1.24762058 epoch total loss 1.16115463
Trained batch 1867 batch loss 0.974315524 epoch total loss 1.16105461
Trained batch 1868 batch loss 1.21737814 epoch total loss 1.16108477
Trained batch 1869 batch loss 1.09314084 epoch total loss 1.16104841
Trained batch 1870 batch loss 1.21358323 epoch total loss 1.16107655
Trained batch 1871 batch loss 1.03521597 epoch total loss 1.16100919
Trained batch 1872 batch loss 1.07324851 epoch total loss 1.16096234
Trained batch 1873 batch loss 1.29231501 epoch total loss 1.16103244
Trained batch 1874 batch loss 1.37639189 epoch total loss 1.16114736
Trained batch 1875 batch loss 1.16855621 epoch total loss 1.16115129
Trained batch 1876 batch loss 1.29321575 epoch total loss 1.16122174
Trained batch 1877 batch loss 1.27208555 epoch total loss 1.16128075
Trained batch 1878 batch loss 1.15061975 epoch total loss 1.16127503
Trained batch 1879 batch loss 1.29659295 epoch total loss 1.16134703
Trained batch 1880 batch loss 1.2124362 epoch total loss 1.16137421
Trained batch 1881 batch loss 1.29126835 epoch total loss 1.16144323
Trained batch 1882 batch loss 1.20540428 epoch total loss 1.1614666
Trained batch 1883 batch loss 1.32459652 epoch total loss 1.16155326
Trained batch 1884 batch loss 1.37980378 epoch total loss 1.16166914
Trained batch 1885 batch loss 0.984806716 epoch total loss 1.16157532
Trained batch 1886 batch loss 1.0282805 epoch total loss 1.16150475
Trained batch 1887 batch loss 1.101982 epoch total loss 1.16147316
Trained batch 1888 batch loss 1.11454439 epoch total loss 1.16144836
Trained batch 1889 batch loss 1.15253258 epoch total loss 1.16144359
Trained batch 1890 batch loss 1.08734822 epoch total loss 1.16140449
Trained batch 1891 batch loss 1.21955538 epoch total loss 1.16143513
Trained batch 1892 batch loss 1.30557799 epoch total loss 1.16151142
Trained batch 1893 batch loss 1.41549754 epoch total loss 1.16164565
Trained batch 1894 batch loss 1.2815944 epoch total loss 1.16170883
Trained batch 1895 batch loss 1.23372674 epoch total loss 1.16174686
Trained batch 1896 batch loss 1.30706024 epoch total loss 1.16182351
Trained batch 1897 batch loss 1.37623298 epoch total loss 1.16193652
Trained batch 1898 batch loss 1.250247 epoch total loss 1.16198301
Trained batch 1899 batch loss 1.44414234 epoch total loss 1.16213167
Trained batch 1900 batch loss 1.32563365 epoch total loss 1.16221774
Trained batch 1901 batch loss 1.07086682 epoch total loss 1.16216958
Trained batch 1902 batch loss 1.22766697 epoch total loss 1.16220415
Trained batch 1903 batch loss 1.1160121 epoch total loss 1.16217983
Trained batch 1904 batch loss 1.01734853 epoch total loss 1.16210377
Trained batch 1905 batch loss 1.03447723 epoch total loss 1.16203666
Trained batch 1906 batch loss 1.18190885 epoch total loss 1.16204715
Trained batch 1907 batch loss 1.15078712 epoch total loss 1.16204131
Trained batch 1908 batch loss 1.12560678 epoch total loss 1.16202211
Trained batch 1909 batch loss 1.08252645 epoch total loss 1.16198051
Trained batch 1910 batch loss 0.938818395 epoch total loss 1.16186357
Trained batch 1911 batch loss 0.877977908 epoch total loss 1.16171503
Trained batch 1912 batch loss 0.774334133 epoch total loss 1.16151237
Trained batch 1913 batch loss 0.817130744 epoch total loss 1.16133237
Trained batch 1914 batch loss 0.884372711 epoch total loss 1.16118765
Trained batch 1915 batch loss 0.95617485 epoch total loss 1.1610806
Trained batch 1916 batch loss 1.31246424 epoch total loss 1.16115952
Trained batch 1917 batch loss 1.34139943 epoch total loss 1.16125357
Trained batch 1918 batch loss 1.32791293 epoch total loss 1.16134048
Trained batch 1919 batch loss 1.42521977 epoch total loss 1.16147792
Trained batch 1920 batch loss 1.31540775 epoch total loss 1.16155815
Trained batch 1921 batch loss 1.2628994 epoch total loss 1.16161096
Trained batch 1922 batch loss 1.25586152 epoch total loss 1.16166
Trained batch 1923 batch loss 1.06618857 epoch total loss 1.16161025
Trained batch 1924 batch loss 1.41013217 epoch total loss 1.16173947
Trained batch 1925 batch loss 1.26400924 epoch total loss 1.16179252
Trained batch 1926 batch loss 1.32196236 epoch total loss 1.16187572
Trained batch 1927 batch loss 1.13989019 epoch total loss 1.1618644
Trained batch 1928 batch loss 1.00254929 epoch total loss 1.16178167
Trained batch 1929 batch loss 1.3167634 epoch total loss 1.1618619
Trained batch 1930 batch loss 1.30173802 epoch total loss 1.16193438
Trained batch 1931 batch loss 1.18217421 epoch total loss 1.16194487
Trained batch 1932 batch loss 1.20172787 epoch total loss 1.16196549
Trained batch 1933 batch loss 1.39089012 epoch total loss 1.16208386
Trained batch 1934 batch loss 1.35170364 epoch total loss 1.16218197
Trained batch 1935 batch loss 1.21118832 epoch total loss 1.16220725
Trained batch 1936 batch loss 1.16101432 epoch total loss 1.16220677
Trained batch 1937 batch loss 1.28208137 epoch total loss 1.16226852
Trained batch 1938 batch loss 1.16221166 epoch total loss 1.16226852
Trained batch 1939 batch loss 1.20722866 epoch total loss 1.16229165
Trained batch 1940 batch loss 0.989208698 epoch total loss 1.16220248
Trained batch 1941 batch loss 1.0620544 epoch total loss 1.16215086
Trained batch 1942 batch loss 0.837735 epoch total loss 1.16198373
Trained batch 1943 batch loss 1.02052248 epoch total loss 1.16191101
Trained batch 1944 batch loss 0.848243177 epoch total loss 1.1617496
Trained batch 1945 batch loss 1.0615989 epoch total loss 1.16169798
Trained batch 1946 batch loss 1.16432643 epoch total loss 1.16169941
Trained batch 1947 batch loss 1.12120295 epoch total loss 1.16167855
Trained batch 1948 batch loss 1.10176206 epoch total loss 1.1616478
Trained batch 1949 batch loss 1.18312669 epoch total loss 1.16165876
Trained batch 1950 batch loss 1.29742849 epoch total loss 1.16172838
Trained batch 1951 batch loss 1.24949622 epoch total loss 1.16177344
Trained batch 1952 batch loss 1.21328878 epoch total loss 1.16179979
Trained batch 1953 batch loss 1.12971163 epoch total loss 1.16178334
Trained batch 1954 batch loss 1.077075 epoch total loss 1.16174006
Trained batch 1955 batch loss 1.07364631 epoch total loss 1.161695
Trained batch 1956 batch loss 1.13808036 epoch total loss 1.16168296
Trained batch 1957 batch loss 1.25893664 epoch total loss 1.16173279
Trained batch 1958 batch loss 1.18244958 epoch total loss 1.16174328
Trained batch 1959 batch loss 1.11953723 epoch total loss 1.16172183
Trained batch 1960 batch loss 1.43460035 epoch total loss 1.16186094
Trained batch 1961 batch loss 1.44335651 epoch total loss 1.16200459
Trained batch 1962 batch loss 1.29108834 epoch total loss 1.16207027
Trained batch 1963 batch loss 1.44486248 epoch total loss 1.1622144
Trained batch 1964 batch loss 1.47949207 epoch total loss 1.16237593
Trained batch 1965 batch loss 1.21807528 epoch total loss 1.16240418
Trained batch 1966 batch loss 1.19944239 epoch total loss 1.16242301
Trained batch 1967 batch loss 1.24120557 epoch total loss 1.16246307
Trained batch 1968 batch loss 1.10744929 epoch total loss 1.16243517
Trained batch 1969 batch loss 1.19228435 epoch total loss 1.16245031
Trained batch 1970 batch loss 1.27645278 epoch total loss 1.16250813
Trained batch 1971 batch loss 1.30806053 epoch total loss 1.16258204
Trained batch 1972 batch loss 1.28226244 epoch total loss 1.16264272
Trained batch 1973 batch loss 1.14307737 epoch total loss 1.16263282
Trained batch 1974 batch loss 1.45596015 epoch total loss 1.16278148
Trained batch 1975 batch loss 1.21305287 epoch total loss 1.16280699
Trained batch 1976 batch loss 1.28223801 epoch total loss 1.16286743
Trained batch 1977 batch loss 1.32646072 epoch total loss 1.16295
Trained batch 1978 batch loss 1.26824117 epoch total loss 1.16300333
Trained batch 1979 batch loss 1.40804768 epoch total loss 1.16312718
Trained batch 1980 batch loss 1.44859266 epoch total loss 1.16327131
Trained batch 1981 batch loss 1.34700656 epoch total loss 1.16336393
Trained batch 1982 batch loss 1.32776427 epoch total loss 1.16344702
Trained batch 1983 batch loss 1.16544104 epoch total loss 1.16344798
Trained batch 1984 batch loss 1.15940273 epoch total loss 1.16344595
Trained batch 1985 batch loss 1.27291942 epoch total loss 1.16350114
Trained batch 1986 batch loss 1.24089408 epoch total loss 1.16354012
Trained batch 1987 batch loss 1.4394871 epoch total loss 1.163679
Trained batch 1988 batch loss 1.4866035 epoch total loss 1.16384149
Trained batch 1989 batch loss 1.38535285 epoch total loss 1.16395271
Trained batch 1990 batch loss 1.4529388 epoch total loss 1.16409791
Trained batch 1991 batch loss 1.2227459 epoch total loss 1.16412735
Trained batch 1992 batch loss 1.21187615 epoch total loss 1.16415131
Trained batch 1993 batch loss 1.1489222 epoch total loss 1.16414368
Trained batch 1994 batch loss 1.09251475 epoch total loss 1.1641078
Trained batch 1995 batch loss 1.27627027 epoch total loss 1.16416407
Trained batch 1996 batch loss 1.17930126 epoch total loss 1.16417158
Trained batch 1997 batch loss 1.11335731 epoch total loss 1.16414607
Trained batch 1998 batch loss 1.1568222 epoch total loss 1.16414237
Trained batch 1999 batch loss 1.0984087 epoch total loss 1.16410947
Trained batch 2000 batch loss 1.05152965 epoch total loss 1.1640532
Trained batch 2001 batch loss 1.1728828 epoch total loss 1.16405761
Trained batch 2002 batch loss 1.11193144 epoch total loss 1.16403151
Trained batch 2003 batch loss 0.979878783 epoch total loss 1.1639396
Trained batch 2004 batch loss 1.05161762 epoch total loss 1.16388357
Trained batch 2005 batch loss 1.19688737 epoch total loss 1.1638999
Trained batch 2006 batch loss 1.08763826 epoch total loss 1.16386187
Trained batch 2007 batch loss 1.06833279 epoch total loss 1.16381431
Trained batch 2008 batch loss 1.16537011 epoch total loss 1.16381502
Trained batch 2009 batch loss 1.19000745 epoch total loss 1.16382813
Trained batch 2010 batch loss 1.16445303 epoch total loss 1.16382849
Trained batch 2011 batch loss 0.995553911 epoch total loss 1.16374481
Trained batch 2012 batch loss 1.21181583 epoch total loss 1.16376877
Trained batch 2013 batch loss 1.09955049 epoch total loss 1.16373682
Trained batch 2014 batch loss 1.17357755 epoch total loss 1.16374171
Trained batch 2015 batch loss 1.03202224 epoch total loss 1.16367638
Trained batch 2016 batch loss 1.07707477 epoch total loss 1.16363347
Trained batch 2017 batch loss 1.15561175 epoch total loss 1.16362941
Trained batch 2018 batch loss 1.29401338 epoch total loss 1.16369402
Trained batch 2019 batch loss 1.2163496 epoch total loss 1.16372
Trained batch 2020 batch loss 1.3231771 epoch total loss 1.16379905
Trained batch 2021 batch loss 1.29233742 epoch total loss 1.16386259
Trained batch 2022 batch loss 1.05537713 epoch total loss 1.16380894
Trained batch 2023 batch loss 1.31325531 epoch total loss 1.16388285
Trained batch 2024 batch loss 1.30914879 epoch total loss 1.1639545
Trained batch 2025 batch loss 1.33387613 epoch total loss 1.16403854
Trained batch 2026 batch loss 1.20836592 epoch total loss 1.16406035
Trained batch 2027 batch loss 1.24152303 epoch total loss 1.1640985
Trained batch 2028 batch loss 1.1895237 epoch total loss 1.16411102
Trained batch 2029 batch loss 1.33934784 epoch total loss 1.16419733
Trained batch 2030 batch loss 1.23482633 epoch total loss 1.16423225
Trained batch 2031 batch loss 1.42589664 epoch total loss 1.164361
Trained batch 2032 batch loss 1.30027688 epoch total loss 1.16442788
Trained batch 2033 batch loss 1.11381328 epoch total loss 1.16440296
Trained batch 2034 batch loss 1.22802329 epoch total loss 1.16443419
Trained batch 2035 batch loss 1.19527864 epoch total loss 1.16444945
Trained batch 2036 batch loss 1.02212143 epoch total loss 1.1643796
Trained batch 2037 batch loss 1.25246692 epoch total loss 1.16442275
Trained batch 2038 batch loss 1.04085612 epoch total loss 1.16436207
Trained batch 2039 batch loss 1.08472466 epoch total loss 1.16432309
Trained batch 2040 batch loss 1.16093254 epoch total loss 1.1643213
Trained batch 2041 batch loss 1.21319413 epoch total loss 1.16434526
Trained batch 2042 batch loss 1.13210905 epoch total loss 1.16432953
Trained batch 2043 batch loss 0.820417404 epoch total loss 1.16416109
Trained batch 2044 batch loss 1.02716708 epoch total loss 1.16409409
Trained batch 2045 batch loss 0.860230744 epoch total loss 1.16394556
Trained batch 2046 batch loss 0.94897151 epoch total loss 1.16384041
Trained batch 2047 batch loss 1.07677042 epoch total loss 1.16379786
Trained batch 2048 batch loss 1.04759169 epoch total loss 1.16374111
Trained batch 2049 batch loss 0.990693688 epoch total loss 1.16365671
Trained batch 2050 batch loss 1.00821233 epoch total loss 1.16358089
Trained batch 2051 batch loss 1.13857865 epoch total loss 1.16356874
Trained batch 2052 batch loss 1.28424096 epoch total loss 1.16362751
Trained batch 2053 batch loss 1.28719568 epoch total loss 1.16368771
Trained batch 2054 batch loss 1.21619916 epoch total loss 1.16371334
Trained batch 2055 batch loss 1.14234233 epoch total loss 1.16370285
Trained batch 2056 batch loss 1.19483078 epoch total loss 1.16371799
Trained batch 2057 batch loss 1.3005259 epoch total loss 1.1637845
Trained batch 2058 batch loss 1.34819198 epoch total loss 1.16387415
Trained batch 2059 batch loss 1.39089334 epoch total loss 1.16398442
Trained batch 2060 batch loss 1.301718 epoch total loss 1.16405129
Trained batch 2061 batch loss 1.19525933 epoch total loss 1.16406643
Trained batch 2062 batch loss 1.1549263 epoch total loss 1.16406202
Trained batch 2063 batch loss 1.03357148 epoch total loss 1.16399884
Trained batch 2064 batch loss 1.22895217 epoch total loss 1.16403031
Trained batch 2065 batch loss 1.13281608 epoch total loss 1.16401517
Trained batch 2066 batch loss 1.1347816 epoch total loss 1.16400111
Trained batch 2067 batch loss 1.09120059 epoch total loss 1.16396594
Trained batch 2068 batch loss 1.10750759 epoch total loss 1.16393852
Trained batch 2069 batch loss 1.11742163 epoch total loss 1.16391611
Trained batch 2070 batch loss 1.10578585 epoch total loss 1.16388798
Trained batch 2071 batch loss 1.17377865 epoch total loss 1.16389275
Trained batch 2072 batch loss 1.05398679 epoch total loss 1.1638397
Trained batch 2073 batch loss 0.983899534 epoch total loss 1.16375291
Trained batch 2074 batch loss 1.18986082 epoch total loss 1.16376555
Trained batch 2075 batch loss 1.30896342 epoch total loss 1.16383553
Trained batch 2076 batch loss 1.07113218 epoch total loss 1.16379082
Trained batch 2077 batch loss 1.24239016 epoch total loss 1.16382873
Trained batch 2078 batch loss 1.16264606 epoch total loss 1.16382813
Trained batch 2079 batch loss 0.744936109 epoch total loss 1.16362655
Trained batch 2080 batch loss 0.970407724 epoch total loss 1.16353369
Trained batch 2081 batch loss 0.882708549 epoch total loss 1.16339886
Trained batch 2082 batch loss 0.97834456 epoch total loss 1.16330993
Trained batch 2083 batch loss 1.03910494 epoch total loss 1.16325021
Trained batch 2084 batch loss 1.14306653 epoch total loss 1.16324055
Trained batch 2085 batch loss 1.31072116 epoch total loss 1.16331136
Trained batch 2086 batch loss 1.14924979 epoch total loss 1.16330457
Trained batch 2087 batch loss 1.15674 epoch total loss 1.16330147
Trained batch 2088 batch loss 1.27169216 epoch total loss 1.16335332
Trained batch 2089 batch loss 1.1846633 epoch total loss 1.16336346
Trained batch 2090 batch loss 1.17262602 epoch total loss 1.16336787
Trained batch 2091 batch loss 1.24455833 epoch total loss 1.16340673
Trained batch 2092 batch loss 1.1027894 epoch total loss 1.16337776
Trained batch 2093 batch loss 1.43190908 epoch total loss 1.16350615
Trained batch 2094 batch loss 1.01586318 epoch total loss 1.16343558
Trained batch 2095 batch loss 1.1590426 epoch total loss 1.16343343
Trained batch 2096 batch loss 0.859789371 epoch total loss 1.16328859
Trained batch 2097 batch loss 1.09864473 epoch total loss 1.16325784
Trained batch 2098 batch loss 0.82568872 epoch total loss 1.1630969
Trained batch 2099 batch loss 1.03493881 epoch total loss 1.16303575
Trained batch 2100 batch loss 1.04356289 epoch total loss 1.16297889
Trained batch 2101 batch loss 0.970739722 epoch total loss 1.16288733
Trained batch 2102 batch loss 0.952492118 epoch total loss 1.1627872
Trained batch 2103 batch loss 1.15284109 epoch total loss 1.16278243
Trained batch 2104 batch loss 1.25716186 epoch total loss 1.16282725
Trained batch 2105 batch loss 1.19334602 epoch total loss 1.1628418
Trained batch 2106 batch loss 1.23767769 epoch total loss 1.16287744
Trained batch 2107 batch loss 1.14699125 epoch total loss 1.16286981
Trained batch 2108 batch loss 0.909212589 epoch total loss 1.16274953
Trained batch 2109 batch loss 0.968291461 epoch total loss 1.16265726
Trained batch 2110 batch loss 1.33662939 epoch total loss 1.16273975
Trained batch 2111 batch loss 1.21650052 epoch total loss 1.16276526
Trained batch 2112 batch loss 1.23208475 epoch total loss 1.16279805
Trained batch 2113 batch loss 1.2667954 epoch total loss 1.1628474
Trained batch 2114 batch loss 1.3336128 epoch total loss 1.1629281
Trained batch 2115 batch loss 1.23391581 epoch total loss 1.1629616
Trained batch 2116 batch loss 1.10216689 epoch total loss 1.16293287
Trained batch 2117 batch loss 1.1272428 epoch total loss 1.16291595
Trained batch 2118 batch loss 0.990606546 epoch total loss 1.16283464
Trained batch 2119 batch loss 1.20131326 epoch total loss 1.16285288
Trained batch 2120 batch loss 1.1720438 epoch total loss 1.16285717
Trained batch 2121 batch loss 1.181517 epoch total loss 1.162866
Trained batch 2122 batch loss 1.1077708 epoch total loss 1.16284
Trained batch 2123 batch loss 0.895409 epoch total loss 1.162714
Trained batch 2124 batch loss 1.06809771 epoch total loss 1.16266954
Trained batch 2125 batch loss 1.07954204 epoch total loss 1.16263044
Trained batch 2126 batch loss 1.21567154 epoch total loss 1.16265535
Trained batch 2127 batch loss 1.25918341 epoch total loss 1.16270077
Trained batch 2128 batch loss 1.33915281 epoch total loss 1.16278362
Trained batch 2129 batch loss 1.30137837 epoch total loss 1.16284871
Trained batch 2130 batch loss 1.26092315 epoch total loss 1.16289473
Trained batch 2131 batch loss 1.31456971 epoch total loss 1.16296589
Trained batch 2132 batch loss 1.27072597 epoch total loss 1.16301644
Trained batch 2133 batch loss 1.05536819 epoch total loss 1.16296601
Trained batch 2134 batch loss 1.21687067 epoch total loss 1.16299117
Trained batch 2135 batch loss 1.25943208 epoch total loss 1.16303647
Trained batch 2136 batch loss 1.28890848 epoch total loss 1.16309536
Trained batch 2137 batch loss 1.18161166 epoch total loss 1.16310394
Trained batch 2138 batch loss 1.08783412 epoch total loss 1.16306877
Trained batch 2139 batch loss 1.3286531 epoch total loss 1.16314626
Trained batch 2140 batch loss 1.12136436 epoch total loss 1.16312671
Trained batch 2141 batch loss 1.15845633 epoch total loss 1.16312444
Trained batch 2142 batch loss 1.38120067 epoch total loss 1.16322625
Trained batch 2143 batch loss 1.04937851 epoch total loss 1.16317308
Trained batch 2144 batch loss 1.13125932 epoch total loss 1.1631583
Trained batch 2145 batch loss 1.20486629 epoch total loss 1.16317773
Trained batch 2146 batch loss 1.13959026 epoch total loss 1.16316676
Trained batch 2147 batch loss 1.04317236 epoch total loss 1.16311085
Trained batch 2148 batch loss 1.12982285 epoch total loss 1.16309536
Trained batch 2149 batch loss 1.41606784 epoch total loss 1.16321301
Trained batch 2150 batch loss 1.05215204 epoch total loss 1.1631614
Trained batch 2151 batch loss 1.12381744 epoch total loss 1.16314316
Trained batch 2152 batch loss 0.941597581 epoch total loss 1.16304016
Trained batch 2153 batch loss 1.16535044 epoch total loss 1.16304123
Trained batch 2154 batch loss 0.885731 epoch total loss 1.16291249
Trained batch 2155 batch loss 1.08295834 epoch total loss 1.16287541
Trained batch 2156 batch loss 1.1848166 epoch total loss 1.16288567
Trained batch 2157 batch loss 1.08480954 epoch total loss 1.16284943
Trained batch 2158 batch loss 1.03924274 epoch total loss 1.16279209
Trained batch 2159 batch loss 1.48437309 epoch total loss 1.1629411
Trained batch 2160 batch loss 1.26986 epoch total loss 1.16299057
Trained batch 2161 batch loss 1.40535045 epoch total loss 1.16310263
Trained batch 2162 batch loss 1.14358664 epoch total loss 1.16309357
Trained batch 2163 batch loss 1.00849867 epoch total loss 1.16302216
Trained batch 2164 batch loss 1.11073279 epoch total loss 1.16299808
Trained batch 2165 batch loss 1.31607199 epoch total loss 1.16306877
Trained batch 2166 batch loss 0.985641 epoch total loss 1.16298687
Trained batch 2167 batch loss 1.23661065 epoch total loss 1.16302085
Trained batch 2168 batch loss 1.24342823 epoch total loss 1.16305792
Trained batch 2169 batch loss 1.15847647 epoch total loss 1.16305578
Trained batch 2170 batch loss 1.04470754 epoch total loss 1.16300118
Trained batch 2171 batch loss 1.18831539 epoch total loss 1.16301286
Trained batch 2172 batch loss 0.996236086 epoch total loss 1.16293609
Trained batch 2173 batch loss 1.05225539 epoch total loss 1.16288519
Trained batch 2174 batch loss 1.04753828 epoch total loss 1.16283214
Trained batch 2175 batch loss 1.40362251 epoch total loss 1.16294277
Trained batch 2176 batch loss 1.0024941 epoch total loss 1.1628691
Trained batch 2177 batch loss 1.40618312 epoch total loss 1.16298091
Trained batch 2178 batch loss 1.55994844 epoch total loss 1.16316319
Trained batch 2179 batch loss 1.51727355 epoch total loss 1.16332567
Trained batch 2180 batch loss 1.61478043 epoch total loss 1.16353273
Trained batch 2181 batch loss 1.50324631 epoch total loss 1.16368854
Trained batch 2182 batch loss 1.23299539 epoch total loss 1.16372025
Trained batch 2183 batch loss 1.16157818 epoch total loss 1.1637193
Trained batch 2184 batch loss 0.982895195 epoch total loss 1.16363645
Trained batch 2185 batch loss 1.15595317 epoch total loss 1.16363299
Trained batch 2186 batch loss 1.2388413 epoch total loss 1.16366732
Trained batch 2187 batch loss 1.12236547 epoch total loss 1.16364849
Trained batch 2188 batch loss 1.10516143 epoch total loss 1.16362178
Trained batch 2189 batch loss 0.986048 epoch total loss 1.1635406
Trained batch 2190 batch loss 0.845263898 epoch total loss 1.16339529
Trained batch 2191 batch loss 0.797474384 epoch total loss 1.16322827
Trained batch 2192 batch loss 0.758819342 epoch total loss 1.16304374
Trained batch 2193 batch loss 1.2148633 epoch total loss 1.16306734
Trained batch 2194 batch loss 0.987308621 epoch total loss 1.16298723
Trained batch 2195 batch loss 1.05851042 epoch total loss 1.16293967
Trained batch 2196 batch loss 1.0428139 epoch total loss 1.16288495
Trained batch 2197 batch loss 1.27088714 epoch total loss 1.16293418
Trained batch 2198 batch loss 1.19126749 epoch total loss 1.16294694
Trained batch 2199 batch loss 1.09182513 epoch total loss 1.16291463
Trained batch 2200 batch loss 1.13720417 epoch total loss 1.16290295
Trained batch 2201 batch loss 1.18246436 epoch total loss 1.16291177
Trained batch 2202 batch loss 1.41721988 epoch total loss 1.16302729
Trained batch 2203 batch loss 1.46587849 epoch total loss 1.16316473
Trained batch 2204 batch loss 1.47837532 epoch total loss 1.16330767
Trained batch 2205 batch loss 1.38307047 epoch total loss 1.16340733
Trained batch 2206 batch loss 1.25186014 epoch total loss 1.1634475
Trained batch 2207 batch loss 1.10998178 epoch total loss 1.16342318
Trained batch 2208 batch loss 1.2698822 epoch total loss 1.16347134
Trained batch 2209 batch loss 1.29437256 epoch total loss 1.16353071
Trained batch 2210 batch loss 1.21495044 epoch total loss 1.16355383
Trained batch 2211 batch loss 0.992696166 epoch total loss 1.16347659
Trained batch 2212 batch loss 1.11470723 epoch total loss 1.16345453
Trained batch 2213 batch loss 1.29785359 epoch total loss 1.16351533
Trained batch 2214 batch loss 1.16994071 epoch total loss 1.16351819
Trained batch 2215 batch loss 1.25443268 epoch total loss 1.1635592
Trained batch 2216 batch loss 1.12734151 epoch total loss 1.16354299
Trained batch 2217 batch loss 1.12098634 epoch total loss 1.16352379
Trained batch 2218 batch loss 1.07043624 epoch total loss 1.16348183
Trained batch 2219 batch loss 1.02657306 epoch total loss 1.1634202
Trained batch 2220 batch loss 1.2243129 epoch total loss 1.16344762
Trained batch 2221 batch loss 1.22506583 epoch total loss 1.16347539
Trained batch 2222 batch loss 1.16757464 epoch total loss 1.16347718
Trained batch 2223 batch loss 1.13286209 epoch total loss 1.16346335
Trained batch 2224 batch loss 1.18409634 epoch total loss 1.16347265
Trained batch 2225 batch loss 1.05063152 epoch total loss 1.16342187
Trained batch 2226 batch loss 1.27085149 epoch total loss 1.16347015
Trained batch 2227 batch loss 1.12628555 epoch total loss 1.16345346
Trained batch 2228 batch loss 1.14042616 epoch total loss 1.16344309
Trained batch 2229 batch loss 1.24871612 epoch total loss 1.16348135
Trained batch 2230 batch loss 1.12033975 epoch total loss 1.16346204
Trained batch 2231 batch loss 1.17237735 epoch total loss 1.16346598
Trained batch 2232 batch loss 1.34767747 epoch total loss 1.16354847
Trained batch 2233 batch loss 1.46581066 epoch total loss 1.16368389
Trained batch 2234 batch loss 1.49264419 epoch total loss 1.16383111
Trained batch 2235 batch loss 1.33261943 epoch total loss 1.16390657
Trained batch 2236 batch loss 1.15723825 epoch total loss 1.16390359
Trained batch 2237 batch loss 1.28498924 epoch total loss 1.16395772
Trained batch 2238 batch loss 1.22106707 epoch total loss 1.16398323
Trained batch 2239 batch loss 1.20997941 epoch total loss 1.16400373
Trained batch 2240 batch loss 1.03419614 epoch total loss 1.16394579
Trained batch 2241 batch loss 0.961521924 epoch total loss 1.16385543
Trained batch 2242 batch loss 0.978663325 epoch total loss 1.16377282
Trained batch 2243 batch loss 1.09384799 epoch total loss 1.16374159
Trained batch 2244 batch loss 0.935319304 epoch total loss 1.16363978
Trained batch 2245 batch loss 1.13506603 epoch total loss 1.16362703
Trained batch 2246 batch loss 1.21214712 epoch total loss 1.16364872
Trained batch 2247 batch loss 1.00110877 epoch total loss 1.16357636
Trained batch 2248 batch loss 1.00028408 epoch total loss 1.16350377
Trained batch 2249 batch loss 1.17636669 epoch total loss 1.16350937
Trained batch 2250 batch loss 0.895209 epoch total loss 1.16339016
Trained batch 2251 batch loss 1.02404451 epoch total loss 1.16332829
Trained batch 2252 batch loss 1.13519645 epoch total loss 1.16331577
Trained batch 2253 batch loss 1.07005918 epoch total loss 1.16327441
Trained batch 2254 batch loss 1.42125142 epoch total loss 1.16338873
Trained batch 2255 batch loss 1.55896223 epoch total loss 1.16356421
Trained batch 2256 batch loss 1.08614147 epoch total loss 1.16353
Trained batch 2257 batch loss 1.16270399 epoch total loss 1.16352952
Trained batch 2258 batch loss 1.37847757 epoch total loss 1.16362476
Trained batch 2259 batch loss 1.2207334 epoch total loss 1.16365
Trained batch 2260 batch loss 1.23698521 epoch total loss 1.16368246
Trained batch 2261 batch loss 1.38270044 epoch total loss 1.16377938
Trained batch 2262 batch loss 1.25195622 epoch total loss 1.16381836
Trained batch 2263 batch loss 1.19208384 epoch total loss 1.16383088
Trained batch 2264 batch loss 1.0775404 epoch total loss 1.16379285
Trained batch 2265 batch loss 0.760271668 epoch total loss 1.16361463
Trained batch 2266 batch loss 0.914157033 epoch total loss 1.16350448
Trained batch 2267 batch loss 0.853284955 epoch total loss 1.16336763
Trained batch 2268 batch loss 0.939843178 epoch total loss 1.16326916
Trained batch 2269 batch loss 0.958553612 epoch total loss 1.16317892
Trained batch 2270 batch loss 0.914781272 epoch total loss 1.16306949
Trained batch 2271 batch loss 0.863479257 epoch total loss 1.16293764
Trained batch 2272 batch loss 0.99075979 epoch total loss 1.16286182
Trained batch 2273 batch loss 1.04508686 epoch total loss 1.16281
Trained batch 2274 batch loss 0.976262 epoch total loss 1.16272795
Trained batch 2275 batch loss 0.85458231 epoch total loss 1.16259253
Trained batch 2276 batch loss 0.984043121 epoch total loss 1.16251409
Trained batch 2277 batch loss 1.03328252 epoch total loss 1.16245735
Trained batch 2278 batch loss 1.30787206 epoch total loss 1.16252112
Trained batch 2279 batch loss 1.32804465 epoch total loss 1.16259384
Trained batch 2280 batch loss 1.34256542 epoch total loss 1.16267276
Trained batch 2281 batch loss 1.14497316 epoch total loss 1.16266501
Trained batch 2282 batch loss 1.44141865 epoch total loss 1.16278708
Trained batch 2283 batch loss 1.30385 epoch total loss 1.16284895
Trained batch 2284 batch loss 1.03046107 epoch total loss 1.16279101
Trained batch 2285 batch loss 1.28467286 epoch total loss 1.16284442
Trained batch 2286 batch loss 1.30482209 epoch total loss 1.16290653
Trained batch 2287 batch loss 1.22865307 epoch total loss 1.16293526
Trained batch 2288 batch loss 1.30293465 epoch total loss 1.16299653
Trained batch 2289 batch loss 1.26540136 epoch total loss 1.16304123
Trained batch 2290 batch loss 1.25415361 epoch total loss 1.16308105
Trained batch 2291 batch loss 1.27545643 epoch total loss 1.16313
Trained batch 2292 batch loss 1.20887661 epoch total loss 1.16315007
Trained batch 2293 batch loss 1.18247008 epoch total loss 1.16315842
Trained batch 2294 batch loss 1.08951426 epoch total loss 1.16312635
Trained batch 2295 batch loss 0.887207866 epoch total loss 1.16300619
Trained batch 2296 batch loss 0.953272104 epoch total loss 1.16291487
Trained batch 2297 batch loss 1.0798955 epoch total loss 1.16287863
Trained batch 2298 batch loss 1.38855755 epoch total loss 1.16297698
Trained batch 2299 batch loss 1.07805252 epoch total loss 1.16294
Trained batch 2300 batch loss 0.812222183 epoch total loss 1.16278756
Trained batch 2301 batch loss 0.72675848 epoch total loss 1.16259813
Trained batch 2302 batch loss 1.32069743 epoch total loss 1.1626668
Trained batch 2303 batch loss 1.28557098 epoch total loss 1.1627202
Trained batch 2304 batch loss 1.20816684 epoch total loss 1.16274
Trained batch 2305 batch loss 1.33477247 epoch total loss 1.16281462
Trained batch 2306 batch loss 1.2477 epoch total loss 1.16285145
Trained batch 2307 batch loss 1.4872148 epoch total loss 1.16299212
Trained batch 2308 batch loss 1.15221882 epoch total loss 1.16298735
Trained batch 2309 batch loss 1.12735069 epoch total loss 1.16297197
Trained batch 2310 batch loss 1.05420578 epoch total loss 1.16292489
Trained batch 2311 batch loss 1.1324054 epoch total loss 1.16291165
Trained batch 2312 batch loss 1.45019925 epoch total loss 1.16303587
Trained batch 2313 batch loss 1.27207303 epoch total loss 1.16308296
Trained batch 2314 batch loss 1.2543633 epoch total loss 1.16312242
Trained batch 2315 batch loss 1.22287 epoch total loss 1.16314828
Trained batch 2316 batch loss 1.04353118 epoch total loss 1.16309655
Trained batch 2317 batch loss 0.952856 epoch total loss 1.16300583
Trained batch 2318 batch loss 1.24649167 epoch total loss 1.16304195
Trained batch 2319 batch loss 1.23836637 epoch total loss 1.16307437
Trained batch 2320 batch loss 1.37372208 epoch total loss 1.16316521
Trained batch 2321 batch loss 1.42344213 epoch total loss 1.16327727
Trained batch 2322 batch loss 1.31054711 epoch total loss 1.16334069
Trained batch 2323 batch loss 1.32458198 epoch total loss 1.16341007
Trained batch 2324 batch loss 1.4362464 epoch total loss 1.16352749
Trained batch 2325 batch loss 1.348984 epoch total loss 1.16360724
Trained batch 2326 batch loss 1.19225621 epoch total loss 1.1636194
Trained batch 2327 batch loss 1.09404159 epoch total loss 1.16358948
Trained batch 2328 batch loss 1.06157613 epoch total loss 1.16354573
Trained batch 2329 batch loss 1.29237247 epoch total loss 1.16360104
Trained batch 2330 batch loss 1.3433634 epoch total loss 1.16367817
Trained batch 2331 batch loss 1.04951096 epoch total loss 1.16362917
Trained batch 2332 batch loss 1.23644257 epoch total loss 1.16366041
Trained batch 2333 batch loss 1.26747036 epoch total loss 1.16370487
Trained batch 2334 batch loss 1.25069189 epoch total loss 1.16374218
Trained batch 2335 batch loss 1.19405043 epoch total loss 1.16375518
Trained batch 2336 batch loss 0.851486266 epoch total loss 1.16362154
Trained batch 2337 batch loss 1.07894588 epoch total loss 1.16358531
Trained batch 2338 batch loss 0.978063941 epoch total loss 1.16350591
Trained batch 2339 batch loss 0.985843182 epoch total loss 1.16343
Trained batch 2340 batch loss 1.00779092 epoch total loss 1.16336346
Trained batch 2341 batch loss 0.966879487 epoch total loss 1.16327953
Trained batch 2342 batch loss 1.28183007 epoch total loss 1.16333008
Trained batch 2343 batch loss 1.11697698 epoch total loss 1.16331029
Trained batch 2344 batch loss 1.1296308 epoch total loss 1.16329587
Trained batch 2345 batch loss 1.13487744 epoch total loss 1.16328371
Trained batch 2346 batch loss 1.11505127 epoch total loss 1.1632632
Trained batch 2347 batch loss 1.28569961 epoch total loss 1.1633153
Trained batch 2348 batch loss 1.136724 epoch total loss 1.16330397
Trained batch 2349 batch loss 1.36605084 epoch total loss 1.16339028
Trained batch 2350 batch loss 1.18990827 epoch total loss 1.1634016
Trained batch 2351 batch loss 1.15176654 epoch total loss 1.1633966
Trained batch 2352 batch loss 1.17994332 epoch total loss 1.16340363
Trained batch 2353 batch loss 1.1557622 epoch total loss 1.16340041
Trained batch 2354 batch loss 0.977476 epoch total loss 1.1633215
Trained batch 2355 batch loss 0.877373815 epoch total loss 1.1632
Trained batch 2356 batch loss 1.00742614 epoch total loss 1.16313386
Trained batch 2357 batch loss 1.08750176 epoch total loss 1.16310179
Trained batch 2358 batch loss 1.08448493 epoch total loss 1.16306841
Trained batch 2359 batch loss 0.993842781 epoch total loss 1.16299677
Trained batch 2360 batch loss 1.16104329 epoch total loss 1.16299593
Trained batch 2361 batch loss 0.968592465 epoch total loss 1.16291356
Trained batch 2362 batch loss 1.24308825 epoch total loss 1.16294754
Trained batch 2363 batch loss 0.961868167 epoch total loss 1.16286242
Trained batch 2364 batch loss 0.984367 epoch total loss 1.16278696
Trained batch 2365 batch loss 1.14053822 epoch total loss 1.16277754
Trained batch 2366 batch loss 1.00325799 epoch total loss 1.16271007
Trained batch 2367 batch loss 1.19431472 epoch total loss 1.16272354
Trained batch 2368 batch loss 1.13405228 epoch total loss 1.16271138
Trained batch 2369 batch loss 1.00299454 epoch total loss 1.16264391
Trained batch 2370 batch loss 1.19480753 epoch total loss 1.1626575
Trained batch 2371 batch loss 0.802597106 epoch total loss 1.16250563
Trained batch 2372 batch loss 0.879854798 epoch total loss 1.16238642
Trained batch 2373 batch loss 1.02424657 epoch total loss 1.16232824
Trained batch 2374 batch loss 1.06394291 epoch total loss 1.16228676
Trained batch 2375 batch loss 1.08155966 epoch total loss 1.16225278
Trained batch 2376 batch loss 1.11068523 epoch total loss 1.16223109
Trained batch 2377 batch loss 1.24890304 epoch total loss 1.16226757
Trained batch 2378 batch loss 1.31858945 epoch total loss 1.16233325
Trained batch 2379 batch loss 0.960318804 epoch total loss 1.16224837
Trained batch 2380 batch loss 1.00524664 epoch total loss 1.16218233
Trained batch 2381 batch loss 1.14461374 epoch total loss 1.16217494
Trained batch 2382 batch loss 1.13805485 epoch total loss 1.16216469
Trained batch 2383 batch loss 0.96256578 epoch total loss 1.162081
Trained batch 2384 batch loss 1.04797745 epoch total loss 1.1620332
Trained batch 2385 batch loss 1.03160763 epoch total loss 1.16197848
Trained batch 2386 batch loss 1.19298673 epoch total loss 1.16199136
Trained batch 2387 batch loss 0.979070544 epoch total loss 1.16191471
Trained batch 2388 batch loss 1.03906906 epoch total loss 1.16186333
Trained batch 2389 batch loss 1.22741294 epoch total loss 1.16189063
Trained batch 2390 batch loss 0.904880881 epoch total loss 1.1617831
Trained batch 2391 batch loss 0.958541274 epoch total loss 1.1616981
Trained batch 2392 batch loss 1.04550886 epoch total loss 1.16164947
Trained batch 2393 batch loss 1.28549588 epoch total loss 1.1617012
Trained batch 2394 batch loss 1.29485762 epoch total loss 1.16175687
Trained batch 2395 batch loss 1.08087254 epoch total loss 1.16172302
Trained batch 2396 batch loss 1.19330144 epoch total loss 1.16173625
Trained batch 2397 batch loss 0.996364474 epoch total loss 1.16166723
Trained batch 2398 batch loss 1.23372674 epoch total loss 1.16169727
Trained batch 2399 batch loss 1.4151684 epoch total loss 1.16180301
Trained batch 2400 batch loss 1.12079418 epoch total loss 1.16178584
Trained batch 2401 batch loss 1.17911649 epoch total loss 1.16179311
Trained batch 2402 batch loss 1.33430767 epoch total loss 1.16186488
Trained batch 2403 batch loss 1.10758829 epoch total loss 1.16184235
Trained batch 2404 batch loss 1.13160086 epoch total loss 1.16182983
Trained batch 2405 batch loss 1.3185904 epoch total loss 1.16189504
Trained batch 2406 batch loss 1.28642011 epoch total loss 1.16194677
Trained batch 2407 batch loss 1.3350569 epoch total loss 1.16201854
Trained batch 2408 batch loss 1.40803552 epoch total loss 1.1621207
Trained batch 2409 batch loss 1.41373515 epoch total loss 1.16222525
Trained batch 2410 batch loss 1.24018955 epoch total loss 1.16225755
Trained batch 2411 batch loss 1.18499494 epoch total loss 1.16226709
Trained batch 2412 batch loss 1.04816079 epoch total loss 1.16221976
Trained batch 2413 batch loss 1.06135237 epoch total loss 1.16217792
Trained batch 2414 batch loss 1.23447645 epoch total loss 1.16220772
Trained batch 2415 batch loss 1.12032771 epoch total loss 1.16219044
Trained batch 2416 batch loss 1.23404276 epoch total loss 1.16222024
Trained batch 2417 batch loss 1.0820291 epoch total loss 1.1621871
Trained batch 2418 batch loss 1.02927375 epoch total loss 1.16213214
Trained batch 2419 batch loss 1.18276584 epoch total loss 1.16214061
Trained batch 2420 batch loss 1.11994457 epoch total loss 1.1621232
Trained batch 2421 batch loss 1.07641757 epoch total loss 1.1620878
Trained batch 2422 batch loss 1.39664423 epoch total loss 1.16218472
Trained batch 2423 batch loss 1.14838016 epoch total loss 1.16217899
Trained batch 2424 batch loss 1.22392452 epoch total loss 1.1622045
Trained batch 2425 batch loss 1.0102607 epoch total loss 1.1621418
Trained batch 2426 batch loss 1.15690827 epoch total loss 1.16213965
Trained batch 2427 batch loss 1.21378303 epoch total loss 1.16216099
Trained batch 2428 batch loss 1.1197387 epoch total loss 1.16214347
Trained batch 2429 batch loss 1.06967378 epoch total loss 1.16210532
Trained batch 2430 batch loss 1.24005473 epoch total loss 1.16213739
Trained batch 2431 batch loss 1.35819256 epoch total loss 1.16221809
Trained batch 2432 batch loss 1.16359377 epoch total loss 1.16221857
Trained batch 2433 batch loss 1.21363497 epoch total loss 1.16223967
Trained batch 2434 batch loss 1.16424048 epoch total loss 1.16224062
Trained batch 2435 batch loss 1.2496767 epoch total loss 1.16227651
Trained batch 2436 batch loss 1.10320866 epoch total loss 1.16225231
Trained batch 2437 batch loss 1.56002951 epoch total loss 1.1624155
Trained batch 2438 batch loss 1.10170674 epoch total loss 1.16239071
Trained batch 2439 batch loss 1.15778232 epoch total loss 1.1623888
Trained batch 2440 batch loss 1.03546727 epoch total loss 1.16233671
Trained batch 2441 batch loss 0.983374596 epoch total loss 1.16226339
Trained batch 2442 batch loss 0.838467121 epoch total loss 1.16213071
Trained batch 2443 batch loss 1.12516522 epoch total loss 1.16211569
Trained batch 2444 batch loss 0.86273247 epoch total loss 1.16199315
Trained batch 2445 batch loss 0.940385103 epoch total loss 1.16190255
Trained batch 2446 batch loss 1.0084362 epoch total loss 1.16183984
Trained batch 2447 batch loss 0.91512233 epoch total loss 1.16173899
Trained batch 2448 batch loss 1.00109982 epoch total loss 1.16167343
Trained batch 2449 batch loss 1.01447296 epoch total loss 1.16161335
Trained batch 2450 batch loss 0.99086386 epoch total loss 1.16154361
Trained batch 2451 batch loss 0.999796152 epoch total loss 1.16147768
Trained batch 2452 batch loss 1.07315612 epoch total loss 1.16144168
Trained batch 2453 batch loss 1.48406661 epoch total loss 1.16157317
Trained batch 2454 batch loss 1.646837 epoch total loss 1.16177094
Trained batch 2455 batch loss 1.50573623 epoch total loss 1.16191101
Trained batch 2456 batch loss 1.65652502 epoch total loss 1.16211236
Trained batch 2457 batch loss 1.54699159 epoch total loss 1.162269
Trained batch 2458 batch loss 1.1781044 epoch total loss 1.16227543
Trained batch 2459 batch loss 1.27688289 epoch total loss 1.16232204
Trained batch 2460 batch loss 1.13830829 epoch total loss 1.16231239
Trained batch 2461 batch loss 0.967254758 epoch total loss 1.16223311
Trained batch 2462 batch loss 1.29548323 epoch total loss 1.16228712
Trained batch 2463 batch loss 1.21513653 epoch total loss 1.16230857
Trained batch 2464 batch loss 1.13667953 epoch total loss 1.1622982
Trained batch 2465 batch loss 1.02184677 epoch total loss 1.16224122
Trained batch 2466 batch loss 1.14383626 epoch total loss 1.16223371
Trained batch 2467 batch loss 0.971291363 epoch total loss 1.16215622
Trained batch 2468 batch loss 1.07142901 epoch total loss 1.16211951
Trained batch 2469 batch loss 1.1253798 epoch total loss 1.16210473
Trained batch 2470 batch loss 1.09821546 epoch total loss 1.16207886
Trained batch 2471 batch loss 1.29992127 epoch total loss 1.16213453
Trained batch 2472 batch loss 0.924908578 epoch total loss 1.16203856
Trained batch 2473 batch loss 1.25711882 epoch total loss 1.16207695
Trained batch 2474 batch loss 1.27352214 epoch total loss 1.16212201
Trained batch 2475 batch loss 0.980039835 epoch total loss 1.16204846
Trained batch 2476 batch loss 1.01947236 epoch total loss 1.16199088
Trained batch 2477 batch loss 1.22701716 epoch total loss 1.16201711
Trained batch 2478 batch loss 1.09953499 epoch total loss 1.16199195
Trained batch 2479 batch loss 1.11158621 epoch total loss 1.16197157
Trained batch 2480 batch loss 1.01563799 epoch total loss 1.16191256
Trained batch 2481 batch loss 1.00928295 epoch total loss 1.16185105
Trained batch 2482 batch loss 1.29321671 epoch total loss 1.16190398
Trained batch 2483 batch loss 1.23093438 epoch total loss 1.16193175
Trained batch 2484 batch loss 1.0328536 epoch total loss 1.1618799
Trained batch 2485 batch loss 1.2268194 epoch total loss 1.161906
Trained batch 2486 batch loss 1.28754973 epoch total loss 1.16195655
Trained batch 2487 batch loss 1.11499333 epoch total loss 1.16193771
Trained batch 2488 batch loss 1.20329261 epoch total loss 1.16195428
Trained batch 2489 batch loss 1.2368958 epoch total loss 1.16198444
Trained batch 2490 batch loss 0.968242645 epoch total loss 1.1619066
Trained batch 2491 batch loss 1.12951541 epoch total loss 1.16189361
Trained batch 2492 batch loss 1.22100878 epoch total loss 1.16191721
Trained batch 2493 batch loss 1.21979237 epoch total loss 1.16194046
Trained batch 2494 batch loss 1.2750504 epoch total loss 1.16198587
Trained batch 2495 batch loss 1.13452554 epoch total loss 1.16197479
Trained batch 2496 batch loss 1.23027253 epoch total loss 1.16200221
Trained batch 2497 batch loss 1.20140123 epoch total loss 1.16201794
Trained batch 2498 batch loss 1.04264 epoch total loss 1.16197026
Trained batch 2499 batch loss 1.17895675 epoch total loss 1.16197705
Trained batch 2500 batch loss 1.33181286 epoch total loss 1.16204488
Trained batch 2501 batch loss 1.0677526 epoch total loss 1.16200721
Trained batch 2502 batch loss 1.34393692 epoch total loss 1.16208
Trained batch 2503 batch loss 0.990863 epoch total loss 1.16201162
Trained batch 2504 batch loss 0.963062584 epoch total loss 1.16193223
Trained batch 2505 batch loss 1.05092883 epoch total loss 1.16188788
Trained batch 2506 batch loss 1.01563191 epoch total loss 1.16182959
Trained batch 2507 batch loss 1.06058371 epoch total loss 1.16178918
Trained batch 2508 batch loss 0.979213595 epoch total loss 1.16171634
Trained batch 2509 batch loss 1.1970737 epoch total loss 1.16173041
Trained batch 2510 batch loss 1.1874218 epoch total loss 1.16174078
Trained batch 2511 batch loss 1.16620779 epoch total loss 1.16174257
Trained batch 2512 batch loss 1.12828207 epoch total loss 1.16172922
Trained batch 2513 batch loss 1.14749908 epoch total loss 1.16172349
Trained batch 2514 batch loss 1.06337333 epoch total loss 1.16168439
Trained batch 2515 batch loss 1.17253423 epoch total loss 1.1616888
Trained batch 2516 batch loss 1.39030671 epoch total loss 1.16177964
Trained batch 2517 batch loss 1.41500497 epoch total loss 1.16188025
Trained batch 2518 batch loss 1.39259017 epoch total loss 1.16197193
Trained batch 2519 batch loss 1.10223937 epoch total loss 1.1619482
Trained batch 2520 batch loss 1.37301874 epoch total loss 1.16203201
Trained batch 2521 batch loss 1.19955695 epoch total loss 1.16204679
Trained batch 2522 batch loss 1.31319547 epoch total loss 1.16210675
Trained batch 2523 batch loss 1.30012119 epoch total loss 1.16216147
Trained batch 2524 batch loss 0.977047563 epoch total loss 1.16208804
Trained batch 2525 batch loss 1.16413 epoch total loss 1.16208887
Trained batch 2526 batch loss 1.08341527 epoch total loss 1.16205776
Trained batch 2527 batch loss 1.12727 epoch total loss 1.16204393
Trained batch 2528 batch loss 1.19637823 epoch total loss 1.16205752
Trained batch 2529 batch loss 1.05027568 epoch total loss 1.16201329
Trained batch 2530 batch loss 1.06545663 epoch total loss 1.16197515
Trained batch 2531 batch loss 1.19994962 epoch total loss 1.16199017
Trained batch 2532 batch loss 1.47439432 epoch total loss 1.16211355
Trained batch 2533 batch loss 1.2527076 epoch total loss 1.16214931
Trained batch 2534 batch loss 1.3379159 epoch total loss 1.16221869
Trained batch 2535 batch loss 1.18081176 epoch total loss 1.16222596
Trained batch 2536 batch loss 1.14108598 epoch total loss 1.16221774
Trained batch 2537 batch loss 1.19889259 epoch total loss 1.16223216
Trained batch 2538 batch loss 1.06020498 epoch total loss 1.16219199
Trained batch 2539 batch loss 1.21022201 epoch total loss 1.16221094
Trained batch 2540 batch loss 1.27641857 epoch total loss 1.16225588
Trained batch 2541 batch loss 1.16439581 epoch total loss 1.16225672
Trained batch 2542 batch loss 1.37507677 epoch total loss 1.1623404
Trained batch 2543 batch loss 1.01033509 epoch total loss 1.16228056
Trained batch 2544 batch loss 1.15622902 epoch total loss 1.16227818
Trained batch 2545 batch loss 0.966880441 epoch total loss 1.1622014
Trained batch 2546 batch loss 1.26696897 epoch total loss 1.16224253
Trained batch 2547 batch loss 1.35340333 epoch total loss 1.16231763
Trained batch 2548 batch loss 1.31993723 epoch total loss 1.1623795
Trained batch 2549 batch loss 1.28968811 epoch total loss 1.16242945
Trained batch 2550 batch loss 1.31741786 epoch total loss 1.16249025
Trained batch 2551 batch loss 1.207057 epoch total loss 1.16250765
Trained batch 2552 batch loss 1.13680422 epoch total loss 1.16249764
Trained batch 2553 batch loss 1.15305686 epoch total loss 1.16249394
Trained batch 2554 batch loss 1.12954473 epoch total loss 1.16248107
Trained batch 2555 batch loss 1.04344559 epoch total loss 1.16243446
Trained batch 2556 batch loss 1.11886048 epoch total loss 1.16241741
Trained batch 2557 batch loss 1.2199266 epoch total loss 1.16244
Trained batch 2558 batch loss 1.20736015 epoch total loss 1.16245747
Trained batch 2559 batch loss 1.00001955 epoch total loss 1.16239393
Trained batch 2560 batch loss 1.18976259 epoch total loss 1.16240466
Trained batch 2561 batch loss 1.10988748 epoch total loss 1.16238415
Trained batch 2562 batch loss 1.24892724 epoch total loss 1.16241789
Trained batch 2563 batch loss 1.00704253 epoch total loss 1.16235733
Trained batch 2564 batch loss 1.13183188 epoch total loss 1.16234541
Trained batch 2565 batch loss 1.24021 epoch total loss 1.16237581
Trained batch 2566 batch loss 1.20753872 epoch total loss 1.16239333
Trained batch 2567 batch loss 1.53579545 epoch total loss 1.16253889
Trained batch 2568 batch loss 1.19779336 epoch total loss 1.1625526
Trained batch 2569 batch loss 1.14012229 epoch total loss 1.16254389
Trained batch 2570 batch loss 0.968631923 epoch total loss 1.16246843
Trained batch 2571 batch loss 1.08893573 epoch total loss 1.16243982
Trained batch 2572 batch loss 0.958291948 epoch total loss 1.16236043
Trained batch 2573 batch loss 1.13896966 epoch total loss 1.16235137
Trained batch 2574 batch loss 1.08980703 epoch total loss 1.16232312
Trained batch 2575 batch loss 1.11549413 epoch total loss 1.162305
Trained batch 2576 batch loss 1.0111928 epoch total loss 1.16224635
Trained batch 2577 batch loss 1.05276418 epoch total loss 1.16220379
Trained batch 2578 batch loss 1.05884051 epoch total loss 1.16216373
Trained batch 2579 batch loss 1.04723334 epoch total loss 1.16211915
Trained batch 2580 batch loss 0.868313074 epoch total loss 1.16200531
Trained batch 2581 batch loss 0.900095105 epoch total loss 1.16190386
Trained batch 2582 batch loss 0.978479266 epoch total loss 1.16183281
Trained batch 2583 batch loss 0.956871212 epoch total loss 1.16175342
Trained batch 2584 batch loss 0.984134555 epoch total loss 1.16168463
Trained batch 2585 batch loss 1.26554918 epoch total loss 1.16172493
Trained batch 2586 batch loss 0.822996318 epoch total loss 1.16159391
Trained batch 2587 batch loss 1.21650374 epoch total loss 1.16161513
Trained batch 2588 batch loss 1.20236373 epoch total loss 1.16163087
Trained batch 2589 batch loss 0.917355239 epoch total loss 1.16153646
Trained batch 2590 batch loss 1.07278323 epoch total loss 1.16150224
Trained batch 2591 batch loss 1.25781929 epoch total loss 1.16153944
Trained batch 2592 batch loss 1.2746377 epoch total loss 1.16158307
Trained batch 2593 batch loss 1.08394861 epoch total loss 1.16155314
Trained batch 2594 batch loss 1.18127429 epoch total loss 1.16156065
Trained batch 2595 batch loss 0.940232515 epoch total loss 1.16147542
Trained batch 2596 batch loss 1.07877827 epoch total loss 1.16144359
Trained batch 2597 batch loss 0.925720155 epoch total loss 1.16135275
Trained batch 2598 batch loss 0.988975704 epoch total loss 1.16128647
Trained batch 2599 batch loss 0.798784137 epoch total loss 1.161147
Trained batch 2600 batch loss 1.02196836 epoch total loss 1.16109347
Trained batch 2601 batch loss 1.08775735 epoch total loss 1.16106522
Trained batch 2602 batch loss 1.08181906 epoch total loss 1.1610347
Trained batch 2603 batch loss 1.01743972 epoch total loss 1.16097951
Trained batch 2604 batch loss 1.3534261 epoch total loss 1.16105354
Trained batch 2605 batch loss 1.24680507 epoch total loss 1.16108644
Trained batch 2606 batch loss 1.30991864 epoch total loss 1.16114354
Trained batch 2607 batch loss 1.04946399 epoch total loss 1.16110075
Trained batch 2608 batch loss 1.17177749 epoch total loss 1.1611048
Trained batch 2609 batch loss 1.25161994 epoch total loss 1.16113961
Trained batch 2610 batch loss 1.31383538 epoch total loss 1.16119802
Trained batch 2611 batch loss 0.997541428 epoch total loss 1.16113532
Trained batch 2612 batch loss 1.39528191 epoch total loss 1.16122496
Trained batch 2613 batch loss 1.11086881 epoch total loss 1.16120565
Trained batch 2614 batch loss 1.24359739 epoch total loss 1.16123724
Trained batch 2615 batch loss 0.914754629 epoch total loss 1.16114295
Trained batch 2616 batch loss 1.06882572 epoch total loss 1.16110766
Trained batch 2617 batch loss 1.31801414 epoch total loss 1.16116774
Trained batch 2618 batch loss 0.996046424 epoch total loss 1.16110468
Trained batch 2619 batch loss 1.22988129 epoch total loss 1.16113091
Trained batch 2620 batch loss 1.15992475 epoch total loss 1.16113043
Trained batch 2621 batch loss 1.00250745 epoch total loss 1.16107
Trained batch 2622 batch loss 1.09242129 epoch total loss 1.16104376
Trained batch 2623 batch loss 0.938866496 epoch total loss 1.16095912
Trained batch 2624 batch loss 0.963178635 epoch total loss 1.16088378
Trained batch 2625 batch loss 1.01723051 epoch total loss 1.16082907
Trained batch 2626 batch loss 0.986416459 epoch total loss 1.16076255
Trained batch 2627 batch loss 1.03030825 epoch total loss 1.16071296
Trained batch 2628 batch loss 1.06734931 epoch total loss 1.16067743
Trained batch 2629 batch loss 1.16676855 epoch total loss 1.1606797
Trained batch 2630 batch loss 1.18394566 epoch total loss 1.16068852
Trained batch 2631 batch loss 1.14730358 epoch total loss 1.16068339
Trained batch 2632 batch loss 1.15805483 epoch total loss 1.16068232
Trained batch 2633 batch loss 1.0588311 epoch total loss 1.1606437
Trained batch 2634 batch loss 0.9501701 epoch total loss 1.16056383
Trained batch 2635 batch loss 1.02567387 epoch total loss 1.16051257
Trained batch 2636 batch loss 1.12284195 epoch total loss 1.16049826
Trained batch 2637 batch loss 0.905271 epoch total loss 1.16040146
Trained batch 2638 batch loss 1.04442823 epoch total loss 1.16035759
Trained batch 2639 batch loss 1.06236184 epoch total loss 1.1603204
Trained batch 2640 batch loss 1.20467567 epoch total loss 1.16033709
Trained batch 2641 batch loss 1.12382054 epoch total loss 1.16032326
Trained batch 2642 batch loss 1.09354353 epoch total loss 1.16029799
Trained batch 2643 batch loss 1.06627703 epoch total loss 1.16026235
Trained batch 2644 batch loss 0.966670692 epoch total loss 1.16018915
Trained batch 2645 batch loss 1.0306344 epoch total loss 1.16014
Trained batch 2646 batch loss 0.848039806 epoch total loss 1.16002214
Trained batch 2647 batch loss 1.29635906 epoch total loss 1.16007376
Trained batch 2648 batch loss 1.16646147 epoch total loss 1.16007614
Trained batch 2649 batch loss 0.925401807 epoch total loss 1.15998745
Trained batch 2650 batch loss 0.935196221 epoch total loss 1.15990269
Trained batch 2651 batch loss 1.01324463 epoch total loss 1.15984738
Trained batch 2652 batch loss 1.068506 epoch total loss 1.15981293
Trained batch 2653 batch loss 1.02290726 epoch total loss 1.15976143
Trained batch 2654 batch loss 1.10014427 epoch total loss 1.1597389
Trained batch 2655 batch loss 1.04285705 epoch total loss 1.15969491
Trained batch 2656 batch loss 1.42320347 epoch total loss 1.15979409
Trained batch 2657 batch loss 1.33927035 epoch total loss 1.15986168
Trained batch 2658 batch loss 1.30128491 epoch total loss 1.15991485
Trained batch 2659 batch loss 1.47532153 epoch total loss 1.16003346
Trained batch 2660 batch loss 1.3771615 epoch total loss 1.16011512
Trained batch 2661 batch loss 1.09144735 epoch total loss 1.16008937
Trained batch 2662 batch loss 1.16746223 epoch total loss 1.16009212
Trained batch 2663 batch loss 0.956363678 epoch total loss 1.16001558
Trained batch 2664 batch loss 1.22309446 epoch total loss 1.16003931
Trained batch 2665 batch loss 0.897693396 epoch total loss 1.15994084
Trained batch 2666 batch loss 1.22496068 epoch total loss 1.15996528
Trained batch 2667 batch loss 1.12757266 epoch total loss 1.15995312
Trained batch 2668 batch loss 1.1060164 epoch total loss 1.15993285
Trained batch 2669 batch loss 1.15013933 epoch total loss 1.15992916
Trained batch 2670 batch loss 1.38672364 epoch total loss 1.16001415
Trained batch 2671 batch loss 1.14875793 epoch total loss 1.16000986
Trained batch 2672 batch loss 1.27337122 epoch total loss 1.16005242
Trained batch 2673 batch loss 1.16021991 epoch total loss 1.16005242
Trained batch 2674 batch loss 1.26881146 epoch total loss 1.16009307
Trained batch 2675 batch loss 1.08990407 epoch total loss 1.16006684
Trained batch 2676 batch loss 1.15791857 epoch total loss 1.16006601
Trained batch 2677 batch loss 0.929366112 epoch total loss 1.15997982
Trained batch 2678 batch loss 0.966317952 epoch total loss 1.15990758
Trained batch 2679 batch loss 1.08206642 epoch total loss 1.15987849
Trained batch 2680 batch loss 1.02809381 epoch total loss 1.15982926
Trained batch 2681 batch loss 0.996273935 epoch total loss 1.15976834
Trained batch 2682 batch loss 1.157969 epoch total loss 1.15976763
Trained batch 2683 batch loss 1.20558798 epoch total loss 1.15978467
Trained batch 2684 batch loss 1.43791509 epoch total loss 1.15988839
Trained batch 2685 batch loss 1.26279211 epoch total loss 1.15992665
Trained batch 2686 batch loss 1.33680749 epoch total loss 1.15999258
Trained batch 2687 batch loss 1.27489376 epoch total loss 1.16003537
Trained batch 2688 batch loss 0.983977437 epoch total loss 1.15996981
Trained batch 2689 batch loss 1.19793522 epoch total loss 1.15998387
Trained batch 2690 batch loss 1.09147203 epoch total loss 1.15995848
Trained batch 2691 batch loss 1.2980001 epoch total loss 1.16000986
Trained batch 2692 batch loss 1.20396781 epoch total loss 1.16002607
Trained batch 2693 batch loss 1.1156801 epoch total loss 1.16000962
Trained batch 2694 batch loss 1.21714699 epoch total loss 1.16003084
Trained batch 2695 batch loss 1.32933116 epoch total loss 1.16009367
Trained batch 2696 batch loss 1.27508092 epoch total loss 1.16013634
Trained batch 2697 batch loss 1.21404743 epoch total loss 1.16015637
Trained batch 2698 batch loss 1.15917087 epoch total loss 1.16015601
Trained batch 2699 batch loss 1.14172757 epoch total loss 1.16014922
Trained batch 2700 batch loss 1.25893784 epoch total loss 1.16018581
Trained batch 2701 batch loss 1.27413058 epoch total loss 1.16022801
Trained batch 2702 batch loss 1.19178796 epoch total loss 1.1602397
Trained batch 2703 batch loss 1.37909245 epoch total loss 1.16032076
Trained batch 2704 batch loss 1.31258476 epoch total loss 1.16037703
Trained batch 2705 batch loss 1.12967086 epoch total loss 1.1603657
Trained batch 2706 batch loss 1.22410357 epoch total loss 1.16038918
Trained batch 2707 batch loss 1.47088337 epoch total loss 1.16050398
Trained batch 2708 batch loss 1.07904148 epoch total loss 1.16047382
Trained batch 2709 batch loss 1.09515047 epoch total loss 1.16044974
Trained batch 2710 batch loss 0.982556224 epoch total loss 1.16038418
Trained batch 2711 batch loss 1.04857564 epoch total loss 1.16034293
Trained batch 2712 batch loss 0.885077596 epoch total loss 1.16024137
Trained batch 2713 batch loss 1.0340842 epoch total loss 1.16019499
Trained batch 2714 batch loss 0.918616176 epoch total loss 1.16010594
Trained batch 2715 batch loss 0.882608294 epoch total loss 1.16000378
Trained batch 2716 batch loss 0.814841151 epoch total loss 1.1598767
Trained batch 2717 batch loss 1.03216815 epoch total loss 1.15982974
Trained batch 2718 batch loss 1.11642075 epoch total loss 1.15981376
Trained batch 2719 batch loss 1.189273 epoch total loss 1.15982461
Trained batch 2720 batch loss 1.32258618 epoch total loss 1.15988433
Trained batch 2721 batch loss 1.37021899 epoch total loss 1.15996158
Trained batch 2722 batch loss 1.44131351 epoch total loss 1.16006505
Trained batch 2723 batch loss 1.1804564 epoch total loss 1.16007257
Trained batch 2724 batch loss 1.54409695 epoch total loss 1.16021347
Trained batch 2725 batch loss 1.11402893 epoch total loss 1.16019654
Trained batch 2726 batch loss 1.21180892 epoch total loss 1.1602155
Trained batch 2727 batch loss 1.35822058 epoch total loss 1.1602881
Trained batch 2728 batch loss 1.50098789 epoch total loss 1.16041303
Trained batch 2729 batch loss 1.58346486 epoch total loss 1.160568
Trained batch 2730 batch loss 1.32143879 epoch total loss 1.16062701
Trained batch 2731 batch loss 1.14811146 epoch total loss 1.16062248
Trained batch 2732 batch loss 1.07535434 epoch total loss 1.16059124
Trained batch 2733 batch loss 1.24569845 epoch total loss 1.16062236
Trained batch 2734 batch loss 1.5524869 epoch total loss 1.16076577
Trained batch 2735 batch loss 1.43218267 epoch total loss 1.16086495
Trained batch 2736 batch loss 1.40847373 epoch total loss 1.16095543
Trained batch 2737 batch loss 1.2297461 epoch total loss 1.16098058
Trained batch 2738 batch loss 1.29344749 epoch total loss 1.16102898
Trained batch 2739 batch loss 1.19128489 epoch total loss 1.16104007
Trained batch 2740 batch loss 1.40920615 epoch total loss 1.16113055
Trained batch 2741 batch loss 1.00954068 epoch total loss 1.16107523
Trained batch 2742 batch loss 1.27951908 epoch total loss 1.16111851
Trained batch 2743 batch loss 1.20084655 epoch total loss 1.16113293
Trained batch 2744 batch loss 1.19288146 epoch total loss 1.16114461
Trained batch 2745 batch loss 1.26452446 epoch total loss 1.16118217
Trained batch 2746 batch loss 1.18898988 epoch total loss 1.1611923
Trained batch 2747 batch loss 1.31279135 epoch total loss 1.16124749
Trained batch 2748 batch loss 1.31491375 epoch total loss 1.1613034
Trained batch 2749 batch loss 1.32418752 epoch total loss 1.16136265
Trained batch 2750 batch loss 1.21875453 epoch total loss 1.16138351
Trained batch 2751 batch loss 1.14442635 epoch total loss 1.16137743
Trained batch 2752 batch loss 1.12875271 epoch total loss 1.16136551
Trained batch 2753 batch loss 1.3138783 epoch total loss 1.16142094
Trained batch 2754 batch loss 1.21425247 epoch total loss 1.16144013
Trained batch 2755 batch loss 1.21085787 epoch total loss 1.16145813
Trained batch 2756 batch loss 1.40531695 epoch total loss 1.16154659
Trained batch 2757 batch loss 1.35618067 epoch total loss 1.16161716
Trained batch 2758 batch loss 1.32249558 epoch total loss 1.16167557
Trained batch 2759 batch loss 1.26219153 epoch total loss 1.16171193
Trained batch 2760 batch loss 1.20463777 epoch total loss 1.16172755
Trained batch 2761 batch loss 1.13905478 epoch total loss 1.16171932
Trained batch 2762 batch loss 1.3972764 epoch total loss 1.16180456
Trained batch 2763 batch loss 1.41302478 epoch total loss 1.16189551
Trained batch 2764 batch loss 1.12588859 epoch total loss 1.16188252
Trained batch 2765 batch loss 1.32680321 epoch total loss 1.16194224
Trained batch 2766 batch loss 1.44424438 epoch total loss 1.16204429
Trained batch 2767 batch loss 1.28543758 epoch total loss 1.16208887
Trained batch 2768 batch loss 1.41332126 epoch total loss 1.16217971
Trained batch 2769 batch loss 1.28629076 epoch total loss 1.16222453
Trained batch 2770 batch loss 1.13890386 epoch total loss 1.16221607
Trained batch 2771 batch loss 0.920357764 epoch total loss 1.16212881
Trained batch 2772 batch loss 1.25168288 epoch total loss 1.16216111
Trained batch 2773 batch loss 1.24042344 epoch total loss 1.16218936
Trained batch 2774 batch loss 1.39318609 epoch total loss 1.16227269
Trained batch 2775 batch loss 1.26655984 epoch total loss 1.16231024
Trained batch 2776 batch loss 1.16865742 epoch total loss 1.16231251
Trained batch 2777 batch loss 1.08623099 epoch total loss 1.16228509
Trained batch 2778 batch loss 1.12661016 epoch total loss 1.16227233
Trained batch 2779 batch loss 1.19564009 epoch total loss 1.16228426
Trained batch 2780 batch loss 1.16521597 epoch total loss 1.16228533
Trained batch 2781 batch loss 1.22537208 epoch total loss 1.1623081
Trained batch 2782 batch loss 1.21218944 epoch total loss 1.16232598
Trained batch 2783 batch loss 1.09152412 epoch total loss 1.16230059
Trained batch 2784 batch loss 1.27175367 epoch total loss 1.16233981
Trained batch 2785 batch loss 1.19027805 epoch total loss 1.16234982
Trained batch 2786 batch loss 1.16273212 epoch total loss 1.16235
Trained batch 2787 batch loss 1.11173642 epoch total loss 1.16233182
Trained batch 2788 batch loss 0.907847881 epoch total loss 1.16224062
Trained batch 2789 batch loss 1.22361851 epoch total loss 1.16226268
Trained batch 2790 batch loss 0.929644585 epoch total loss 1.16217935
Trained batch 2791 batch loss 1.04499257 epoch total loss 1.16213727
Trained batch 2792 batch loss 0.929143786 epoch total loss 1.16205382
Trained batch 2793 batch loss 1.00555491 epoch total loss 1.1619978
Trained batch 2794 batch loss 1.00222826 epoch total loss 1.16194069
Trained batch 2795 batch loss 1.08429515 epoch total loss 1.1619128
Trained batch 2796 batch loss 0.960769117 epoch total loss 1.16184092
Trained batch 2797 batch loss 0.868559897 epoch total loss 1.16173601
Trained batch 2798 batch loss 0.960941672 epoch total loss 1.16166425
Trained batch 2799 batch loss 0.812517047 epoch total loss 1.16153955
Trained batch 2800 batch loss 0.944013953 epoch total loss 1.16146183
Trained batch 2801 batch loss 1.0261066 epoch total loss 1.16141355
Trained batch 2802 batch loss 1.2919277 epoch total loss 1.16146016
Trained batch 2803 batch loss 1.43411279 epoch total loss 1.16155744
Trained batch 2804 batch loss 1.25234628 epoch total loss 1.16158986
Trained batch 2805 batch loss 1.24642754 epoch total loss 1.16162
Trained batch 2806 batch loss 1.2859683 epoch total loss 1.16166437
Trained batch 2807 batch loss 1.26203179 epoch total loss 1.1617
Trained batch 2808 batch loss 1.2248385 epoch total loss 1.16172254
Trained batch 2809 batch loss 1.1920172 epoch total loss 1.16173339
Trained batch 2810 batch loss 1.14630449 epoch total loss 1.16172791
Trained batch 2811 batch loss 1.28883266 epoch total loss 1.16177309
Trained batch 2812 batch loss 1.54240584 epoch total loss 1.16190851
Trained batch 2813 batch loss 1.45033073 epoch total loss 1.16201103
Trained batch 2814 batch loss 1.44909215 epoch total loss 1.16211307
Trained batch 2815 batch loss 1.35474658 epoch total loss 1.1621815
Trained batch 2816 batch loss 1.27331066 epoch total loss 1.16222084
Trained batch 2817 batch loss 1.43989658 epoch total loss 1.16231942
Trained batch 2818 batch loss 1.43500423 epoch total loss 1.16241622
Trained batch 2819 batch loss 1.29344106 epoch total loss 1.16246271
Trained batch 2820 batch loss 1.10649109 epoch total loss 1.1624428
Trained batch 2821 batch loss 1.21860671 epoch total loss 1.16246271
Trained batch 2822 batch loss 1.11667085 epoch total loss 1.1624465
Trained batch 2823 batch loss 1.31933117 epoch total loss 1.16250205
Trained batch 2824 batch loss 1.18720376 epoch total loss 1.16251087
Trained batch 2825 batch loss 1.26646304 epoch total loss 1.16254759
Trained batch 2826 batch loss 1.23578739 epoch total loss 1.16257358
Trained batch 2827 batch loss 1.25913262 epoch total loss 1.16260767
Trained batch 2828 batch loss 1.16323745 epoch total loss 1.16260791
Trained batch 2829 batch loss 1.11874807 epoch total loss 1.16259241
Trained batch 2830 batch loss 1.12784958 epoch total loss 1.16258013
Trained batch 2831 batch loss 1.10734463 epoch total loss 1.1625607
Trained batch 2832 batch loss 1.02273417 epoch total loss 1.16251123
Trained batch 2833 batch loss 1.03595972 epoch total loss 1.16246653
Trained batch 2834 batch loss 0.898147345 epoch total loss 1.1623733
Trained batch 2835 batch loss 0.884872913 epoch total loss 1.16227543
Trained batch 2836 batch loss 1.20760775 epoch total loss 1.16229141
Trained batch 2837 batch loss 1.35969853 epoch total loss 1.16236091
Trained batch 2838 batch loss 1.16327572 epoch total loss 1.16236126
Trained batch 2839 batch loss 1.11323881 epoch total loss 1.16234398
Trained batch 2840 batch loss 1.08147395 epoch total loss 1.16231549
Trained batch 2841 batch loss 1.24196649 epoch total loss 1.1623435
Trained batch 2842 batch loss 1.23827028 epoch total loss 1.16237032
Trained batch 2843 batch loss 1.09589148 epoch total loss 1.16234696
Trained batch 2844 batch loss 1.18975759 epoch total loss 1.1623565
Trained batch 2845 batch loss 1.07830107 epoch total loss 1.16232705
Trained batch 2846 batch loss 1.2356596 epoch total loss 1.1623528
Trained batch 2847 batch loss 1.17734289 epoch total loss 1.16235793
Trained batch 2848 batch loss 1.08433223 epoch total loss 1.16233051
Trained batch 2849 batch loss 1.06820989 epoch total loss 1.16229749
Trained batch 2850 batch loss 1.21775985 epoch total loss 1.16231692
Trained batch 2851 batch loss 1.35039568 epoch total loss 1.16238284
Trained batch 2852 batch loss 1.23501265 epoch total loss 1.16240835
Trained batch 2853 batch loss 1.25132561 epoch total loss 1.16243947
Trained batch 2854 batch loss 1.18343687 epoch total loss 1.16244686
Trained batch 2855 batch loss 1.09388673 epoch total loss 1.1624229
Trained batch 2856 batch loss 1.13340199 epoch total loss 1.16241264
Trained batch 2857 batch loss 1.27916098 epoch total loss 1.16245353
Trained batch 2858 batch loss 1.27333 epoch total loss 1.16249228
Trained batch 2859 batch loss 1.26184988 epoch total loss 1.16252708
Trained batch 2860 batch loss 1.14816344 epoch total loss 1.16252208
Trained batch 2861 batch loss 1.08223939 epoch total loss 1.16249406
Trained batch 2862 batch loss 1.38329 epoch total loss 1.16257119
Trained batch 2863 batch loss 1.18306637 epoch total loss 1.16257834
Trained batch 2864 batch loss 1.385885 epoch total loss 1.16265643
Trained batch 2865 batch loss 1.38273239 epoch total loss 1.1627332
Trained batch 2866 batch loss 1.47084892 epoch total loss 1.16284072
Trained batch 2867 batch loss 1.46030092 epoch total loss 1.16294444
Trained batch 2868 batch loss 1.34801245 epoch total loss 1.16300893
Trained batch 2869 batch loss 1.49826729 epoch total loss 1.16312587
Trained batch 2870 batch loss 1.10485935 epoch total loss 1.16310561
Trained batch 2871 batch loss 1.03972 epoch total loss 1.16306269
Trained batch 2872 batch loss 1.14927578 epoch total loss 1.1630578
Trained batch 2873 batch loss 1.11423302 epoch total loss 1.16304076
Trained batch 2874 batch loss 1.36592674 epoch total loss 1.16311145
Trained batch 2875 batch loss 1.37757671 epoch total loss 1.16318607
Trained batch 2876 batch loss 1.27378726 epoch total loss 1.16322446
Trained batch 2877 batch loss 1.00767112 epoch total loss 1.16317034
Trained batch 2878 batch loss 1.06108177 epoch total loss 1.16313493
Trained batch 2879 batch loss 0.909642398 epoch total loss 1.16304684
Trained batch 2880 batch loss 1.06260276 epoch total loss 1.16301191
Trained batch 2881 batch loss 1.1619271 epoch total loss 1.16301155
Trained batch 2882 batch loss 1.04092038 epoch total loss 1.16296923
Trained batch 2883 batch loss 1.18591034 epoch total loss 1.1629771
Trained batch 2884 batch loss 1.07786083 epoch total loss 1.16294765
Trained batch 2885 batch loss 1.33061731 epoch total loss 1.16300571
Trained batch 2886 batch loss 1.2569505 epoch total loss 1.16303825
Trained batch 2887 batch loss 1.13522804 epoch total loss 1.1630286
Trained batch 2888 batch loss 1.24932265 epoch total loss 1.16305852
Trained batch 2889 batch loss 1.33104777 epoch total loss 1.16311657
Trained batch 2890 batch loss 1.37044203 epoch total loss 1.16318834
Trained batch 2891 batch loss 0.965298414 epoch total loss 1.16311991
Trained batch 2892 batch loss 0.926590204 epoch total loss 1.16303802
Trained batch 2893 batch loss 0.993595779 epoch total loss 1.16297948
Trained batch 2894 batch loss 1.06376803 epoch total loss 1.16294527
Trained batch 2895 batch loss 1.01806748 epoch total loss 1.1628952
Trained batch 2896 batch loss 0.92496407 epoch total loss 1.16281307
Trained batch 2897 batch loss 0.931752503 epoch total loss 1.1627332
Trained batch 2898 batch loss 0.800162554 epoch total loss 1.16260815
Trained batch 2899 batch loss 0.929609716 epoch total loss 1.1625278
Trained batch 2900 batch loss 0.990038097 epoch total loss 1.16246831
Trained batch 2901 batch loss 0.878601372 epoch total loss 1.16237044
Trained batch 2902 batch loss 0.928672433 epoch total loss 1.16228986
Trained batch 2903 batch loss 1.19076335 epoch total loss 1.16229963
Trained batch 2904 batch loss 1.13009739 epoch total loss 1.16228867
Trained batch 2905 batch loss 1.04002476 epoch total loss 1.16224658
Trained batch 2906 batch loss 1.30592012 epoch total loss 1.16229594
Trained batch 2907 batch loss 1.01518989 epoch total loss 1.16224539
Trained batch 2908 batch loss 1.29818761 epoch total loss 1.162292
Trained batch 2909 batch loss 1.05037379 epoch total loss 1.16225362
Trained batch 2910 batch loss 0.981686354 epoch total loss 1.16219151
Trained batch 2911 batch loss 0.820936322 epoch total loss 1.16207433
Trained batch 2912 batch loss 1.02440166 epoch total loss 1.162027
Trained batch 2913 batch loss 0.959960759 epoch total loss 1.16195762
Trained batch 2914 batch loss 0.931018353 epoch total loss 1.16187835
Trained batch 2915 batch loss 1.0971 epoch total loss 1.16185617
Trained batch 2916 batch loss 1.03322518 epoch total loss 1.16181207
Trained batch 2917 batch loss 1.01657856 epoch total loss 1.16176224
Trained batch 2918 batch loss 1.32203853 epoch total loss 1.16181719
Trained batch 2919 batch loss 1.19508076 epoch total loss 1.16182864
Trained batch 2920 batch loss 1.0696981 epoch total loss 1.16179705
Trained batch 2921 batch loss 1.0733459 epoch total loss 1.16176665
Trained batch 2922 batch loss 1.18068969 epoch total loss 1.1617732
Trained batch 2923 batch loss 1.19219613 epoch total loss 1.16178358
Trained batch 2924 batch loss 1.32144856 epoch total loss 1.16183817
Trained batch 2925 batch loss 1.23760116 epoch total loss 1.16186404
Trained batch 2926 batch loss 1.13177085 epoch total loss 1.16185379
Trained batch 2927 batch loss 1.35004354 epoch total loss 1.16191816
Trained batch 2928 batch loss 1.08607221 epoch total loss 1.16189229
Trained batch 2929 batch loss 0.923847437 epoch total loss 1.16181099
Trained batch 2930 batch loss 1.01599216 epoch total loss 1.16176128
Trained batch 2931 batch loss 1.07293451 epoch total loss 1.161731
Trained batch 2932 batch loss 0.969296515 epoch total loss 1.16166532
Trained batch 2933 batch loss 1.1181649 epoch total loss 1.16165042
Trained batch 2934 batch loss 0.930711389 epoch total loss 1.16157174
Trained batch 2935 batch loss 1.22147012 epoch total loss 1.16159213
Trained batch 2936 batch loss 1.22078443 epoch total loss 1.16161227
Trained batch 2937 batch loss 1.1969825 epoch total loss 1.16162431
Trained batch 2938 batch loss 1.47553086 epoch total loss 1.16173124
Trained batch 2939 batch loss 1.24897635 epoch total loss 1.16176093
Trained batch 2940 batch loss 1.27149081 epoch total loss 1.16179824
Trained batch 2941 batch loss 1.41219985 epoch total loss 1.16188335
Trained batch 2942 batch loss 1.25518203 epoch total loss 1.16191506
Trained batch 2943 batch loss 1.20440435 epoch total loss 1.16192949
Trained batch 2944 batch loss 1.37185585 epoch total loss 1.16200078
Trained batch 2945 batch loss 1.18253124 epoch total loss 1.16200769
Trained batch 2946 batch loss 1.22978866 epoch total loss 1.1620307
Trained batch 2947 batch loss 1.19918668 epoch total loss 1.16204333
Trained batch 2948 batch loss 1.14099145 epoch total loss 1.1620363
Trained batch 2949 batch loss 1.14566827 epoch total loss 1.1620307
Trained batch 2950 batch loss 1.12826109 epoch total loss 1.16201925
Trained batch 2951 batch loss 1.08675504 epoch total loss 1.16199374
Trained batch 2952 batch loss 1.23473358 epoch total loss 1.1620183
Trained batch 2953 batch loss 1.33497345 epoch total loss 1.16207683
Trained batch 2954 batch loss 1.23534501 epoch total loss 1.16210175
Trained batch 2955 batch loss 1.30893648 epoch total loss 1.16215134
Trained batch 2956 batch loss 1.37369418 epoch total loss 1.16222298
Trained batch 2957 batch loss 1.17525697 epoch total loss 1.16222739
Trained batch 2958 batch loss 0.794620752 epoch total loss 1.16210306
Trained batch 2959 batch loss 0.906989694 epoch total loss 1.16201687
Trained batch 2960 batch loss 1.19868135 epoch total loss 1.16202927
Trained batch 2961 batch loss 1.23155522 epoch total loss 1.16205275
Trained batch 2962 batch loss 1.19050038 epoch total loss 1.16206229
Trained batch 2963 batch loss 1.13378811 epoch total loss 1.16205275
Trained batch 2964 batch loss 1.21629786 epoch total loss 1.16207111
Trained batch 2965 batch loss 1.32831669 epoch total loss 1.16212714
Trained batch 2966 batch loss 1.27327657 epoch total loss 1.16216457
Trained batch 2967 batch loss 1.24597204 epoch total loss 1.16219294
Trained batch 2968 batch loss 1.36061978 epoch total loss 1.1622597
Trained batch 2969 batch loss 1.2374289 epoch total loss 1.16228509
Trained batch 2970 batch loss 1.03718817 epoch total loss 1.16224301
Trained batch 2971 batch loss 0.907651186 epoch total loss 1.1621573
Trained batch 2972 batch loss 0.72865963 epoch total loss 1.1620115
Trained batch 2973 batch loss 0.868926704 epoch total loss 1.16191292
Trained batch 2974 batch loss 1.13149238 epoch total loss 1.16190267
Trained batch 2975 batch loss 1.37523651 epoch total loss 1.16197443
Trained batch 2976 batch loss 1.25726533 epoch total loss 1.16200638
Trained batch 2977 batch loss 1.21205902 epoch total loss 1.16202331
Trained batch 2978 batch loss 1.46008122 epoch total loss 1.16212332
Trained batch 2979 batch loss 1.38026023 epoch total loss 1.16219652
Trained batch 2980 batch loss 1.218647 epoch total loss 1.16221559
Trained batch 2981 batch loss 1.41523123 epoch total loss 1.16230047
Trained batch 2982 batch loss 1.45828509 epoch total loss 1.16239965
Trained batch 2983 batch loss 1.35070944 epoch total loss 1.16246283
Trained batch 2984 batch loss 1.29952812 epoch total loss 1.16250885
Trained batch 2985 batch loss 1.08081198 epoch total loss 1.16248143
Trained batch 2986 batch loss 1.0257324 epoch total loss 1.16243565
Trained batch 2987 batch loss 0.995333672 epoch total loss 1.16237962
Trained batch 2988 batch loss 1.08700633 epoch total loss 1.16235447
Trained batch 2989 batch loss 0.990656376 epoch total loss 1.16229701
Trained batch 2990 batch loss 0.888074517 epoch total loss 1.16220534
Trained batch 2991 batch loss 1.10230231 epoch total loss 1.16218531
Trained batch 2992 batch loss 0.990685 epoch total loss 1.16212797
Trained batch 2993 batch loss 0.949663639 epoch total loss 1.16205704
Trained batch 2994 batch loss 0.745468557 epoch total loss 1.16191781
Trained batch 2995 batch loss 1.08355522 epoch total loss 1.1618917
Trained batch 2996 batch loss 0.99974668 epoch total loss 1.16183758
Trained batch 2997 batch loss 1.09827089 epoch total loss 1.16181636
Trained batch 2998 batch loss 1.11235321 epoch total loss 1.16179979
Trained batch 2999 batch loss 1.04287672 epoch total loss 1.16176021
Trained batch 3000 batch loss 1.13495779 epoch total loss 1.16175127
Trained batch 3001 batch loss 0.931872725 epoch total loss 1.16167474
Trained batch 3002 batch loss 0.885701716 epoch total loss 1.16158283
Trained batch 3003 batch loss 0.940494895 epoch total loss 1.16150916
Trained batch 3004 batch loss 0.960849643 epoch total loss 1.1614424
Trained batch 3005 batch loss 0.873032391 epoch total loss 1.16134644
Trained batch 3006 batch loss 0.919306278 epoch total loss 1.16126585
Trained batch 3007 batch loss 1.14347923 epoch total loss 1.16126
Trained batch 3008 batch loss 0.912126422 epoch total loss 1.16117716
Trained batch 3009 batch loss 1.03701663 epoch total loss 1.16113591
Trained batch 3010 batch loss 0.99638778 epoch total loss 1.16108119
Trained batch 3011 batch loss 1.16252923 epoch total loss 1.16108167
Trained batch 3012 batch loss 1.06216 epoch total loss 1.16104889
Trained batch 3013 batch loss 0.961649716 epoch total loss 1.16098261
Trained batch 3014 batch loss 1.02637327 epoch total loss 1.16093802
Trained batch 3015 batch loss 1.00623035 epoch total loss 1.16088676
Trained batch 3016 batch loss 1.06598 epoch total loss 1.16085529
Trained batch 3017 batch loss 1.33187294 epoch total loss 1.16091192
Trained batch 3018 batch loss 1.12991619 epoch total loss 1.16090167
Trained batch 3019 batch loss 1.11800909 epoch total loss 1.16088736
Trained batch 3020 batch loss 1.12789583 epoch total loss 1.16087651
Trained batch 3021 batch loss 1.03974795 epoch total loss 1.16083634
Trained batch 3022 batch loss 1.0451 epoch total loss 1.16079807
Trained batch 3023 batch loss 1.12097216 epoch total loss 1.16078496
Trained batch 3024 batch loss 1.009552 epoch total loss 1.16073501
Trained batch 3025 batch loss 1.34136724 epoch total loss 1.16079462
Trained batch 3026 batch loss 1.25436735 epoch total loss 1.16082561
Trained batch 3027 batch loss 1.34994388 epoch total loss 1.16088808
Trained batch 3028 batch loss 1.29457736 epoch total loss 1.16093218
Trained batch 3029 batch loss 1.1455853 epoch total loss 1.16092718
Trained batch 3030 batch loss 1.19865644 epoch total loss 1.16093957
Trained batch 3031 batch loss 1.00516701 epoch total loss 1.1608882
Trained batch 3032 batch loss 1.28372884 epoch total loss 1.16092873
Trained batch 3033 batch loss 1.36700952 epoch total loss 1.16099656
Trained batch 3034 batch loss 0.980869234 epoch total loss 1.16093731
Trained batch 3035 batch loss 1.15824461 epoch total loss 1.16093636
Trained batch 3036 batch loss 1.1224097 epoch total loss 1.1609236
Trained batch 3037 batch loss 1.23904 epoch total loss 1.16094935
Trained batch 3038 batch loss 1.13819408 epoch total loss 1.16094184
Trained batch 3039 batch loss 1.27652764 epoch total loss 1.16098
Trained batch 3040 batch loss 1.00639307 epoch total loss 1.16092908
Trained batch 3041 batch loss 1.13993466 epoch total loss 1.16092217
Trained batch 3042 batch loss 1.361624 epoch total loss 1.16098809
Trained batch 3043 batch loss 1.14674199 epoch total loss 1.16098344
Trained batch 3044 batch loss 1.16545308 epoch total loss 1.16098487
Trained batch 3045 batch loss 1.06243503 epoch total loss 1.16095257
Trained batch 3046 batch loss 1.20105517 epoch total loss 1.1609658
Trained batch 3047 batch loss 1.28596222 epoch total loss 1.16100681
Trained batch 3048 batch loss 1.15310526 epoch total loss 1.16100419
Trained batch 3049 batch loss 1.27111411 epoch total loss 1.16104031
Trained batch 3050 batch loss 1.18163788 epoch total loss 1.16104698
Trained batch 3051 batch loss 1.21018398 epoch total loss 1.16106308
Trained batch 3052 batch loss 1.34533095 epoch total loss 1.16112339
Trained batch 3053 batch loss 1.12515521 epoch total loss 1.16111171
Trained batch 3054 batch loss 1.32755089 epoch total loss 1.16116619
Trained batch 3055 batch loss 1.17282057 epoch total loss 1.16117
Trained batch 3056 batch loss 1.31680226 epoch total loss 1.16122103
Trained batch 3057 batch loss 1.05822587 epoch total loss 1.16118729
Trained batch 3058 batch loss 1.27421951 epoch total loss 1.16122425
Trained batch 3059 batch loss 1.15871978 epoch total loss 1.16122341
Trained batch 3060 batch loss 1.09719956 epoch total loss 1.16120243
Trained batch 3061 batch loss 1.31520545 epoch total loss 1.16125274
Trained batch 3062 batch loss 1.16834927 epoch total loss 1.16125512
Trained batch 3063 batch loss 1.10063243 epoch total loss 1.16123533
Trained batch 3064 batch loss 1.24151826 epoch total loss 1.16126144
Trained batch 3065 batch loss 1.19353378 epoch total loss 1.16127205
Trained batch 3066 batch loss 1.18120122 epoch total loss 1.16127849
Trained batch 3067 batch loss 1.36492634 epoch total loss 1.16134501
Trained batch 3068 batch loss 1.15653706 epoch total loss 1.16134334
Trained batch 3069 batch loss 1.10837805 epoch total loss 1.16132617
Trained batch 3070 batch loss 1.19547427 epoch total loss 1.16133726
Trained batch 3071 batch loss 1.1726377 epoch total loss 1.16134095
Trained batch 3072 batch loss 1.06231308 epoch total loss 1.16130865
Trained batch 3073 batch loss 1.11085033 epoch total loss 1.16129231
Trained batch 3074 batch loss 1.19216466 epoch total loss 1.16130233
Trained batch 3075 batch loss 1.03648412 epoch total loss 1.16126168
Trained batch 3076 batch loss 1.12366748 epoch total loss 1.16124952
Trained batch 3077 batch loss 1.07502961 epoch total loss 1.16122139
Trained batch 3078 batch loss 1.18902397 epoch total loss 1.16123044
Trained batch 3079 batch loss 1.07000566 epoch total loss 1.16120088
Trained batch 3080 batch loss 1.07004631 epoch total loss 1.1611712
Trained batch 3081 batch loss 0.935063303 epoch total loss 1.16109788
Trained batch 3082 batch loss 1.25768721 epoch total loss 1.16112912
Trained batch 3083 batch loss 1.23592448 epoch total loss 1.16115344
Trained batch 3084 batch loss 1.18704414 epoch total loss 1.16116178
Trained batch 3085 batch loss 1.19268394 epoch total loss 1.16117203
Trained batch 3086 batch loss 1.06263959 epoch total loss 1.16114008
Trained batch 3087 batch loss 1.05267239 epoch total loss 1.16110492
Trained batch 3088 batch loss 1.31488037 epoch total loss 1.16115475
Trained batch 3089 batch loss 1.11259413 epoch total loss 1.16113901
Trained batch 3090 batch loss 1.18826628 epoch total loss 1.16114783
Trained batch 3091 batch loss 1.04406571 epoch total loss 1.16110992
Trained batch 3092 batch loss 1.14934111 epoch total loss 1.16110611
Trained batch 3093 batch loss 0.915187061 epoch total loss 1.1610266
Trained batch 3094 batch loss 1.15456021 epoch total loss 1.16102457
Trained batch 3095 batch loss 1.05687308 epoch total loss 1.16099095
Trained batch 3096 batch loss 0.981856108 epoch total loss 1.16093302
Trained batch 3097 batch loss 0.895730376 epoch total loss 1.16084743
Trained batch 3098 batch loss 1.0628196 epoch total loss 1.16081583
Trained batch 3099 batch loss 1.05659425 epoch total loss 1.16078222
Trained batch 3100 batch loss 1.04235315 epoch total loss 1.16074395
Trained batch 3101 batch loss 0.86841774 epoch total loss 1.16064966
Trained batch 3102 batch loss 1.09930277 epoch total loss 1.16062987
Trained batch 3103 batch loss 0.980916381 epoch total loss 1.16057193
Trained batch 3104 batch loss 1.07700968 epoch total loss 1.16054499
Trained batch 3105 batch loss 1.39698029 epoch total loss 1.16062117
Trained batch 3106 batch loss 1.27049327 epoch total loss 1.16065657
Trained batch 3107 batch loss 1.1137799 epoch total loss 1.16064143
Trained batch 3108 batch loss 1.24287939 epoch total loss 1.1606679
Trained batch 3109 batch loss 1.2994523 epoch total loss 1.1607126
Trained batch 3110 batch loss 1.13125432 epoch total loss 1.16070318
Trained batch 3111 batch loss 1.09595537 epoch total loss 1.16068232
Trained batch 3112 batch loss 1.31218874 epoch total loss 1.16073108
Trained batch 3113 batch loss 1.12104452 epoch total loss 1.16071832
Trained batch 3114 batch loss 1.17038047 epoch total loss 1.16072142
Trained batch 3115 batch loss 0.95321846 epoch total loss 1.16065478
Trained batch 3116 batch loss 1.03038633 epoch total loss 1.16061294
Trained batch 3117 batch loss 1.52255023 epoch total loss 1.16072905
Trained batch 3118 batch loss 1.30575156 epoch total loss 1.16077554
Trained batch 3786 batch loss 0.960137129 epoch total loss 1.1633532
Trained batch 3787 batch loss 1.01521277 epoch total loss 1.16331398
Trained batch 3788 batch loss 1.04688 epoch total loss 1.16328323
Trained batch 3789 batch loss 1.12459636 epoch total loss 1.1632731
Trained batch 3790 batch loss 1.19374609 epoch total loss 1.16328108
Trained batch 3791 batch loss 1.04934025 epoch total loss 1.16325104
Trained batch 3792 batch loss 1.12303853 epoch total loss 1.16324043
Trained batch 3793 batch loss 1.05000782 epoch total loss 1.16321051
Trained batch 3794 batch loss 1.17788577 epoch total loss 1.16321433
Trained batch 3795 batch loss 1.16537571 epoch total loss 1.16321504
Trained batch 3796 batch loss 1.21389008 epoch total loss 1.16322827
Trained batch 3797 batch loss 1.36945558 epoch total loss 1.16328263
Trained batch 3798 batch loss 1.26597011 epoch total loss 1.16330981
Trained batch 3799 batch loss 1.18926549 epoch total loss 1.16331661
Trained batch 3800 batch loss 1.40986264 epoch total loss 1.16338146
Trained batch 3801 batch loss 1.39681709 epoch total loss 1.16344297
Trained batch 3802 batch loss 1.23920488 epoch total loss 1.16346288
Trained batch 3803 batch loss 1.36161351 epoch total loss 1.16351497
Trained batch 3804 batch loss 1.2235713 epoch total loss 1.16353083
Trained batch 3805 batch loss 1.23445964 epoch total loss 1.16354942
Trained batch 3806 batch loss 1.13731647 epoch total loss 1.16354251
Trained batch 3807 batch loss 1.23659825 epoch total loss 1.16356182
Trained batch 3808 batch loss 1.14917064 epoch total loss 1.16355801
Trained batch 3809 batch loss 1.31146097 epoch total loss 1.16359687
Trained batch 3810 batch loss 1.28940821 epoch total loss 1.16363
Trained batch 3811 batch loss 1.18433583 epoch total loss 1.16363549
Trained batch 3812 batch loss 1.10015857 epoch total loss 1.1636188
Trained batch 3813 batch loss 1.03264976 epoch total loss 1.16358447
Trained batch 3814 batch loss 1.11720538 epoch total loss 1.16357231
Trained batch 3815 batch loss 1.06848133 epoch total loss 1.1635474
Trained batch 3816 batch loss 1.04763091 epoch total loss 1.163517
Trained batch 3817 batch loss 1.03685451 epoch total loss 1.16348374
Trained batch 3818 batch loss 1.17159367 epoch total loss 1.16348588
Trained batch 3819 batch loss 1.34096885 epoch total loss 1.16353226
Trained batch 3820 batch loss 1.32520413 epoch total loss 1.16357458
Trained batch 3821 batch loss 1.32325113 epoch total loss 1.16361642
Trained batch 3822 batch loss 1.36339605 epoch total loss 1.16366863
Trained batch 3823 batch loss 1.31585765 epoch total loss 1.16370845
Trained batch 3824 batch loss 1.21882892 epoch total loss 1.16372287
Trained batch 3825 batch loss 1.22314596 epoch total loss 1.16373837
Trained batch 3826 batch loss 1.37933016 epoch total loss 1.16379476
Trained batch 3827 batch loss 1.12135148 epoch total loss 1.16378367
Trained batch 3828 batch loss 1.11722684 epoch total loss 1.16377151
Trained batch 3829 batch loss 1.09126115 epoch total loss 1.16375268
Trained batch 3830 batch loss 0.84981215 epoch total loss 1.16367066
Trained batch 3831 batch loss 1.13634348 epoch total loss 1.16366339
Trained batch 3832 batch loss 0.839655817 epoch total loss 1.16357899
Trained batch 3833 batch loss 0.959475636 epoch total loss 1.1635257
Trained batch 3834 batch loss 1.05980039 epoch total loss 1.16349852
Trained batch 3835 batch loss 0.979724407 epoch total loss 1.1634506
Trained batch 3836 batch loss 1.24639606 epoch total loss 1.16347229
Trained batch 3837 batch loss 1.2036562 epoch total loss 1.16348267
Trained batch 3838 batch loss 1.09258008 epoch total loss 1.16346431
Trained batch 3839 batch loss 1.2076335 epoch total loss 1.16347575
Trained batch 3840 batch loss 1.04017782 epoch total loss 1.16344368
Trained batch 3841 batch loss 1.07081676 epoch total loss 1.16341949
Trained batch 3842 batch loss 0.890013754 epoch total loss 1.16334844
Trained batch 3843 batch loss 1.0036397 epoch total loss 1.16330671
Trained batch 3844 batch loss 1.19692516 epoch total loss 1.16331542
Trained batch 3845 batch loss 1.07678282 epoch total loss 1.16329288
Trained batch 3846 batch loss 1.14702499 epoch total loss 1.16328871
Trained batch 3847 batch loss 1.10751939 epoch total loss 1.16327417
Trained batch 3848 batch loss 0.963136911 epoch total loss 1.16322219
Trained batch 3849 batch loss 1.20303273 epoch total loss 1.16323256
Trained batch 3850 batch loss 1.14544725 epoch total loss 1.16322803
Trained batch 3851 batch loss 1.15167511 epoch total loss 1.16322505
Trained batch 3852 batch loss 1.46629679 epoch total loss 1.16330373
Trained batch 3853 batch loss 1.24234784 epoch total loss 1.16332424
Trained batch 3854 batch loss 1.31446421 epoch total loss 1.16336346
Trained batch 3855 batch loss 1.2629441 epoch total loss 1.16338933
Trained batch 3856 batch loss 0.96478188 epoch total loss 1.16333783
Trained batch 3857 batch loss 1.04859281 epoch total loss 1.16330814
Trained batch 3858 batch loss 1.07359159 epoch total loss 1.1632849
Trained batch 3859 batch loss 1.07501817 epoch total loss 1.16326201
Trained batch 3860 batch loss 1.16578639 epoch total loss 1.16326272
Trained batch 3861 batch loss 1.20343518 epoch total loss 1.16327322
Trained batch 3862 batch loss 1.22459888 epoch total loss 1.16328907
Trained batch 3863 batch loss 1.32530749 epoch total loss 1.16333103
Trained batch 3864 batch loss 1.18072748 epoch total loss 1.16333556
Trained batch 3865 batch loss 1.24749207 epoch total loss 1.16335726
Trained batch 3866 batch loss 1.23911142 epoch total loss 1.16337693
Trained batch 3867 batch loss 1.00345278 epoch total loss 1.16333556
Trained batch 3868 batch loss 1.19283915 epoch total loss 1.16334319
Trained batch 3869 batch loss 1.26645744 epoch total loss 1.16336989
Trained batch 3870 batch loss 1.36633158 epoch total loss 1.16342235
Trained batch 3871 batch loss 1.3535223 epoch total loss 1.16347146
Trained batch 3872 batch loss 1.39270377 epoch total loss 1.16353059
Trained batch 3873 batch loss 1.60219073 epoch total loss 1.16364384
Trained batch 3874 batch loss 1.42577469 epoch total loss 1.16371143
Trained batch 3875 batch loss 1.73710942 epoch total loss 1.16385949
Trained batch 3876 batch loss 1.27577758 epoch total loss 1.16388845
Trained batch 3877 batch loss 1.25173843 epoch total loss 1.1639111
Trained batch 3878 batch loss 1.53143752 epoch total loss 1.16400588
Trained batch 3879 batch loss 1.42639971 epoch total loss 1.16407347
Trained batch 3880 batch loss 1.31120253 epoch total loss 1.16411138
Trained batch 3881 batch loss 1.43256164 epoch total loss 1.16418052
Trained batch 3882 batch loss 1.2115643 epoch total loss 1.16419268
Trained batch 3883 batch loss 1.26050436 epoch total loss 1.16421759
Trained batch 3884 batch loss 1.06214452 epoch total loss 1.16419125
Trained batch 3885 batch loss 0.939148426 epoch total loss 1.16413331
Trained batch 3886 batch loss 0.993524551 epoch total loss 1.16408944
Trained batch 3887 batch loss 0.985394597 epoch total loss 1.16404343
Trained batch 3888 batch loss 1.01433945 epoch total loss 1.1640048
Trained batch 3889 batch loss 0.919785321 epoch total loss 1.1639421
Trained batch 3890 batch loss 1.03515208 epoch total loss 1.16390896
Trained batch 3891 batch loss 1.28332913 epoch total loss 1.1639396
Trained batch 3892 batch loss 1.31206179 epoch total loss 1.16397774
Trained batch 3893 batch loss 1.5994761 epoch total loss 1.16408956
Trained batch 3894 batch loss 1.39482355 epoch total loss 1.16414893
Trained batch 3895 batch loss 1.28726816 epoch total loss 1.16418052
Trained batch 3896 batch loss 1.39234316 epoch total loss 1.16423905
Trained batch 3897 batch loss 1.41146564 epoch total loss 1.16430259
Trained batch 3898 batch loss 1.26060319 epoch total loss 1.16432726
Trained batch 3899 batch loss 1.44447613 epoch total loss 1.16439915
Trained batch 3900 batch loss 1.23518014 epoch total loss 1.16441727
Trained batch 3901 batch loss 1.32302868 epoch total loss 1.16445804
Trained batch 3902 batch loss 1.24331427 epoch total loss 1.16447818
Trained batch 3903 batch loss 1.15170181 epoch total loss 1.16447496
Trained batch 3904 batch loss 1.33400559 epoch total loss 1.16451836
Trained batch 3905 batch loss 1.37871253 epoch total loss 1.16457331
Trained batch 3906 batch loss 1.33624971 epoch total loss 1.1646173
Trained batch 3907 batch loss 1.20590067 epoch total loss 1.16462791
Trained batch 3908 batch loss 1.18908 epoch total loss 1.16463411
Trained batch 3909 batch loss 0.781023 epoch total loss 1.164536
Trained batch 3910 batch loss 1.02133918 epoch total loss 1.1644994
Trained batch 3911 batch loss 1.24053943 epoch total loss 1.16451895
Trained batch 3912 batch loss 1.27201629 epoch total loss 1.16454637
Trained batch 3913 batch loss 1.22288322 epoch total loss 1.16456127
Trained batch 3914 batch loss 1.39905119 epoch total loss 1.16462111
Trained batch 3915 batch loss 1.21316314 epoch total loss 1.16463363
Trained batch 3916 batch loss 1.32915115 epoch total loss 1.16467559
Trained batch 3917 batch loss 1.10750914 epoch total loss 1.16466093
Trained batch 3918 batch loss 1.12957788 epoch total loss 1.16465199
Trained batch 3919 batch loss 1.29577494 epoch total loss 1.16468549
Trained batch 3920 batch loss 1.29297864 epoch total loss 1.16471815
Trained batch 3921 batch loss 1.32817948 epoch total loss 1.16475987
Trained batch 3922 batch loss 1.42693448 epoch total loss 1.16482663
Trained batch 3923 batch loss 1.31569743 epoch total loss 1.16486514
Trained batch 3924 batch loss 1.31111813 epoch total loss 1.16490245
Trained batch 3925 batch loss 1.35832965 epoch total loss 1.16495168
Trained batch 3926 batch loss 1.38038313 epoch total loss 1.16500664
Trained batch 3927 batch loss 1.38550973 epoch total loss 1.16506279
Trained batch 3928 batch loss 1.57967615 epoch total loss 1.16516829
Trained batch 3929 batch loss 1.48343039 epoch total loss 1.16524935
Trained batch 3930 batch loss 1.41712785 epoch total loss 1.16531336
Trained batch 3931 batch loss 1.22666097 epoch total loss 1.16532898
Trained batch 3932 batch loss 1.06677461 epoch total loss 1.16530395
Trained batch 3933 batch loss 1.09915864 epoch total loss 1.16528714
Trained batch 3934 batch loss 0.946399093 epoch total loss 1.16523147
Trained batch 3935 batch loss 1.14545357 epoch total loss 1.16522646
Trained batch 3936 batch loss 1.27670598 epoch total loss 1.16525483
Trained batch 3937 batch loss 1.3007431 epoch total loss 1.16528916
Trained batch 3938 batch loss 1.06575704 epoch total loss 1.16526401
Trained batch 3939 batch loss 1.2879914 epoch total loss 1.16529512
Trained batch 3940 batch loss 1.18848145 epoch total loss 1.16530108
Trained batch 3941 batch loss 1.07511234 epoch total loss 1.1652782
Trained batch 3942 batch loss 1.20345223 epoch total loss 1.16528785
Trained batch 3943 batch loss 1.09897113 epoch total loss 1.16527116
Trained batch 3944 batch loss 1.19082582 epoch total loss 1.1652776
Trained batch 3945 batch loss 1.29936266 epoch total loss 1.16531157
Trained batch 3946 batch loss 1.30206442 epoch total loss 1.16534626
Trained batch 3947 batch loss 1.12939644 epoch total loss 1.1653372
Trained batch 3948 batch loss 1.22999203 epoch total loss 1.16535354
Trained batch 3949 batch loss 1.23446798 epoch total loss 1.16537106
Trained batch 3950 batch loss 1.29601371 epoch total loss 1.16540408
Trained batch 3951 batch loss 1.25092554 epoch total loss 1.16542578
Trained batch 3952 batch loss 1.21893167 epoch total loss 1.16543925
Trained batch 3953 batch loss 1.30579281 epoch total loss 1.16547477
Trained batch 3954 batch loss 1.2382071 epoch total loss 1.16549313
Trained batch 3955 batch loss 1.34170079 epoch total loss 1.16553771
Trained batch 3956 batch loss 1.52139401 epoch total loss 1.16562772
Trained batch 3957 batch loss 1.2209363 epoch total loss 1.16564167
Trained batch 3958 batch loss 1.45583296 epoch total loss 1.16571498
Trained batch 3959 batch loss 1.29769659 epoch total loss 1.16574836
Trained batch 3960 batch loss 1.4367609 epoch total loss 1.16581678
Trained batch 3961 batch loss 1.4539361 epoch total loss 1.1658895
Trained batch 3962 batch loss 1.4015404 epoch total loss 1.16594899
Trained batch 3963 batch loss 1.26986575 epoch total loss 1.16597521
Trained batch 3964 batch loss 1.23746252 epoch total loss 1.16599321
Trained batch 3965 batch loss 1.34069788 epoch total loss 1.16603732
Trained batch 3966 batch loss 1.32089186 epoch total loss 1.1660763
Trained batch 3967 batch loss 1.24673104 epoch total loss 1.16609657
Trained batch 3968 batch loss 1.51831591 epoch total loss 1.1661855
Trained batch 3969 batch loss 1.43058491 epoch total loss 1.16625214
Trained batch 3970 batch loss 1.4172492 epoch total loss 1.16631532
Trained batch 3971 batch loss 1.39479923 epoch total loss 1.1663729
Trained batch 3972 batch loss 1.30372405 epoch total loss 1.16640759
Trained batch 3973 batch loss 1.36584353 epoch total loss 1.16645765
Trained batch 3974 batch loss 1.30698824 epoch total loss 1.16649306
Trained batch 3975 batch loss 1.30015111 epoch total loss 1.16652679
Trained batch 3976 batch loss 1.42564487 epoch total loss 1.166592
Trained batch 3977 batch loss 1.37654531 epoch total loss 1.16664469
Trained batch 3978 batch loss 1.21920478 epoch total loss 1.16665792
Trained batch 3979 batch loss 1.37733328 epoch total loss 1.16671097
Trained batch 3980 batch loss 1.42641091 epoch total loss 1.16677618
Trained batch 3981 batch loss 1.28871346 epoch total loss 1.1668067
Trained batch 3982 batch loss 1.23607612 epoch total loss 1.1668241
Trained batch 3983 batch loss 1.23429823 epoch total loss 1.16684103
Trained batch 3984 batch loss 1.32321715 epoch total loss 1.16688025
Trained batch 3985 batch loss 1.26274943 epoch total loss 1.16690433
Trained batch 3986 batch loss 1.26073337 epoch total loss 1.16692793
Trained batch 3987 batch loss 1.16564417 epoch total loss 1.16692758
Trained batch 3988 batch loss 1.29064548 epoch total loss 1.16695857
Trained batch 3989 batch loss 1.19667745 epoch total loss 1.16696596
Trained batch 3990 batch loss 1.27803612 epoch total loss 1.16699374
Trained batch 3991 batch loss 0.992160559 epoch total loss 1.16695
Trained batch 3992 batch loss 0.865569711 epoch total loss 1.16687453
Trained batch 3993 batch loss 1.07548499 epoch total loss 1.16685164
Trained batch 3994 batch loss 0.921969175 epoch total loss 1.16679037
Trained batch 3995 batch loss 0.868868291 epoch total loss 1.16671574
Trained batch 3996 batch loss 0.774711609 epoch total loss 1.16661763
Trained batch 3997 batch loss 0.815992951 epoch total loss 1.16652989
Trained batch 3998 batch loss 1.13357687 epoch total loss 1.16652179
Trained batch 3999 batch loss 1.20896435 epoch total loss 1.1665324
Trained batch 4000 batch loss 1.13199186 epoch total loss 1.16652369
Trained batch 4001 batch loss 1.16156399 epoch total loss 1.1665225
Trained batch 4002 batch loss 1.29548454 epoch total loss 1.16655469
Trained batch 4003 batch loss 1.39503288 epoch total loss 1.16661179
Trained batch 4004 batch loss 1.41815066 epoch total loss 1.16667449
Trained batch 4005 batch loss 1.39213872 epoch total loss 1.16673076
Trained batch 4006 batch loss 1.33756328 epoch total loss 1.16677344
Trained batch 4007 batch loss 1.19606185 epoch total loss 1.16678071
Trained batch 4008 batch loss 1.19125772 epoch total loss 1.16678691
Trained batch 4009 batch loss 1.12814116 epoch total loss 1.16677725
Trained batch 4010 batch loss 1.275105 epoch total loss 1.16680419
Trained batch 4011 batch loss 1.29973602 epoch total loss 1.16683733
Trained batch 4012 batch loss 1.28446484 epoch total loss 1.16686666
Trained batch 4013 batch loss 1.1118896 epoch total loss 1.16685295
Trained batch 4014 batch loss 1.19996953 epoch total loss 1.1668613
Trained batch 4015 batch loss 1.10398388 epoch total loss 1.16684568
Trained batch 4016 batch loss 1.20487297 epoch total loss 1.16685522
Trained batch 4017 batch loss 1.32616878 epoch total loss 1.16689479
Trained batch 4018 batch loss 1.58555198 epoch total loss 1.16699898
Trained batch 4019 batch loss 1.52376926 epoch total loss 1.16708779
Trained batch 4020 batch loss 1.29732668 epoch total loss 1.16712022
Trained batch 4021 batch loss 1.18071914 epoch total loss 1.16712356
Trained batch 4022 batch loss 1.26838732 epoch total loss 1.16714883
Trained batch 4023 batch loss 1.11830449 epoch total loss 1.16713667
Trained batch 4024 batch loss 1.32585645 epoch total loss 1.16717601
Trained batch 4025 batch loss 1.22580576 epoch total loss 1.16719055
Trained batch 4026 batch loss 1.09736693 epoch total loss 1.16717315
Trained batch 4027 batch loss 0.987638593 epoch total loss 1.16712856
Trained batch 4028 batch loss 1.28784227 epoch total loss 1.1671586
Trained batch 4029 batch loss 1.3456248 epoch total loss 1.16720295
Trained batch 4030 batch loss 1.3145349 epoch total loss 1.16723943
Trained batch 4031 batch loss 1.39196944 epoch total loss 1.16729522
Trained batch 4032 batch loss 1.24444723 epoch total loss 1.16731441
Trained batch 4033 batch loss 1.32262385 epoch total loss 1.16735303
Trained batch 4034 batch loss 1.33090043 epoch total loss 1.16739357
Trained batch 4035 batch loss 1.2925334 epoch total loss 1.16742456
Trained batch 4036 batch loss 0.992111444 epoch total loss 1.16738117
Trained batch 4037 batch loss 1.16844153 epoch total loss 1.16738141
Trained batch 4038 batch loss 1.32434654 epoch total loss 1.16742027
Trained batch 4039 batch loss 1.12699258 epoch total loss 1.16741025
Trained batch 4040 batch loss 1.17162228 epoch total loss 1.16741121
Trained batch 4041 batch loss 1.04452801 epoch total loss 1.16738081
Trained batch 4042 batch loss 0.968433261 epoch total loss 1.16733158
Trained batch 4043 batch loss 1.06691587 epoch total loss 1.16730666
Trained batch 4044 batch loss 0.894496322 epoch total loss 1.16723919
Trained batch 4045 batch loss 1.19120061 epoch total loss 1.16724515
Trained batch 4046 batch loss 1.02659285 epoch total loss 1.16721034
Trained batch 4047 batch loss 1.1387651 epoch total loss 1.16720331
Trained batch 4048 batch loss 0.945729494 epoch total loss 1.16714859
Trained batch 4049 batch loss 0.760694087 epoch total loss 1.16704822
Trained batch 4050 batch loss 0.87622714 epoch total loss 1.16697657
Trained batch 4051 batch loss 0.867451191 epoch total loss 1.16690266
Trained batch 4052 batch loss 0.797645807 epoch total loss 1.16681159
Trained batch 4053 batch loss 1.12469792 epoch total loss 1.1668011
Trained batch 4054 batch loss 1.07777596 epoch total loss 1.16677916
Trained batch 4055 batch loss 1.02534795 epoch total loss 1.16674423
Trained batch 4056 batch loss 1.22624922 epoch total loss 1.16675889
Trained batch 4057 batch loss 1.15752029 epoch total loss 1.16675663
Trained batch 4058 batch loss 1.14022112 epoch total loss 1.16675007
Trained batch 4059 batch loss 1.37845421 epoch total loss 1.16680229
Trained batch 4060 batch loss 1.2257036 epoch total loss 1.16681671
Trained batch 4061 batch loss 1.23618066 epoch total loss 1.16683388
Trained batch 4062 batch loss 0.907551587 epoch total loss 1.1667701
Trained batch 4063 batch loss 1.24209654 epoch total loss 1.16678858
Trained batch 4064 batch loss 1.35219216 epoch total loss 1.16683424
Trained batch 4065 batch loss 1.06795645 epoch total loss 1.1668098
Trained batch 4066 batch loss 1.26593626 epoch total loss 1.16683424
Trained batch 4067 batch loss 1.13424921 epoch total loss 1.16682625
Trained batch 4068 batch loss 1.05694532 epoch total loss 1.16679931
Trained batch 4069 batch loss 1.23780227 epoch total loss 1.16681671
Trained batch 4070 batch loss 1.42157459 epoch total loss 1.1668793
Trained batch 4071 batch loss 1.36562896 epoch total loss 1.16692817
Trained batch 4072 batch loss 1.25741434 epoch total loss 1.16695035
Trained batch 4073 batch loss 1.2552824 epoch total loss 1.16697204
Trained batch 4074 batch loss 1.15836251 epoch total loss 1.1669699
Trained batch 4075 batch loss 1.18045211 epoch total loss 1.16697323
Trained batch 4076 batch loss 1.0873822 epoch total loss 1.16695368
Trained batch 4077 batch loss 1.10774159 epoch total loss 1.16693926
Trained batch 4078 batch loss 0.972072 epoch total loss 1.16689146
Trained batch 4079 batch loss 0.864752054 epoch total loss 1.16681743
Trained batch 4080 batch loss 0.893739641 epoch total loss 1.16675043
Trained batch 4081 batch loss 0.844461501 epoch total loss 1.1666714
Trained batch 4082 batch loss 0.664678514 epoch total loss 1.16654837
Trained batch 4083 batch loss 0.933334947 epoch total loss 1.16649127
Trained batch 4084 batch loss 0.908001661 epoch total loss 1.16642797
Trained batch 4085 batch loss 0.813409925 epoch total loss 1.16634154
Trained batch 4086 batch loss 0.868069887 epoch total loss 1.16626859
Trained batch 4087 batch loss 0.85991329 epoch total loss 1.1661936
Trained batch 4088 batch loss 1.18225408 epoch total loss 1.16619754
Trained batch 4089 batch loss 1.33853114 epoch total loss 1.16623962
Trained batch 4090 batch loss 1.13925076 epoch total loss 1.16623306
Trained batch 4091 batch loss 1.35383511 epoch total loss 1.16627896
Trained batch 4092 batch loss 1.23909855 epoch total loss 1.16629672
Trained batch 4093 batch loss 1.10261726 epoch total loss 1.16628122
Trained batch 4094 batch loss 1.39007878 epoch total loss 1.16633582
Trained batch 4095 batch loss 1.38841343 epoch total loss 1.16639006
Trained batch 4096 batch loss 1.29390705 epoch total loss 1.16642118
Trained batch 4097 batch loss 1.39826155 epoch total loss 1.1664778
Trained batch 4098 batch loss 1.60868156 epoch total loss 1.1665858
Trained batch 4099 batch loss 1.51885402 epoch total loss 1.16667175
Trained batch 4100 batch loss 1.55495977 epoch total loss 1.16676652
Trained batch 4101 batch loss 1.59896088 epoch total loss 1.16687191
Trained batch 4102 batch loss 1.11677241 epoch total loss 1.16685975
Trained batch 4103 batch loss 0.928613365 epoch total loss 1.16680169
Trained batch 4104 batch loss 0.885164917 epoch total loss 1.16673303
Trained batch 4105 batch loss 1.17905104 epoch total loss 1.16673613
Trained batch 4106 batch loss 1.31014371 epoch total loss 1.16677105
Trained batch 4107 batch loss 0.956582308 epoch total loss 1.16671979
Trained batch 4108 batch loss 0.998872519 epoch total loss 1.16667902
Trained batch 4109 batch loss 0.868973732 epoch total loss 1.16660655
Trained batch 4110 batch loss 1.21300244 epoch total loss 1.16661787
Trained batch 4111 batch loss 1.32163906 epoch total loss 1.16665554
Trained batch 4112 batch loss 1.02274847 epoch total loss 1.16662061
Trained batch 4113 batch loss 1.21407413 epoch total loss 1.16663218
Trained batch 4114 batch loss 1.17191839 epoch total loss 1.16663337
Trained batch 4115 batch loss 1.30950963 epoch total loss 1.16666818
Trained batch 4116 batch loss 1.19787526 epoch total loss 1.16667569
Trained batch 4117 batch loss 1.13702464 epoch total loss 1.16666853
Trained batch 4118 batch loss 1.31880951 epoch total loss 1.16670549
Trained batch 4119 batch loss 1.2003541 epoch total loss 1.1667136
Trained batch 4120 batch loss 1.18692803 epoch total loss 1.16671848
Trained batch 4121 batch loss 1.17968118 epoch total loss 1.1667217
Trained batch 4122 batch loss 1.08474994 epoch total loss 1.16670179
Trained batch 4123 batch loss 1.26772475 epoch total loss 1.16672635
Trained batch 4124 batch loss 1.27225375 epoch total loss 1.16675198
Trained batch 4125 batch loss 1.22932351 epoch total loss 1.16676712
Trained batch 4126 batch loss 1.00630879 epoch total loss 1.16672826
Trained batch 4127 batch loss 1.2726481 epoch total loss 1.16675389
Trained batch 4128 batch loss 0.991849 epoch total loss 1.16671145
Trained batch 4129 batch loss 1.08334208 epoch total loss 1.1666913
Trained batch 4130 batch loss 1.32486355 epoch total loss 1.16672957
Trained batch 4131 batch loss 1.25333774 epoch total loss 1.16675055
Trained batch 4132 batch loss 1.30943751 epoch total loss 1.16678512
Trained batch 4133 batch loss 1.33354473 epoch total loss 1.16682553
Trained batch 4134 batch loss 1.3488884 epoch total loss 1.16686964
Trained batch 4135 batch loss 1.23301709 epoch total loss 1.16688561
Trained batch 4136 batch loss 1.09202099 epoch total loss 1.16686738
Trained batch 4137 batch loss 0.922609031 epoch total loss 1.16680837
Trained batch 4138 batch loss 1.09279823 epoch total loss 1.16679049
Trained batch 4139 batch loss 1.04402387 epoch total loss 1.1667608
Trained batch 4140 batch loss 1.38027573 epoch total loss 1.16681242
Trained batch 4141 batch loss 1.21516263 epoch total loss 1.1668241
Trained batch 4142 batch loss 0.890558481 epoch total loss 1.16675746
Trained batch 4143 batch loss 1.04755235 epoch total loss 1.16672862
Trained batch 4144 batch loss 1.10942209 epoch total loss 1.16671479
Trained batch 4145 batch loss 1.12209558 epoch total loss 1.16670406
Trained batch 4146 batch loss 0.998255 epoch total loss 1.16666341
Trained batch 4147 batch loss 1.06938529 epoch total loss 1.16663992
Trained batch 4148 batch loss 1.11590123 epoch total loss 1.16662765
Trained batch 4149 batch loss 1.18291545 epoch total loss 1.16663158
Trained batch 4150 batch loss 1.02059853 epoch total loss 1.16659641
Trained batch 4151 batch loss 1.13730371 epoch total loss 1.16658926
Trained batch 4152 batch loss 0.981824577 epoch total loss 1.1665448
Trained batch 4153 batch loss 1.11176157 epoch total loss 1.16653168
Trained batch 4154 batch loss 1.36097229 epoch total loss 1.16657841
Trained batch 4155 batch loss 1.22991467 epoch total loss 1.16659367
Trained batch 4156 batch loss 1.52295363 epoch total loss 1.16667938
Trained batch 4157 batch loss 1.10247374 epoch total loss 1.166664
Trained batch 4158 batch loss 1.00838697 epoch total loss 1.16662598
Trained batch 4159 batch loss 1.05885458 epoch total loss 1.16660011
Trained batch 4160 batch loss 1.11549139 epoch total loss 1.16658783
Trained batch 4161 batch loss 0.817510724 epoch total loss 1.16650391
Trained batch 4162 batch loss 0.898532152 epoch total loss 1.16643953
Trained batch 4163 batch loss 0.68743217 epoch total loss 1.1663245
Trained batch 4164 batch loss 0.956364393 epoch total loss 1.16627407
Trained batch 4165 batch loss 1.24012041 epoch total loss 1.16629183
Trained batch 4166 batch loss 0.934356332 epoch total loss 1.16623616
Trained batch 4167 batch loss 1.18239653 epoch total loss 1.1662401
Trained batch 4168 batch loss 1.1285578 epoch total loss 1.16623104
Trained batch 4169 batch loss 1.14608061 epoch total loss 1.16622627
Trained batch 4170 batch loss 1.18342423 epoch total loss 1.16623032
Trained batch 4171 batch loss 1.10527241 epoch total loss 1.16621578
Trained batch 4172 batch loss 0.975925 epoch total loss 1.16617024
Trained batch 4173 batch loss 1.1553117 epoch total loss 1.16616762
Trained batch 4174 batch loss 1.3482343 epoch total loss 1.16621125
Trained batch 4175 batch loss 1.15520835 epoch total loss 1.16620862
Trained batch 4176 batch loss 1.2928009 epoch total loss 1.1662389
Trained batch 4177 batch loss 1.26642132 epoch total loss 1.16626298
Trained batch 4178 batch loss 1.1077044 epoch total loss 1.16624904
Trained batch 4179 batch loss 1.18518436 epoch total loss 1.16625357
Trained batch 4180 batch loss 1.05871916 epoch total loss 1.16622782
Trained batch 4181 batch loss 1.10287607 epoch total loss 1.16621268
Trained batch 4182 batch loss 1.27158034 epoch total loss 1.16623783
Trained batch 4183 batch loss 1.08848763 epoch total loss 1.16621923
Trained batch 4184 batch loss 1.2132 epoch total loss 1.16623044
Trained batch 4185 batch loss 1.05646646 epoch total loss 1.16620433
Trained batch 4186 batch loss 1.15597391 epoch total loss 1.16620183
Trained batch 4187 batch loss 1.15978718 epoch total loss 1.16620028
Trained batch 4188 batch loss 1.20798266 epoch total loss 1.16621017
Trained batch 4189 batch loss 0.983057737 epoch total loss 1.16616642
Trained batch 4190 batch loss 0.99850291 epoch total loss 1.16612649
Trained batch 4191 batch loss 1.03476405 epoch total loss 1.16609514
Trained batch 4192 batch loss 1.1749289 epoch total loss 1.16609716
Trained batch 4193 batch loss 1.15510559 epoch total loss 1.16609454
Trained batch 4194 batch loss 1.21140766 epoch total loss 1.16610539
Trained batch 4195 batch loss 1.16412759 epoch total loss 1.16610491
Trained batch 4196 batch loss 1.21273208 epoch total loss 1.166116
Trained batch 4197 batch loss 1.43960595 epoch total loss 1.16618121
Trained batch 4198 batch loss 1.23787546 epoch total loss 1.16619825
Trained batch 4199 batch loss 1.27458167 epoch total loss 1.166224
Trained batch 4200 batch loss 1.07926917 epoch total loss 1.16620326
Trained batch 4201 batch loss 1.36041355 epoch total loss 1.16624951
Trained batch 4202 batch loss 1.02881289 epoch total loss 1.16621673
Trained batch 4203 batch loss 1.23642659 epoch total loss 1.16623342
Trained batch 4204 batch loss 1.34187794 epoch total loss 1.16627526
Trained batch 4205 batch loss 1.19155502 epoch total loss 1.16628122
Trained batch 4206 batch loss 1.18541884 epoch total loss 1.16628575
Trained batch 4207 batch loss 1.28111398 epoch total loss 1.16631305
Trained batch 4208 batch loss 1.28795815 epoch total loss 1.16634202
Trained batch 4209 batch loss 1.09197235 epoch total loss 1.16632438
Trained batch 4210 batch loss 1.04409301 epoch total loss 1.16629529
Trained batch 4211 batch loss 1.239604 epoch total loss 1.16631269
Trained batch 4212 batch loss 1.01459467 epoch total loss 1.16627669
Trained batch 4213 batch loss 1.09245729 epoch total loss 1.16625917
Trained batch 4214 batch loss 1.01213408 epoch total loss 1.16622257
Trained batch 4215 batch loss 1.17010188 epoch total loss 1.16622341
Trained batch 4216 batch loss 1.03207946 epoch total loss 1.1661917
Trained batch 4217 batch loss 1.04033303 epoch total loss 1.16616189
Trained batch 4218 batch loss 1.09174263 epoch total loss 1.16614425
Trained batch 4219 batch loss 1.23122573 epoch total loss 1.16615975
Trained batch 4220 batch loss 1.19959426 epoch total loss 1.16616762
Trained batch 4221 batch loss 1.26737034 epoch total loss 1.1661917
Trained batch 4222 batch loss 1.24457896 epoch total loss 1.16621029
Trained batch 4223 batch loss 1.20005023 epoch total loss 1.16621828
Trained batch 4224 batch loss 1.2573123 epoch total loss 1.16623986
Trained batch 4225 batch loss 1.37989736 epoch total loss 1.1662904
Trained batch 4226 batch loss 1.20668721 epoch total loss 1.16629994
Trained batch 4227 batch loss 1.27500379 epoch total loss 1.16632569
Trained batch 4228 batch loss 1.17545414 epoch total loss 1.16632783
Trained batch 4229 batch loss 1.23193097 epoch total loss 1.16634333
Trained batch 4230 batch loss 1.1604948 epoch total loss 1.1663419
Trained batch 4231 batch loss 1.38457716 epoch total loss 1.16639364
Trained batch 4232 batch loss 1.23303652 epoch total loss 1.16640925
Trained batch 4233 batch loss 1.34862733 epoch total loss 1.16645229
Trained batch 4234 batch loss 1.39867115 epoch total loss 1.16650712
Trained batch 4235 batch loss 1.28784204 epoch total loss 1.16653585
Trained batch 4236 batch loss 1.30216765 epoch total loss 1.16656792
Trained batch 4237 batch loss 1.2576164 epoch total loss 1.16658938
Trained batch 4238 batch loss 1.22688115 epoch total loss 1.16660368
Trained batch 4239 batch loss 1.35796487 epoch total loss 1.16664886
Trained batch 4240 batch loss 1.13969195 epoch total loss 1.16664243
Trained batch 4241 batch loss 1.27114594 epoch total loss 1.1666671
Trained batch 4242 batch loss 1.11250794 epoch total loss 1.16665423
Trained batch 4243 batch loss 1.29535103 epoch total loss 1.16668463
Trained batch 4244 batch loss 1.37466979 epoch total loss 1.1667335
Trained batch 4245 batch loss 1.32050335 epoch total loss 1.16676974
Trained batch 4246 batch loss 1.2430377 epoch total loss 1.16678774
Trained batch 4247 batch loss 1.05137289 epoch total loss 1.16676056
Trained batch 4248 batch loss 1.0425806 epoch total loss 1.16673124
Trained batch 4249 batch loss 1.0232563 epoch total loss 1.1666975
Trained batch 4250 batch loss 0.971363842 epoch total loss 1.16665149
Trained batch 4251 batch loss 1.27916491 epoch total loss 1.16667807
Trained batch 4252 batch loss 1.24694157 epoch total loss 1.16669691
Trained batch 4253 batch loss 1.15884984 epoch total loss 1.16669512
Trained batch 4254 batch loss 1.04613602 epoch total loss 1.16666663
Trained batch 4255 batch loss 1.25370574 epoch total loss 1.16668713
Trained batch 4256 batch loss 1.14444518 epoch total loss 1.166682
Trained batch 4257 batch loss 1.10289347 epoch total loss 1.16666698
Trained batch 4258 batch loss 0.974580884 epoch total loss 1.16662192
Trained batch 4259 batch loss 1.25104117 epoch total loss 1.16664171
Trained batch 4260 batch loss 1.19201279 epoch total loss 1.16664767
Trained batch 4261 batch loss 0.952826142 epoch total loss 1.16659737
Trained batch 4262 batch loss 1.25712442 epoch total loss 1.1666187
Trained batch 4263 batch loss 1.03768158 epoch total loss 1.16658843
Trained batch 4264 batch loss 0.833085656 epoch total loss 1.16651022
Trained batch 4265 batch loss 1.31340575 epoch total loss 1.16654468
Trained batch 4266 batch loss 1.10815358 epoch total loss 1.16653097
Trained batch 4267 batch loss 1.1001997 epoch total loss 1.16651535
Trained batch 4268 batch loss 1.09455574 epoch total loss 1.16649854
Trained batch 4269 batch loss 1.10779691 epoch total loss 1.16648483
Trained batch 4270 batch loss 1.0778482 epoch total loss 1.16646397
Trained batch 4271 batch loss 1.06060863 epoch total loss 1.16643918
Trained batch 4272 batch loss 1.01231718 epoch total loss 1.16640306
Trained batch 4273 batch loss 1.02769554 epoch total loss 1.16637063
Trained batch 4274 batch loss 1.11524689 epoch total loss 1.16635871
Trained batch 4275 batch loss 1.13856542 epoch total loss 1.16635227
Trained batch 4276 batch loss 1.22097874 epoch total loss 1.16636503
Trained batch 4277 batch loss 1.35238075 epoch total loss 1.16640854
Trained batch 4278 batch loss 1.22329545 epoch total loss 1.16642189
Trained batch 4279 batch loss 0.978970766 epoch total loss 1.16637802
Trained batch 4280 batch loss 1.0109942 epoch total loss 1.16634178
Trained batch 4281 batch loss 1.12548757 epoch total loss 1.16633224
Trained batch 4282 batch loss 1.13100529 epoch total loss 1.16632402
Trained batch 4283 batch loss 0.876492143 epoch total loss 1.16625631
Trained batch 4284 batch loss 1.037287 epoch total loss 1.16622615
Trained batch 4285 batch loss 0.949909091 epoch total loss 1.1661756
Trained batch 4286 batch loss 1.03227437 epoch total loss 1.16614437
Trained batch 4287 batch loss 1.00977194 epoch total loss 1.16610789
Trained batch 4288 batch loss 1.02846956 epoch total loss 1.16607571
Trained batch 4289 batch loss 0.87984097 epoch total loss 1.16600907
Trained batch 4290 batch loss 0.673035 epoch total loss 1.16589403
Trained batch 4291 batch loss 0.73066479 epoch total loss 1.16579258
Trained batch 4292 batch loss 0.820218146 epoch total loss 1.16571212
Trained batch 4293 batch loss 0.906745553 epoch total loss 1.1656518
Trained batch 4294 batch loss 1.00205779 epoch total loss 1.16561365
Trained batch 4295 batch loss 0.981851 epoch total loss 1.16557086
Trained batch 4296 batch loss 1.1943419 epoch total loss 1.16557753
Trained batch 4297 batch loss 1.38662934 epoch total loss 1.16562903
Trained batch 4298 batch loss 1.34348416 epoch total loss 1.16567039
Trained batch 4299 batch loss 1.37243354 epoch total loss 1.16571856
Trained batch 4300 batch loss 1.15849376 epoch total loss 1.16571689
Trained batch 4301 batch loss 1.19682097 epoch total loss 1.16572404
Trained batch 4302 batch loss 1.10222673 epoch total loss 1.16570926
Trained batch 4303 batch loss 1.07225192 epoch total loss 1.16568756
Trained batch 4304 batch loss 1.09304583 epoch total loss 1.16567075
Trained batch 4305 batch loss 1.2778976 epoch total loss 1.16569674
Trained batch 4306 batch loss 0.87697506 epoch total loss 1.16562974
Trained batch 4307 batch loss 1.08960843 epoch total loss 1.1656121
Trained batch 4308 batch loss 1.08591974 epoch total loss 1.16559362
Trained batch 4309 batch loss 1.34036088 epoch total loss 1.16563416
Trained batch 4310 batch loss 1.19111681 epoch total loss 1.16564012
Trained batch 4311 batch loss 1.02304721 epoch total loss 1.16560698
Trained batch 4312 batch loss 1.19443643 epoch total loss 1.16561365
Trained batch 4313 batch loss 1.13983202 epoch total loss 1.16560757
Trained batch 4314 batch loss 1.17666984 epoch total loss 1.16561019
Trained batch 4315 batch loss 0.997253 epoch total loss 1.16557109
Trained batch 4316 batch loss 1.10082102 epoch total loss 1.16555607
Trained batch 4317 batch loss 0.958528936 epoch total loss 1.16550815
Trained batch 4318 batch loss 0.915321708 epoch total loss 1.16545022
Trained batch 4319 batch loss 0.916479766 epoch total loss 1.16539264
Trained batch 4320 batch loss 1.01953602 epoch total loss 1.16535878
Trained batch 4321 batch loss 1.01393592 epoch total loss 1.16532385
Trained batch 4322 batch loss 1.11592984 epoch total loss 1.16531241
Trained batch 4323 batch loss 0.953283787 epoch total loss 1.1652633
Trained batch 4324 batch loss 1.30857611 epoch total loss 1.16529644
Trained batch 4325 batch loss 1.02336252 epoch total loss 1.16526365
Trained batch 4326 batch loss 0.9921363 epoch total loss 1.1652236
Trained batch 4327 batch loss 1.17115521 epoch total loss 1.16522503
Trained batch 4328 batch loss 1.26237392 epoch total loss 1.16524744
Trained batch 4329 batch loss 0.877434552 epoch total loss 1.16518092
Trained batch 4330 batch loss 1.32176352 epoch total loss 1.16521716
Trained batch 4331 batch loss 1.08352911 epoch total loss 1.16519821
Trained batch 4332 batch loss 1.2013092 epoch total loss 1.16520655
Trained batch 4333 batch loss 1.21451461 epoch total loss 1.16521788
Trained batch 4334 batch loss 0.996097565 epoch total loss 1.16517889
Trained batch 4335 batch loss 1.39024007 epoch total loss 1.16523075
Trained batch 4336 batch loss 1.14608133 epoch total loss 1.16522634
Trained batch 4337 batch loss 1.05312705 epoch total loss 1.16520047
Trained batch 4338 batch loss 1.12275815 epoch total loss 1.1651907
Trained batch 4339 batch loss 1.15829813 epoch total loss 1.16518903
Trained batch 4340 batch loss 1.07881188 epoch total loss 1.16516912
Trained batch 4341 batch loss 1.07511258 epoch total loss 1.16514838
Trained batch 4342 batch loss 1.086743 epoch total loss 1.16513038
Trained batch 4343 batch loss 1.00666833 epoch total loss 1.1650939
Trained batch 4344 batch loss 1.05961323 epoch total loss 1.16506958
Trained batch 4345 batch loss 1.22519195 epoch total loss 1.16508341
Trained batch 4346 batch loss 1.37861967 epoch total loss 1.16513252
Trained batch 4347 batch loss 1.25433159 epoch total loss 1.16515303
Trained batch 4348 batch loss 1.19986725 epoch total loss 1.16516101
Trained batch 4349 batch loss 1.35812545 epoch total loss 1.16520536
Trained batch 4350 batch loss 1.02713275 epoch total loss 1.16517365
Trained batch 4351 batch loss 1.07675648 epoch total loss 1.16515326
Trained batch 4352 batch loss 1.12213731 epoch total loss 1.16514337
Trained batch 4353 batch loss 1.1735177 epoch total loss 1.16514528
Trained batch 4354 batch loss 1.29976618 epoch total loss 1.16517627
Trained batch 4355 batch loss 1.45378447 epoch total loss 1.16524243
Trained batch 4356 batch loss 1.43226075 epoch total loss 1.16530371
Trained batch 4357 batch loss 1.24082494 epoch total loss 1.16532099
Trained batch 4358 batch loss 1.48145986 epoch total loss 1.16539359
Trained batch 4359 batch loss 1.24628806 epoch total loss 1.16541207
Trained batch 4360 batch loss 1.36733651 epoch total loss 1.16545832
Trained batch 4361 batch loss 1.2642504 epoch total loss 1.16548097
Trained batch 4362 batch loss 1.53178072 epoch total loss 1.16556501
Trained batch 4363 batch loss 1.35131 epoch total loss 1.16560745
Trained batch 4364 batch loss 1.61166835 epoch total loss 1.16570973
Trained batch 4365 batch loss 1.31794846 epoch total loss 1.16574454
Trained batch 4366 batch loss 1.29678428 epoch total loss 1.16577458
Trained batch 4367 batch loss 1.40458345 epoch total loss 1.1658293
Trained batch 4368 batch loss 1.25789452 epoch total loss 1.1658504
Trained batch 4369 batch loss 1.04173684 epoch total loss 1.16582191
Trained batch 4370 batch loss 1.21134853 epoch total loss 1.1658324
Trained batch 4371 batch loss 0.901184857 epoch total loss 1.16577184
Trained batch 4372 batch loss 0.913988471 epoch total loss 1.16571426
Trained batch 4373 batch loss 0.966608763 epoch total loss 1.16566885
Trained batch 4374 batch loss 0.952591062 epoch total loss 1.16562009
Trained batch 4375 batch loss 1.08545303 epoch total loss 1.16560173
Trained batch 4376 batch loss 1.2636739 epoch total loss 1.16562414
Trained batch 4377 batch loss 1.30736065 epoch total loss 1.16565657
Trained batch 4378 batch loss 1.2121675 epoch total loss 1.16566718
Trained batch 4379 batch loss 1.31783926 epoch total loss 1.16570199
Trained batch 4380 batch loss 1.11673427 epoch total loss 1.16569078
Trained batch 4381 batch loss 1.03108692 epoch total loss 1.16566014
Trained batch 4382 batch loss 1.25127935 epoch total loss 1.16567969
Trained batch 4383 batch loss 1.05701399 epoch total loss 1.1656549
Trained batch 4384 batch loss 0.891995192 epoch total loss 1.16559255
Trained batch 4385 batch loss 0.970667839 epoch total loss 1.16554809
Trained batch 4386 batch loss 0.863146782 epoch total loss 1.16547918
Trained batch 4387 batch loss 0.950811207 epoch total loss 1.16543019
Trained batch 4388 batch loss 1.06010771 epoch total loss 1.16540611
Trained batch 4389 batch loss 1.07392764 epoch total loss 1.16538525
Trained batch 4390 batch loss 1.14486909 epoch total loss 1.1653806
Trained batch 4391 batch loss 0.939880252 epoch total loss 1.16532934
Trained batch 4392 batch loss 0.921352267 epoch total loss 1.16527379
Trained batch 4393 batch loss 1.24994409 epoch total loss 1.1652931
Trained batch 4394 batch loss 0.873892546 epoch total loss 1.1652267
Trained batch 4395 batch loss 0.933883131 epoch total loss 1.16517413
Trained batch 4396 batch loss 1.19494152 epoch total loss 1.16518092
Trained batch 4397 batch loss 1.08442259 epoch total loss 1.16516256
Trained batch 4398 batch loss 1.03087151 epoch total loss 1.16513205
Trained batch 4399 batch loss 0.949754119 epoch total loss 1.16508305
Trained batch 4400 batch loss 0.874475241 epoch total loss 1.16501701
Trained batch 4401 batch loss 1.08913851 epoch total loss 1.16499984
Trained batch 4402 batch loss 0.764958739 epoch total loss 1.16490901
Trained batch 4403 batch loss 0.91539228 epoch total loss 1.16485226
Trained batch 4404 batch loss 0.918741107 epoch total loss 1.16479647
Trained batch 4405 batch loss 0.992003202 epoch total loss 1.16475725
Trained batch 4406 batch loss 0.979810953 epoch total loss 1.16471541
Trained batch 4407 batch loss 0.927917242 epoch total loss 1.16466153
Trained batch 4408 batch loss 0.891290545 epoch total loss 1.16459954
Trained batch 4409 batch loss 1.11379123 epoch total loss 1.16458797
Trained batch 4410 batch loss 1.1833322 epoch total loss 1.16459215
Trained batch 4411 batch loss 1.06461358 epoch total loss 1.1645695
Trained batch 4412 batch loss 1.09792018 epoch total loss 1.16455448
Trained batch 4413 batch loss 1.34934545 epoch total loss 1.1645962
Trained batch 4414 batch loss 1.09998059 epoch total loss 1.16458166
Trained batch 4415 batch loss 1.20629036 epoch total loss 1.16459107
Trained batch 4416 batch loss 1.06486 epoch total loss 1.16456842
Trained batch 4417 batch loss 0.849396586 epoch total loss 1.16449714
Trained batch 4418 batch loss 0.794932961 epoch total loss 1.16441357
Trained batch 4419 batch loss 0.936176121 epoch total loss 1.16436183
Trained batch 4420 batch loss 0.957953691 epoch total loss 1.1643151
Trained batch 4421 batch loss 1.08530712 epoch total loss 1.16429734
Trained batch 4422 batch loss 1.28810549 epoch total loss 1.16432536
Trained batch 4423 batch loss 1.03872132 epoch total loss 1.16429687
Trained batch 4424 batch loss 1.0577271 epoch total loss 1.16427279
Trained batch 4425 batch loss 1.03557539 epoch total loss 1.1642437
Trained batch 4426 batch loss 1.39106417 epoch total loss 1.16429496
Trained batch 4427 batch loss 1.50700438 epoch total loss 1.16437232
Trained batch 4428 batch loss 1.29266787 epoch total loss 1.16440129
Trained batch 4429 batch loss 1.21267688 epoch total loss 1.16441226
Trained batch 4430 batch loss 1.24323094 epoch total loss 1.16443
Trained batch 4431 batch loss 1.12155056 epoch total loss 1.16442037
Trained batch 4432 batch loss 0.988978326 epoch total loss 1.16438067
Trained batch 4433 batch loss 0.967581391 epoch total loss 1.16433632
Trained batch 4434 batch loss 1.31242836 epoch total loss 1.1643697
Trained batch 4435 batch loss 1.21498847 epoch total loss 1.16438115
Trained batch 4436 batch loss 1.27533233 epoch total loss 1.16440618
Trained batch 4437 batch loss 1.27950644 epoch total loss 1.16443205
Trained batch 4438 batch loss 1.1541853 epoch total loss 1.16442978
Trained batch 4439 batch loss 1.28495216 epoch total loss 1.16445696
Trained batch 4440 batch loss 1.47361016 epoch total loss 1.16452658
Trained batch 4441 batch loss 0.97950381 epoch total loss 1.16448498
Trained batch 4442 batch loss 1.31032491 epoch total loss 1.16451776
Trained batch 4443 batch loss 0.947398305 epoch total loss 1.16446888
Trained batch 4444 batch loss 1.1795696 epoch total loss 1.16447234
Trained batch 4445 batch loss 0.934814692 epoch total loss 1.16442072
Trained batch 4446 batch loss 0.825509787 epoch total loss 1.16434455
Trained batch 4447 batch loss 1.06963396 epoch total loss 1.16432333
Trained batch 4448 batch loss 0.972857177 epoch total loss 1.16428018
Trained batch 4449 batch loss 1.13353777 epoch total loss 1.16427326
Trained batch 4450 batch loss 0.986086726 epoch total loss 1.16423321
Trained batch 4451 batch loss 1.08813334 epoch total loss 1.16421604
Trained batch 4452 batch loss 1.09972894 epoch total loss 1.16420162
Trained batch 4453 batch loss 1.23948932 epoch total loss 1.16421843
Trained batch 4454 batch loss 1.45132327 epoch total loss 1.1642828
Trained batch 4455 batch loss 1.07860458 epoch total loss 1.16426361
Trained batch 4456 batch loss 1.1647166 epoch total loss 1.16426373
Trained batch 4457 batch loss 1.23748529 epoch total loss 1.16428
Trained batch 4458 batch loss 1.34301448 epoch total loss 1.16432011
Trained batch 4459 batch loss 1.15994763 epoch total loss 1.16431916
Trained batch 4460 batch loss 1.17706466 epoch total loss 1.16432202
Trained batch 4461 batch loss 1.02563894 epoch total loss 1.16429102
Trained batch 4462 batch loss 1.20758653 epoch total loss 1.16430068
Trained batch 4463 batch loss 1.24590504 epoch total loss 1.16431904
Trained batch 4464 batch loss 1.15048409 epoch total loss 1.16431594
Trained batch 4465 batch loss 0.920800388 epoch total loss 1.16426146
Trained batch 4466 batch loss 1.19771647 epoch total loss 1.16426897
Trained batch 4467 batch loss 0.991590619 epoch total loss 1.16423035
Trained batch 4468 batch loss 1.30723023 epoch total loss 1.16426229
Trained batch 4469 batch loss 1.2868557 epoch total loss 1.16428959
Trained batch 4470 batch loss 1.30091548 epoch total loss 1.16432023
Trained batch 4471 batch loss 1.35624933 epoch total loss 1.16436315
Trained batch 4472 batch loss 1.24637389 epoch total loss 1.1643815
Trained batch 4473 batch loss 1.24288762 epoch total loss 1.16439903
Trained batch 4474 batch loss 1.0812571 epoch total loss 1.16438043
Trained batch 4475 batch loss 1.12610173 epoch total loss 1.16437185
Trained batch 4476 batch loss 1.0883249 epoch total loss 1.1643548
Trained batch 4477 batch loss 0.922701359 epoch total loss 1.16430092
Trained batch 4478 batch loss 0.996849716 epoch total loss 1.16426361
Trained batch 4479 batch loss 0.984375477 epoch total loss 1.16422343
Trained batch 4480 batch loss 1.05622935 epoch total loss 1.16419923
Trained batch 4481 batch loss 1.14666748 epoch total loss 1.1641953
Trained batch 4482 batch loss 1.17487633 epoch total loss 1.16419768
Trained batch 4483 batch loss 1.12550449 epoch total loss 1.1641891
Trained batch 4484 batch loss 1.16589332 epoch total loss 1.16418946
Trained batch 4485 batch loss 1.33751059 epoch total loss 1.16422808
Trained batch 4486 batch loss 1.31729376 epoch total loss 1.16426218
Trained batch 4487 batch loss 1.1691587 epoch total loss 1.16426325
Trained batch 4488 batch loss 0.987605512 epoch total loss 1.16422391
Trained batch 4489 batch loss 1.23529458 epoch total loss 1.16423976
Trained batch 4490 batch loss 1.1480118 epoch total loss 1.16423619
Trained batch 4491 batch loss 1.15743089 epoch total loss 1.16423464
Trained batch 4492 batch loss 1.18597579 epoch total loss 1.16423941
Trained batch 4493 batch loss 1.18803239 epoch total loss 1.16424477
Trained batch 4494 batch loss 1.3298254 epoch total loss 1.16428149
Trained batch 4495 batch loss 1.1274507 epoch total loss 1.16427338
Trained batch 4496 batch loss 1.428303 epoch total loss 1.16433203
Trained batch 4497 batch loss 1.01960754 epoch total loss 1.16429985
Trained batch 4498 batch loss 1.03847873 epoch total loss 1.16427195
Trained batch 4499 batch loss 1.11681271 epoch total loss 1.16426134
Trained batch 4500 batch loss 1.00332677 epoch total loss 1.16422558
Trained batch 4501 batch loss 0.913394 epoch total loss 1.16416991
Trained batch 4502 batch loss 0.90546453 epoch total loss 1.16411245
Trained batch 4503 batch loss 0.950997293 epoch total loss 1.16406512
Trained batch 4504 batch loss 0.898095369 epoch total loss 1.16400599
Trained batch 4505 batch loss 1.13609433 epoch total loss 1.1639998
Trained batch 4506 batch loss 1.40627909 epoch total loss 1.16405356
Trained batch 4507 batch loss 1.23794293 epoch total loss 1.16407
Trained batch 4508 batch loss 1.21811414 epoch total loss 1.16408205
Trained batch 4509 batch loss 1.39306545 epoch total loss 1.16413283
Trained batch 4510 batch loss 1.41826701 epoch total loss 1.16418922
Trained batch 4511 batch loss 1.08473659 epoch total loss 1.16417158
Trained batch 4512 batch loss 1.23886335 epoch total loss 1.16418815
Trained batch 4513 batch loss 1.18057203 epoch total loss 1.16419184
Trained batch 4514 batch loss 1.0705775 epoch total loss 1.1641711
Trained batch 4515 batch loss 1.10616159 epoch total loss 1.16415823
Trained batch 4516 batch loss 1.25871503 epoch total loss 1.16417921
Trained batch 4517 batch loss 1.19031954 epoch total loss 1.16418493
Trained batch 4518 batch loss 0.95463419 epoch total loss 1.16413856
Trained batch 4519 batch loss 1.01363707 epoch total loss 1.1641053
Trained batch 4520 batch loss 1.06199217 epoch total loss 1.16408265
Trained batch 4521 batch loss 1.10036564 epoch total loss 1.1640687
Trained batch 4522 batch loss 0.891952634 epoch total loss 1.1640085
Trained batch 4523 batch loss 0.943285525 epoch total loss 1.16395974
Trained batch 4524 batch loss 0.992424488 epoch total loss 1.16392171
Trained batch 4525 batch loss 0.837430835 epoch total loss 1.16384959
Trained batch 4526 batch loss 0.910395861 epoch total loss 1.16379356
Trained batch 4527 batch loss 1.04339373 epoch total loss 1.16376698
Trained batch 4528 batch loss 1.03458583 epoch total loss 1.16373849
Trained batch 4529 batch loss 1.12010491 epoch total loss 1.16372883
Trained batch 4530 batch loss 0.98522675 epoch total loss 1.16368949
Trained batch 4531 batch loss 1.15701389 epoch total loss 1.16368806
Trained batch 4532 batch loss 1.41580081 epoch total loss 1.16374373
Trained batch 4533 batch loss 1.0566467 epoch total loss 1.16372
Trained batch 4534 batch loss 1.31018019 epoch total loss 1.16375232
Trained batch 4535 batch loss 1.16714907 epoch total loss 1.16375303
Trained batch 4536 batch loss 1.03746843 epoch total loss 1.16372526
Trained batch 4537 batch loss 1.30484533 epoch total loss 1.16375637
Trained batch 4538 batch loss 1.02405572 epoch total loss 1.1637255
Trained batch 4539 batch loss 1.00821567 epoch total loss 1.16369128
Trained batch 4540 batch loss 1.16461587 epoch total loss 1.1636914
Trained batch 4541 batch loss 1.22577512 epoch total loss 1.16370511
Trained batch 4542 batch loss 1.34819174 epoch total loss 1.16374564
Trained batch 4543 batch loss 1.13514018 epoch total loss 1.16373944
Trained batch 4544 batch loss 1.18913 epoch total loss 1.16374493
Trained batch 4545 batch loss 1.30662274 epoch total loss 1.1637764
Trained batch 4546 batch loss 1.27506208 epoch total loss 1.16380084
Trained batch 4547 batch loss 1.42079258 epoch total loss 1.16385734
Trained batch 4548 batch loss 1.41941786 epoch total loss 1.16391361
Trained batch 4549 batch loss 1.43222666 epoch total loss 1.1639725
Trained batch 4550 batch loss 0.930297613 epoch total loss 1.16392112
Trained batch 4551 batch loss 1.22893262 epoch total loss 1.16393542
Trained batch 4552 batch loss 1.14064169 epoch total loss 1.1639303
Trained batch 4553 batch loss 1.1104033 epoch total loss 1.16391861
Trained batch 4554 batch loss 1.07702494 epoch total loss 1.16389954
Trained batch 4555 batch loss 1.18592548 epoch total loss 1.16390443
Trained batch 4556 batch loss 1.1863029 epoch total loss 1.16390932
Trained batch 4557 batch loss 1.14150095 epoch total loss 1.16390443
Trained batch 4558 batch loss 0.946482956 epoch total loss 1.16385674
Trained batch 4559 batch loss 1.0749433 epoch total loss 1.16383719
Trained batch 4560 batch loss 1.15928125 epoch total loss 1.16383612
Trained batch 4561 batch loss 1.02325487 epoch total loss 1.16380537
Trained batch 4562 batch loss 1.12086463 epoch total loss 1.16379595
Trained batch 4563 batch loss 1.16803527 epoch total loss 1.1637969
Trained batch 4564 batch loss 1.07766342 epoch total loss 1.16377807
Trained batch 4565 batch loss 1.14326155 epoch total loss 1.16377354
Trained batch 4566 batch loss 1.19940686 epoch total loss 1.16378129
Trained batch 4567 batch loss 1.21508622 epoch total loss 1.16379249
Trained batch 4568 batch loss 1.24852633 epoch total loss 1.16381097
Trained batch 4569 batch loss 1.34122217 epoch total loss 1.16384983
Trained batch 4570 batch loss 0.770975828 epoch total loss 1.16376388
Trained batch 4571 batch loss 0.923710406 epoch total loss 1.16371143
Trained batch 4572 batch loss 0.8115955 epoch total loss 1.1636343
Trained batch 4573 batch loss 1.00202 epoch total loss 1.16359901
Trained batch 4574 batch loss 0.886588 epoch total loss 1.16353846
Trained batch 4575 batch loss 0.841629386 epoch total loss 1.16346812
Trained batch 4576 batch loss 0.860993743 epoch total loss 1.16340196
Trained batch 4577 batch loss 0.777952909 epoch total loss 1.1633178
Trained batch 4578 batch loss 0.717680275 epoch total loss 1.16322041
Trained batch 4579 batch loss 0.845632792 epoch total loss 1.16315114
Trained batch 4580 batch loss 1.06975698 epoch total loss 1.16313076
Trained batch 4581 batch loss 1.17824602 epoch total loss 1.16313398
Trained batch 4582 batch loss 1.05107856 epoch total loss 1.16310954
Trained batch 4583 batch loss 1.26575112 epoch total loss 1.16313195
Trained batch 4584 batch loss 1.28628647 epoch total loss 1.16315877
Trained batch 4585 batch loss 1.24853086 epoch total loss 1.16317737
Trained batch 4586 batch loss 1.19092011 epoch total loss 1.16318345
Trained batch 4587 batch loss 1.48599863 epoch total loss 1.16325378
Trained batch 4588 batch loss 1.32278466 epoch total loss 1.16328859
Trained batch 4589 batch loss 1.24459755 epoch total loss 1.16330636
Trained batch 4590 batch loss 1.32413387 epoch total loss 1.1633414
Trained batch 4591 batch loss 1.24966025 epoch total loss 1.16336012
Trained batch 4592 batch loss 1.35849285 epoch total loss 1.16340256
Trained batch 4593 batch loss 1.30563676 epoch total loss 1.16343355
Trained batch 4594 batch loss 1.28114855 epoch total loss 1.16345918
Trained batch 4595 batch loss 1.32707644 epoch total loss 1.16349483
Trained batch 4596 batch loss 1.31304967 epoch total loss 1.16352737
Trained batch 4597 batch loss 1.28184676 epoch total loss 1.16355312
Trained batch 4598 batch loss 1.23561478 epoch total loss 1.16356885
Trained batch 4599 batch loss 1.27722108 epoch total loss 1.16359353
Trained batch 4600 batch loss 1.15919173 epoch total loss 1.16359258
Trained batch 4601 batch loss 1.35217 epoch total loss 1.16363358
Trained batch 4602 batch loss 1.11504745 epoch total loss 1.16362298
Trained batch 4603 batch loss 1.16131294 epoch total loss 1.1636225
Trained batch 4604 batch loss 1.19761038 epoch total loss 1.16362989
Trained batch 4605 batch loss 1.10267329 epoch total loss 1.16361666
Trained batch 4606 batch loss 1.17656815 epoch total loss 1.16361952
Trained batch 4607 batch loss 1.05386209 epoch total loss 1.16359568
Trained batch 4608 batch loss 1.24036884 epoch total loss 1.16361225
Trained batch 4609 batch loss 1.26603127 epoch total loss 1.16363454
Trained batch 4610 batch loss 1.12782431 epoch total loss 1.16362679
Trained batch 4611 batch loss 1.04413915 epoch total loss 1.1636008
Trained batch 4612 batch loss 1.35254097 epoch total loss 1.16364181
Trained batch 4613 batch loss 1.24882412 epoch total loss 1.16366029
Trained batch 4614 batch loss 1.09945369 epoch total loss 1.16364634
Trained batch 4615 batch loss 0.919368744 epoch total loss 1.16359353
Trained batch 4616 batch loss 1.23461461 epoch total loss 1.16360879
Trained batch 4617 batch loss 1.34055269 epoch total loss 1.16364706
Trained batch 4618 batch loss 1.09202075 epoch total loss 1.16363156
Trained batch 4619 batch loss 1.26947546 epoch total loss 1.16365445
Trained batch 4620 batch loss 1.25886679 epoch total loss 1.16367507
Trained batch 4621 batch loss 1.25217271 epoch total loss 1.16369414
Trained batch 4622 batch loss 1.47921801 epoch total loss 1.16376233
Trained batch 4623 batch loss 1.21719646 epoch total loss 1.16377389
Trained batch 4624 batch loss 1.35902894 epoch total loss 1.16381609
Trained batch 4625 batch loss 1.35911679 epoch total loss 1.16385829
Trained batch 4626 batch loss 1.41400361 epoch total loss 1.16391242
Trained batch 4627 batch loss 1.31148028 epoch total loss 1.16394436
Trained batch 4628 batch loss 1.42068505 epoch total loss 1.1639998
Trained batch 4629 batch loss 1.07605588 epoch total loss 1.16398084
Trained batch 4630 batch loss 0.957695663 epoch total loss 1.16393626
Trained batch 4631 batch loss 1.11493707 epoch total loss 1.16392565
Trained batch 4632 batch loss 1.17298818 epoch total loss 1.16392756
Trained batch 4633 batch loss 1.05585384 epoch total loss 1.16390419
Trained batch 4634 batch loss 1.07802796 epoch total loss 1.16388571
Trained batch 4635 batch loss 1.1556778 epoch total loss 1.16388392
Trained batch 4636 batch loss 1.12796354 epoch total loss 1.16387618
Trained batch 4637 batch loss 1.24483538 epoch total loss 1.16389358
Trained batch 4638 batch loss 1.09160829 epoch total loss 1.16387808
Trained batch 4639 batch loss 1.14819121 epoch total loss 1.16387463
Trained batch 4640 batch loss 1.34801841 epoch total loss 1.16391432
Trained batch 4641 batch loss 1.30527878 epoch total loss 1.16394472
Trained batch 4642 batch loss 1.07705712 epoch total loss 1.16392612
Trained batch 4643 batch loss 1.09909582 epoch total loss 1.16391206
Trained batch 4644 batch loss 1.06494427 epoch total loss 1.16389084
Trained batch 4645 batch loss 1.15114832 epoch total loss 1.1638881
Trained batch 4646 batch loss 1.20752859 epoch total loss 1.16389751
Trained batch 4647 batch loss 1.30523372 epoch total loss 1.16392791
Trained batch 4648 batch loss 1.27097344 epoch total loss 1.16395092
Trained batch 4649 batch loss 1.07585549 epoch total loss 1.16393197
Trained batch 4650 batch loss 1.11999846 epoch total loss 1.16392255
Trained batch 4651 batch loss 1.1436007 epoch total loss 1.16391814
Trained batch 4652 batch loss 1.21596193 epoch total loss 1.16392934
Trained batch 4653 batch loss 1.05021727 epoch total loss 1.16390491
Trained batch 4654 batch loss 1.15006196 epoch total loss 1.16390193
Trained batch 4655 batch loss 1.25056505 epoch total loss 1.16392052
Trained batch 4656 batch loss 1.19777584 epoch total loss 1.16392779
Trained batch 4657 batch loss 1.21731985 epoch total loss 1.16393924
Trained batch 4658 batch loss 1.12040186 epoch total loss 1.16392994
Trained batch 4659 batch loss 1.25830209 epoch total loss 1.1639502
Trained batch 4660 batch loss 1.43548989 epoch total loss 1.16400838
Trained batch 4661 batch loss 1.44949055 epoch total loss 1.16406977
Trained batch 4662 batch loss 1.03326273 epoch total loss 1.16404164
Trained batch 4663 batch loss 0.991663098 epoch total loss 1.16400468
Trained batch 4664 batch loss 1.41237211 epoch total loss 1.16405797
Trained batch 4665 batch loss 1.46962547 epoch total loss 1.16412354
Trained batch 4666 batch loss 1.21391153 epoch total loss 1.16413414
Trained batch 4667 batch loss 1.02693689 epoch total loss 1.16410482
Trained batch 4668 batch loss 1.1759305 epoch total loss 1.16410732
Trained batch 4669 batch loss 1.25251389 epoch total loss 1.16412616
Trained batch 4670 batch loss 1.18996155 epoch total loss 1.16413176
Trained batch 4671 batch loss 0.935415387 epoch total loss 1.16408277
Trained batch 4672 batch loss 1.2914722 epoch total loss 1.16411006
Trained batch 4673 batch loss 1.32516193 epoch total loss 1.16414452
Trained batch 4674 batch loss 1.49670517 epoch total loss 1.16421568
Trained batch 4675 batch loss 1.12403762 epoch total loss 1.1642071
Trained batch 4676 batch loss 1.22324681 epoch total loss 1.16421962
Trained batch 4677 batch loss 1.3555007 epoch total loss 1.16426051
Trained batch 4678 batch loss 1.21395731 epoch total loss 1.16427112
Trained batch 4679 batch loss 1.21309638 epoch total loss 1.16428149
Trained batch 4680 batch loss 1.2618053 epoch total loss 1.16430235
Trained batch 4681 batch loss 1.0005126 epoch total loss 1.16426742
Trained batch 4682 batch loss 1.29556108 epoch total loss 1.16429543
Trained batch 4683 batch loss 1.26600778 epoch total loss 1.16431713
Trained batch 4684 batch loss 0.884099483 epoch total loss 1.16425729
Trained batch 4685 batch loss 1.29322314 epoch total loss 1.16428494
Trained batch 4686 batch loss 1.26980209 epoch total loss 1.16430748
Trained batch 4687 batch loss 1.21281409 epoch total loss 1.16431785
Trained batch 4688 batch loss 1.18779469 epoch total loss 1.16432285
Trained batch 4689 batch loss 1.09191084 epoch total loss 1.16430748
Trained batch 4690 batch loss 0.937891603 epoch total loss 1.1642592
Trained batch 4691 batch loss 1.13032866 epoch total loss 1.16425192
Trained batch 4692 batch loss 0.956164777 epoch total loss 1.16420758
Trained batch 4693 batch loss 1.26296759 epoch total loss 1.16422868
Trained batch 4694 batch loss 1.2396338 epoch total loss 1.16424477
Trained batch 4695 batch loss 1.2107203 epoch total loss 1.16425467
Trained batch 4696 batch loss 1.15853858 epoch total loss 1.16425347
Trained batch 4697 batch loss 1.38076234 epoch total loss 1.16429961
Trained batch 4698 batch loss 1.55069518 epoch total loss 1.16438186
Trained batch 4699 batch loss 1.12193775 epoch total loss 1.16437292
Trained batch 4700 batch loss 1.21899474 epoch total loss 1.1643846
Trained batch 4701 batch loss 1.29779255 epoch total loss 1.16441298
Trained batch 4702 batch loss 1.37615275 epoch total loss 1.16445792
Trained batch 4703 batch loss 1.02839196 epoch total loss 1.16442895
Trained batch 4704 batch loss 1.29366112 epoch total loss 1.16445637
Trained batch 4705 batch loss 1.08677506 epoch total loss 1.16443992
Trained batch 4706 batch loss 1.1561625 epoch total loss 1.16443825
Trained batch 4707 batch loss 0.92081809 epoch total loss 1.16438651
Trained batch 4708 batch loss 1.06222129 epoch total loss 1.1643647
Trained batch 4709 batch loss 1.05394149 epoch total loss 1.16434121
Trained batch 4710 batch loss 1.14966941 epoch total loss 1.16433811
Trained batch 4711 batch loss 1.01332474 epoch total loss 1.16430604
Trained batch 4712 batch loss 1.13157868 epoch total loss 1.16429913
Trained batch 4713 batch loss 0.939923406 epoch total loss 1.16425145
Trained batch 4714 batch loss 0.980006218 epoch total loss 1.16421235
Trained batch 4715 batch loss 1.16824841 epoch total loss 1.1642133
Trained batch 4716 batch loss 1.08213222 epoch total loss 1.1641959
Trained batch 4717 batch loss 0.883286119 epoch total loss 1.16413629
Trained batch 4718 batch loss 0.959575534 epoch total loss 1.1640929
Trained batch 4719 batch loss 1.06788278 epoch total loss 1.16407251
Trained batch 4720 batch loss 1.02599192 epoch total loss 1.16404331
Trained batch 4721 batch loss 1.17682385 epoch total loss 1.16404593
Trained batch 4722 batch loss 1.21564388 epoch total loss 1.1640569
Trained batch 4723 batch loss 1.0747366 epoch total loss 1.16403794
Trained batch 4724 batch loss 1.29991722 epoch total loss 1.16406679
Trained batch 4725 batch loss 1.20692527 epoch total loss 1.16407585
Trained batch 4726 batch loss 1.25387609 epoch total loss 1.16409481
Trained batch 4727 batch loss 1.17535484 epoch total loss 1.16409719
Trained batch 4728 batch loss 1.32409763 epoch total loss 1.16413105
Trained batch 4729 batch loss 1.11466765 epoch total loss 1.16412067
Trained batch 4730 batch loss 1.18333459 epoch total loss 1.16412461
Trained batch 4731 batch loss 1.07203293 epoch total loss 1.16410518
Trained batch 4732 batch loss 1.09984779 epoch total loss 1.16409159
Trained batch 4733 batch loss 0.897996485 epoch total loss 1.16403532
Trained batch 4734 batch loss 0.884522319 epoch total loss 1.16397643
Trained batch 4735 batch loss 0.966749668 epoch total loss 1.16393471
Trained batch 4736 batch loss 0.980188668 epoch total loss 1.16389585
Trained batch 4737 batch loss 0.964141846 epoch total loss 1.16385376
Trained batch 4738 batch loss 1.06907225 epoch total loss 1.16383374
Trained batch 4739 batch loss 1.00026882 epoch total loss 1.16379929
Trained batch 4740 batch loss 1.04611516 epoch total loss 1.16377437
Trained batch 4741 batch loss 1.04661393 epoch total loss 1.16374958
Trained batch 4742 batch loss 1.09984 epoch total loss 1.1637361
Trained batch 4743 batch loss 1.24830818 epoch total loss 1.16375399
Trained batch 4744 batch loss 1.17344093 epoch total loss 1.16375601
Trained batch 4745 batch loss 1.45588458 epoch total loss 1.16381764
Trained batch 4746 batch loss 1.44883168 epoch total loss 1.16387761
Trained batch 4747 batch loss 1.65736282 epoch total loss 1.16398156
Trained batch 4748 batch loss 1.07301283 epoch total loss 1.16396248
Trained batch 4749 batch loss 1.13272107 epoch total loss 1.16395593
Trained batch 4750 batch loss 1.12068605 epoch total loss 1.16394675
Trained batch 4751 batch loss 0.990206838 epoch total loss 1.16391015
Trained batch 4752 batch loss 1.07696509 epoch total loss 1.16389191
Trained batch 4753 batch loss 1.12388647 epoch total loss 1.16388357
Trained batch 4754 batch loss 1.23454642 epoch total loss 1.16389835
Trained batch 4755 batch loss 1.16816068 epoch total loss 1.16389918
Trained batch 4756 batch loss 1.08147764 epoch total loss 1.1638819
Trained batch 4757 batch loss 1.05095482 epoch total loss 1.16385818
Trained batch 4758 batch loss 0.931161046 epoch total loss 1.16380918
Trained batch 4759 batch loss 0.879341543 epoch total loss 1.16374946
Trained batch 4760 batch loss 0.918998837 epoch total loss 1.16369808
Trained batch 4761 batch loss 0.804206491 epoch total loss 1.1636225
Trained batch 4762 batch loss 0.791218877 epoch total loss 1.1635443
Trained batch 4763 batch loss 0.669575334 epoch total loss 1.16344059
Trained batch 4764 batch loss 0.691642404 epoch total loss 1.1633414
Trained batch 4765 batch loss 0.631594 epoch total loss 1.16323
Trained batch 4766 batch loss 0.719329238 epoch total loss 1.16313672
Trained batch 4767 batch loss 0.897972941 epoch total loss 1.16308117
Trained batch 4768 batch loss 0.750479162 epoch total loss 1.16299462
Trained batch 4769 batch loss 1.00179434 epoch total loss 1.16296077
Trained batch 4770 batch loss 0.914988518 epoch total loss 1.16290879
Trained batch 4771 batch loss 0.92735976 epoch total loss 1.16285944
Trained batch 4772 batch loss 1.19403481 epoch total loss 1.162866
Trained batch 4773 batch loss 1.20799899 epoch total loss 1.16287541
Trained batch 4774 batch loss 1.04507601 epoch total loss 1.16285074
Trained batch 4775 batch loss 1.05230975 epoch total loss 1.16282749
Trained batch 4776 batch loss 1.05730224 epoch total loss 1.16280544
Trained batch 4777 batch loss 0.948386431 epoch total loss 1.1627605
Trained batch 4778 batch loss 1.27660954 epoch total loss 1.16278422
Trained batch 4779 batch loss 1.20533276 epoch total loss 1.16279316
Trained batch 4780 batch loss 0.934526742 epoch total loss 1.16274548
Trained batch 4781 batch loss 1.35824585 epoch total loss 1.16278636
Trained batch 4782 batch loss 1.13402987 epoch total loss 1.16278028
Trained batch 4783 batch loss 1.17693305 epoch total loss 1.16278327
Trained batch 4784 batch loss 1.15505695 epoch total loss 1.16278172
Trained batch 4785 batch loss 1.23615694 epoch total loss 1.16279709
Trained batch 4786 batch loss 1.1633718 epoch total loss 1.16279721
Trained batch 4787 batch loss 1.05049336 epoch total loss 1.16277373
Trained batch 4788 batch loss 0.941666 epoch total loss 1.16272759
Trained batch 4789 batch loss 1.1366533 epoch total loss 1.16272211
Trained batch 4790 batch loss 0.87543869 epoch total loss 1.16266215
Trained batch 4791 batch loss 0.875088513 epoch total loss 1.16260219
Trained batch 4792 batch loss 1.32682347 epoch total loss 1.1626364
Trained batch 4793 batch loss 1.2888428 epoch total loss 1.16266274
Trained batch 4794 batch loss 1.1617074 epoch total loss 1.16266251
Trained batch 4795 batch loss 1.01955688 epoch total loss 1.1626327
Trained batch 4796 batch loss 1.04350626 epoch total loss 1.16260779
Trained batch 4797 batch loss 1.07565379 epoch total loss 1.16258967
Trained batch 4798 batch loss 1.21389771 epoch total loss 1.1626004
Trained batch 4799 batch loss 1.07356644 epoch total loss 1.16258192
Trained batch 4800 batch loss 1.03956938 epoch total loss 1.16255629
Trained batch 4801 batch loss 1.15180588 epoch total loss 1.16255403
Trained batch 4802 batch loss 1.23564625 epoch total loss 1.16256928
Trained batch 4803 batch loss 1.20622456 epoch total loss 1.16257834
Trained batch 4804 batch loss 1.12091136 epoch total loss 1.16256976
Trained batch 4805 batch loss 1.00481462 epoch total loss 1.16253686
Trained batch 4806 batch loss 0.9690727 epoch total loss 1.16249669
Trained batch 4807 batch loss 1.04218197 epoch total loss 1.16247165
Trained batch 4808 batch loss 1.16083622 epoch total loss 1.16247118
Trained batch 4809 batch loss 1.18302953 epoch total loss 1.16247547
Trained batch 4810 batch loss 1.07210839 epoch total loss 1.16245675
Trained batch 4811 batch loss 1.33630657 epoch total loss 1.16249287
Trained batch 4812 batch loss 1.12196314 epoch total loss 1.16248453
Trained batch 4813 batch loss 1.1651299 epoch total loss 1.162485
Trained batch 4814 batch loss 1.07400668 epoch total loss 1.16246676
Trained batch 4815 batch loss 1.19655228 epoch total loss 1.1624738
Trained batch 4816 batch loss 1.4172436 epoch total loss 1.16252685
Trained batch 4817 batch loss 1.06661963 epoch total loss 1.16250682
Trained batch 4818 batch loss 1.00259757 epoch total loss 1.16247356
Trained batch 4819 batch loss 0.932907581 epoch total loss 1.16242599
Trained batch 4820 batch loss 0.904848039 epoch total loss 1.16237259
Trained batch 4821 batch loss 1.12164 epoch total loss 1.16236413
Trained batch 4822 batch loss 1.20796525 epoch total loss 1.16237354
Trained batch 4823 batch loss 1.34974027 epoch total loss 1.16241241
Trained batch 4824 batch loss 1.18997848 epoch total loss 1.16241813
Trained batch 4825 batch loss 1.16259527 epoch total loss 1.16241813
Trained batch 4826 batch loss 1.07548022 epoch total loss 1.16240013
Trained batch 4827 batch loss 1.18490088 epoch total loss 1.16240489
Trained batch 4828 batch loss 1.019135 epoch total loss 1.16237521
Trained batch 4829 batch loss 1.23417449 epoch total loss 1.16239011
Trained batch 4830 batch loss 0.854313612 epoch total loss 1.16232634
Trained batch 4831 batch loss 1.20898068 epoch total loss 1.16233599
Trained batch 4832 batch loss 1.32789314 epoch total loss 1.16237032
Trained batch 4833 batch loss 0.944839597 epoch total loss 1.16232526
Trained batch 4834 batch loss 1.06679869 epoch total loss 1.16230559
Trained batch 4835 batch loss 1.1299386 epoch total loss 1.1622988
Trained batch 4836 batch loss 1.39885879 epoch total loss 1.16234779
Trained batch 4837 batch loss 1.50190306 epoch total loss 1.16241801
Trained batch 4838 batch loss 1.07436454 epoch total loss 1.16239977
Trained batch 4839 batch loss 1.435938 epoch total loss 1.16245627
Trained batch 4840 batch loss 1.20788765 epoch total loss 1.16246569
Trained batch 4841 batch loss 0.981773555 epoch total loss 1.16242838
Trained batch 4842 batch loss 1.09044909 epoch total loss 1.16241348
Trained batch 4843 batch loss 1.07400465 epoch total loss 1.16239536
Trained batch 4844 batch loss 1.09056723 epoch total loss 1.16238046
Trained batch 4845 batch loss 1.34521437 epoch total loss 1.16241813
Trained batch 4846 batch loss 1.1516999 epoch total loss 1.16241598
Trained batch 4847 batch loss 1.19694316 epoch total loss 1.16242313
Trained batch 4848 batch loss 1.09546447 epoch total loss 1.16240931
Trained batch 4849 batch loss 1.20921421 epoch total loss 1.16241896
Trained batch 4850 batch loss 0.88839972 epoch total loss 1.16236234
Trained batch 4851 batch loss 1.18665862 epoch total loss 1.16236734
Trained batch 4852 batch loss 1.00974333 epoch total loss 1.16233587
Trained batch 4853 batch loss 1.2980324 epoch total loss 1.16236389
Trained batch 4854 batch loss 0.961422503 epoch total loss 1.1623224
Trained batch 4855 batch loss 1.22616696 epoch total loss 1.16233552
Trained batch 4856 batch loss 1.19031084 epoch total loss 1.16234136
Trained batch 4857 batch loss 1.28403425 epoch total loss 1.16236639
Trained batch 4858 batch loss 1.11943078 epoch total loss 1.16235769
Trained batch 4859 batch loss 1.24231577 epoch total loss 1.16237402
Trained batch 4860 batch loss 1.25443196 epoch total loss 1.16239297
Trained batch 4861 batch loss 1.42715085 epoch total loss 1.16244745
Trained batch 4862 batch loss 1.34040928 epoch total loss 1.16248405
Trained batch 4863 batch loss 1.25454187 epoch total loss 1.162503
Trained batch 4864 batch loss 1.12211215 epoch total loss 1.16249466
Trained batch 4865 batch loss 1.10073256 epoch total loss 1.1624819
Trained batch 4866 batch loss 1.24687159 epoch total loss 1.16249931
Trained batch 4867 batch loss 1.27987289 epoch total loss 1.16252339
Trained batch 4868 batch loss 1.17878139 epoch total loss 1.16252673
Trained batch 4869 batch loss 1.31463766 epoch total loss 1.16255796
Trained batch 4870 batch loss 1.24226689 epoch total loss 1.16257429
Trained batch 4871 batch loss 1.12455344 epoch total loss 1.16256642
Trained batch 4872 batch loss 1.25116801 epoch total loss 1.16258466
Trained batch 4873 batch loss 1.19272447 epoch total loss 1.16259086
Trained batch 4874 batch loss 1.19501066 epoch total loss 1.16259742
Trained batch 4875 batch loss 1.20839071 epoch total loss 1.16260684
Trained batch 4876 batch loss 1.25301456 epoch total loss 1.16262543
Trained batch 4877 batch loss 1.2966814 epoch total loss 1.16265297
Trained batch 4878 batch loss 1.25084019 epoch total loss 1.16267097
Trained batch 4879 batch loss 1.31145644 epoch total loss 1.16270149
Trained batch 4880 batch loss 1.28901529 epoch total loss 1.16272748
Trained batch 4881 batch loss 1.38700223 epoch total loss 1.16277337
Trained batch 4882 batch loss 1.14695704 epoch total loss 1.16277015
Trained batch 4883 batch loss 1.15663505 epoch total loss 1.16276896
Trained batch 4884 batch loss 0.998987556 epoch total loss 1.16273546
Trained batch 4885 batch loss 0.979524612 epoch total loss 1.16269791
Trained batch 4886 batch loss 1.0126133 epoch total loss 1.16266716
Trained batch 4887 batch loss 0.939657032 epoch total loss 1.1626215
Trained batch 4888 batch loss 1.2123282 epoch total loss 1.16263175
Trained batch 4889 batch loss 1.16180158 epoch total loss 1.16263151
Trained batch 4890 batch loss 1.30334234 epoch total loss 1.16266024
Trained batch 4891 batch loss 1.29199481 epoch total loss 1.16268671
Trained batch 4892 batch loss 1.08437908 epoch total loss 1.16267073
Trained batch 4893 batch loss 0.907627344 epoch total loss 1.16261864
Trained batch 4894 batch loss 1.10685027 epoch total loss 1.16260719
Trained batch 4895 batch loss 0.851549804 epoch total loss 1.16254365
Trained batch 4896 batch loss 0.878493249 epoch total loss 1.1624856
Trained batch 4897 batch loss 0.869085133 epoch total loss 1.16242576
Trained batch 4898 batch loss 0.995597 epoch total loss 1.16239166
Trained batch 4899 batch loss 1.12934256 epoch total loss 1.16238499
Trained batch 4900 batch loss 0.877003372 epoch total loss 1.16232669
Trained batch 4901 batch loss 1.10446167 epoch total loss 1.16231489
Trained batch 4902 batch loss 1.00189614 epoch total loss 1.16228223
Trained batch 4903 batch loss 0.773916423 epoch total loss 1.16220295
Trained batch 4904 batch loss 1.1372354 epoch total loss 1.16219795
Trained batch 4905 batch loss 1.08411074 epoch total loss 1.16218197
Trained batch 4906 batch loss 1.12134647 epoch total loss 1.16217363
Trained batch 4907 batch loss 1.08648634 epoch total loss 1.16215825
Trained batch 4908 batch loss 1.06336606 epoch total loss 1.1621381
Trained batch 4909 batch loss 0.92100668 epoch total loss 1.16208899
Trained batch 4910 batch loss 0.872029 epoch total loss 1.16202986
Trained batch 4911 batch loss 0.772538185 epoch total loss 1.16195059
Trained batch 4912 batch loss 0.774944067 epoch total loss 1.16187179
Trained batch 4913 batch loss 0.796605468 epoch total loss 1.1617974
Trained batch 4914 batch loss 0.763730824 epoch total loss 1.16171634
Trained batch 4915 batch loss 0.731069684 epoch total loss 1.16162872
Trained batch 4916 batch loss 0.823000848 epoch total loss 1.16155994
Trained batch 4917 batch loss 0.940054595 epoch total loss 1.16151488
Trained batch 4918 batch loss 0.860297918 epoch total loss 1.1614536
Trained batch 4919 batch loss 0.992766619 epoch total loss 1.16141927
Trained batch 4920 batch loss 0.883839786 epoch total loss 1.16136289
Trained batch 4921 batch loss 0.725854516 epoch total loss 1.16127443
Trained batch 4922 batch loss 0.669137836 epoch total loss 1.16117442
Trained batch 4923 batch loss 0.792458892 epoch total loss 1.16109943
Trained batch 4924 batch loss 1.07394838 epoch total loss 1.16108179
Trained batch 4925 batch loss 1.24472988 epoch total loss 1.16109872
Trained batch 4926 batch loss 1.06727052 epoch total loss 1.16107965
Trained batch 4927 batch loss 1.12366974 epoch total loss 1.16107202
Trained batch 4928 batch loss 1.30487323 epoch total loss 1.16110122
Trained batch 4929 batch loss 1.2903769 epoch total loss 1.16112745
Trained batch 4930 batch loss 1.16592813 epoch total loss 1.1611284
Trained batch 4931 batch loss 1.19260168 epoch total loss 1.16113484
Trained batch 4932 batch loss 0.906791568 epoch total loss 1.16108322
Trained batch 4933 batch loss 0.977521122 epoch total loss 1.16104603
Trained batch 4934 batch loss 1.11642265 epoch total loss 1.16103697
Trained batch 4935 batch loss 1.17999744 epoch total loss 1.16104078
Trained batch 4936 batch loss 1.22326612 epoch total loss 1.16105342
Trained batch 4937 batch loss 1.11776185 epoch total loss 1.1610446
Trained batch 4938 batch loss 1.26483905 epoch total loss 1.16106558
Trained batch 4939 batch loss 1.1875174 epoch total loss 1.16107094
Trained batch 4940 batch loss 1.07663393 epoch total loss 1.1610539
Trained batch 4941 batch loss 1.00792027 epoch total loss 1.16102278
Trained batch 4942 batch loss 1.08369827 epoch total loss 1.16100717
Trained batch 4943 batch loss 1.27574015 epoch total loss 1.16103041
Trained batch 4944 batch loss 0.97256732 epoch total loss 1.16099226
Trained batch 4945 batch loss 1.26067078 epoch total loss 1.16101241
Trained batch 4946 batch loss 1.0230695 epoch total loss 1.16098452
Trained batch 4947 batch loss 1.05379188 epoch total loss 1.16096282
Trained batch 4948 batch loss 1.12964511 epoch total loss 1.16095662
Trained batch 4949 batch loss 1.18777275 epoch total loss 1.16096199
Trained batch 4950 batch loss 1.03708923 epoch total loss 1.16093695
Trained batch 4951 batch loss 1.06352186 epoch total loss 1.16091728
Trained batch 4952 batch loss 0.9499439 epoch total loss 1.16087472
Trained batch 4953 batch loss 1.1139636 epoch total loss 1.16086519
Trained batch 4954 batch loss 1.05281603 epoch total loss 1.16084337
Trained batch 4955 batch loss 1.06417274 epoch total loss 1.16082382
Trained batch 4956 batch loss 1.14043295 epoch total loss 1.16081965
Trained batch 4957 batch loss 1.18384051 epoch total loss 1.16082442
Trained batch 4958 batch loss 1.21355665 epoch total loss 1.16083503
Trained batch 4959 batch loss 1.33805549 epoch total loss 1.16087067
Trained batch 4960 batch loss 1.12192547 epoch total loss 1.16086292
Trained batch 4961 batch loss 1.27257204 epoch total loss 1.16088533
Trained batch 4962 batch loss 1.12189484 epoch total loss 1.16087759
Trained batch 4963 batch loss 1.17620087 epoch total loss 1.16088068
Trained batch 4964 batch loss 1.24128675 epoch total loss 1.16089678
Trained batch 4965 batch loss 1.07508576 epoch total loss 1.16087961
Trained batch 4966 batch loss 1.0559212 epoch total loss 1.16085851
Trained batch 4967 batch loss 1.16533709 epoch total loss 1.16085947
Trained batch 4968 batch loss 1.10152686 epoch total loss 1.16084754
Trained batch 4969 batch loss 1.33059132 epoch total loss 1.16088164
Trained batch 4970 batch loss 1.18093908 epoch total loss 1.16088569
Trained batch 4971 batch loss 1.17939794 epoch total loss 1.16088939
Trained batch 4972 batch loss 1.3110745 epoch total loss 1.16091967
Trained batch 4973 batch loss 1.32297254 epoch total loss 1.16095209
Trained batch 4974 batch loss 1.28428197 epoch total loss 1.16097689
Trained batch 4975 batch loss 1.30710626 epoch total loss 1.16100633
Trained batch 4976 batch loss 1.35094428 epoch total loss 1.16104448
Trained batch 4977 batch loss 1.35284662 epoch total loss 1.1610831
Trained batch 4978 batch loss 1.30653501 epoch total loss 1.16111231
Trained batch 4979 batch loss 1.34393358 epoch total loss 1.16114902
Trained batch 4980 batch loss 1.4159205 epoch total loss 1.16120017
Trained batch 4981 batch loss 1.33203745 epoch total loss 1.1612345
Trained batch 4982 batch loss 1.29693925 epoch total loss 1.16126168
Trained batch 4983 batch loss 1.26310182 epoch total loss 1.16128218
Trained batch 4984 batch loss 1.29504848 epoch total loss 1.161309
Trained batch 4985 batch loss 1.48436749 epoch total loss 1.16137373
Trained batch 4986 batch loss 1.31625485 epoch total loss 1.16140485
Trained batch 4987 batch loss 1.36549687 epoch total loss 1.16144586
Trained batch 4988 batch loss 1.06631422 epoch total loss 1.16142678
Trained batch 4989 batch loss 1.23009944 epoch total loss 1.16144049
Trained batch 4990 batch loss 1.10883963 epoch total loss 1.16143
Trained batch 4991 batch loss 1.09378409 epoch total loss 1.16141641
Trained batch 4992 batch loss 1.13648295 epoch total loss 1.16141152
Trained batch 4993 batch loss 0.993722558 epoch total loss 1.16137791
Trained batch 4994 batch loss 1.03583121 epoch total loss 1.16135275
Trained batch 4995 batch loss 1.18144381 epoch total loss 1.16135681
Trained batch 4996 batch loss 1.21229339 epoch total loss 1.16136694
Trained batch 4997 batch loss 1.2878828 epoch total loss 1.16139233
Trained batch 4998 batch loss 1.40505981 epoch total loss 1.16144109
Trained batch 4999 batch loss 1.22859287 epoch total loss 1.16145456
Trained batch 5000 batch loss 1.58126807 epoch total loss 1.16153848
Trained batch 5001 batch loss 1.3870306 epoch total loss 1.16158354
Trained batch 5002 batch loss 1.41837239 epoch total loss 1.16163492
Trained batch 5003 batch loss 1.042961 epoch total loss 1.1616112
Trained batch 5004 batch loss 1.09353971 epoch total loss 1.16159773
Trained batch 5005 batch loss 1.15577114 epoch total loss 1.16159654
Trained batch 5006 batch loss 1.04470646 epoch total loss 1.16157317
Trained batch 5007 batch loss 1.09069693 epoch total loss 1.1615591
Trained batch 5008 batch loss 1.21525037 epoch total loss 1.16156983
Trained batch 5009 batch loss 1.14534223 epoch total loss 1.16156662
Trained batch 5010 batch loss 1.0301367 epoch total loss 1.16154039
Trained batch 5011 batch loss 1.0685128 epoch total loss 1.16152179
Trained batch 5012 batch loss 1.03066587 epoch total loss 1.16149569
Trained batch 5013 batch loss 1.08131766 epoch total loss 1.16147971
Trained batch 5014 batch loss 1.15645552 epoch total loss 1.16147876
Trained batch 5015 batch loss 1.21647978 epoch total loss 1.16148961
Trained batch 5016 batch loss 1.08341813 epoch total loss 1.16147411
Trained batch 5017 batch loss 1.07766891 epoch total loss 1.16145742
Trained batch 5018 batch loss 1.05278063 epoch total loss 1.16143572
Trained batch 5019 batch loss 0.980599344 epoch total loss 1.16139972
Trained batch 5020 batch loss 1.04463744 epoch total loss 1.16137636
Trained batch 5021 batch loss 0.97430253 epoch total loss 1.16133904
Trained batch 5022 batch loss 1.06022525 epoch total loss 1.1613189
Trained batch 5023 batch loss 0.945181727 epoch total loss 1.16127586
Trained batch 5024 batch loss 1.13526547 epoch total loss 1.16127074
Trained batch 5025 batch loss 1.04032755 epoch total loss 1.16124666
Trained batch 5026 batch loss 1.34311104 epoch total loss 1.1612829
Trained batch 5027 batch loss 1.16868317 epoch total loss 1.16128433
Trained batch 5028 batch loss 1.06534886 epoch total loss 1.16126525
Trained batch 5029 batch loss 1.0950253 epoch total loss 1.16125214
Trained batch 5030 batch loss 1.2259866 epoch total loss 1.16126502
Trained batch 5031 batch loss 1.19872034 epoch total loss 1.16127253
Trained batch 5032 batch loss 1.21625769 epoch total loss 1.16128337
Trained batch 5033 batch loss 1.3151772 epoch total loss 1.16131389
Trained batch 5034 batch loss 1.19127798 epoch total loss 1.16132
Trained batch 5035 batch loss 1.46058583 epoch total loss 1.16137934
Trained batch 5036 batch loss 1.2855022 epoch total loss 1.16140401
Trained batch 5037 batch loss 1.28818738 epoch total loss 1.16142917
Trained batch 5038 batch loss 1.31685758 epoch total loss 1.16146
Trained batch 5039 batch loss 1.06243181 epoch total loss 1.16144037
Trained batch 5040 batch loss 1.09717715 epoch total loss 1.16142762
Trained batch 5041 batch loss 0.991101325 epoch total loss 1.16139388
Trained batch 5042 batch loss 1.13646126 epoch total loss 1.16138887
Trained batch 5043 batch loss 1.25929344 epoch total loss 1.16140831
Trained batch 5044 batch loss 1.13868666 epoch total loss 1.16140378
Trained batch 5045 batch loss 1.23004 epoch total loss 1.16141737
Trained batch 5046 batch loss 1.07828522 epoch total loss 1.16140079
Trained batch 5047 batch loss 1.21479774 epoch total loss 1.1614114
Trained batch 5048 batch loss 1.15043283 epoch total loss 1.16140926
Trained batch 5049 batch loss 1.30129659 epoch total loss 1.16143692
Trained batch 5050 batch loss 1.27383471 epoch total loss 1.16145921
Trained batch 5051 batch loss 1.19838476 epoch total loss 1.16146648
Trained batch 5052 batch loss 1.24719107 epoch total loss 1.16148341
Trained batch 5053 batch loss 1.16405666 epoch total loss 1.161484
Trained batch 5054 batch loss 1.07423615 epoch total loss 1.16146672
Trained batch 5055 batch loss 1.06070423 epoch total loss 1.16144669
Trained batch 5056 batch loss 1.15856981 epoch total loss 1.16144621
Trained batch 5057 batch loss 1.23391485 epoch total loss 1.16146052
Trained batch 5058 batch loss 1.28718936 epoch total loss 1.16148531
Trained batch 5059 batch loss 1.29401588 epoch total loss 1.16151154
Trained batch 5060 batch loss 1.07464147 epoch total loss 1.16149437
Trained batch 5061 batch loss 1.37069833 epoch total loss 1.16153574
Trained batch 5062 batch loss 1.10219634 epoch total loss 1.16152394
Trained batch 5063 batch loss 1.12496972 epoch total loss 1.16151679
Trained batch 5064 batch loss 1.09456468 epoch total loss 1.16150355
Trained batch 5065 batch loss 1.46569788 epoch total loss 1.16156363
Trained batch 5066 batch loss 1.36791921 epoch total loss 1.16160429
Trained batch 5067 batch loss 1.21403694 epoch total loss 1.16161466
Trained batch 5068 batch loss 1.35210288 epoch total loss 1.16165221
Trained batch 5069 batch loss 1.3749187 epoch total loss 1.16169429
Trained batch 5070 batch loss 1.08118844 epoch total loss 1.16167843
Trained batch 5071 batch loss 1.28107274 epoch total loss 1.16170192
Trained batch 5072 batch loss 1.26083875 epoch total loss 1.16172147
Trained batch 5073 batch loss 1.41736698 epoch total loss 1.16177189
Trained batch 5074 batch loss 1.36134624 epoch total loss 1.16181123
Trained batch 5075 batch loss 1.16196918 epoch total loss 1.16181135
Trained batch 5076 batch loss 1.29880011 epoch total loss 1.16183829
Trained batch 5077 batch loss 1.24568057 epoch total loss 1.16185474
Trained batch 5078 batch loss 1.30636525 epoch total loss 1.16188323
Trained batch 5079 batch loss 1.21970296 epoch total loss 1.16189456
Trained batch 5080 batch loss 1.23836553 epoch total loss 1.1619097
Trained batch 5081 batch loss 1.33159316 epoch total loss 1.16194308
Trained batch 5082 batch loss 1.22404921 epoch total loss 1.16195524
Trained batch 5083 batch loss 1.13292646 epoch total loss 1.16194952
Trained batch 5084 batch loss 1.16456878 epoch total loss 1.16195
Trained batch 5085 batch loss 1.0944922 epoch total loss 1.16193688
Trained batch 5086 batch loss 1.17804623 epoch total loss 1.16194
Trained batch 5087 batch loss 0.945730329 epoch total loss 1.16189754
Trained batch 5088 batch loss 1.09309864 epoch total loss 1.16188407
Trained batch 5089 batch loss 0.984331131 epoch total loss 1.16184914
Trained batch 5090 batch loss 1.27399695 epoch total loss 1.16187119
Trained batch 5091 batch loss 1.19139755 epoch total loss 1.16187704
Trained batch 5092 batch loss 1.3125695 epoch total loss 1.1619066
Trained batch 5093 batch loss 1.13028538 epoch total loss 1.1619004
Trained batch 5094 batch loss 1.11214602 epoch total loss 1.16189063
Trained batch 5095 batch loss 1.23874569 epoch total loss 1.16190577
Trained batch 5096 batch loss 1.09525871 epoch total loss 1.16189265
Trained batch 5097 batch loss 1.23585153 epoch total loss 1.1619072
Trained batch 5098 batch loss 1.31058502 epoch total loss 1.16193628
Trained batch 5099 batch loss 1.12812376 epoch total loss 1.16192961
Trained batch 5100 batch loss 1.07696629 epoch total loss 1.16191304
Trained batch 5101 batch loss 1.1977303 epoch total loss 1.16192007
Trained batch 5102 batch loss 1.11869645 epoch total loss 1.16191161
Trained batch 5103 batch loss 1.2069701 epoch total loss 1.16192043
Trained batch 5104 batch loss 1.07196498 epoch total loss 1.16190279
Trained batch 5105 batch loss 1.2526722 epoch total loss 1.16192043
Trained batch 5106 batch loss 1.22418094 epoch total loss 1.16193271
Trained batch 5107 batch loss 1.35963988 epoch total loss 1.16197145
Trained batch 5108 batch loss 1.19016528 epoch total loss 1.16197693
Trained batch 5109 batch loss 1.13359928 epoch total loss 1.16197133
Trained batch 5110 batch loss 1.04922283 epoch total loss 1.16194928
Trained batch 5111 batch loss 1.2653811 epoch total loss 1.16196966
Trained batch 5112 batch loss 1.18422627 epoch total loss 1.16197395
Trained batch 5113 batch loss 1.23977804 epoch total loss 1.16198909
Trained batch 5114 batch loss 1.13498259 epoch total loss 1.16198385
Trained batch 5115 batch loss 1.1289866 epoch total loss 1.16197741
Trained batch 5116 batch loss 1.06019914 epoch total loss 1.16195738
Trained batch 5117 batch loss 1.05331016 epoch total loss 1.16193616
Trained batch 5118 batch loss 1.4092828 epoch total loss 1.16198444
Trained batch 5119 batch loss 1.23141348 epoch total loss 1.16199803
Trained batch 5120 batch loss 1.23740506 epoch total loss 1.16201282
Trained batch 5121 batch loss 1.39213562 epoch total loss 1.16205764
Trained batch 5122 batch loss 1.16917086 epoch total loss 1.16205907
Trained batch 5123 batch loss 1.00984442 epoch total loss 1.16202927
Trained batch 5124 batch loss 1.15853858 epoch total loss 1.16202867
Trained batch 5125 batch loss 1.08939695 epoch total loss 1.16201448
Trained batch 5126 batch loss 1.01417804 epoch total loss 1.16198564
Trained batch 5127 batch loss 1.12103486 epoch total loss 1.16197765
Trained batch 5128 batch loss 1.42978752 epoch total loss 1.16202986
Trained batch 5129 batch loss 1.18831205 epoch total loss 1.16203499
Trained batch 5130 batch loss 1.30643392 epoch total loss 1.16206324
Trained batch 5131 batch loss 1.05191159 epoch total loss 1.16204166
Trained batch 5132 batch loss 1.20206678 epoch total loss 1.16204953
Trained batch 5133 batch loss 1.06764126 epoch total loss 1.16203117
Trained batch 5134 batch loss 1.28881395 epoch total loss 1.16205585
Trained batch 5135 batch loss 1.24366546 epoch total loss 1.1620717
Trained batch 5136 batch loss 1.18637753 epoch total loss 1.16207647
Trained batch 5137 batch loss 1.29641581 epoch total loss 1.16210258
Trained batch 5138 batch loss 1.26749909 epoch total loss 1.1621232
Trained batch 5139 batch loss 1.21150088 epoch total loss 1.16213274
Trained batch 5140 batch loss 1.30279386 epoch total loss 1.16216016
Trained batch 5141 batch loss 1.24644744 epoch total loss 1.16217649
Trained batch 5142 batch loss 1.10130894 epoch total loss 1.16216469
Trained batch 5143 batch loss 1.18044615 epoch total loss 1.16216826
Trained batch 5144 batch loss 1.08529317 epoch total loss 1.16215336
Trained batch 5145 batch loss 1.19169736 epoch total loss 1.16215909
Trained batch 5146 batch loss 1.00282907 epoch total loss 1.16212821
Trained batch 5147 batch loss 0.913943172 epoch total loss 1.16207993
Trained batch 5148 batch loss 1.13262343 epoch total loss 1.16207433
Trained batch 5149 batch loss 1.33911598 epoch total loss 1.16210866
Trained batch 5150 batch loss 1.02606416 epoch total loss 1.16208231
Trained batch 5151 batch loss 1.06364596 epoch total loss 1.16206312
Trained batch 5152 batch loss 1.19414091 epoch total loss 1.16206932
Trained batch 5153 batch loss 0.888225913 epoch total loss 1.16201627
Trained batch 5154 batch loss 1.11293554 epoch total loss 1.16200674
Trained batch 5155 batch loss 1.02041161 epoch total loss 1.1619792
Trained batch 5156 batch loss 0.947199762 epoch total loss 1.16193759
Trained batch 5157 batch loss 1.07850969 epoch total loss 1.16192138
Trained batch 5158 batch loss 0.967873216 epoch total loss 1.16188383
Trained batch 5159 batch loss 0.982801557 epoch total loss 1.16184914
Trained batch 5160 batch loss 0.994960546 epoch total loss 1.16181684
Trained batch 5161 batch loss 0.923488855 epoch total loss 1.16177058
Trained batch 5162 batch loss 1.19438279 epoch total loss 1.1617769
Trained batch 5163 batch loss 1.12050819 epoch total loss 1.16176891
Trained batch 5164 batch loss 1.14795828 epoch total loss 1.16176629
Trained batch 5165 batch loss 1.09010935 epoch total loss 1.16175246
Trained batch 5166 batch loss 1.05969286 epoch total loss 1.16173267
Trained batch 5167 batch loss 1.0626421 epoch total loss 1.16171336
Trained batch 5168 batch loss 1.04983473 epoch total loss 1.16169178
Trained batch 5169 batch loss 1.22189546 epoch total loss 1.16170335
Trained batch 5170 batch loss 1.1716435 epoch total loss 1.16170537
Trained batch 5171 batch loss 1.43169498 epoch total loss 1.16175759
Trained batch 5172 batch loss 1.14001274 epoch total loss 1.16175342
Trained batch 5173 batch loss 1.11749029 epoch total loss 1.16174483
Trained batch 5174 batch loss 1.0817101 epoch total loss 1.16172934
Trained batch 5175 batch loss 0.933755755 epoch total loss 1.16168523
Trained batch 5176 batch loss 1.0758394 epoch total loss 1.16166866
Trained batch 5177 batch loss 1.09195399 epoch total loss 1.16165519
Trained batch 5178 batch loss 1.07634044 epoch total loss 1.16163862
Trained batch 5179 batch loss 0.984817803 epoch total loss 1.16160452
Trained batch 5180 batch loss 1.23504007 epoch total loss 1.16161859
Trained batch 5181 batch loss 1.20325732 epoch total loss 1.1616267
Trained batch 5182 batch loss 1.13430977 epoch total loss 1.16162133
Trained batch 5183 batch loss 0.996045053 epoch total loss 1.16158938
Trained batch 5184 batch loss 1.08736444 epoch total loss 1.16157508
Trained batch 5185 batch loss 0.842370927 epoch total loss 1.16151357
Trained batch 5186 batch loss 1.08147037 epoch total loss 1.16149807
Trained batch 5187 batch loss 1.00454307 epoch total loss 1.16146779
Trained batch 5188 batch loss 1.08729148 epoch total loss 1.1614536
Trained batch 5189 batch loss 1.01394272 epoch total loss 1.16142523
Trained batch 5190 batch loss 1.46963024 epoch total loss 1.1614846
Trained batch 5191 batch loss 1.28730249 epoch total loss 1.1615088
Trained batch 5192 batch loss 1.38610721 epoch total loss 1.16155207
Trained batch 5193 batch loss 1.38041878 epoch total loss 1.16159415
Trained batch 5194 batch loss 1.22544909 epoch total loss 1.16160655
Trained batch 5195 batch loss 1.13192177 epoch total loss 1.16160083
Trained batch 5196 batch loss 1.17554665 epoch total loss 1.16160357
Trained batch 5197 batch loss 1.24244928 epoch total loss 1.16161907
Trained batch 5198 batch loss 1.33677292 epoch total loss 1.1616528
Trained batch 5199 batch loss 1.23419428 epoch total loss 1.16166687
Trained batch 5200 batch loss 1.20603561 epoch total loss 1.16167533
Trained batch 5201 batch loss 1.12321234 epoch total loss 1.16166794
Trained batch 5202 batch loss 1.15399337 epoch total loss 1.16166639
Trained batch 5203 batch loss 1.10198414 epoch total loss 1.16165495
Trained batch 5204 batch loss 1.218606 epoch total loss 1.16166592
Trained batch 5205 batch loss 1.19584692 epoch total loss 1.16167247
Trained batch 5206 batch loss 1.15531564 epoch total loss 1.16167128
Trained batch 5207 batch loss 0.945176899 epoch total loss 1.16162968
Trained batch 5208 batch loss 1.27934885 epoch total loss 1.16165233
Trained batch 5209 batch loss 1.00786519 epoch total loss 1.16162276
Trained batch 5210 batch loss 0.947868526 epoch total loss 1.16158175
Trained batch 5211 batch loss 1.21465814 epoch total loss 1.16159201
Trained batch 5212 batch loss 1.23664582 epoch total loss 1.16160643
Trained batch 5213 batch loss 1.28576422 epoch total loss 1.16163015
Trained batch 5214 batch loss 1.30331695 epoch total loss 1.16165733
Trained batch 5215 batch loss 1.10289013 epoch total loss 1.16164613
Trained batch 5216 batch loss 1.10283124 epoch total loss 1.1616348
Trained batch 5217 batch loss 1.31723 epoch total loss 1.16166472
Trained batch 5218 batch loss 1.34963894 epoch total loss 1.16170073
Trained batch 5219 batch loss 1.30787301 epoch total loss 1.16172874
Trained batch 5220 batch loss 1.22106647 epoch total loss 1.16174018
Trained batch 5221 batch loss 1.29952705 epoch total loss 1.16176653
Trained batch 5222 batch loss 1.19765663 epoch total loss 1.16177344
Trained batch 5223 batch loss 1.18461263 epoch total loss 1.16177773
Trained batch 5224 batch loss 1.37484813 epoch total loss 1.16181862
Trained batch 5225 batch loss 1.31253791 epoch total loss 1.16184747
Trained batch 5226 batch loss 1.2226125 epoch total loss 1.16185904
Trained batch 5227 batch loss 1.12923062 epoch total loss 1.16185284
Trained batch 5228 batch loss 1.20525122 epoch total loss 1.16186118
Trained batch 5229 batch loss 1.1036737 epoch total loss 1.16185
Trained batch 5230 batch loss 1.09722352 epoch total loss 1.16183758
Trained batch 5231 batch loss 1.28589976 epoch total loss 1.16186142
Trained batch 5232 batch loss 1.12078333 epoch total loss 1.16185343
Trained batch 5233 batch loss 1.20939863 epoch total loss 1.16186261
Trained batch 5234 batch loss 1.05061734 epoch total loss 1.16184139
Trained batch 5235 batch loss 1.36146665 epoch total loss 1.16187942
Trained batch 5236 batch loss 1.35904777 epoch total loss 1.16191709
Trained batch 5237 batch loss 1.41876745 epoch total loss 1.1619662
Trained batch 5238 batch loss 1.20532846 epoch total loss 1.16197443
Trained batch 5239 batch loss 1.29270148 epoch total loss 1.16199934
Trained batch 5240 batch loss 1.21688724 epoch total loss 1.16200984
Trained batch 5241 batch loss 0.949207783 epoch total loss 1.1619693
Trained batch 5242 batch loss 1.12291217 epoch total loss 1.16196179
Trained batch 5243 batch loss 1.2328167 epoch total loss 1.16197538
Trained batch 5244 batch loss 1.39959967 epoch total loss 1.16202068
Trained batch 5245 batch loss 1.20923114 epoch total loss 1.16202974
Trained batch 5246 batch loss 1.38410664 epoch total loss 1.16207206
Trained batch 5247 batch loss 1.17048979 epoch total loss 1.16207361
Trained batch 5248 batch loss 1.43343258 epoch total loss 1.16212535
Trained batch 5249 batch loss 1.33061481 epoch total loss 1.16215742
Trained batch 5250 batch loss 1.20031786 epoch total loss 1.16216469
Trained batch 5251 batch loss 1.20720077 epoch total loss 1.16217327
Trained batch 5252 batch loss 1.14697 epoch total loss 1.16217041
Trained batch 5253 batch loss 1.17516601 epoch total loss 1.16217291
Trained batch 5254 batch loss 1.19058609 epoch total loss 1.16217828
Trained batch 5255 batch loss 1.24589682 epoch total loss 1.16219425
Trained batch 5256 batch loss 1.26164496 epoch total loss 1.16221309
Trained batch 5257 batch loss 1.14460301 epoch total loss 1.16220975
Trained batch 5258 batch loss 1.1822896 epoch total loss 1.16221356
Trained batch 5259 batch loss 1.43102837 epoch total loss 1.1622647
Trained batch 5260 batch loss 1.09206975 epoch total loss 1.16225135
Trained batch 5261 batch loss 1.31246638 epoch total loss 1.16228
Trained batch 5262 batch loss 1.12163281 epoch total loss 1.16227221
Trained batch 5263 batch loss 1.06244659 epoch total loss 1.16225326
Trained batch 5264 batch loss 1.21759176 epoch total loss 1.16226387
Trained batch 5265 batch loss 1.14372361 epoch total loss 1.16226029
Trained batch 5266 batch loss 1.27610946 epoch total loss 1.16228187
Trained batch 5267 batch loss 1.05626464 epoch total loss 1.16226172
Trained batch 5268 batch loss 1.08091557 epoch total loss 1.16224623
Trained batch 5269 batch loss 1.26278663 epoch total loss 1.1622653
Trained batch 5270 batch loss 1.22676897 epoch total loss 1.16227758
Trained batch 5271 batch loss 1.0285399 epoch total loss 1.16225207
Trained batch 5272 batch loss 1.29462886 epoch total loss 1.16227722
Trained batch 5273 batch loss 1.50071561 epoch total loss 1.16234136
Trained batch 5274 batch loss 1.13494408 epoch total loss 1.16233611
Trained batch 5275 batch loss 1.02669263 epoch total loss 1.16231048
Trained batch 5276 batch loss 1.20854747 epoch total loss 1.16231918
Trained batch 5277 batch loss 1.26504302 epoch total loss 1.16233861
Trained batch 5278 batch loss 1.32463908 epoch total loss 1.16236937
Trained batch 5279 batch loss 1.26258278 epoch total loss 1.16238844
Trained batch 5280 batch loss 0.944463909 epoch total loss 1.16234708
Trained batch 5281 batch loss 1.1193558 epoch total loss 1.16233897
Trained batch 5282 batch loss 1.07050145 epoch total loss 1.16232157
Trained batch 5283 batch loss 1.35396707 epoch total loss 1.16235781
Trained batch 5284 batch loss 1.13026023 epoch total loss 1.16235173
Trained batch 5285 batch loss 1.02462769 epoch total loss 1.16232562
Trained batch 5286 batch loss 1.09954751 epoch total loss 1.16231382
Trained batch 5287 batch loss 0.973063707 epoch total loss 1.16227806
Trained batch 5288 batch loss 0.977146804 epoch total loss 1.16224301
Trained batch 5289 batch loss 1.14135516 epoch total loss 1.16223896
Trained batch 5290 batch loss 0.955967784 epoch total loss 1.1622
Trained batch 5291 batch loss 1.02425122 epoch total loss 1.16217399
Trained batch 5292 batch loss 0.976840615 epoch total loss 1.16213894
Trained batch 5293 batch loss 1.10919881 epoch total loss 1.16212904
Trained batch 5294 batch loss 1.20610154 epoch total loss 1.16213727
Trained batch 5295 batch loss 1.26850176 epoch total loss 1.16215742
Trained batch 5296 batch loss 1.15824294 epoch total loss 1.1621567
Trained batch 5297 batch loss 1.02329719 epoch total loss 1.16213048
Trained batch 5298 batch loss 1.16859102 epoch total loss 1.16213167
Trained batch 5299 batch loss 1.34078193 epoch total loss 1.1621654
Trained batch 5300 batch loss 1.21162522 epoch total loss 1.1621747
Trained batch 5301 batch loss 1.54176331 epoch total loss 1.16224635
Trained batch 5302 batch loss 1.42734146 epoch total loss 1.1622963
Trained batch 5303 batch loss 1.42799973 epoch total loss 1.16234648
Trained batch 5304 batch loss 1.42145121 epoch total loss 1.16239536
Trained batch 5305 batch loss 1.38859236 epoch total loss 1.16243792
Trained batch 5306 batch loss 1.2388314 epoch total loss 1.16245234
Trained batch 5307 batch loss 1.20447242 epoch total loss 1.16246033
Trained batch 5308 batch loss 1.07442403 epoch total loss 1.16244364
Trained batch 5309 batch loss 1.15457439 epoch total loss 1.16244221
Trained batch 5310 batch loss 1.29066801 epoch total loss 1.16246629
Trained batch 5311 batch loss 1.36156344 epoch total loss 1.16250384
Trained batch 5312 batch loss 1.23748755 epoch total loss 1.16251791
Trained batch 5313 batch loss 1.14209783 epoch total loss 1.16251397
Trained batch 5314 batch loss 1.23879099 epoch total loss 1.1625284
Trained batch 5315 batch loss 1.12842894 epoch total loss 1.16252196
Trained batch 5316 batch loss 1.22129357 epoch total loss 1.16253304
Trained batch 5317 batch loss 1.06901968 epoch total loss 1.1625154
Trained batch 5318 batch loss 0.953231871 epoch total loss 1.16247594
Trained batch 5319 batch loss 1.00842094 epoch total loss 1.16244698
Trained batch 5320 batch loss 1.26648664 epoch total loss 1.16246665
Trained batch 5321 batch loss 1.22536993 epoch total loss 1.16247845
Trained batch 5322 batch loss 1.1958282 epoch total loss 1.16248477
Trained batch 5323 batch loss 1.23107529 epoch total loss 1.16249752
Trained batch 5324 batch loss 0.941213 epoch total loss 1.16245604
Trained batch 5325 batch loss 0.882488966 epoch total loss 1.16240346
Trained batch 5326 batch loss 0.790659547 epoch total loss 1.16233361
Trained batch 5327 batch loss 1.24129319 epoch total loss 1.16234839
Trained batch 5328 batch loss 1.26261926 epoch total loss 1.16236722
Trained batch 5329 batch loss 1.39285505 epoch total loss 1.1624105
Trained batch 5330 batch loss 1.34621119 epoch total loss 1.16244507
Trained batch 5331 batch loss 1.17098272 epoch total loss 1.16244662
Trained batch 5332 batch loss 1.02360225 epoch total loss 1.16242051
Trained batch 5333 batch loss 1.10638189 epoch total loss 1.16241
Trained batch 5334 batch loss 1.34596038 epoch total loss 1.16244447
Trained batch 5335 batch loss 1.21461546 epoch total loss 1.16245437
Trained batch 5336 batch loss 1.0731225 epoch total loss 1.16243756
Trained batch 5337 batch loss 1.02432775 epoch total loss 1.16241169
Trained batch 5338 batch loss 0.890647888 epoch total loss 1.16236079
Trained batch 5339 batch loss 1.13405681 epoch total loss 1.16235554
Trained batch 5340 batch loss 0.956621766 epoch total loss 1.16231704
Trained batch 5341 batch loss 1.0418694 epoch total loss 1.16229451
Trained batch 5342 batch loss 1.0719794 epoch total loss 1.16227758
Trained batch 5343 batch loss 0.795070887 epoch total loss 1.1622088
Trained batch 5344 batch loss 0.906087697 epoch total loss 1.16216087
Trained batch 5345 batch loss 0.957118392 epoch total loss 1.16212249
Trained batch 5346 batch loss 0.879092753 epoch total loss 1.16206956
Trained batch 5347 batch loss 0.896368086 epoch total loss 1.16201985
Trained batch 5348 batch loss 0.981789172 epoch total loss 1.16198623
Trained batch 5349 batch loss 0.898192167 epoch total loss 1.16193688
Trained batch 5350 batch loss 0.953256786 epoch total loss 1.16189778
Trained batch 5351 batch loss 0.920233071 epoch total loss 1.16185272
Trained batch 5352 batch loss 0.946981072 epoch total loss 1.16181254
Trained batch 5353 batch loss 1.23094547 epoch total loss 1.16182542
Trained batch 5354 batch loss 1.19802642 epoch total loss 1.16183221
Trained batch 5355 batch loss 1.41684389 epoch total loss 1.1618799
Trained batch 5356 batch loss 1.37795448 epoch total loss 1.16192019
Trained batch 5357 batch loss 1.48442221 epoch total loss 1.16198039
Trained batch 5358 batch loss 1.34747708 epoch total loss 1.16201508
Trained batch 5359 batch loss 1.56355095 epoch total loss 1.16209
Trained batch 5360 batch loss 1.45339632 epoch total loss 1.1621443
Trained batch 5361 batch loss 1.18992853 epoch total loss 1.16214955
Trained batch 5362 batch loss 1.3724637 epoch total loss 1.16218877
Trained batch 5363 batch loss 1.28102899 epoch total loss 1.16221094
Trained batch 5364 batch loss 1.37989056 epoch total loss 1.16225159
Trained batch 5365 batch loss 1.44090927 epoch total loss 1.16230345
Trained batch 5366 batch loss 1.42205834 epoch total loss 1.16235185
Trained batch 5367 batch loss 1.25067544 epoch total loss 1.1623683
Trained batch 5368 batch loss 1.1357522 epoch total loss 1.16236329
Trained batch 5369 batch loss 0.967674375 epoch total loss 1.16232705
Trained batch 5370 batch loss 1.18524337 epoch total loss 1.16233134
Trained batch 5371 batch loss 1.17202246 epoch total loss 1.16233313
Trained batch 5372 batch loss 1.38919961 epoch total loss 1.16237533
Trained batch 5373 batch loss 1.47707248 epoch total loss 1.16243386
Trained batch 5374 batch loss 1.26802087 epoch total loss 1.16245353
Trained batch 5375 batch loss 1.51507437 epoch total loss 1.16251922
Trained batch 5376 batch loss 1.46312761 epoch total loss 1.16257501
Trained batch 5377 batch loss 1.31885886 epoch total loss 1.16260409
Trained batch 5378 batch loss 1.33186793 epoch total loss 1.16263556
Trained batch 5379 batch loss 1.27968454 epoch total loss 1.16265738
Trained batch 5380 batch loss 1.08233714 epoch total loss 1.16264248
Trained batch 5381 batch loss 1.17930317 epoch total loss 1.16264558
Trained batch 5382 batch loss 1.47627807 epoch total loss 1.16270375
Trained batch 5383 batch loss 1.11408269 epoch total loss 1.16269481
Trained batch 5384 batch loss 1.23223519 epoch total loss 1.16270781
Trained batch 5385 batch loss 1.02306771 epoch total loss 1.16268182
Trained batch 5386 batch loss 1.29555309 epoch total loss 1.16270649
Trained batch 5387 batch loss 1.03221822 epoch total loss 1.16268218
Trained batch 5388 batch loss 1.29425681 epoch total loss 1.16270673
Trained batch 5389 batch loss 1.23154163 epoch total loss 1.16271949
Trained batch 5390 batch loss 1.18821728 epoch total loss 1.16272414
Trained batch 5391 batch loss 1.30215812 epoch total loss 1.16275
Trained batch 5392 batch loss 1.17165756 epoch total loss 1.16275167
Trained batch 5393 batch loss 1.11380279 epoch total loss 1.16274261
Trained batch 5394 batch loss 1.12938118 epoch total loss 1.16273642
Trained batch 5395 batch loss 0.838488638 epoch total loss 1.16267633
Trained batch 5396 batch loss 1.20244384 epoch total loss 1.16268373
Trained batch 5397 batch loss 1.09344292 epoch total loss 1.16267085
Trained batch 5398 batch loss 1.28201473 epoch total loss 1.16269302
Trained batch 5399 batch loss 1.25483513 epoch total loss 1.16271007
Trained batch 5400 batch loss 1.20833194 epoch total loss 1.16271853
Trained batch 5401 batch loss 1.17967725 epoch total loss 1.16272163
Trained batch 5402 batch loss 1.03618264 epoch total loss 1.16269827
Trained batch 5403 batch loss 1.2405231 epoch total loss 1.16271269
Trained batch 5404 batch loss 1.00755417 epoch total loss 1.16268396
Trained batch 5405 batch loss 1.36319423 epoch total loss 1.16272104
Trained batch 5406 batch loss 0.981195927 epoch total loss 1.16268742
Trained batch 5407 batch loss 1.15459919 epoch total loss 1.16268599
Trained batch 5408 batch loss 0.887353122 epoch total loss 1.16263509
Trained batch 5409 batch loss 1.23125648 epoch total loss 1.16264772
Trained batch 5410 batch loss 1.16073346 epoch total loss 1.16264737
Trained batch 5411 batch loss 1.16863286 epoch total loss 1.16264844
Trained batch 5412 batch loss 1.16225493 epoch total loss 1.16264832
Trained batch 5413 batch loss 1.0431093 epoch total loss 1.16262627
Trained batch 5414 batch loss 1.21247053 epoch total loss 1.16263545
Trained batch 5415 batch loss 1.31864786 epoch total loss 1.16266429
Trained batch 5416 batch loss 1.51194072 epoch total loss 1.16272879
Trained batch 5417 batch loss 1.21004891 epoch total loss 1.16273749
Trained batch 5418 batch loss 1.39783549 epoch total loss 1.16278088
Trained batch 5419 batch loss 1.05657947 epoch total loss 1.16276133
Trained batch 5420 batch loss 1.36564744 epoch total loss 1.16279876
Trained batch 5421 batch loss 1.20574355 epoch total loss 1.16280663
Trained batch 5422 batch loss 1.30194986 epoch total loss 1.16283226
Trained batch 5423 batch loss 1.18238068 epoch total loss 1.16283596
Trained batch 5424 batch loss 1.53777719 epoch total loss 1.16290498
Trained batch 5425 batch loss 1.01227951 epoch total loss 1.1628772
Trained batch 5426 batch loss 1.3057549 epoch total loss 1.16290355
Trained batch 5427 batch loss 1.27559257 epoch total loss 1.16292429
Trained batch 5428 batch loss 1.3038888 epoch total loss 1.16295016
Trained batch 5429 batch loss 1.42309785 epoch total loss 1.1629982
Trained batch 5430 batch loss 1.29455829 epoch total loss 1.1630224
Trained batch 5431 batch loss 1.25275254 epoch total loss 1.16303897
Trained batch 5432 batch loss 1.03711915 epoch total loss 1.16301572
Trained batch 5433 batch loss 1.1087513 epoch total loss 1.16300583
Trained batch 5434 batch loss 1.46832991 epoch total loss 1.16306198
Trained batch 5435 batch loss 1.19134617 epoch total loss 1.1630671
Trained batch 5436 batch loss 1.11072731 epoch total loss 1.16305757
Trained batch 5437 batch loss 1.27507496 epoch total loss 1.16307807
Trained batch 5438 batch loss 1.41164207 epoch total loss 1.16312385
Trained batch 5439 batch loss 1.32971501 epoch total loss 1.16315448
Trained batch 5440 batch loss 1.15332949 epoch total loss 1.16315258
Trained batch 5441 batch loss 1.27463472 epoch total loss 1.16317308
Trained batch 5442 batch loss 1.29972315 epoch total loss 1.16319823
Trained batch 5443 batch loss 1.04804277 epoch total loss 1.16317701
Trained batch 5444 batch loss 1.06940889 epoch total loss 1.16315973
Trained batch 5445 batch loss 1.04864335 epoch total loss 1.16313875
Trained batch 5446 batch loss 1.21901309 epoch total loss 1.163149
Trained batch 5447 batch loss 1.26129556 epoch total loss 1.16316712
Trained batch 5448 batch loss 1.22545266 epoch total loss 1.16317856
Trained batch 5449 batch loss 1.33084643 epoch total loss 1.16320932
Trained batch 5450 batch loss 0.984915316 epoch total loss 1.16317666
Trained batch 5451 batch loss 1.11751246 epoch total loss 1.16316831
Trained batch 5452 batch loss 1.02792788 epoch total loss 1.1631434
Trained batch 5453 batch loss 1.27310741 epoch total loss 1.16316354
Trained batch 5454 batch loss 1.18483806 epoch total loss 1.1631676
Trained batch 5455 batch loss 1.13620269 epoch total loss 1.16316259
Trained batch 5456 batch loss 1.02483332 epoch total loss 1.16313732
Trained batch 5457 batch loss 1.04419363 epoch total loss 1.1631155
Trained batch 5458 batch loss 1.05758309 epoch total loss 1.16309619
Trained batch 5459 batch loss 0.988518715 epoch total loss 1.16306424
Trained batch 5460 batch loss 0.982322693 epoch total loss 1.1630311
Trained batch 5461 batch loss 1.03832221 epoch total loss 1.16300821
Trained batch 5462 batch loss 1.1266886 epoch total loss 1.16300154
Trained batch 5463 batch loss 0.850202739 epoch total loss 1.16294432
Trained batch 5464 batch loss 1.28263438 epoch total loss 1.16296613
Trained batch 5465 batch loss 1.07727766 epoch total loss 1.16295052
Trained batch 5466 batch loss 1.10629749 epoch total loss 1.16294014
Trained batch 5467 batch loss 1.25166178 epoch total loss 1.16295636
Trained batch 5468 batch loss 1.35394144 epoch total loss 1.16299129
Trained batch 5469 batch loss 0.898071051 epoch total loss 1.16294277
Trained batch 5470 batch loss 1.09369659 epoch total loss 1.16293013
Trained batch 5471 batch loss 1.22005892 epoch total loss 1.16294062
Trained batch 5472 batch loss 1.13588023 epoch total loss 1.16293561
Trained batch 5473 batch loss 1.12914848 epoch total loss 1.16292942
Trained batch 5474 batch loss 1.28336275 epoch total loss 1.16295147
Trained batch 5475 batch loss 1.29613936 epoch total loss 1.16297567
Trained batch 5476 batch loss 1.36789227 epoch total loss 1.1630131
Trained batch 5477 batch loss 1.53049755 epoch total loss 1.1630801
Trained batch 5478 batch loss 1.09850156 epoch total loss 1.16306841
Trained batch 5479 batch loss 1.29910994 epoch total loss 1.16309321
Trained batch 5480 batch loss 1.27273226 epoch total loss 1.16311324
Trained batch 5481 batch loss 1.04712331 epoch total loss 1.16309214
Trained batch 5482 batch loss 1.10385823 epoch total loss 1.16308141
Trained batch 5483 batch loss 1.27049398 epoch total loss 1.16310096
Trained batch 5484 batch loss 1.07265306 epoch total loss 1.16308451
Trained batch 5485 batch loss 1.21794033 epoch total loss 1.16309452
Trained batch 5486 batch loss 1.17737043 epoch total loss 1.16309702
Trained batch 5487 batch loss 1.3217051 epoch total loss 1.16312599
Trained batch 5488 batch loss 1.41742134 epoch total loss 1.16317236
Trained batch 5489 batch loss 1.34186506 epoch total loss 1.16320491
Trained batch 5490 batch loss 1.352947 epoch total loss 1.16323948
Trained batch 5491 batch loss 1.24878192 epoch total loss 1.1632551
Trained batch 5492 batch loss 0.958447695 epoch total loss 1.16321778
Trained batch 5493 batch loss 1.02426529 epoch total loss 1.16319251
Trained batch 5494 batch loss 1.16540623 epoch total loss 1.16319299
Trained batch 5495 batch loss 1.3079102 epoch total loss 1.16321933
Trained batch 5496 batch loss 1.0006907 epoch total loss 1.16318965
Trained batch 5497 batch loss 1.03859472 epoch total loss 1.163167
Trained batch 5498 batch loss 1.04644012 epoch total loss 1.16314578
Trained batch 5499 batch loss 1.07450783 epoch total loss 1.16312969
Trained batch 5500 batch loss 1.03269172 epoch total loss 1.16310596
Trained batch 5501 batch loss 1.02579236 epoch total loss 1.16308105
Trained batch 5502 batch loss 1.21139169 epoch total loss 1.16308987
Trained batch 5503 batch loss 1.40515876 epoch total loss 1.16313386
Trained batch 5504 batch loss 1.30548561 epoch total loss 1.16315973
Trained batch 5505 batch loss 1.32882428 epoch total loss 1.16318977
Trained batch 5506 batch loss 1.45540118 epoch total loss 1.16324294
Trained batch 5507 batch loss 1.24005842 epoch total loss 1.16325688
Trained batch 5508 batch loss 1.31099367 epoch total loss 1.16328371
Trained batch 5509 batch loss 1.41692269 epoch total loss 1.16332972
Trained batch 5510 batch loss 1.37454224 epoch total loss 1.16336811
Trained batch 5511 batch loss 1.24038327 epoch total loss 1.16338205
Trained batch 5512 batch loss 1.08873987 epoch total loss 1.16336858
Trained batch 5513 batch loss 1.15255165 epoch total loss 1.16336656
Trained batch 5514 batch loss 1.22679 epoch total loss 1.163378
Trained batch 5515 batch loss 0.894963503 epoch total loss 1.16332936
Trained batch 5516 batch loss 1.21404219 epoch total loss 1.16333854
Trained batch 5517 batch loss 1.32636356 epoch total loss 1.16336799
Trained batch 5518 batch loss 0.990258217 epoch total loss 1.16333663
Trained batch 5519 batch loss 0.896873355 epoch total loss 1.16328835
Trained batch 5520 batch loss 1.39470565 epoch total loss 1.1633302
Trained batch 5521 batch loss 1.3027277 epoch total loss 1.16335547
Trained batch 5522 batch loss 1.31905174 epoch total loss 1.16338372
Trained batch 5523 batch loss 1.22612417 epoch total loss 1.16339505
Trained batch 5524 batch loss 1.3055222 epoch total loss 1.1634208
Trained batch 5525 batch loss 1.31367183 epoch total loss 1.16344798
Trained batch 5526 batch loss 1.0711987 epoch total loss 1.16343129
Trained batch 5527 batch loss 0.97996 epoch total loss 1.16339803
Trained batch 5528 batch loss 1.06393456 epoch total loss 1.16338
Trained batch 5529 batch loss 1.06519616 epoch total loss 1.16336238
Trained batch 5530 batch loss 1.40551639 epoch total loss 1.16340613
Trained batch 5531 batch loss 1.3557117 epoch total loss 1.16344082
Trained batch 5532 batch loss 1.21165669 epoch total loss 1.16344953
Trained batch 5533 batch loss 1.46593988 epoch total loss 1.16350412
Trained batch 5534 batch loss 1.36202204 epoch total loss 1.16354
Trained batch 5535 batch loss 1.2032125 epoch total loss 1.16354716
Trained batch 5536 batch loss 1.22917426 epoch total loss 1.16355896
Trained batch 5537 batch loss 1.37029266 epoch total loss 1.16359627
Trained batch 5538 batch loss 1.41888249 epoch total loss 1.16364241
Trained batch 5539 batch loss 1.37251282 epoch total loss 1.16368008
Trained batch 5540 batch loss 1.1479125 epoch total loss 1.16367722
Trained batch 5541 batch loss 1.25661755 epoch total loss 1.16369402
Trained batch 5542 batch loss 1.25819349 epoch total loss 1.16371119
Trained batch 5543 batch loss 1.05983567 epoch total loss 1.16369247
Trained batch 5544 batch loss 1.16081214 epoch total loss 1.16369188
Trained batch 5545 batch loss 0.947196 epoch total loss 1.1636529
Trained batch 5546 batch loss 1.07308984 epoch total loss 1.16363657
Trained batch 5547 batch loss 1.03128457 epoch total loss 1.16361272
Trained batch 5548 batch loss 0.949837565 epoch total loss 1.1635741
Trained batch 5549 batch loss 1.03617835 epoch total loss 1.16355121
Trained batch 5550 batch loss 1.01953101 epoch total loss 1.16352522
Trained batch 5551 batch loss 1.0236336 epoch total loss 1.1635
Trained batch 5552 batch loss 0.839189649 epoch total loss 1.16344154
Epoch 3 train loss 1.16344153881073
Validated batch 1 batch loss 1.06600761
Validated batch 2 batch loss 1.24475491
Validated batch 3 batch loss 1.24795914
Validated batch 4 batch loss 1.07301354
Validated batch 5 batch loss 1.24909234
Validated batch 6 batch loss 1.05530751
Validated batch 7 batch loss 1.03926837
Validated batch 8 batch loss 1.17466402
Validated batch 9 batch loss 1.20679164
Validated batch 10 batch loss 1.14524555
Validated batch 11 batch loss 1.11856222
Validated batch 12 batch loss 1.01698029
Validated batch 13 batch loss 1.27694011
Validated batch 14 batch loss 1.052459
Validated batch 15 batch loss 0.914759636
Validated batch 16 batch loss 1.04768455
Validated batch 17 batch loss 1.20400274
Validated batch 18 batch loss 0.91550678
Validated batch 19 batch loss 1.31040788
Validated batch 20 batch loss 1.14555
Validated batch 21 batch loss 1.29324269
Validated batch 22 batch loss 1.0996716
Validated batch 23 batch loss 1.18829906
Validated batch 24 batch loss 1.26334679
Validated batch 25 batch loss 1.10839057
Validated batch 26 batch loss 1.02379131
Validated batch 27 batch loss 1.40602458
Validated batch 28 batch loss 1.19833481
Validated batch 29 batch loss 1.19811678
Validated batch 30 batch loss 1.14847457
Validated batch 31 batch loss 1.23441052
Validated batch 32 batch loss 1.23700857
Validated batch 33 batch loss 1.2606492
Validated batch 34 batch loss 1.19091773
Validated batch 35 batch loss 1.01975918
Validated batch 36 batch loss 1.13841009
Validated batch 37 batch loss 1.09717512
Validated batch 38 batch loss 0.974704862
Validated batch 39 batch loss 1.24266696
Validated batch 40 batch loss 1.56972337
Validated batch 41 batch loss 1.2296443
Validated batch 42 batch loss 1.02066302
Validated batch 43 batch loss 1.00993228
Validated batch 44 batch loss 1.20535684
Validated batch 45 batch loss 1.47807395
Validated batch 46 batch loss 1.1053133
Validated batch 47 batch loss 1.00322819
Validated batch 48 batch loss 1.04769897
Validated batch 49 batch loss 0.916773558
Validated batch 50 batch loss 1.19105434
Validated batch 51 batch loss 1.29536295
Validated batch 52 batch loss 1.25119209
Validated batch 53 batch loss 1.22615039
Validated batch 54 batch loss 1.15183878
Validated batch 55 batch loss 1.11089575
Validated batch 56 batch loss 1.27756786
Validated batch 57 batch loss 1.29415786
Validated batch 58 batch loss 1.03222215
Validated batch 59 batch loss 1.16841483
Validated batch 60 batch loss 1.06821644
Validated batch 61 batch loss 1.05975318
Validated batch 62 batch loss 1.16538095
Validated batch 63 batch loss 1.21512282
Validated batch 64 batch loss 1.25593185
Validated batch 65 batch loss 1.42591023
Validated batch 66 batch loss 1.23239243
Validated batch 67 batch loss 1.35715234
Validated batch 68 batch loss 1.23320901
Validated batch 69 batch loss 0.915241
Validated batch 70 batch loss 1.17055929
Validated batch 71 batch loss 1.41561604
Validated batch 72 batch loss 1.35795879
Validated batch 73 batch loss 1.17460501
Validated batch 74 batch loss 1.08814645
Validated batch 75 batch loss 0.903846741
Validated batch 76 batch loss 0.893351197
Validated batch 77 batch loss 1.3028686
Validated batch 78 batch loss 1.04891694
Validated batch 79 batch loss 1.54774046
Validated batch 80 batch loss 1.15705657
Validated batch 81 batch loss 1.01449871
Validated batch 82 batch loss 1.33065736
Validated batch 83 batch loss 1.17354941
Validated batch 84 batch loss 1.06541348
Validated batch 85 batch loss 1.39850807
Validated batch 86 batch loss 1.04302728
Validated batch 87 batch loss 0.982704937
Validated batch 88 batch loss 0.991695
Validated batch 89 batch loss 1.18462098
Validated batch 90 batch loss 1.15293026
Validated batch 91 batch loss 1.23337877
Validated batch 92 batch loss 1.30914545
Validated batch 93 batch loss 1.23300564
Validated batch 94 batch loss 0.982037783
Validated batch 95 batch loss 1.00048053
Validated batch 96 batch loss 1.09967196
Validated batch 97 batch loss 1.07613993
Validated batch 98 batch loss 1.24333322
Validated batch 99 batch loss 1.14292932
Validated batch 100 batch loss 1.16625929
Validated batch 101 batch loss 1.3674252
Validated batch 102 batch loss 1.30424094
Validated batch 103 batch loss 1.13979566
Validated batch 104 batch loss 1.02660275
Validated batch 105 batch loss 1.35286713
Validated batch 106 batch loss 1.24804544
Validated batch 107 batch loss 0.932729602
Validated batch 108 batch loss 1.19627917
Validated batch 109 batch loss 1.30768228
Validated batch 110 batch loss 1.12758541
Validated batch 111 batch loss 1.33595991
Validated batch 112 batch loss 1.31407452
Validated batch 113 batch loss 1.51161182
Validated batch 114 batch loss 1.38282752
Validated batch 115 batch loss 1.3748107
Validated batch 116 batch loss 1.23736537
Validated batch 117 batch loss 1.08737302
Validated batch 118 batch loss 0.938617
Validated batch 119 batch loss 1.22484386
Validated batch 120 batch loss 1.15673137
Validated batch 121 batch loss 1.27756262
Validated batch 122 batch loss 1.21144605
Validated batch 123 batch loss 1.24887276
Validated batch 124 batch loss 1.26595628
Validated batch 125 batch loss 1.30223274
Validated batch 126 batch loss 1.16762733
Validated batch 127 batch loss 1.0497508
Validated batch 128 batch loss 1.18632114
Validated batch 129 batch loss 1.26376414
Validated batch 130 batch loss 1.42553663
Validated batch 131 batch loss 1.14782679
Validated batch 132 batch loss 1.40369201
Validated batch 133 batch loss 1.18889
Validated batch 134 batch loss 1.21599317
Validated batch 135 batch loss 1.17869639
Validated batch 136 batch loss 1.19792199
Validated batch 137 batch loss 1.00288749
Validated batch 138 batch loss 1.1690197
Validated batch 139 batch loss 1.07054865
Validated batch 140 batch loss 0.904182792
Validated batch 141 batch loss 0.731193423
Validated batch 142 batch loss 0.82050097
Validated batch 143 batch loss 1.3095392
Validated batch 144 batch loss 1.2095933
Validated batch 145 batch loss 1.207165
Validated batch 146 batch loss 1.18426681
Validated batch 147 batch loss 1.0725565
Validated batch 148 batch loss 1.13980067
Validated batch 149 batch loss 1.17928934
Validated batch 150 batch loss 1.10301042
Validated batch 151 batch loss 1.03769684
Validated batch 152 batch loss 1.31580353
Validated batch 153 batch loss 1.03790784
Validated batch 154 batch loss 1.17073894
Validated batch 155 batch loss 1.20622206
Validated batch 156 batch loss 1.23000753
Validated batch 157 batch loss 1.36846602
Validated batch 158 batch loss 1.24000502
Validated batch 159 batch loss 1.11198688
Validated batch 160 batch loss 0.907625139
Validated batch 161 batch loss 1.28069329
Validated batch 162 batch loss 0.911337733
Validated batch 163 batch loss 0.98055023
Validated batch 164 batch loss 1.01915395
Validated batch 165 batch loss 1.46398509
Validated batch 166 batch loss 1.16024423
Validated batch 167 batch loss 1.10550642
Validated batch 168 batch loss 1.2373929
Validated batch 169 batch loss 1.37134182
Validated batch 170 batch loss 1.46240497
Validated batch 171 batch loss 1.1390239
Validated batch 172 batch loss 1.13222015
Validated batch 173 batch loss 1.3182323
Validated batch 174 batch loss 1.27676511
Validated batch 175 batch loss 1.25410676
Validated batch 176 batch loss 1.25494385
Validated batch 177 batch loss 1.28030443
Validated batch 178 batch loss 1.29658151
Validated batch 179 batch loss 1.14190757
Validated batch 180 batch loss 1.09405959
Validated batch 181 batch loss 1.04937899
Validated batch 182 batch loss 1.1389029
Validated batch 183 batch loss 1.00328171
Validated batch 184 batch loss 1.27468038
Validated batch 185 batch loss 1.19869661
Validated batch 186 batch loss 1.20455253
Validated batch 187 batch loss 1.00594115
Validated batch 188 batch loss 1.22649145
Validated batch 189 batch loss 1.29171336
Validated batch 190 batch loss 1.06355381
Validated batch 191 batch loss 1.15110326
Validated batch 192 batch loss 1.12284064
Validated batch 193 batch loss 1.15511501
Validated batch 194 batch loss 1.00470638
Validated batch 195 batch loss 1.28542006
Validated batch 196 batch loss 1.28682387
Validated batch 197 batch loss 1.15017843
Validated batch 198 batch loss 0.99716723
Validated batch 199 batch loss 1.06153655
Validated batch 200 batch loss 1.01588607
Validated batch 201 batch loss 1.31524849
Validated batch 202 batch loss 1.10625851
Validated batch 203 batch loss 0.994634151
Validated batch 204 batch loss 1.24130845
Validated batch 205 batch loss 1.05041528
Validated batch 206 batch loss 1.18013096
Validated batch 207 batch loss 1.38863623
Validated batch 208 batch loss 1.18461978
Validated batch 209 batch loss 1.03240943
Validated batch 210 batch loss 1.11161149
Validated batch 211 batch loss 1.20660043
Validated batch 212 batch loss 1.36702323
Validated batch 213 batch loss 1.20158672
Validated batch 214 batch loss 1.26004803
Validated batch 215 batch loss 1.43780124
Validated batch 216 batch loss 1.37720156
Validated batch 217 batch loss 1.32437932
Validated batch 218 batch loss 1.17466414
Validated batch 219 batch loss 1.16737771
Validated batch 220 batch loss 1.31104183
Validated batch 221 batch loss 1.38752055
Validated batch 222 batch loss 1.18760753
Validated batch 223 batch loss 1.18394399
Validated batch 224 batch loss 1.05421352
Validated batch 225 batch loss 1.27655768
Validated batch 226 batch loss 1.21631503
Validated batch 227 batch loss 1.2483834
Validated batch 228 batch loss 1.19569695
Validated batch 229 batch loss 1.40870261
Validated batch 230 batch loss 1.23293591
Validated batch 231 batch loss 1.60806167
Validated batch 232 batch loss 1.05671
Validated batch 233 batch loss 1.30899131
Validated batch 234 batch loss 1.35217547
Validated batch 235 batch loss 1.21309531
Validated batch 236 batch loss 1.23322105
Validated batch 237 batch loss 1.37347245
Validated batch 238 batch loss 1.14993048
Validated batch 239 batch loss 1.25726426
Validated batch 240 batch loss 1.2548666
Validated batch 241 batch loss 1.23043704
Validated batch 242 batch loss 1.26618838
Validated batch 243 batch loss 1.21814179
Validated batch 244 batch loss 1.27764356
Validated batch 245 batch loss 1.3666923
Validated batch 246 batch loss 1.37291574
Validated batch 247 batch loss 1.35926533
Validated batch 248 batch loss 1.08058298
Validated batch 249 batch loss 1.35894156
Validated batch 250 batch loss 1.42078853
Validated batch 251 batch loss 1.13186741
Validated batch 252 batch loss 1.32396042
Validated batch 253 batch loss 1.22073936
Validated batch 254 batch loss 1.10815096
Validated batch 255 batch loss 0.879006565
Validated batch 256 batch loss 1.16560864
Validated batch 257 batch loss 1.08700562
Validated batch 258 batch loss 1.27476871
Validated batch 259 batch loss 1.24012232
Validated batch 260 batch loss 1.21754265
Validated batch 261 batch loss 1.37298298
Validated batch 262 batch loss 1.34091377
Validated batch 263 batch loss 1.20478296
Validated batch 264 batch loss 1.34936333
Validated batch 265 batch loss 1.33616734
Validated batch 266 batch loss 1.23244715
Validated batch 267 batch loss 1.21108687
Validated batch 268 batch loss 1.19312334
Validated batch 269 batch loss 1.1496166
Validated batch 270 batch loss 1.09547877
Validated batch 271 batch loss 1.22449183
Validated batch 272 batch loss 1.31329155
Validated batch 273 batch loss 1.23705113
Validated batch 274 batch loss 1.34482753
Validated batch 275 batch loss 1.08697057
Validated batch 276 batch loss 1.23494184
Validated batch 277 batch loss 1.23258448
Validated batch 278 batch loss 1.31050301
Validated batch 279 batch loss 1.34534597
Validated batch 280 batch loss 1.38530385
Validated batch 281 batch loss 1.07943451
Validated batch 282 batch loss 1.19282627
Validated batch 283 batch loss 0.990475059
Validated batch 284 batch loss 1.42644
Validated batch 285 batch loss 1.37175679
Validated batch 286 batch loss 1.22585666
Validated batch 287 batch loss 0.893849
Validated batch 288 batch loss 1.13938868
Validated batch 289 batch loss 1.26973474
Validated batch 290 batch loss 0.923908889
Validated batch 291 batch loss 1.42438197
Validated batch 292 batch loss 1.20396972
Validated batch 293 batch loss 1.14164484
Validated batch 294 batch loss 1.03776574
Validated batch 295 batch loss 0.964849234
Validated batch 296 batch loss 1.21029687
Validated batch 297 batch loss 1.14567173
Validated batch 298 batch loss 1.33286595
Validated batch 299 batch loss 1.13748038
Validated batch 300 batch loss 1.28588223
Validated batch 301 batch loss 1.10476351
Validated batch 302 batch loss 1.29751348
Validated batch 303 batch loss 1.39405262
Validated batch 304 batch loss 1.07482743
Validated batch 305 batch loss 1.26165164
Validated batch 306 batch loss 1.04859376
Validated batch 307 batch loss 1.09136415
Validated batch 308 batch loss 1.02165842
Validated batch 309 batch loss 1.12160039
Validated batch 310 batch loss 1.0643357
Validated batch 311 batch loss 1.1929369
Validated batch 312 batch loss 1.24241698
Validated batch 313 batch loss 1.35263336
Validated batch 314 batch loss 1.20163393
Validated batch 315 batch loss 1.22748089
Validated batch 316 batch loss 1.19273734
Validated batch 317 batch loss 1.21090984
Validated batch 318 batch loss 1.25224638
Validated batch 319 batch loss 1.2046833
Validated batch 320 batch loss 1.33131456
Validated batch 321 batch loss 1.30742788
Validated batch 322 batch loss 1.39576316
Validated batch 323 batch loss 1.21619534
Validated batch 324 batch loss 1.13429546
Validated batch 325 batch loss 1.05015481
Validated batch 326 batch loss 1.37953615
Validated batch 327 batch loss 1.20732141
Validated batch 328 batch loss 1.06294012
Validated batch 329 batch loss 1.17328477
Validated batch 330 batch loss 0.891518891
Validated batch 331 batch loss 1.12318063
Validated batch 332 batch loss 1.20809412
Validated batch 333 batch loss 1.32043624
Validated batch 334 batch loss 1.1184299
Validated batch 335 batch loss 0.992545724
Validated batch 336 batch loss 0.938517511
Validated batch 337 batch loss 1.23715365
Validated batch 338 batch loss 1.33274043
Validated batch 339 batch loss 1.13060129
Validated batch 340 batch loss 1.20784736
Validated batch 341 batch loss 1.17131221
Validated batch 342 batch loss 1.18036699
Validated batch 343 batch loss 1.1824863
Validated batch 344 batch loss 1.13192427
Validated batch 345 batch loss 1.11293435
Validated batch 346 batch loss 1.28858793
Validated batch 347 batch loss 1.33452809
Validated batch 348 batch loss 1.06613922
Validated batch 349 batch loss 1.33114457
Validated batch 350 batch loss 1.11951876
Validated batch 351 batch loss 1.21509302
Validated batch 352 batch loss 1.23328888
Validated batch 353 batch loss 1.4953202
Validated batch 354 batch loss 1.30293453
Validated batch 355 batch loss 1.61107385
Validated batch 356 batch loss 1.52426291
Validated batch 357 batch loss 1.3643291
Validated batch 358 batch loss 1.43887126
Validated batch 359 batch loss 1.11244583
Validated batch 360 batch loss 1.14570618
Validated batch 361 batch loss 1.13946247
Validated batch 362 batch loss 1.16067278
Validated batch 363 batch loss 1.31686056
Validated batch 364 batch loss 1.23139334
Validated batch 365 batch loss 1.05590272
Validated batch 366 batch loss 1.04267454
Validated batch 367 batch loss 0.977258503
Validated batch 368 batch loss 1.20013595
Validated batch 369 batch loss 0.938676834
Validated batch 370 batch loss 1.1594224
Validated batch 371 batch loss 1.12751985
Validated batch 372 batch loss 1.26540828
Validated batch 373 batch loss 1.51102877
Validated batch 374 batch loss 1.20494962
Validated batch 375 batch loss 0.979064703
Validated batch 376 batch loss 1.21672273
Validated batch 377 batch loss 1.08431828
Validated batch 378 batch loss 0.886300385
Validated batch 379 batch loss 1.15078187
Validated batch 380 batch loss 1.32541132
Validated batch 381 batch loss 1.24802732
Validated batch 382 batch loss 1.26099777
Validated batch 383 batch loss 0.882855892
Validated batch 384 batch loss 1.2632004
Validated batch 385 batch loss 1.10840559
Validated batch 386 batch loss 1.09309912
Validated batch 387 batch loss 1.26289988
Validated batch 388 batch loss 1.24615979
Validated batch 389 batch loss 0.93160665
Validated batch 390 batch loss 1.2705574
Validated batch 391 batch loss 1.35673189
Validated batch 392 batch loss 1.22524714
Validated batch 393 batch loss 1.08808744
Validated batch 394 batch loss 1.29146731
Validated batch 395 batch loss 1.35012269
Validated batch 396 batch loss 0.999847353
Validated batch 397 batch loss 1.18198204
Validated batch 398 batch loss 1.09430861
Validated batch 399 batch loss 1.32183456
Validated batch 400 batch loss 1.33586144
Validated batch 401 batch loss 0.979098797
Validated batch 402 batch loss 0.810473442
Validated batch 403 batch loss 1.3928318
Validated batch 404 batch loss 1.38519681
Validated batch 405 batch loss 1.49354517
Validated batch 406 batch loss 1.2842226
Validated batch 407 batch loss 1.11118484
Validated batch 408 batch loss 1.22018945
Validated batch 409 batch loss 1.22898638
Validated batch 410 batch loss 1.12350798
Validated batch 411 batch loss 1.0824703
Validated batch 412 batch loss 1.04735982
Validated batch 413 batch loss 1.13880801
Validated batch 414 batch loss 0.899769425
Validated batch 415 batch loss 1.13549185
Validated batch 416 batch loss 1.13743615
Validated batch 417 batch loss 1.14832973
Validated batch 418 batch loss 1.22168088
Validated batch 419 batch loss 0.985407174
Validated batch 420 batch loss 1.31121492
Validated batch 421 batch loss 1.3799876
Validated batch 422 batch loss 1.34711611
Validated batch 423 batch loss 1.53601575
Validated batch 424 batch loss 1.1949234
Validated batch 425 batch loss 1.13915324
Validated batch 426 batch loss 1.35596228
Validated batch 427 batch loss 1.44939899
Validated batch 428 batch loss 1.40706468
Validated batch 429 batch loss 1.33016038
Validated batch 430 batch loss 1.36685324
Validated batch 431 batch loss 1.36979091
Validated batch 432 batch loss 1.31075835
Validated batch 433 batch loss 1.21801329
Validated batch 434 batch loss 1.10338378
Validated batch 435 batch loss 1.05533946
Validated batch 436 batch loss 1.29857183
Validated batch 437 batch loss 1.2943939
Validated batch 438 batch loss 1.53856826
Validated batch 439 batch loss 1.35281086
Validated batch 440 batch loss 1.14407492
Validated batch 441 batch loss 1.19782662
Validated batch 442 batch loss 1.15729547
Validated batch 443 batch loss 1.18599415
Validated batch 444 batch loss 1.11737013
Validated batch 445 batch loss 1.37559485
Validated batch 446 batch loss 1.56886792
Validated batch 447 batch loss 0.987977
Validated batch 448 batch loss 1.04910243
Validated batch 449 batch loss 1.06912136
Validated batch 450 batch loss 1.16548479
Validated batch 451 batch loss 1.32404268
Validated batch 452 batch loss 1.18011105
Validated batch 453 batch loss 0.975803
Validated batch 454 batch loss 0.806630194
Validated batch 455 batch loss 0.885691524
Validated batch 456 batch loss 0.996339738
Validated batch 457 batch loss 1.08834302
Validated batch 458 batch loss 0.992100239
Validated batch 459 batch loss 1.20896244
Validated batch 460 batch loss 1.29010832
Validated batch 461 batch loss 1.17395175
Validated batch 462 batch loss 1.20978785
Validated batch 463 batch loss 1.15799749
Validated batch 464 batch loss 1.14518535
Validated batch 465 batch loss 1.27508271
Validated batch 466 batch loss 1.18108928
Validated batch 467 batch loss 1.25541449
Validated batch 468 batch loss 1.26639485
Validated batch 469 batch loss 1.32603168
Validated batch 470 batch loss 1.22993064
Validated batch 471 batch loss 1.04780555
Validated batch 472 batch loss 1.22127652
Validated batch 473 batch loss 1.26251364
Validated batch 474 batch loss 1.12996984
Validated batch 475 batch loss 0.988489509
Validated batch 476 batch loss 1.36372185
Validated batch 477 batch loss 1.14704823
Validated batch 478 batch loss 1.22039771
Validated batch 479 batch loss 1.23441935
Validated batch 480 batch loss 1.38217628
Validated batch 481 batch loss 1.26435018
Validated batch 482 batch loss 1.63490462
Validated batch 483 batch loss 1.5200007
Validated batch 484 batch loss 1.14063382
Validated batch 485 batch loss 1.39581871
Validated batch 486 batch loss 1.03511453
Validated batch 487 batch loss 1.08011079
Validated batch 488 batch loss 1.29275334
Validated batch 489 batch loss 1.1966145
Validated batch 490 batch loss 1.06621158
Validated batch 491 batch loss 1.46064496
Validated batch 492 batch loss 1.2718302
Validated batch 493 batch loss 1.32960987
Validated batch 494 batch loss 1.15094805
Validated batch 495 batch loss 1.10456777
Validated batch 496 batch loss 1.19350243
Validated batch 497 batch loss 1.36654961
Validated batch 498 batch loss 1.28614354
Validated batch 499 batch loss 1.09168816
Validated batch 500 batch loss 1.13810909
Validated batch 501 batch loss 1.38297439
Validated batch 502 batch loss 1.13271475
Validated batch 503 batch loss 1.20914495
Validated batch 504 batch loss 1.19361138
Validated batch 505 batch loss 1.23070836
Validated batch 506 batch loss 0.957573771
Validated batch 507 batch loss 1.16082263
Validated batch 508 batch loss 1.08757854
Validated batch 509 batch loss 1.16092956
Validated batch 510 batch loss 1.3406173
Validated batch 511 batch loss 1.21936691
Validated batch 512 batch loss 1.40437722
Validated batch 513 batch loss 1.60722184
Validated batch 514 batch loss 1.26749063
Validated batch 515 batch loss 1.23943567
Validated batch 516 batch loss 1.02291274
Validated batch 517 batch loss 1.00405145
Validated batch 518 batch loss 1.35865378
Validated batch 519 batch loss 1.24283326
Validated batch 520 batch loss 1.47229
Validated batch 521 batch loss 1.09377539
Validated batch 522 batch loss 1.17075753
Validated batch 523 batch loss 1.2213887
Validated batch 524 batch loss 1.3019011
Validated batch 525 batch loss 1.10502124
Validated batch 526 batch loss 1.28795052
Validated batch 527 batch loss 1.19963253
Validated batch 528 batch loss 1.3662219
Validated batch 529 batch loss 1.31108308
Validated batch 530 batch loss 1.36013174
Validated batch 531 batch loss 0.965025604
Validated batch 532 batch loss 0.940257311
Validated batch 533 batch loss 1.08102965
Validated batch 534 batch loss 1.06686711
Validated batch 535 batch loss 1.31339824
Validated batch 536 batch loss 1.17557192
Validated batch 537 batch loss 1.29643404
Validated batch 538 batch loss 1.2776022
Validated batch 539 batch loss 1.17844355
Validated batch 540 batch loss 1.08643556
Validated batch 541 batch loss 0.973095894
Validated batch 542 batch loss 1.1677165
Validated batch 543 batch loss 1.40052009
Validated batch 544 batch loss 1.09363317
Validated batch 545 batch loss 1.33575416
Validated batch 546 batch loss 1.1885488
Validated batch 547 batch loss 1.14595532
Validated batch 548 batch loss 1.23611379
Validated batch 549 batch loss 1.40727663
Validated batch 550 batch loss 1.20895195
Validated batch 551 batch loss 1.15734255
Validated batch 552 batch loss 1.16359854
Validated batch 553 batch loss 1.39596081
Validated batch 554 batch loss 1.26151407
Validated batch 555 batch loss 0.967449784
Validated batch 556 batch loss 1.19896638
Validated batch 557 batch loss 1.21202326
Validated batch 558 batch loss 1.12809086
Validated batch 559 batch loss 1.26933813
Validated batch 560 batch loss 1.17132831
Validated batch 561 batch loss 0.983069
Validated batch 562 batch loss 1.2644968
Validated batch 563 batch loss 1.2336117
Validated batch 564 batch loss 0.996842146
Validated batch 565 batch loss 0.959254265
Validated batch 566 batch loss 1.05725884
Validated batch 567 batch loss 0.997929096
Validated batch 568 batch loss 1.28873515
Validated batch 569 batch loss 1.24858093
Validated batch 570 batch loss 1.17236066
Validated batch 571 batch loss 1.40038681
Validated batch 572 batch loss 0.90825057
Validated batch 573 batch loss 1.21141839
Validated batch 574 batch loss 1.19725752
Validated batch 575 batch loss 1.62454259
Validated batch 576 batch loss 1.28195119
Validated batch 577 batch loss 1.01839638
Validated batch 578 batch loss 1.04023314
Validated batch 579 batch loss 1.1443783
Validated batch 580 batch loss 0.905502677
Validated batch 581 batch loss 1.31658685
Validated batch 582 batch loss 1.12738395
Validated batch 583 batch loss 0.91902858
Validated batch 584 batch loss 0.808828473
Validated batch 585 batch loss 1.09819949
Validated batch 586 batch loss 0.930798173
Validated batch 587 batch loss 1.13381553
Validated batch 588 batch loss 1.16017628
Validated batch 589 batch loss 1.12647986
Validated batch 590 batch loss 1.03884113
Validated batch 591 batch loss 1.20672917
Validated batch 592 batch loss 1.14473534
Validated batch 593 batch loss 0.856788039
Validated batch 594 batch loss 1.0639987
Validated batch 595 batch loss 1.25215113
Validated batch 596 batch loss 0.908587754
Validated batch 597 batch loss 1.03263199
Validated batch 598 batch loss 1.37608051
Validated batch 599 batch loss 1.4012754
Validated batch 600 batch loss 0.942878
Validated batch 601 batch loss 0.858657241
Validated batch 602 batch loss 1.21160197
Validated batch 603 batch loss 1.03032982
Validated batch 604 batch loss 1.08612895
Validated batch 605 batch loss 1.30381429
Validated batch 606 batch loss 1.2817719
Validated batch 607 batch loss 0.97332561
Validated batch 608 batch loss 1.1695627
Validated batch 609 batch loss 1.32120836
Validated batch 610 batch loss 1.17334604
Validated batch 611 batch loss 1.32030463
Validated batch 612 batch loss 1.28409457
Validated batch 613 batch loss 1.19598389
Validated batch 614 batch loss 1.35363984
Validated batch 615 batch loss 1.16014802
Validated batch 616 batch loss 1.47287607
Validated batch 617 batch loss 1.1704824
Validated batch 618 batch loss 1.13177967
Validated batch 619 batch loss 1.095397
Validated batch 620 batch loss 1.02250695
Validated batch 621 batch loss 1.18823898
Validated batch 622 batch loss 1.42867589
Validated batch 623 batch loss 1.26551318
Validated batch 624 batch loss 1.31638885
Validated batch 625 batch loss 1.1860975
Validated batch 626 batch loss 0.991557837
Validated batch 627 batch loss 0.999211133
Validated batch 628 batch loss 0.895987868
Validated batch 629 batch loss 0.898789823
Validated batch 630 batch loss 1.2071135
Validated batch 631 batch loss 0.837015271
Validated batch 632 batch loss 1.13907409
Validated batch 633 batch loss 1.34040499
Validated batch 634 batch loss 1.21006322
Validated batch 635 batch loss 0.845762849
Validated batch 636 batch loss 1.09235573
Validated batch 637 batch loss 1.10206366
Validated batch 638 batch loss 0.989166617
Validated batch 639 batch loss 1.15206659
Validated batch 640 batch loss 1.30648863
Validated batch 641 batch loss 1.15424013
Validated batch 642 batch loss 1.44171453
Validated batch 643 batch loss 1.37251282
Validated batch 644 batch loss 1.20052683
Validated batch 645 batch loss 1.37028432
Validated batch 646 batch loss 1.08794713
Validated batch 647 batch loss 1.21577084
Validated batch 648 batch loss 1.15271258
Validated batch 649 batch loss 1.20887661
Validated batch 650 batch loss 1.28722835
Validated batch 651 batch loss 1.15551162
Validated batch 652 batch loss 1.16583967
Validated batch 653 batch loss 1.28992808
Validated batch 654 batch loss 0.93508333
Validated batch 655 batch loss 1.33068478
Validated batch 656 batch loss 1.35002875
Validated batch 657 batch loss 1.05107653
Validated batch 658 batch loss 0.939722359
Validated batch 659 batch loss 1.35649037
Validated batch 660 batch loss 1.12502122
Validated batch 661 batch loss 1.29120016
Validated batch 662 batch loss 1.35076928
Validated batch 663 batch loss 0.977129519
Validated batch 664 batch loss 1.23582721
Validated batch 665 batch loss 1.18301129
Validated batch 666 batch loss 1.2343502
Validated batch 667 batch loss 1.15573382
Validated batch 668 batch loss 1.26831317
Validated batch 669 batch loss 1.28264165
Validated batch 670 batch loss 1.32697272
Validated batch 671 batch loss 1.1772908
Validated batch 672 batch loss 1.20868039
Validated batch 673 batch loss 1.25937343
Validated batch 674 batch loss 1.34512854
Validated batch 675 batch loss 1.1130625
Validated batch 676 batch loss 1.50915742
Validated batch 677 batch loss 1.04549968
Validated batch 678 batch loss 1.20477629
Validated batch 679 batch loss 1.28603411
Validated batch 680 batch loss 1.26793766
Validated batch 681 batch loss 1.10471427
Validated batch 682 batch loss 1.22301674
Validated batch 683 batch loss 1.08894706
Validated batch 684 batch loss 1.14601946
Validated batch 685 batch loss 1.07126164
Validated batch 686 batch loss 1.22340775
Validated batch 687 batch loss 1.31545854
Validated batch 688 batch loss 1.19812489
Validated batch 689 batch loss 1.24293303
Validated batch 690 batch loss 1.18405735
Validated batch 691 batch loss 1.37275326
Validated batch 692 batch loss 1.00368404
Validated batch 693 batch loss 1.13372
Validated batch 694 batch loss 1.22515559
Validated batch 695 batch loss 1.00393069
Validated batch 696 batch loss 1.28294194
Validated batch 697 batch loss 1.29418874
Validated batch 698 batch loss 1.31583285
Validated batch 699 batch loss 1.45991206
Validated batch 700 batch loss 1.10561991
Validated batch 701 batch loss 1.42908716
Validated batch 702 batch loss 1.39768887
Validated batch 703 batch loss 1.27936578
Validated batch 704 batch loss 1.37813163
Validated batch 705 batch loss 1.13739586
Validated batch 706 batch loss 1.30768895
Validated batch 707 batch loss 1.07314968
Validated batch 708 batch loss 1.29228735
Validated batch 709 batch loss 1.27512193
Validated batch 710 batch loss 1.08561337
Validated batch 711 batch loss 1.34722972
Validated batch 712 batch loss 1.40486646
Validated batch 713 batch loss 1.54506373
Validated batch 714 batch loss 1.07123971
Validated batch 715 batch loss 1.10931885
Validated batch 716 batch loss 1.12950134
Validated batch 717 batch loss 1.0297873
Validated batch 718 batch loss 1.11592269
Validated batch 719 batch loss 1.08020568
Validated batch 720 batch loss 1.11954522
Validated batch 721 batch loss 1.50687647
Validated batch 722 batch loss 1.25704408
Validated batch 723 batch loss 1.05948949
Validated batch 724 batch loss 1.03894043
Validated batch 725 batch loss 1.0627948
Validated batch 726 batch loss 1.01285481
Validated batch 727 batch loss 0.869331419
Validated batch 728 batch loss 1.21552
Validated batch 729 batch loss 1.26098955
Validated batch 730 batch loss 1.32722139
Validated batch 731 batch loss 1.0895071
Validated batch 732 batch loss 1.2510519
Validated batch 733 batch loss 1.30127549
Validated batch 734 batch loss 1.19726062
Validated batch 735 batch loss 1.00473821
Validated batch 736 batch loss 0.992140532
Validated batch 737 batch loss 1.24968445
Validated batch 738 batch loss 1.14407063
Epoch 3 val loss 1.191519021987915
Start epoch 4 with learning rate 0.0003
Start distributed traininng...
Trained batch 1 batch loss 1.42428339 epoch total loss 1.42428339
Trained batch 2 batch loss 1.42438173 epoch total loss 1.42433262
Trained batch 3 batch loss 1.09900177 epoch total loss 1.315889
Trained batch 4 batch loss 1.01529169 epoch total loss 1.2407397
Trained batch 5 batch loss 0.940606833 epoch total loss 1.18071306
Trained batch 6 batch loss 0.887348711 epoch total loss 1.13181901
Trained batch 7 batch loss 1.1065805 epoch total loss 1.12821352
Trained batch 8 batch loss 1.22117281 epoch total loss 1.13983345
Trained batch 9 batch loss 1.2979753 epoch total loss 1.15740478
Trained batch 10 batch loss 1.29870558 epoch total loss 1.1715349
Trained batch 11 batch loss 1.19870496 epoch total loss 1.17400491
Trained batch 12 batch loss 1.10775161 epoch total loss 1.16848385
Trained batch 13 batch loss 1.08844972 epoch total loss 1.16232729
Trained batch 14 batch loss 1.14837503 epoch total loss 1.16133082
Trained batch 15 batch loss 1.12606788 epoch total loss 1.15897989
Trained batch 16 batch loss 1.35635531 epoch total loss 1.17131591
Trained batch 17 batch loss 1.11568391 epoch total loss 1.16804349
Trained batch 18 batch loss 1.25837052 epoch total loss 1.17306173
Trained batch 19 batch loss 1.36340964 epoch total loss 1.18308
Trained batch 20 batch loss 1.37697411 epoch total loss 1.19277465
Trained batch 21 batch loss 1.22635269 epoch total loss 1.19437361
Trained batch 22 batch loss 1.3057636 epoch total loss 1.19943678
Trained batch 23 batch loss 1.47303629 epoch total loss 1.21133244
Trained batch 24 batch loss 1.30895 epoch total loss 1.21539986
Trained batch 25 batch loss 1.39842856 epoch total loss 1.22272098
Trained batch 26 batch loss 1.37913227 epoch total loss 1.22873676
Trained batch 27 batch loss 1.10334349 epoch total loss 1.2240926
Trained batch 28 batch loss 1.32362485 epoch total loss 1.22764719
Trained batch 29 batch loss 1.10788405 epoch total loss 1.22351742
Trained batch 30 batch loss 0.915300548 epoch total loss 1.2132436
Trained batch 31 batch loss 0.959784389 epoch total loss 1.20506752
Trained batch 32 batch loss 1.1995399 epoch total loss 1.20489478
Trained batch 33 batch loss 1.1803118 epoch total loss 1.20414984
Trained batch 34 batch loss 1.24560535 epoch total loss 1.20536911
Trained batch 35 batch loss 1.17331719 epoch total loss 1.20445335
Trained batch 36 batch loss 1.12739301 epoch total loss 1.20231283
Trained batch 37 batch loss 1.08135867 epoch total loss 1.19904375
Trained batch 38 batch loss 0.990480483 epoch total loss 1.19355536
Trained batch 39 batch loss 0.910189033 epoch total loss 1.18628955
Trained batch 40 batch loss 1.0944159 epoch total loss 1.18399274
Trained batch 41 batch loss 1.14509547 epoch total loss 1.18304408
Trained batch 42 batch loss 1.36293828 epoch total loss 1.18732727
Trained batch 43 batch loss 1.13173413 epoch total loss 1.18603432
Trained batch 44 batch loss 1.09510374 epoch total loss 1.18396771
Trained batch 45 batch loss 1.26068473 epoch total loss 1.18567264
Trained batch 46 batch loss 1.15652061 epoch total loss 1.18503881
Trained batch 47 batch loss 1.03630984 epoch total loss 1.18187439
Trained batch 48 batch loss 1.2436136 epoch total loss 1.18316066
Trained batch 49 batch loss 1.29527724 epoch total loss 1.18544865
Trained batch 50 batch loss 1.31676507 epoch total loss 1.18807507
Trained batch 51 batch loss 1.1496644 epoch total loss 1.1873219
Trained batch 52 batch loss 1.29054952 epoch total loss 1.18930709
Trained batch 53 batch loss 1.25156045 epoch total loss 1.19048166
Trained batch 54 batch loss 1.30761099 epoch total loss 1.19265068
Trained batch 55 batch loss 1.27269018 epoch total loss 1.19410598
Trained batch 56 batch loss 1.42955422 epoch total loss 1.19831049
Trained batch 57 batch loss 1.3087728 epoch total loss 1.20024836
Trained batch 58 batch loss 1.23134041 epoch total loss 1.20078433
Trained batch 59 batch loss 1.19482946 epoch total loss 1.20068347
Trained batch 60 batch loss 1.23211861 epoch total loss 1.2012074
Trained batch 61 batch loss 1.25244188 epoch total loss 1.20204723
Trained batch 62 batch loss 1.25604141 epoch total loss 1.20291817
Trained batch 63 batch loss 1.33332419 epoch total loss 1.204988
Trained batch 64 batch loss 1.48495901 epoch total loss 1.20936263
Trained batch 65 batch loss 1.32738328 epoch total loss 1.2111783
Trained batch 66 batch loss 1.29930854 epoch total loss 1.21251369
Trained batch 67 batch loss 1.30737889 epoch total loss 1.21392953
Trained batch 68 batch loss 1.34193087 epoch total loss 1.21581197
Trained batch 69 batch loss 1.30445957 epoch total loss 1.21709669
Trained batch 70 batch loss 1.32175374 epoch total loss 1.21859181
Trained batch 71 batch loss 1.20609283 epoch total loss 1.21841586
Trained batch 72 batch loss 1.38960791 epoch total loss 1.22079349
Trained batch 73 batch loss 1.21110547 epoch total loss 1.22066081
Trained batch 74 batch loss 1.28956795 epoch total loss 1.22159195
Trained batch 75 batch loss 1.10657525 epoch total loss 1.22005844
Trained batch 76 batch loss 1.33027613 epoch total loss 1.22150862
Trained batch 77 batch loss 1.38184786 epoch total loss 1.22359097
Trained batch 78 batch loss 1.05977917 epoch total loss 1.22149086
Trained batch 79 batch loss 1.1618588 epoch total loss 1.22073591
Trained batch 80 batch loss 1.26728189 epoch total loss 1.22131777
Trained batch 81 batch loss 1.1911056 epoch total loss 1.22094476
Trained batch 82 batch loss 1.19799614 epoch total loss 1.22066498
Trained batch 83 batch loss 1.16651034 epoch total loss 1.22001255
Trained batch 84 batch loss 1.07434034 epoch total loss 1.21827829
Trained batch 85 batch loss 1.24187565 epoch total loss 1.21855593
Trained batch 86 batch loss 1.28089547 epoch total loss 1.21928084
Trained batch 87 batch loss 1.23320198 epoch total loss 1.21944082
Trained batch 88 batch loss 1.13009727 epoch total loss 1.21842563
Trained batch 89 batch loss 0.976542056 epoch total loss 1.21570778
Trained batch 90 batch loss 0.976883471 epoch total loss 1.21305418
Trained batch 91 batch loss 1.08722222 epoch total loss 1.21167135
Trained batch 92 batch loss 0.960435033 epoch total loss 1.20894051
Trained batch 93 batch loss 0.998120666 epoch total loss 1.20667362
Trained batch 94 batch loss 1.11068439 epoch total loss 1.20565248
Trained batch 95 batch loss 1.10944557 epoch total loss 1.20463979
Trained batch 96 batch loss 1.12280333 epoch total loss 1.20378733
Trained batch 97 batch loss 1.23948801 epoch total loss 1.20415533
Trained batch 98 batch loss 1.11828637 epoch total loss 1.20327914
Trained batch 99 batch loss 1.10415757 epoch total loss 1.2022779
Trained batch 100 batch loss 1.01927972 epoch total loss 1.20044792
Trained batch 101 batch loss 0.778548062 epoch total loss 1.1962707
Trained batch 102 batch loss 1.10459304 epoch total loss 1.19537187
Trained batch 103 batch loss 1.1003871 epoch total loss 1.19444966
Trained batch 104 batch loss 1.1502074 epoch total loss 1.19402432
Trained batch 105 batch loss 1.40369248 epoch total loss 1.1960212
Trained batch 106 batch loss 1.31158 epoch total loss 1.19711137
Trained batch 107 batch loss 1.12469935 epoch total loss 1.1964345
Trained batch 108 batch loss 1.18696392 epoch total loss 1.19634688
Trained batch 109 batch loss 1.16343677 epoch total loss 1.19604492
Trained batch 110 batch loss 1.18212938 epoch total loss 1.19591844
Trained batch 111 batch loss 1.19414234 epoch total loss 1.19590235
Trained batch 112 batch loss 1.17016852 epoch total loss 1.19567263
Trained batch 113 batch loss 1.07449126 epoch total loss 1.19460022
Trained batch 114 batch loss 1.02821994 epoch total loss 1.19314063
Trained batch 115 batch loss 1.03944993 epoch total loss 1.19180417
Trained batch 116 batch loss 1.1020937 epoch total loss 1.19103086
Trained batch 117 batch loss 1.19835401 epoch total loss 1.19109333
Trained batch 118 batch loss 1.24251509 epoch total loss 1.19152915
Trained batch 119 batch loss 1.08907843 epoch total loss 1.19066823
Trained batch 120 batch loss 1.37247562 epoch total loss 1.19218326
Trained batch 121 batch loss 1.38827395 epoch total loss 1.19380391
Trained batch 122 batch loss 1.27563727 epoch total loss 1.1944747
Trained batch 123 batch loss 1.10677409 epoch total loss 1.19376171
Trained batch 124 batch loss 1.44442225 epoch total loss 1.19578314
Trained batch 125 batch loss 0.962966442 epoch total loss 1.19392061
Trained batch 126 batch loss 1.29085302 epoch total loss 1.19468987
Trained batch 127 batch loss 1.03715622 epoch total loss 1.1934495
Trained batch 128 batch loss 1.17805266 epoch total loss 1.19332922
Trained batch 129 batch loss 1.36155677 epoch total loss 1.19463336
Trained batch 130 batch loss 1.26607716 epoch total loss 1.19518292
Trained batch 131 batch loss 1.38722742 epoch total loss 1.19664884
Trained batch 132 batch loss 1.32110691 epoch total loss 1.19759178
Trained batch 133 batch loss 1.16602182 epoch total loss 1.19735432
Trained batch 134 batch loss 1.06515336 epoch total loss 1.19636774
Trained batch 135 batch loss 1.05612564 epoch total loss 1.19532883
Trained batch 136 batch loss 1.08935308 epoch total loss 1.19454968
Trained batch 137 batch loss 1.04993451 epoch total loss 1.1934942
Trained batch 138 batch loss 1.21055341 epoch total loss 1.19361782
Trained batch 139 batch loss 0.989934862 epoch total loss 1.19215238
Trained batch 140 batch loss 0.953145921 epoch total loss 1.19044518
Trained batch 141 batch loss 1.09407353 epoch total loss 1.18976164
Trained batch 142 batch loss 0.959340811 epoch total loss 1.18813896
Trained batch 143 batch loss 0.959731758 epoch total loss 1.18654168
Trained batch 144 batch loss 0.986626506 epoch total loss 1.18515348
Trained batch 145 batch loss 1.21902704 epoch total loss 1.18538702
Trained batch 146 batch loss 1.18779171 epoch total loss 1.18540347
Trained batch 147 batch loss 1.10560548 epoch total loss 1.18486059
Trained batch 148 batch loss 1.26158178 epoch total loss 1.18537903
Trained batch 149 batch loss 1.42354822 epoch total loss 1.18697751
Trained batch 150 batch loss 1.24848247 epoch total loss 1.18738759
Trained batch 151 batch loss 0.917349041 epoch total loss 1.18559921
Trained batch 152 batch loss 1.12788033 epoch total loss 1.18521953
Trained batch 153 batch loss 1.284168 epoch total loss 1.18586624
Trained batch 154 batch loss 1.3024807 epoch total loss 1.18662345
Trained batch 155 batch loss 1.35508823 epoch total loss 1.18771029
Trained batch 156 batch loss 1.49111462 epoch total loss 1.18965518
Trained batch 157 batch loss 1.12324095 epoch total loss 1.18923223
Trained batch 158 batch loss 1.15455341 epoch total loss 1.18901277
Trained batch 159 batch loss 1.13394964 epoch total loss 1.18866646
Trained batch 160 batch loss 1.26204884 epoch total loss 1.18912518
Trained batch 161 batch loss 1.30005264 epoch total loss 1.18981409
Trained batch 162 batch loss 1.27771807 epoch total loss 1.19035673
Trained batch 163 batch loss 1.24702597 epoch total loss 1.19070446
Trained batch 164 batch loss 1.08969283 epoch total loss 1.19008851
Trained batch 165 batch loss 1.11345029 epoch total loss 1.18962407
Trained batch 166 batch loss 0.878850698 epoch total loss 1.18775189
Trained batch 167 batch loss 0.847631335 epoch total loss 1.1857152
Trained batch 168 batch loss 1.04415834 epoch total loss 1.18487263
Trained batch 169 batch loss 1.05551231 epoch total loss 1.18410718
Trained batch 170 batch loss 1.31782734 epoch total loss 1.18489373
Trained batch 171 batch loss 1.08837104 epoch total loss 1.18432915
Trained batch 172 batch loss 1.18021417 epoch total loss 1.18430531
Trained batch 173 batch loss 1.27550769 epoch total loss 1.18483257
Trained batch 174 batch loss 1.15979552 epoch total loss 1.18468857
Trained batch 175 batch loss 1.15481901 epoch total loss 1.18451786
Trained batch 176 batch loss 1.06116772 epoch total loss 1.18381703
Trained batch 177 batch loss 1.21335554 epoch total loss 1.18398392
Trained batch 178 batch loss 1.03243947 epoch total loss 1.18313253
Trained batch 179 batch loss 1.17537594 epoch total loss 1.18308914
Trained batch 180 batch loss 1.21086109 epoch total loss 1.18324351
Trained batch 181 batch loss 1.09903717 epoch total loss 1.18277824
Trained batch 182 batch loss 0.9598248 epoch total loss 1.18155313
Trained batch 183 batch loss 1.15527439 epoch total loss 1.1814096
Trained batch 184 batch loss 0.826189637 epoch total loss 1.179479
Trained batch 185 batch loss 1.02402318 epoch total loss 1.1786387
Trained batch 186 batch loss 1.08972561 epoch total loss 1.17816067
Trained batch 187 batch loss 1.15261829 epoch total loss 1.17802405
Trained batch 188 batch loss 1.35159445 epoch total loss 1.17894733
Trained batch 189 batch loss 1.22005963 epoch total loss 1.17916477
Trained batch 190 batch loss 1.17078269 epoch total loss 1.17912066
Trained batch 191 batch loss 1.05426228 epoch total loss 1.17846692
Trained batch 192 batch loss 1.20411849 epoch total loss 1.17860055
Trained batch 193 batch loss 1.27058434 epoch total loss 1.17907715
Trained batch 194 batch loss 1.02992249 epoch total loss 1.17830837
Trained batch 195 batch loss 0.952452 epoch total loss 1.17715013
Trained batch 196 batch loss 1.12484431 epoch total loss 1.17688322
Trained batch 197 batch loss 1.15558362 epoch total loss 1.1767751
Trained batch 198 batch loss 0.982108235 epoch total loss 1.17579186
Trained batch 199 batch loss 1.01881683 epoch total loss 1.17500305
Trained batch 200 batch loss 1.04828548 epoch total loss 1.17436945
Trained batch 201 batch loss 0.993770063 epoch total loss 1.17347097
Trained batch 202 batch loss 0.945564151 epoch total loss 1.17234266
Trained batch 203 batch loss 1.00805616 epoch total loss 1.17153335
Trained batch 204 batch loss 1.05438805 epoch total loss 1.17095912
Trained batch 205 batch loss 1.27625227 epoch total loss 1.17147267
Trained batch 206 batch loss 1.2405417 epoch total loss 1.171808
Trained batch 207 batch loss 1.06267619 epoch total loss 1.17128074
Trained batch 208 batch loss 1.09925485 epoch total loss 1.17093456
Trained batch 209 batch loss 1.14173937 epoch total loss 1.17079484
Trained batch 210 batch loss 0.957884073 epoch total loss 1.16978097
Trained batch 211 batch loss 1.0716964 epoch total loss 1.16931617
Trained batch 212 batch loss 1.23717141 epoch total loss 1.16963625
Trained batch 213 batch loss 1.32045341 epoch total loss 1.17034423
Trained batch 214 batch loss 1.30755019 epoch total loss 1.17098546
Trained batch 215 batch loss 1.28071392 epoch total loss 1.1714958
Trained batch 216 batch loss 1.24984646 epoch total loss 1.17185855
Trained batch 217 batch loss 0.953870893 epoch total loss 1.17085397
Trained batch 218 batch loss 1.24262333 epoch total loss 1.17118323
Trained batch 219 batch loss 1.05812931 epoch total loss 1.17066693
Trained batch 220 batch loss 1.13225305 epoch total loss 1.17049241
Trained batch 221 batch loss 1.02452171 epoch total loss 1.16983199
Trained batch 222 batch loss 1.02435112 epoch total loss 1.1691767
Trained batch 223 batch loss 1.03104603 epoch total loss 1.16855717
Trained batch 224 batch loss 0.997453332 epoch total loss 1.16779339
Trained batch 225 batch loss 1.0022223 epoch total loss 1.16705751
Trained batch 226 batch loss 1.28334928 epoch total loss 1.16757214
Trained batch 227 batch loss 1.06950831 epoch total loss 1.16714025
Trained batch 228 batch loss 1.18364918 epoch total loss 1.16721261
Trained batch 229 batch loss 1.22429085 epoch total loss 1.16746199
Trained batch 230 batch loss 1.09941626 epoch total loss 1.16716611
Trained batch 231 batch loss 1.16467047 epoch total loss 1.16715539
Trained batch 232 batch loss 1.16908932 epoch total loss 1.16716373
Trained batch 233 batch loss 1.15912402 epoch total loss 1.16712916
Trained batch 234 batch loss 1.19540381 epoch total loss 1.16725
Trained batch 235 batch loss 1.07035744 epoch total loss 1.16683769
Trained batch 236 batch loss 1.0795604 epoch total loss 1.16646779
Trained batch 237 batch loss 1.05109286 epoch total loss 1.16598094
Trained batch 238 batch loss 1.16935921 epoch total loss 1.16599524
Trained batch 239 batch loss 1.07954073 epoch total loss 1.16563344
Trained batch 240 batch loss 1.13344014 epoch total loss 1.16549933
Trained batch 241 batch loss 1.15820158 epoch total loss 1.16546905
Trained batch 242 batch loss 1.26370215 epoch total loss 1.16587496
Trained batch 243 batch loss 1.28280401 epoch total loss 1.16635621
Trained batch 244 batch loss 1.18679452 epoch total loss 1.16644
Trained batch 245 batch loss 1.08366776 epoch total loss 1.16610217
Trained batch 246 batch loss 0.935575485 epoch total loss 1.16516507
Trained batch 247 batch loss 0.951127291 epoch total loss 1.16429865
Trained batch 248 batch loss 1.13553786 epoch total loss 1.16418254
Trained batch 249 batch loss 0.985907912 epoch total loss 1.16346657
Trained batch 250 batch loss 1.15221286 epoch total loss 1.16342163
Trained batch 251 batch loss 1.08322275 epoch total loss 1.16310215
Trained batch 252 batch loss 0.890080333 epoch total loss 1.16201866
Trained batch 253 batch loss 1.15403509 epoch total loss 1.16198707
Trained batch 254 batch loss 0.966178894 epoch total loss 1.16121614
Trained batch 255 batch loss 1.16103256 epoch total loss 1.16121554
Trained batch 256 batch loss 1.235744 epoch total loss 1.16150665
Trained batch 257 batch loss 1.10475111 epoch total loss 1.16128576
Trained batch 258 batch loss 0.821321368 epoch total loss 1.15996802
Trained batch 259 batch loss 0.994208097 epoch total loss 1.15932798
Trained batch 260 batch loss 1.00247121 epoch total loss 1.15872478
Trained batch 261 batch loss 0.929373264 epoch total loss 1.15784609
Trained batch 262 batch loss 1.150877 epoch total loss 1.15781939
Trained batch 263 batch loss 0.921452522 epoch total loss 1.15692067
Trained batch 264 batch loss 1.06181407 epoch total loss 1.15656054
Trained batch 265 batch loss 1.32521987 epoch total loss 1.157197
Trained batch 266 batch loss 1.26709414 epoch total loss 1.15761
Trained batch 267 batch loss 1.35386741 epoch total loss 1.15834522
Trained batch 268 batch loss 1.42776299 epoch total loss 1.15935051
Trained batch 269 batch loss 1.3879472 epoch total loss 1.16020024
Trained batch 270 batch loss 1.29406786 epoch total loss 1.16069603
Trained batch 271 batch loss 1.27605367 epoch total loss 1.16112173
Trained batch 272 batch loss 1.28690958 epoch total loss 1.16158414
Trained batch 273 batch loss 1.26879 epoch total loss 1.16197693
Trained batch 274 batch loss 1.2184763 epoch total loss 1.16218317
Trained batch 275 batch loss 1.25546741 epoch total loss 1.16252232
Trained batch 276 batch loss 1.17294836 epoch total loss 1.16256011
Trained batch 277 batch loss 1.38041866 epoch total loss 1.16334665
Trained batch 278 batch loss 1.32859528 epoch total loss 1.16394103
Trained batch 279 batch loss 1.5322206 epoch total loss 1.16526103
Trained batch 280 batch loss 1.21921933 epoch total loss 1.16545367
Trained batch 281 batch loss 1.22367859 epoch total loss 1.16566098
Trained batch 282 batch loss 1.31775165 epoch total loss 1.16620028
Trained batch 283 batch loss 1.18124735 epoch total loss 1.16625345
Trained batch 284 batch loss 1.05858099 epoch total loss 1.16587436
Trained batch 285 batch loss 1.30599451 epoch total loss 1.16636598
Trained batch 286 batch loss 1.20933735 epoch total loss 1.1665163
Trained batch 287 batch loss 1.22956109 epoch total loss 1.16673589
Trained batch 288 batch loss 0.972754836 epoch total loss 1.16606236
Trained batch 289 batch loss 1.27536547 epoch total loss 1.16644061
Trained batch 290 batch loss 1.26156473 epoch total loss 1.16676855
Trained batch 291 batch loss 1.14890969 epoch total loss 1.16670716
Trained batch 292 batch loss 0.971645951 epoch total loss 1.16603911
Trained batch 293 batch loss 1.29016876 epoch total loss 1.16646278
Trained batch 294 batch loss 1.16212523 epoch total loss 1.16644812
Trained batch 295 batch loss 1.10728776 epoch total loss 1.16624761
Trained batch 296 batch loss 1.266325 epoch total loss 1.16658568
Trained batch 297 batch loss 1.23858047 epoch total loss 1.16682804
Trained batch 298 batch loss 1.09418964 epoch total loss 1.16658425
Trained batch 299 batch loss 1.17840528 epoch total loss 1.16662383
Trained batch 300 batch loss 1.24240792 epoch total loss 1.16687644
Trained batch 301 batch loss 1.16897523 epoch total loss 1.16688335
Trained batch 302 batch loss 1.19734204 epoch total loss 1.16698432
Trained batch 303 batch loss 0.998321 epoch total loss 1.16642761
Trained batch 304 batch loss 1.00562418 epoch total loss 1.16589868
Trained batch 305 batch loss 1.2790556 epoch total loss 1.16626966
Trained batch 306 batch loss 1.26962519 epoch total loss 1.16660738
Trained batch 307 batch loss 1.23714101 epoch total loss 1.16683722
Trained batch 308 batch loss 1.04196858 epoch total loss 1.16643178
Trained batch 309 batch loss 1.00839591 epoch total loss 1.16592038
Trained batch 310 batch loss 1.16954827 epoch total loss 1.16593206
Trained batch 311 batch loss 1.08690572 epoch total loss 1.16567802
Trained batch 312 batch loss 1.23709035 epoch total loss 1.16590691
Trained batch 313 batch loss 1.00732303 epoch total loss 1.16540015
Trained batch 314 batch loss 1.12711382 epoch total loss 1.1652782
Trained batch 315 batch loss 1.02905035 epoch total loss 1.16484582
Trained batch 316 batch loss 1.02157891 epoch total loss 1.16439235
Trained batch 317 batch loss 1.10222149 epoch total loss 1.16419637
Trained batch 318 batch loss 1.06564879 epoch total loss 1.16388643
Trained batch 319 batch loss 1.27817583 epoch total loss 1.16424465
Trained batch 320 batch loss 0.906128168 epoch total loss 1.16343808
Trained batch 321 batch loss 0.977291167 epoch total loss 1.16285813
Trained batch 322 batch loss 1.04085755 epoch total loss 1.16247928
Trained batch 323 batch loss 0.998926759 epoch total loss 1.161973
Trained batch 324 batch loss 0.882512093 epoch total loss 1.1611104
Trained batch 325 batch loss 0.861669302 epoch total loss 1.16018903
Trained batch 326 batch loss 0.845885038 epoch total loss 1.15922487
Trained batch 327 batch loss 0.850154161 epoch total loss 1.15827978
Trained batch 328 batch loss 0.852987289 epoch total loss 1.15734899
Trained batch 329 batch loss 0.861446 epoch total loss 1.15644968
Trained batch 330 batch loss 0.986351073 epoch total loss 1.15593421
Trained batch 331 batch loss 1.1206491 epoch total loss 1.15582752
Trained batch 332 batch loss 1.42079735 epoch total loss 1.15662563
Trained batch 333 batch loss 1.05257273 epoch total loss 1.15631318
Trained batch 334 batch loss 1.34751797 epoch total loss 1.15688562
Trained batch 335 batch loss 1.38544464 epoch total loss 1.15756786
Trained batch 336 batch loss 1.27860248 epoch total loss 1.15792811
Trained batch 337 batch loss 1.07575893 epoch total loss 1.15768421
Trained batch 338 batch loss 1.14340842 epoch total loss 1.15764201
Trained batch 339 batch loss 1.12339246 epoch total loss 1.15754092
Trained batch 340 batch loss 1.23281598 epoch total loss 1.15776229
Trained batch 341 batch loss 1.46084392 epoch total loss 1.15865111
Trained batch 342 batch loss 1.37739253 epoch total loss 1.15929067
Trained batch 343 batch loss 1.33544481 epoch total loss 1.15980422
Trained batch 344 batch loss 1.34007645 epoch total loss 1.16032839
Trained batch 345 batch loss 1.06628191 epoch total loss 1.16005576
Trained batch 346 batch loss 1.25190187 epoch total loss 1.16032124
Trained batch 347 batch loss 0.888653338 epoch total loss 1.15953827
Trained batch 348 batch loss 1.05771768 epoch total loss 1.15924561
Trained batch 349 batch loss 0.8460899 epoch total loss 1.15834832
Trained batch 350 batch loss 0.842962265 epoch total loss 1.15744722
Trained batch 351 batch loss 0.894609213 epoch total loss 1.15669847
Trained batch 352 batch loss 1.11905611 epoch total loss 1.15659153
Trained batch 353 batch loss 0.865590453 epoch total loss 1.1557672
Trained batch 354 batch loss 0.827735186 epoch total loss 1.15484047
Trained batch 355 batch loss 0.800758362 epoch total loss 1.15384305
Trained batch 356 batch loss 1.02925491 epoch total loss 1.15349317
Trained batch 357 batch loss 1.18815148 epoch total loss 1.1535902
Trained batch 358 batch loss 0.978050232 epoch total loss 1.15309989
Trained batch 359 batch loss 1.21299565 epoch total loss 1.15326667
Trained batch 360 batch loss 1.30582166 epoch total loss 1.15369046
Trained batch 361 batch loss 1.0472827 epoch total loss 1.15339565
Trained batch 362 batch loss 0.841466188 epoch total loss 1.15253389
Trained batch 363 batch loss 1.0526036 epoch total loss 1.15225863
Trained batch 364 batch loss 1.06552911 epoch total loss 1.15202034
Trained batch 365 batch loss 1.08884978 epoch total loss 1.15184724
Trained batch 366 batch loss 1.19990981 epoch total loss 1.15197861
Trained batch 367 batch loss 1.07561922 epoch total loss 1.15177059
Trained batch 368 batch loss 1.0472517 epoch total loss 1.15148652
Trained batch 369 batch loss 1.19225526 epoch total loss 1.15159702
Trained batch 370 batch loss 0.925614476 epoch total loss 1.15098631
Trained batch 371 batch loss 0.957868 epoch total loss 1.15046573
Trained batch 372 batch loss 0.938513577 epoch total loss 1.14989591
Trained batch 373 batch loss 0.80504024 epoch total loss 1.14897144
Trained batch 374 batch loss 0.866769791 epoch total loss 1.14821684
Trained batch 375 batch loss 0.910386 epoch total loss 1.14758265
Trained batch 376 batch loss 1.0502677 epoch total loss 1.14732385
Trained batch 377 batch loss 1.10679913 epoch total loss 1.14721644
Trained batch 378 batch loss 1.27992654 epoch total loss 1.14756751
Trained batch 379 batch loss 1.0843606 epoch total loss 1.14740074
Trained batch 380 batch loss 1.28154647 epoch total loss 1.14775372
Trained batch 381 batch loss 1.21527052 epoch total loss 1.14793098
Trained batch 382 batch loss 1.18588901 epoch total loss 1.14803028
Trained batch 383 batch loss 0.837752163 epoch total loss 1.14722013
Trained batch 384 batch loss 1.25608277 epoch total loss 1.14750361
Trained batch 385 batch loss 0.920257151 epoch total loss 1.14691341
Trained batch 386 batch loss 0.898111343 epoch total loss 1.14626873
Trained batch 387 batch loss 1.20879841 epoch total loss 1.14643037
Trained batch 388 batch loss 1.08853555 epoch total loss 1.14628112
Trained batch 389 batch loss 1.2942518 epoch total loss 1.14666152
Trained batch 390 batch loss 1.14644825 epoch total loss 1.14666104
Trained batch 391 batch loss 1.00495839 epoch total loss 1.14629853
Trained batch 392 batch loss 1.03475952 epoch total loss 1.14601398
Trained batch 393 batch loss 0.891813517 epoch total loss 1.14536715
Trained batch 394 batch loss 0.93652761 epoch total loss 1.14483714
Trained batch 395 batch loss 0.904639602 epoch total loss 1.14422905
Trained batch 396 batch loss 0.732899547 epoch total loss 1.14319038
Trained batch 397 batch loss 1.27576196 epoch total loss 1.14352429
Trained batch 398 batch loss 1.07202268 epoch total loss 1.14334464
Trained batch 399 batch loss 1.14892793 epoch total loss 1.14335859
Trained batch 400 batch loss 0.977180064 epoch total loss 1.14294314
Trained batch 401 batch loss 1.07371485 epoch total loss 1.14277041
Trained batch 402 batch loss 1.13454866 epoch total loss 1.14275
Trained batch 403 batch loss 1.03865719 epoch total loss 1.1424917
Trained batch 404 batch loss 0.879410386 epoch total loss 1.14184058
Trained batch 405 batch loss 1.12494195 epoch total loss 1.14179885
Trained batch 406 batch loss 1.07849574 epoch total loss 1.14164293
Trained batch 407 batch loss 1.13635492 epoch total loss 1.14162993
Trained batch 408 batch loss 1.26681495 epoch total loss 1.14193678
Trained batch 409 batch loss 1.29374504 epoch total loss 1.14230788
Trained batch 410 batch loss 1.08588 epoch total loss 1.14217019
Trained batch 411 batch loss 1.13610542 epoch total loss 1.14215553
Trained batch 412 batch loss 1.19027638 epoch total loss 1.14227223
Trained batch 413 batch loss 1.30840075 epoch total loss 1.14267457
Trained batch 414 batch loss 1.55685496 epoch total loss 1.14367497
Trained batch 415 batch loss 1.34533691 epoch total loss 1.14416087
Trained batch 416 batch loss 1.41462374 epoch total loss 1.14481103
Trained batch 417 batch loss 1.28529191 epoch total loss 1.14514792
Trained batch 418 batch loss 1.4526329 epoch total loss 1.14588356
Trained batch 419 batch loss 1.22674012 epoch total loss 1.14607656
Trained batch 420 batch loss 1.05936718 epoch total loss 1.14587
Trained batch 421 batch loss 1.29904628 epoch total loss 1.1462338
Trained batch 422 batch loss 1.14826226 epoch total loss 1.14623868
Trained batch 423 batch loss 1.14224136 epoch total loss 1.14622915
Trained batch 424 batch loss 0.954777479 epoch total loss 1.1457777
Trained batch 425 batch loss 0.93654561 epoch total loss 1.14528537
Trained batch 426 batch loss 1.07186079 epoch total loss 1.14511299
Trained batch 427 batch loss 1.10213137 epoch total loss 1.14501238
Trained batch 428 batch loss 1.04047728 epoch total loss 1.14476812
Trained batch 429 batch loss 1.16928267 epoch total loss 1.14482522
Trained batch 430 batch loss 0.903695 epoch total loss 1.14426446
Trained batch 431 batch loss 1.13984251 epoch total loss 1.14425421
Trained batch 432 batch loss 1.1559149 epoch total loss 1.14428115
Trained batch 433 batch loss 1.17673576 epoch total loss 1.14435613
Trained batch 434 batch loss 1.05120385 epoch total loss 1.14414144
Trained batch 435 batch loss 1.20812392 epoch total loss 1.14428854
Trained batch 436 batch loss 1.12457252 epoch total loss 1.14424336
Trained batch 437 batch loss 1.17179346 epoch total loss 1.14430642
Trained batch 438 batch loss 1.18850601 epoch total loss 1.14440727
Trained batch 439 batch loss 0.899292707 epoch total loss 1.1438489
Trained batch 440 batch loss 1.18868256 epoch total loss 1.14395082
Trained batch 441 batch loss 1.12137604 epoch total loss 1.14389968
Trained batch 442 batch loss 1.2090559 epoch total loss 1.14404702
Trained batch 443 batch loss 1.26660872 epoch total loss 1.14432371
Trained batch 444 batch loss 1.11964238 epoch total loss 1.14426804
Trained batch 445 batch loss 1.42374682 epoch total loss 1.14489603
Trained batch 446 batch loss 1.35915303 epoch total loss 1.14537656
Trained batch 447 batch loss 1.29034352 epoch total loss 1.14570069
Trained batch 448 batch loss 1.3619833 epoch total loss 1.14618361
Trained batch 449 batch loss 1.07043266 epoch total loss 1.14601481
Trained batch 450 batch loss 1.12026262 epoch total loss 1.14595759
Trained batch 451 batch loss 1.2017535 epoch total loss 1.14608133
Trained batch 452 batch loss 1.08663344 epoch total loss 1.14594972
Trained batch 453 batch loss 1.16635728 epoch total loss 1.1459949
Trained batch 454 batch loss 1.1812129 epoch total loss 1.14607251
Trained batch 455 batch loss 1.24644578 epoch total loss 1.14629304
Trained batch 456 batch loss 0.892692149 epoch total loss 1.14573693
Trained batch 457 batch loss 1.15396595 epoch total loss 1.14575505
Trained batch 458 batch loss 1.30616128 epoch total loss 1.14610529
Trained batch 459 batch loss 1.36002994 epoch total loss 1.1465714
Trained batch 460 batch loss 1.2564137 epoch total loss 1.14681017
Trained batch 461 batch loss 1.14871359 epoch total loss 1.14681435
Trained batch 462 batch loss 1.15279269 epoch total loss 1.14682722
Trained batch 463 batch loss 1.10092759 epoch total loss 1.14672816
Trained batch 464 batch loss 1.30344367 epoch total loss 1.14706588
Trained batch 465 batch loss 1.1287905 epoch total loss 1.14702666
Trained batch 466 batch loss 1.21907115 epoch total loss 1.14718115
Trained batch 467 batch loss 1.26041782 epoch total loss 1.14742374
Trained batch 468 batch loss 1.23728395 epoch total loss 1.14761579
Trained batch 469 batch loss 1.27909219 epoch total loss 1.14789617
Trained batch 470 batch loss 1.1265502 epoch total loss 1.14785063
Trained batch 471 batch loss 1.08466697 epoch total loss 1.14771652
Trained batch 472 batch loss 1.1336776 epoch total loss 1.14768672
Trained batch 473 batch loss 1.27393031 epoch total loss 1.14795363
Trained batch 474 batch loss 1.24321866 epoch total loss 1.14815462
Trained batch 475 batch loss 0.937592626 epoch total loss 1.1477114
Trained batch 476 batch loss 1.22051096 epoch total loss 1.14786434
Trained batch 477 batch loss 1.14235413 epoch total loss 1.14785278
Trained batch 478 batch loss 1.21094406 epoch total loss 1.14798474
Trained batch 479 batch loss 1.05023074 epoch total loss 1.14778066
Trained batch 480 batch loss 1.11039 epoch total loss 1.14770281
Trained batch 481 batch loss 1.30852747 epoch total loss 1.1480372
Trained batch 482 batch loss 1.19520211 epoch total loss 1.14813495
Trained batch 483 batch loss 1.50425625 epoch total loss 1.14887238
Trained batch 484 batch loss 1.48798084 epoch total loss 1.14957297
Trained batch 485 batch loss 1.1591382 epoch total loss 1.14959264
Trained batch 486 batch loss 1.02971315 epoch total loss 1.14934599
Trained batch 487 batch loss 1.34879637 epoch total loss 1.1497556
Trained batch 488 batch loss 1.32514191 epoch total loss 1.15011501
Trained batch 489 batch loss 1.03629112 epoch total loss 1.1498822
Trained batch 490 batch loss 1.19823265 epoch total loss 1.1499809
Trained batch 491 batch loss 1.15962505 epoch total loss 1.15000057
Trained batch 492 batch loss 1.09598947 epoch total loss 1.14989078
Trained batch 493 batch loss 1.28267419 epoch total loss 1.15016007
Trained batch 494 batch loss 1.14487898 epoch total loss 1.15014946
Trained batch 495 batch loss 1.16022396 epoch total loss 1.15016973
Trained batch 496 batch loss 0.977751255 epoch total loss 1.14982212
Trained batch 497 batch loss 0.914038301 epoch total loss 1.14934778
Trained batch 498 batch loss 0.843279 epoch total loss 1.14873314
Trained batch 499 batch loss 0.86315906 epoch total loss 1.14816082
Trained batch 500 batch loss 0.93243897 epoch total loss 1.1477294
Trained batch 501 batch loss 0.66259253 epoch total loss 1.14676106
Trained batch 502 batch loss 0.903631449 epoch total loss 1.14627671
Trained batch 503 batch loss 1.10338533 epoch total loss 1.14619148
Trained batch 504 batch loss 1.03456461 epoch total loss 1.14597
Trained batch 505 batch loss 1.08999228 epoch total loss 1.145859
Trained batch 506 batch loss 1.12659276 epoch total loss 1.14582098
Trained batch 507 batch loss 1.15042925 epoch total loss 1.14583
Trained batch 508 batch loss 1.103513 epoch total loss 1.14574683
Trained batch 509 batch loss 1.02179718 epoch total loss 1.14550328
Trained batch 510 batch loss 1.03888392 epoch total loss 1.14529419
Trained batch 511 batch loss 1.13197386 epoch total loss 1.14526808
Trained batch 512 batch loss 1.14043033 epoch total loss 1.14525867
Trained batch 513 batch loss 1.19414091 epoch total loss 1.14535403
Trained batch 514 batch loss 1.26624823 epoch total loss 1.14558911
Trained batch 515 batch loss 1.46771193 epoch total loss 1.1462146
Trained batch 516 batch loss 1.25459743 epoch total loss 1.14642465
Trained batch 517 batch loss 1.2017715 epoch total loss 1.1465317
Trained batch 518 batch loss 1.03985643 epoch total loss 1.14632583
Trained batch 519 batch loss 1.22891498 epoch total loss 1.14648497
Trained batch 520 batch loss 1.28294253 epoch total loss 1.14674747
Trained batch 521 batch loss 1.07923198 epoch total loss 1.14661777
Trained batch 522 batch loss 1.12447023 epoch total loss 1.14657533
Trained batch 523 batch loss 1.36323857 epoch total loss 1.14698958
Trained batch 524 batch loss 1.01953745 epoch total loss 1.14674628
Trained batch 525 batch loss 1.43276143 epoch total loss 1.14729106
Trained batch 526 batch loss 1.1033926 epoch total loss 1.14720762
Trained batch 527 batch loss 1.11229861 epoch total loss 1.14714146
Trained batch 528 batch loss 1.12531865 epoch total loss 1.14710009
Trained batch 529 batch loss 1.16353118 epoch total loss 1.14713109
Trained batch 530 batch loss 1.01816213 epoch total loss 1.14688778
Trained batch 531 batch loss 1.03136373 epoch total loss 1.14667022
Trained batch 532 batch loss 0.999838412 epoch total loss 1.14639425
Trained batch 533 batch loss 1.05997777 epoch total loss 1.14623213
Trained batch 534 batch loss 1.04690623 epoch total loss 1.14604616
Trained batch 535 batch loss 1.09849513 epoch total loss 1.14595735
Trained batch 536 batch loss 1.14046764 epoch total loss 1.14594698
Trained batch 537 batch loss 1.00210154 epoch total loss 1.14567912
Trained batch 538 batch loss 0.975511551 epoch total loss 1.14536285
Trained batch 539 batch loss 1.16846919 epoch total loss 1.14540565
Trained batch 540 batch loss 1.23654294 epoch total loss 1.14557445
Trained batch 541 batch loss 1.35958171 epoch total loss 1.14597
Trained batch 542 batch loss 1.04651272 epoch total loss 1.14578652
Trained batch 543 batch loss 1.18289447 epoch total loss 1.14585495
Trained batch 544 batch loss 1.12868 epoch total loss 1.14582336
Trained batch 545 batch loss 1.09814882 epoch total loss 1.14573586
Trained batch 546 batch loss 1.54540253 epoch total loss 1.1464678
Trained batch 547 batch loss 1.48631716 epoch total loss 1.14708912
Trained batch 548 batch loss 1.30910921 epoch total loss 1.14738476
Trained batch 549 batch loss 1.24166954 epoch total loss 1.14755654
Trained batch 550 batch loss 1.14286709 epoch total loss 1.14754808
Trained batch 551 batch loss 1.38595712 epoch total loss 1.14798081
Trained batch 552 batch loss 1.17770171 epoch total loss 1.14803457
Trained batch 553 batch loss 1.16881871 epoch total loss 1.14807212
Trained batch 554 batch loss 1.26634097 epoch total loss 1.14828563
Trained batch 555 batch loss 1.2557677 epoch total loss 1.14847934
Trained batch 556 batch loss 1.26085794 epoch total loss 1.1486814
Trained batch 557 batch loss 1.06835628 epoch total loss 1.14853716
Trained batch 558 batch loss 1.10944676 epoch total loss 1.14846718
Trained batch 559 batch loss 1.22764194 epoch total loss 1.1486088
Trained batch 560 batch loss 1.28034484 epoch total loss 1.148844
Trained batch 561 batch loss 1.12628722 epoch total loss 1.14880383
Trained batch 562 batch loss 1.06226182 epoch total loss 1.14864981
Trained batch 563 batch loss 1.4541986 epoch total loss 1.14919257
Trained batch 564 batch loss 1.23140931 epoch total loss 1.14933836
Trained batch 565 batch loss 1.17702484 epoch total loss 1.14938724
Trained batch 566 batch loss 1.19964051 epoch total loss 1.14947605
Trained batch 567 batch loss 1.14062619 epoch total loss 1.14946043
Trained batch 568 batch loss 1.12867022 epoch total loss 1.14942384
Trained batch 569 batch loss 1.22002506 epoch total loss 1.14954793
Trained batch 570 batch loss 1.08152699 epoch total loss 1.14942861
Trained batch 571 batch loss 1.11884415 epoch total loss 1.14937508
Trained batch 572 batch loss 0.965100825 epoch total loss 1.14905286
Trained batch 573 batch loss 1.09294665 epoch total loss 1.14895499
Trained batch 574 batch loss 1.10674191 epoch total loss 1.14888144
Trained batch 575 batch loss 1.20868993 epoch total loss 1.14898539
Trained batch 576 batch loss 1.29042625 epoch total loss 1.14923096
Trained batch 577 batch loss 1.09657335 epoch total loss 1.14913964
Trained batch 578 batch loss 1.16192412 epoch total loss 1.14916182
Trained batch 579 batch loss 0.894359767 epoch total loss 1.14872169
Trained batch 580 batch loss 0.921776295 epoch total loss 1.14833033
Trained batch 581 batch loss 1.18347263 epoch total loss 1.14839089
Trained batch 582 batch loss 1.06746078 epoch total loss 1.14825177
Trained batch 583 batch loss 1.05534124 epoch total loss 1.14809239
Trained batch 584 batch loss 1.13498545 epoch total loss 1.14807
Trained batch 585 batch loss 1.09661245 epoch total loss 1.14798212
Trained batch 586 batch loss 1.23029065 epoch total loss 1.14812255
Trained batch 587 batch loss 1.26451516 epoch total loss 1.14832079
Trained batch 588 batch loss 1.20600724 epoch total loss 1.1484189
Trained batch 589 batch loss 1.32911098 epoch total loss 1.14872563
Trained batch 590 batch loss 1.09248459 epoch total loss 1.14863038
Trained batch 591 batch loss 1.1671437 epoch total loss 1.14866161
Trained batch 592 batch loss 1.07708168 epoch total loss 1.14854074
Trained batch 593 batch loss 1.07172525 epoch total loss 1.14841115
Trained batch 594 batch loss 1.07443404 epoch total loss 1.1482867
Trained batch 595 batch loss 1.28603911 epoch total loss 1.14851809
Trained batch 596 batch loss 1.06355524 epoch total loss 1.14837551
Trained batch 597 batch loss 1.03374314 epoch total loss 1.14818358
Trained batch 598 batch loss 1.15134 epoch total loss 1.14818883
Trained batch 599 batch loss 0.915727079 epoch total loss 1.1478008
Trained batch 600 batch loss 0.90612781 epoch total loss 1.14739799
Trained batch 601 batch loss 1.09727 epoch total loss 1.14731455
Trained batch 602 batch loss 1.25017273 epoch total loss 1.14748549
Trained batch 603 batch loss 1.18093681 epoch total loss 1.14754093
Trained batch 604 batch loss 1.07854116 epoch total loss 1.14742672
Trained batch 605 batch loss 1.02746034 epoch total loss 1.14722836
Trained batch 606 batch loss 0.929148078 epoch total loss 1.14686847
Trained batch 607 batch loss 0.995711923 epoch total loss 1.14661956
Trained batch 608 batch loss 1.13479948 epoch total loss 1.14660013
Trained batch 609 batch loss 1.00888777 epoch total loss 1.14637399
Trained batch 610 batch loss 1.01979816 epoch total loss 1.14616644
Trained batch 611 batch loss 1.23093319 epoch total loss 1.14630532
Trained batch 612 batch loss 0.995145679 epoch total loss 1.1460582
Trained batch 613 batch loss 1.19667 epoch total loss 1.14614081
Trained batch 614 batch loss 0.844781041 epoch total loss 1.14564991
Trained batch 615 batch loss 1.31403756 epoch total loss 1.14592373
Trained batch 616 batch loss 1.22404397 epoch total loss 1.14605057
Trained batch 617 batch loss 1.27626169 epoch total loss 1.14626157
Trained batch 618 batch loss 1.14877391 epoch total loss 1.14626575
Trained batch 619 batch loss 1.11405325 epoch total loss 1.14621365
Trained batch 620 batch loss 1.16143966 epoch total loss 1.14623821
Trained batch 621 batch loss 1.27612555 epoch total loss 1.14644742
Trained batch 622 batch loss 1.2742877 epoch total loss 1.14665294
Trained batch 623 batch loss 1.17295 epoch total loss 1.14669526
Trained batch 624 batch loss 0.956407905 epoch total loss 1.14639032
Trained batch 625 batch loss 1.13983154 epoch total loss 1.14637983
Trained batch 626 batch loss 1.37126803 epoch total loss 1.14673901
Trained batch 627 batch loss 1.35400927 epoch total loss 1.14706957
Trained batch 628 batch loss 1.06000328 epoch total loss 1.14693093
Trained batch 629 batch loss 1.13954246 epoch total loss 1.14691913
Trained batch 630 batch loss 1.36116338 epoch total loss 1.14725924
Trained batch 631 batch loss 0.992697239 epoch total loss 1.14701426
Trained batch 632 batch loss 1.04349339 epoch total loss 1.14685047
Trained batch 633 batch loss 1.30891109 epoch total loss 1.14710653
Trained batch 634 batch loss 1.0261997 epoch total loss 1.14691579
Trained batch 635 batch loss 1.20763755 epoch total loss 1.1470114
Trained batch 636 batch loss 1.09925342 epoch total loss 1.1469363
Trained batch 637 batch loss 1.23831987 epoch total loss 1.14707983
Trained batch 638 batch loss 1.4188714 epoch total loss 1.14750576
Trained batch 639 batch loss 1.29327786 epoch total loss 1.14773393
Trained batch 640 batch loss 1.25435662 epoch total loss 1.14790046
Trained batch 641 batch loss 1.21123064 epoch total loss 1.14799929
Trained batch 642 batch loss 1.17416918 epoch total loss 1.14804
Trained batch 643 batch loss 1.09173036 epoch total loss 1.14795256
Trained batch 644 batch loss 1.23264503 epoch total loss 1.14808404
Trained batch 645 batch loss 1.06222594 epoch total loss 1.14795101
Trained batch 646 batch loss 1.1972388 epoch total loss 1.1480273
Trained batch 647 batch loss 1.28441381 epoch total loss 1.14823818
Trained batch 648 batch loss 1.35311317 epoch total loss 1.14855433
Trained batch 649 batch loss 1.13687015 epoch total loss 1.14853621
Trained batch 650 batch loss 1.18344617 epoch total loss 1.14859
Trained batch 651 batch loss 1.27272701 epoch total loss 1.1487807
Trained batch 652 batch loss 1.24649024 epoch total loss 1.14893043
Trained batch 653 batch loss 1.29468298 epoch total loss 1.14915371
Trained batch 654 batch loss 0.939633727 epoch total loss 1.14883327
Trained batch 655 batch loss 1.07309246 epoch total loss 1.14871776
Trained batch 656 batch loss 1.18086159 epoch total loss 1.14876664
Trained batch 657 batch loss 1.32841873 epoch total loss 1.1490401
Trained batch 658 batch loss 1.15111387 epoch total loss 1.14904332
Trained batch 659 batch loss 1.06788301 epoch total loss 1.14892018
Trained batch 660 batch loss 1.1941396 epoch total loss 1.14898872
Trained batch 661 batch loss 1.28112066 epoch total loss 1.14918852
Trained batch 662 batch loss 1.10793829 epoch total loss 1.14912617
Trained batch 663 batch loss 1.23795724 epoch total loss 1.14926028
Trained batch 664 batch loss 1.31192923 epoch total loss 1.14950526
Trained batch 665 batch loss 1.04605007 epoch total loss 1.14934969
Trained batch 666 batch loss 1.05124092 epoch total loss 1.14920235
Trained batch 667 batch loss 1.16030419 epoch total loss 1.14921892
Trained batch 668 batch loss 1.21013963 epoch total loss 1.14931023
Trained batch 669 batch loss 1.12710536 epoch total loss 1.14927697
Trained batch 670 batch loss 0.947153 epoch total loss 1.14897525
Trained batch 671 batch loss 1.20990479 epoch total loss 1.14906609
Trained batch 672 batch loss 1.20143366 epoch total loss 1.14914393
Trained batch 673 batch loss 1.06683588 epoch total loss 1.14902163
Trained batch 674 batch loss 1.17780089 epoch total loss 1.1490643
Trained batch 675 batch loss 1.12159824 epoch total loss 1.14902365
Trained batch 676 batch loss 1.32462811 epoch total loss 1.14928341
Trained batch 677 batch loss 0.986676693 epoch total loss 1.1490432
Trained batch 678 batch loss 1.07838535 epoch total loss 1.14893901
Trained batch 679 batch loss 1.18911719 epoch total loss 1.14899814
Trained batch 680 batch loss 1.24491835 epoch total loss 1.14913917
Trained batch 681 batch loss 1.25022829 epoch total loss 1.1492877
Trained batch 682 batch loss 1.11591578 epoch total loss 1.14923871
Trained batch 683 batch loss 0.981187761 epoch total loss 1.14899266
Trained batch 684 batch loss 0.892053485 epoch total loss 1.14861703
Trained batch 685 batch loss 1.14264798 epoch total loss 1.14860833
Trained batch 686 batch loss 1.38708889 epoch total loss 1.14895594
Trained batch 687 batch loss 0.936910629 epoch total loss 1.14864731
Trained batch 688 batch loss 1.04556167 epoch total loss 1.14849734
Trained batch 689 batch loss 0.975280464 epoch total loss 1.14824593
Trained batch 690 batch loss 0.8289873 epoch total loss 1.14778328
Trained batch 691 batch loss 1.11085629 epoch total loss 1.14772975
Trained batch 692 batch loss 0.840006828 epoch total loss 1.1472851
Trained batch 693 batch loss 1.09278846 epoch total loss 1.14720654
Trained batch 694 batch loss 1.02581692 epoch total loss 1.14703155
Trained batch 695 batch loss 1.08832526 epoch total loss 1.14694715
Trained batch 696 batch loss 1.1624558 epoch total loss 1.14696944
Trained batch 697 batch loss 1.0330081 epoch total loss 1.14680588
Trained batch 698 batch loss 1.18290448 epoch total loss 1.14685762
Trained batch 699 batch loss 1.16241813 epoch total loss 1.14687991
Trained batch 700 batch loss 1.15042 epoch total loss 1.14688492
Trained batch 701 batch loss 1.25271225 epoch total loss 1.14703584
Trained batch 702 batch loss 1.20185375 epoch total loss 1.14711392
Trained batch 703 batch loss 1.22162604 epoch total loss 1.1472199
Trained batch 704 batch loss 1.04334211 epoch total loss 1.14707232
Trained batch 705 batch loss 1.20634341 epoch total loss 1.14715648
Trained batch 706 batch loss 1.09201264 epoch total loss 1.14707839
Trained batch 707 batch loss 0.980049729 epoch total loss 1.14684212
Trained batch 708 batch loss 1.02460074 epoch total loss 1.14666951
Trained batch 709 batch loss 0.871830165 epoch total loss 1.14628184
Trained batch 710 batch loss 1.21563554 epoch total loss 1.14637947
Trained batch 711 batch loss 1.35729635 epoch total loss 1.14667618
Trained batch 712 batch loss 1.22077799 epoch total loss 1.14678025
Trained batch 713 batch loss 1.51640797 epoch total loss 1.14729857
Trained batch 714 batch loss 1.41112602 epoch total loss 1.14766812
Trained batch 715 batch loss 1.30654144 epoch total loss 1.14789033
Trained batch 716 batch loss 1.31570578 epoch total loss 1.14812469
Trained batch 717 batch loss 1.31711674 epoch total loss 1.14836049
Trained batch 718 batch loss 1.29814529 epoch total loss 1.14856911
Trained batch 719 batch loss 1.43697286 epoch total loss 1.14897013
Trained batch 720 batch loss 1.11098301 epoch total loss 1.14891744
Trained batch 721 batch loss 1.28759873 epoch total loss 1.14910972
Trained batch 722 batch loss 1.1222738 epoch total loss 1.14907253
Trained batch 723 batch loss 1.18773699 epoch total loss 1.14912605
Trained batch 724 batch loss 1.20196533 epoch total loss 1.14919901
Trained batch 725 batch loss 1.07918262 epoch total loss 1.14910245
Trained batch 726 batch loss 0.951363385 epoch total loss 1.14883
Trained batch 727 batch loss 1.13806701 epoch total loss 1.14881516
Trained batch 728 batch loss 1.14699674 epoch total loss 1.14881265
Trained batch 729 batch loss 1.24440014 epoch total loss 1.14894378
Trained batch 730 batch loss 0.954898 epoch total loss 1.14867795
Trained batch 731 batch loss 1.10442507 epoch total loss 1.14861739
Trained batch 732 batch loss 0.916550934 epoch total loss 1.14830041
Trained batch 733 batch loss 1.09236097 epoch total loss 1.14822412
Trained batch 734 batch loss 1.25040615 epoch total loss 1.14836335
Trained batch 735 batch loss 0.93104583 epoch total loss 1.14806759
Trained batch 736 batch loss 1.00293231 epoch total loss 1.14787042
Trained batch 737 batch loss 1.31955945 epoch total loss 1.14810348
Trained batch 738 batch loss 1.29003549 epoch total loss 1.14829576
Trained batch 739 batch loss 1.27812707 epoch total loss 1.14847147
Trained batch 740 batch loss 1.21453214 epoch total loss 1.14856076
Trained batch 741 batch loss 1.36457515 epoch total loss 1.14885223
Trained batch 742 batch loss 1.1832571 epoch total loss 1.1488986
Trained batch 743 batch loss 1.14978886 epoch total loss 1.14889979
Trained batch 744 batch loss 1.21701956 epoch total loss 1.14899135
Trained batch 745 batch loss 1.33259416 epoch total loss 1.14923775
Trained batch 746 batch loss 1.38317907 epoch total loss 1.14955139
Trained batch 747 batch loss 1.4796021 epoch total loss 1.14999318
Trained batch 748 batch loss 1.28323185 epoch total loss 1.15017128
Trained batch 749 batch loss 1.5710274 epoch total loss 1.15073323
Trained batch 750 batch loss 1.59645879 epoch total loss 1.15132749
Trained batch 751 batch loss 1.35647511 epoch total loss 1.1516006
Trained batch 752 batch loss 0.881783605 epoch total loss 1.15124178
Trained batch 753 batch loss 0.968571305 epoch total loss 1.15099919
Trained batch 754 batch loss 1.02034736 epoch total loss 1.15082586
Trained batch 755 batch loss 1.02021039 epoch total loss 1.15065289
Trained batch 756 batch loss 1.19573319 epoch total loss 1.15071249
Trained batch 757 batch loss 0.960710108 epoch total loss 1.15046155
Trained batch 758 batch loss 1.12062335 epoch total loss 1.1504221
Trained batch 759 batch loss 1.50012898 epoch total loss 1.15088284
Trained batch 760 batch loss 1.45274568 epoch total loss 1.15128
Trained batch 761 batch loss 1.08003283 epoch total loss 1.15118647
Trained batch 762 batch loss 1.24217117 epoch total loss 1.15130579
Trained batch 763 batch loss 1.14594471 epoch total loss 1.15129876
Trained batch 764 batch loss 1.07216108 epoch total loss 1.15119517
Trained batch 765 batch loss 1.18617702 epoch total loss 1.15124094
Trained batch 766 batch loss 1.16235018 epoch total loss 1.15125537
Trained batch 767 batch loss 1.25202203 epoch total loss 1.15138674
Trained batch 768 batch loss 1.31931913 epoch total loss 1.15160549
Trained batch 769 batch loss 1.43941629 epoch total loss 1.15197968
Trained batch 770 batch loss 1.53531182 epoch total loss 1.1524775
Trained batch 771 batch loss 1.2314508 epoch total loss 1.15258
Trained batch 772 batch loss 1.30890727 epoch total loss 1.15278244
Trained batch 773 batch loss 1.33554912 epoch total loss 1.15301895
Trained batch 774 batch loss 1.21459389 epoch total loss 1.15309846
Trained batch 775 batch loss 0.968040347 epoch total loss 1.15285969
Trained batch 776 batch loss 0.983242393 epoch total loss 1.15264106
Trained batch 777 batch loss 0.943450212 epoch total loss 1.15237176
Trained batch 778 batch loss 0.818295956 epoch total loss 1.15194237
Trained batch 779 batch loss 1.00664759 epoch total loss 1.15175593
Trained batch 780 batch loss 0.84262377 epoch total loss 1.15135956
Trained batch 781 batch loss 1.0716809 epoch total loss 1.15125751
Trained batch 782 batch loss 1.03408027 epoch total loss 1.15110767
Trained batch 783 batch loss 1.08145809 epoch total loss 1.15101874
Trained batch 784 batch loss 1.17108107 epoch total loss 1.15104437
Trained batch 785 batch loss 1.25820744 epoch total loss 1.15118086
Trained batch 786 batch loss 0.960287571 epoch total loss 1.15093791
Trained batch 787 batch loss 1.06437206 epoch total loss 1.150828
Trained batch 788 batch loss 1.22933447 epoch total loss 1.15092754
Trained batch 789 batch loss 1.01396871 epoch total loss 1.15075397
Trained batch 790 batch loss 1.18904662 epoch total loss 1.15080237
Trained batch 791 batch loss 1.15655375 epoch total loss 1.15080965
Trained batch 792 batch loss 1.13734746 epoch total loss 1.15079272
Trained batch 793 batch loss 1.25868785 epoch total loss 1.15092874
Trained batch 794 batch loss 1.23582673 epoch total loss 1.15103567
Trained batch 795 batch loss 0.94515872 epoch total loss 1.15077662
Trained batch 796 batch loss 1.13009858 epoch total loss 1.15075076
Trained batch 797 batch loss 1.12678218 epoch total loss 1.1507206
Trained batch 798 batch loss 1.01794147 epoch total loss 1.15055418
Trained batch 799 batch loss 1.10899985 epoch total loss 1.1505022
Trained batch 800 batch loss 1.24765921 epoch total loss 1.15062368
Trained batch 801 batch loss 1.03178215 epoch total loss 1.15047538
Trained batch 802 batch loss 1.37368059 epoch total loss 1.15075362
Trained batch 803 batch loss 1.11122608 epoch total loss 1.15070438
Trained batch 804 batch loss 1.10256159 epoch total loss 1.15064454
Trained batch 805 batch loss 1.18595362 epoch total loss 1.15068841
Trained batch 806 batch loss 1.08160913 epoch total loss 1.1506027
Trained batch 807 batch loss 1.0082525 epoch total loss 1.15042627
Trained batch 808 batch loss 1.07067847 epoch total loss 1.15032756
Trained batch 809 batch loss 0.981174648 epoch total loss 1.15011847
Trained batch 810 batch loss 1.24657619 epoch total loss 1.15023756
Trained batch 811 batch loss 1.20088387 epoch total loss 1.1503
Trained batch 812 batch loss 1.15972686 epoch total loss 1.15031159
Trained batch 813 batch loss 1.15411747 epoch total loss 1.15031636
Trained batch 814 batch loss 1.2378335 epoch total loss 1.15042388
Trained batch 815 batch loss 1.19619417 epoch total loss 1.15047991
Trained batch 816 batch loss 1.28238893 epoch total loss 1.15064168
Trained batch 817 batch loss 1.06227303 epoch total loss 1.15053344
Trained batch 818 batch loss 1.27444339 epoch total loss 1.15068495
Trained batch 819 batch loss 1.06312764 epoch total loss 1.15057802
Trained batch 820 batch loss 1.23107862 epoch total loss 1.15067613
Trained batch 821 batch loss 1.0635519 epoch total loss 1.15057
Trained batch 822 batch loss 1.1971488 epoch total loss 1.15062666
Trained batch 823 batch loss 1.22601414 epoch total loss 1.15071833
Trained batch 824 batch loss 1.33271217 epoch total loss 1.15093911
Trained batch 825 batch loss 1.00502121 epoch total loss 1.1507622
Trained batch 826 batch loss 0.955559433 epoch total loss 1.15052593
Trained batch 827 batch loss 1.12125671 epoch total loss 1.15049052
Trained batch 828 batch loss 1.01141584 epoch total loss 1.15032256
Trained batch 829 batch loss 1.05719101 epoch total loss 1.15021026
Trained batch 830 batch loss 1.04899859 epoch total loss 1.15008831
Trained batch 831 batch loss 0.992582321 epoch total loss 1.14989877
Trained batch 832 batch loss 1.02842855 epoch total loss 1.14975274
Trained batch 833 batch loss 1.10775185 epoch total loss 1.14970231
Trained batch 834 batch loss 0.938685238 epoch total loss 1.14944923
Trained batch 835 batch loss 1.05417109 epoch total loss 1.14933515
Trained batch 836 batch loss 1.03463745 epoch total loss 1.14919794
Trained batch 837 batch loss 1.23483479 epoch total loss 1.14930034
Trained batch 838 batch loss 1.21188164 epoch total loss 1.14937496
Trained batch 839 batch loss 1.1682198 epoch total loss 1.14939737
Trained batch 840 batch loss 1.13846934 epoch total loss 1.14938438
Trained batch 841 batch loss 1.15182805 epoch total loss 1.14938736
Trained batch 842 batch loss 1.27518153 epoch total loss 1.14953673
Trained batch 843 batch loss 1.08671153 epoch total loss 1.14946222
Trained batch 844 batch loss 1.14835143 epoch total loss 1.14946103
Trained batch 845 batch loss 1.0797143 epoch total loss 1.14937842
Trained batch 846 batch loss 1.22208321 epoch total loss 1.14946437
Trained batch 847 batch loss 1.02511036 epoch total loss 1.14931762
Trained batch 848 batch loss 1.34723449 epoch total loss 1.14955091
Trained batch 849 batch loss 1.31816363 epoch total loss 1.14974952
Trained batch 850 batch loss 1.22882938 epoch total loss 1.14984262
Trained batch 851 batch loss 1.40091455 epoch total loss 1.15013766
Trained batch 852 batch loss 1.1963526 epoch total loss 1.1501919
Trained batch 853 batch loss 1.19651079 epoch total loss 1.15024626
Trained batch 854 batch loss 1.4071703 epoch total loss 1.15054703
Trained batch 855 batch loss 1.29330802 epoch total loss 1.15071404
Trained batch 856 batch loss 1.08883095 epoch total loss 1.1506418
Trained batch 857 batch loss 1.20991492 epoch total loss 1.15071094
Trained batch 858 batch loss 1.14302683 epoch total loss 1.15070188
Trained batch 859 batch loss 1.29646587 epoch total loss 1.15087163
Trained batch 860 batch loss 1.14594066 epoch total loss 1.15086579
Trained batch 861 batch loss 1.47494411 epoch total loss 1.15124226
Trained batch 862 batch loss 1.21184587 epoch total loss 1.15131247
Trained batch 863 batch loss 1.15603518 epoch total loss 1.15131795
Trained batch 864 batch loss 0.971910954 epoch total loss 1.15111029
Trained batch 865 batch loss 1.01576424 epoch total loss 1.15095389
Trained batch 866 batch loss 0.956441224 epoch total loss 1.15072918
Trained batch 867 batch loss 1.10936832 epoch total loss 1.1506815
Trained batch 868 batch loss 0.961837292 epoch total loss 1.15046394
Trained batch 869 batch loss 1.13837814 epoch total loss 1.15045
Trained batch 870 batch loss 1.04671955 epoch total loss 1.15033078
Trained batch 871 batch loss 1.20991075 epoch total loss 1.15039921
Trained batch 872 batch loss 1.22913182 epoch total loss 1.15048945
Trained batch 873 batch loss 1.01214337 epoch total loss 1.15033102
Trained batch 874 batch loss 0.981875181 epoch total loss 1.15013826
Trained batch 875 batch loss 0.951691031 epoch total loss 1.14991152
Trained batch 876 batch loss 1.2573638 epoch total loss 1.15003419
Trained batch 877 batch loss 0.843910515 epoch total loss 1.14968514
Trained batch 878 batch loss 0.907667637 epoch total loss 1.14940953
Trained batch 879 batch loss 0.924096227 epoch total loss 1.14915311
Trained batch 880 batch loss 0.871207058 epoch total loss 1.14883733
Trained batch 881 batch loss 0.907357812 epoch total loss 1.14856315
Trained batch 882 batch loss 0.964066207 epoch total loss 1.14835393
Trained batch 883 batch loss 0.950946 epoch total loss 1.14813042
Trained batch 884 batch loss 0.8071661 epoch total loss 1.14774466
Trained batch 885 batch loss 1.10816646 epoch total loss 1.1477
Trained batch 886 batch loss 1.29853272 epoch total loss 1.14787018
Trained batch 887 batch loss 1.01339412 epoch total loss 1.14771855
Trained batch 888 batch loss 1.21634448 epoch total loss 1.14779592
Trained batch 889 batch loss 0.99195385 epoch total loss 1.14762056
Trained batch 890 batch loss 1.00049806 epoch total loss 1.14745522
Trained batch 891 batch loss 1.22456098 epoch total loss 1.14754176
Trained batch 892 batch loss 1.07447815 epoch total loss 1.14745986
Trained batch 893 batch loss 1.21929061 epoch total loss 1.14754021
Trained batch 894 batch loss 1.17634225 epoch total loss 1.14757252
Trained batch 895 batch loss 0.96323669 epoch total loss 1.14736652
Trained batch 896 batch loss 1.13359916 epoch total loss 1.14735115
Trained batch 897 batch loss 1.21726537 epoch total loss 1.14742911
Trained batch 898 batch loss 1.22870433 epoch total loss 1.14751971
Trained batch 899 batch loss 1.24413753 epoch total loss 1.14762712
Trained batch 900 batch loss 1.07196975 epoch total loss 1.14754307
Trained batch 901 batch loss 1.33638334 epoch total loss 1.14775276
Trained batch 902 batch loss 1.11742198 epoch total loss 1.14771914
Trained batch 903 batch loss 1.32381105 epoch total loss 1.14791417
Trained batch 904 batch loss 1.2668705 epoch total loss 1.14804578
Trained batch 905 batch loss 1.40497375 epoch total loss 1.14832973
Trained batch 906 batch loss 1.32948542 epoch total loss 1.14852965
Trained batch 907 batch loss 0.959627628 epoch total loss 1.14832139
Trained batch 908 batch loss 0.997587264 epoch total loss 1.14815533
Trained batch 909 batch loss 1.09596896 epoch total loss 1.14809787
Trained batch 910 batch loss 1.02585387 epoch total loss 1.14796352
Trained batch 911 batch loss 1.10337758 epoch total loss 1.14791465
Trained batch 912 batch loss 1.05498052 epoch total loss 1.14781272
Trained batch 913 batch loss 1.22021532 epoch total loss 1.147892
Trained batch 914 batch loss 1.02756524 epoch total loss 1.14776039
Trained batch 915 batch loss 1.02386808 epoch total loss 1.14762509
Trained batch 916 batch loss 1.13416719 epoch total loss 1.14761031
Trained batch 917 batch loss 0.999263048 epoch total loss 1.14744854
Trained batch 918 batch loss 1.10667825 epoch total loss 1.14740419
Trained batch 919 batch loss 1.14595985 epoch total loss 1.14740264
Trained batch 920 batch loss 1.12847638 epoch total loss 1.14738202
Trained batch 921 batch loss 0.982875407 epoch total loss 1.14720345
Trained batch 922 batch loss 1.24225712 epoch total loss 1.14730656
Trained batch 923 batch loss 1.23281384 epoch total loss 1.14739919
Trained batch 924 batch loss 0.991804302 epoch total loss 1.14723074
Trained batch 925 batch loss 1.29034472 epoch total loss 1.1473856
Trained batch 926 batch loss 1.00627065 epoch total loss 1.14723313
Trained batch 927 batch loss 0.817818522 epoch total loss 1.14687788
Trained batch 928 batch loss 1.0579958 epoch total loss 1.14678204
Trained batch 929 batch loss 0.856937885 epoch total loss 1.14647007
Trained batch 930 batch loss 0.816281 epoch total loss 1.14611506
Trained batch 931 batch loss 0.711595654 epoch total loss 1.14564824
Trained batch 932 batch loss 0.894385278 epoch total loss 1.14537871
Trained batch 933 batch loss 0.814198196 epoch total loss 1.1450237
Trained batch 934 batch loss 0.760155916 epoch total loss 1.1446116
Trained batch 935 batch loss 0.700030386 epoch total loss 1.14413619
Trained batch 936 batch loss 1.14303446 epoch total loss 1.144135
Trained batch 937 batch loss 1.01911712 epoch total loss 1.14400172
Trained batch 938 batch loss 1.10544503 epoch total loss 1.1439606
Trained batch 939 batch loss 1.14548266 epoch total loss 1.14396226
Trained batch 940 batch loss 1.10585856 epoch total loss 1.14392173
Trained batch 941 batch loss 1.27240539 epoch total loss 1.14405823
Trained batch 942 batch loss 1.05496597 epoch total loss 1.14396369
Trained batch 943 batch loss 1.33230639 epoch total loss 1.14416337
Trained batch 944 batch loss 1.32969 epoch total loss 1.14436
Trained batch 945 batch loss 1.21743822 epoch total loss 1.14443719
Trained batch 946 batch loss 1.27533877 epoch total loss 1.1445756
Trained batch 947 batch loss 1.26146805 epoch total loss 1.1446991
Trained batch 948 batch loss 1.31052136 epoch total loss 1.14487398
Trained batch 949 batch loss 1.36673331 epoch total loss 1.14510775
Trained batch 950 batch loss 1.36341727 epoch total loss 1.14533758
Trained batch 951 batch loss 1.28892767 epoch total loss 1.1454885
Trained batch 952 batch loss 1.31267273 epoch total loss 1.1456641
Trained batch 953 batch loss 1.18295836 epoch total loss 1.14570332
Trained batch 954 batch loss 1.27647209 epoch total loss 1.14584041
Trained batch 955 batch loss 1.16357589 epoch total loss 1.14585888
Trained batch 956 batch loss 1.32359815 epoch total loss 1.14604485
Trained batch 957 batch loss 1.34039474 epoch total loss 1.14624798
Trained batch 958 batch loss 1.42912269 epoch total loss 1.14654326
Trained batch 959 batch loss 1.16789269 epoch total loss 1.14656544
Trained batch 960 batch loss 1.24606133 epoch total loss 1.14666915
Trained batch 961 batch loss 1.16654825 epoch total loss 1.14668977
Trained batch 962 batch loss 1.19555974 epoch total loss 1.14674056
Trained batch 963 batch loss 1.35667634 epoch total loss 1.14695859
Trained batch 964 batch loss 1.159145 epoch total loss 1.14697123
Trained batch 965 batch loss 1.11402154 epoch total loss 1.14693713
Trained batch 966 batch loss 0.812461793 epoch total loss 1.14659095
Trained batch 967 batch loss 1.02779174 epoch total loss 1.14646804
Trained batch 968 batch loss 1.04035079 epoch total loss 1.14635849
Trained batch 969 batch loss 0.733777285 epoch total loss 1.14593267
Trained batch 970 batch loss 0.903113842 epoch total loss 1.14568233
Trained batch 971 batch loss 0.887927175 epoch total loss 1.14541698
Trained batch 972 batch loss 1.18050456 epoch total loss 1.1454531
Trained batch 973 batch loss 1.13300109 epoch total loss 1.14544034
Trained batch 974 batch loss 1.05624247 epoch total loss 1.14534879
Trained batch 975 batch loss 1.13657224 epoch total loss 1.14533985
Trained batch 976 batch loss 1.05644488 epoch total loss 1.14524865
Trained batch 977 batch loss 1.12199903 epoch total loss 1.14522481
Trained batch 978 batch loss 0.833075881 epoch total loss 1.14490569
Trained batch 979 batch loss 1.01254225 epoch total loss 1.1447705
Trained batch 980 batch loss 1.01912379 epoch total loss 1.14464235
Trained batch 981 batch loss 0.983970881 epoch total loss 1.14447856
Trained batch 982 batch loss 1.19400299 epoch total loss 1.14452899
Trained batch 983 batch loss 0.966707528 epoch total loss 1.14434803
Trained batch 984 batch loss 1.02236652 epoch total loss 1.14422405
Trained batch 985 batch loss 1.01072538 epoch total loss 1.14408863
Trained batch 986 batch loss 1.08021247 epoch total loss 1.14402378
Trained batch 987 batch loss 1.17428541 epoch total loss 1.14405441
Trained batch 988 batch loss 1.37389851 epoch total loss 1.14428711
Trained batch 989 batch loss 1.14375508 epoch total loss 1.14428663
Trained batch 990 batch loss 1.25127625 epoch total loss 1.14439464
Trained batch 991 batch loss 1.39346933 epoch total loss 1.14464593
Trained batch 992 batch loss 1.16936994 epoch total loss 1.14467084
Trained batch 993 batch loss 1.12650156 epoch total loss 1.14465249
Trained batch 994 batch loss 0.700335 epoch total loss 1.14420545
Trained batch 995 batch loss 1.14282584 epoch total loss 1.14420402
Trained batch 996 batch loss 0.785472512 epoch total loss 1.14384389
Trained batch 997 batch loss 1.18578577 epoch total loss 1.14388597
Trained batch 998 batch loss 1.26446593 epoch total loss 1.14400685
Trained batch 999 batch loss 1.19884968 epoch total loss 1.1440618
Trained batch 1000 batch loss 1.2145642 epoch total loss 1.14413238
Trained batch 1001 batch loss 1.1652298 epoch total loss 1.14415348
Trained batch 1002 batch loss 1.38028157 epoch total loss 1.14438903
Trained batch 1003 batch loss 1.14587772 epoch total loss 1.14439058
Trained batch 1004 batch loss 1.0601418 epoch total loss 1.14430666
Trained batch 1005 batch loss 1.09092474 epoch total loss 1.14425361
Trained batch 1006 batch loss 1.27276814 epoch total loss 1.1443814
Trained batch 1007 batch loss 1.26753974 epoch total loss 1.14450371
Trained batch 1008 batch loss 1.39605641 epoch total loss 1.14475322
Trained batch 1009 batch loss 1.28587222 epoch total loss 1.14489305
Trained batch 1010 batch loss 1.54263902 epoch total loss 1.14528692
Trained batch 1011 batch loss 1.50890362 epoch total loss 1.14564657
Trained batch 1012 batch loss 1.48585737 epoch total loss 1.14598274
Trained batch 1013 batch loss 1.17453456 epoch total loss 1.14601088
Trained batch 1014 batch loss 1.42527056 epoch total loss 1.14628637
Trained batch 1015 batch loss 1.54991603 epoch total loss 1.14668405
Trained batch 1016 batch loss 1.29826808 epoch total loss 1.14683318
Trained batch 1017 batch loss 1.38743222 epoch total loss 1.14706981
Trained batch 1018 batch loss 1.22468412 epoch total loss 1.14714611
Trained batch 1019 batch loss 1.35757458 epoch total loss 1.14735258
Trained batch 1020 batch loss 1.25693011 epoch total loss 1.14746
Trained batch 1021 batch loss 0.845371723 epoch total loss 1.14716411
Trained batch 1022 batch loss 0.760676622 epoch total loss 1.14678586
Trained batch 1023 batch loss 1.11717534 epoch total loss 1.14675689
Trained batch 1024 batch loss 0.990651429 epoch total loss 1.14660442
Trained batch 1025 batch loss 0.953406572 epoch total loss 1.14641595
Trained batch 1026 batch loss 0.904441655 epoch total loss 1.14618
Trained batch 1027 batch loss 0.965811133 epoch total loss 1.14600444
Trained batch 1028 batch loss 1.35990942 epoch total loss 1.14621246
Trained batch 1029 batch loss 1.07953382 epoch total loss 1.14614773
Trained batch 1030 batch loss 1.41984797 epoch total loss 1.14641333
Trained batch 1031 batch loss 1.33584964 epoch total loss 1.14659715
Trained batch 1032 batch loss 1.36602259 epoch total loss 1.1468097
Trained batch 1033 batch loss 1.29577231 epoch total loss 1.14695382
Trained batch 1034 batch loss 1.4783299 epoch total loss 1.14727426
Trained batch 1035 batch loss 1.23595154 epoch total loss 1.14736
Trained batch 1036 batch loss 1.27417612 epoch total loss 1.1474824
Trained batch 1037 batch loss 1.30063367 epoch total loss 1.1476301
Trained batch 1038 batch loss 1.31687176 epoch total loss 1.14779317
Trained batch 1039 batch loss 1.13625789 epoch total loss 1.14778209
Trained batch 1040 batch loss 1.13951409 epoch total loss 1.1477741
Trained batch 1041 batch loss 1.20982575 epoch total loss 1.1478337
Trained batch 1042 batch loss 1.47529411 epoch total loss 1.14814806
Trained batch 1043 batch loss 1.2042 epoch total loss 1.14820182
Trained batch 1044 batch loss 1.20354629 epoch total loss 1.14825475
Trained batch 1045 batch loss 1.25750279 epoch total loss 1.14835918
Trained batch 1046 batch loss 1.26180029 epoch total loss 1.14846778
Trained batch 1047 batch loss 1.33632839 epoch total loss 1.14864719
Trained batch 1048 batch loss 1.33296621 epoch total loss 1.14882302
Trained batch 1049 batch loss 1.26820934 epoch total loss 1.14893687
Trained batch 1050 batch loss 1.2202518 epoch total loss 1.1490047
Trained batch 1051 batch loss 1.27036846 epoch total loss 1.14912021
Trained batch 1052 batch loss 1.07195771 epoch total loss 1.14904678
Trained batch 1053 batch loss 1.2363162 epoch total loss 1.14912975
Trained batch 1054 batch loss 1.20023847 epoch total loss 1.14917815
Trained batch 1055 batch loss 1.31281805 epoch total loss 1.14933336
Trained batch 1056 batch loss 1.09932661 epoch total loss 1.14928603
Trained batch 1057 batch loss 1.07452738 epoch total loss 1.14921534
Trained batch 1058 batch loss 1.10178292 epoch total loss 1.14917052
Trained batch 1059 batch loss 0.93055 epoch total loss 1.14896405
Trained batch 1060 batch loss 1.21037853 epoch total loss 1.14902198
Trained batch 1061 batch loss 1.17877686 epoch total loss 1.14905
Trained batch 1062 batch loss 1.15012717 epoch total loss 1.14905107
Trained batch 1063 batch loss 1.16395032 epoch total loss 1.14906502
Trained batch 1064 batch loss 1.20982087 epoch total loss 1.14912224
Trained batch 1065 batch loss 1.21397591 epoch total loss 1.14918315
Trained batch 1066 batch loss 1.19934428 epoch total loss 1.14923012
Trained batch 1067 batch loss 1.19148779 epoch total loss 1.14926982
Trained batch 1068 batch loss 1.14135873 epoch total loss 1.14926243
Trained batch 1069 batch loss 1.1957165 epoch total loss 1.14930582
Trained batch 1070 batch loss 0.955786586 epoch total loss 1.14912498
Trained batch 1071 batch loss 1.23542321 epoch total loss 1.14920557
Trained batch 1072 batch loss 1.2145772 epoch total loss 1.1492666
Trained batch 1073 batch loss 1.08082318 epoch total loss 1.14920282
Trained batch 1074 batch loss 1.07153177 epoch total loss 1.14913046
Trained batch 1075 batch loss 1.20221567 epoch total loss 1.14917994
Trained batch 1076 batch loss 0.917898536 epoch total loss 1.14896488
Trained batch 1077 batch loss 1.18438053 epoch total loss 1.14899778
Trained batch 1078 batch loss 1.31670284 epoch total loss 1.14915323
Trained batch 1079 batch loss 1.42906058 epoch total loss 1.14941275
Trained batch 1080 batch loss 1.18322277 epoch total loss 1.14944398
Trained batch 1081 batch loss 1.45454574 epoch total loss 1.14972627
Trained batch 1082 batch loss 1.30076575 epoch total loss 1.14986587
Trained batch 1083 batch loss 0.997961581 epoch total loss 1.14972556
Trained batch 1084 batch loss 1.12137544 epoch total loss 1.14969945
Trained batch 1085 batch loss 1.17854476 epoch total loss 1.14972603
Trained batch 1086 batch loss 1.14731634 epoch total loss 1.14972389
Trained batch 1087 batch loss 1.02953672 epoch total loss 1.14961326
Trained batch 1088 batch loss 1.0568943 epoch total loss 1.14952803
Trained batch 1089 batch loss 1.28038335 epoch total loss 1.14964819
Trained batch 1090 batch loss 1.29269385 epoch total loss 1.14977944
Trained batch 1091 batch loss 0.952967048 epoch total loss 1.14959908
Trained batch 1092 batch loss 1.30171931 epoch total loss 1.14973843
Trained batch 1093 batch loss 1.22759604 epoch total loss 1.1498096
Trained batch 1094 batch loss 1.13591182 epoch total loss 1.14979684
Trained batch 1095 batch loss 1.08111429 epoch total loss 1.14973414
Trained batch 1096 batch loss 1.19396889 epoch total loss 1.14977443
Trained batch 1097 batch loss 1.24343121 epoch total loss 1.14985979
Trained batch 1098 batch loss 0.777167439 epoch total loss 1.14952052
Trained batch 1099 batch loss 0.933132589 epoch total loss 1.14932358
Trained batch 1100 batch loss 0.959507704 epoch total loss 1.14915097
Trained batch 1101 batch loss 1.01628828 epoch total loss 1.14903021
Trained batch 1102 batch loss 0.978648067 epoch total loss 1.14887559
Trained batch 1103 batch loss 1.19903862 epoch total loss 1.14892113
Trained batch 1104 batch loss 1.08749187 epoch total loss 1.14886546
Trained batch 1105 batch loss 1.09217656 epoch total loss 1.1488142
Trained batch 1106 batch loss 1.26944566 epoch total loss 1.14892328
Trained batch 1107 batch loss 1.09676874 epoch total loss 1.14887619
Trained batch 1108 batch loss 1.20594168 epoch total loss 1.14892769
Trained batch 1109 batch loss 0.964839697 epoch total loss 1.14876163
Trained batch 1110 batch loss 1.08950901 epoch total loss 1.14870822
Trained batch 1111 batch loss 1.00743198 epoch total loss 1.14858115
Trained batch 1112 batch loss 0.930863202 epoch total loss 1.14838541
Trained batch 1113 batch loss 0.922221124 epoch total loss 1.14818215
Trained batch 1114 batch loss 1.01419795 epoch total loss 1.14806187
Trained batch 1115 batch loss 0.980013669 epoch total loss 1.14791107
Trained batch 1116 batch loss 1.13452744 epoch total loss 1.14789915
Trained batch 1117 batch loss 1.06813264 epoch total loss 1.14782774
Trained batch 1118 batch loss 1.00197649 epoch total loss 1.14769721
Trained batch 1119 batch loss 0.895641327 epoch total loss 1.1474719
Trained batch 1120 batch loss 1.01350093 epoch total loss 1.14735234
Trained batch 1121 batch loss 1.13778245 epoch total loss 1.14734387
Trained batch 1122 batch loss 1.0287863 epoch total loss 1.14723825
Trained batch 1123 batch loss 1.07926857 epoch total loss 1.1471777
Trained batch 1124 batch loss 1.15099514 epoch total loss 1.14718103
Trained batch 1125 batch loss 1.23225832 epoch total loss 1.14725673
Trained batch 1126 batch loss 1.29926133 epoch total loss 1.1473918
Trained batch 1127 batch loss 1.24118984 epoch total loss 1.147475
Trained batch 1128 batch loss 1.22080517 epoch total loss 1.14754009
Trained batch 1129 batch loss 1.37698412 epoch total loss 1.14774323
Trained batch 1130 batch loss 1.10857463 epoch total loss 1.14770854
Trained batch 1131 batch loss 1.32715797 epoch total loss 1.1478672
Trained batch 1132 batch loss 1.39167655 epoch total loss 1.14808261
Trained batch 1133 batch loss 1.55498338 epoch total loss 1.14844167
Trained batch 1134 batch loss 1.27750802 epoch total loss 1.14855552
Trained batch 1135 batch loss 1.13235831 epoch total loss 1.14854121
Trained batch 1136 batch loss 0.91148 epoch total loss 1.14833248
Trained batch 1137 batch loss 1.11440992 epoch total loss 1.14830267
Trained batch 1138 batch loss 1.31489682 epoch total loss 1.14844906
Trained batch 1139 batch loss 1.54828012 epoch total loss 1.14880013
Trained batch 1140 batch loss 1.31314993 epoch total loss 1.14894426
Trained batch 1141 batch loss 1.29598749 epoch total loss 1.14907324
Trained batch 1142 batch loss 0.936314881 epoch total loss 1.14888692
Trained batch 1143 batch loss 0.886396706 epoch total loss 1.1486572
Trained batch 1144 batch loss 1.15602076 epoch total loss 1.14866364
Trained batch 1145 batch loss 0.980193436 epoch total loss 1.14851654
Trained batch 1146 batch loss 0.997903943 epoch total loss 1.14838505
Trained batch 1147 batch loss 1.07897 epoch total loss 1.14832461
Trained batch 1148 batch loss 1.00196505 epoch total loss 1.14819705
Trained batch 1149 batch loss 1.24393749 epoch total loss 1.14828038
Trained batch 1150 batch loss 1.04422927 epoch total loss 1.1481899
Trained batch 1151 batch loss 1.06972647 epoch total loss 1.14812171
Trained batch 1152 batch loss 1.19328046 epoch total loss 1.14816082
Trained batch 1153 batch loss 1.01317108 epoch total loss 1.14804375
Trained batch 1154 batch loss 0.919740677 epoch total loss 1.14784598
Trained batch 1155 batch loss 1.13990521 epoch total loss 1.14783907
Trained batch 1156 batch loss 0.964303195 epoch total loss 1.1476804
Trained batch 1157 batch loss 1.25160885 epoch total loss 1.14777017
Trained batch 1158 batch loss 1.0054065 epoch total loss 1.14764726
Trained batch 1159 batch loss 1.21901965 epoch total loss 1.14770877
Trained batch 1160 batch loss 1.31974745 epoch total loss 1.14785707
Trained batch 1161 batch loss 1.38587856 epoch total loss 1.14806199
Trained batch 1162 batch loss 1.24302888 epoch total loss 1.14814377
Trained batch 1163 batch loss 1.14609921 epoch total loss 1.14814198
Trained batch 1164 batch loss 1.00819123 epoch total loss 1.14802182
Trained batch 1165 batch loss 1.07612038 epoch total loss 1.14796007
Trained batch 1166 batch loss 1.19837 epoch total loss 1.14800334
Trained batch 1167 batch loss 1.12739611 epoch total loss 1.1479857
Trained batch 1168 batch loss 1.22701502 epoch total loss 1.14805341
Trained batch 1169 batch loss 1.00994444 epoch total loss 1.14793527
Trained batch 1170 batch loss 1.28943932 epoch total loss 1.14805615
Trained batch 1171 batch loss 1.06826282 epoch total loss 1.14798796
Trained batch 1172 batch loss 1.34578204 epoch total loss 1.14815676
Trained batch 1173 batch loss 1.04949391 epoch total loss 1.1480726
Trained batch 1174 batch loss 1.17299044 epoch total loss 1.14809382
Trained batch 1175 batch loss 0.999300182 epoch total loss 1.14796722
Trained batch 1176 batch loss 1.065099 epoch total loss 1.14789665
Trained batch 1177 batch loss 1.10781622 epoch total loss 1.14786267
Trained batch 1178 batch loss 0.990436077 epoch total loss 1.14772904
Trained batch 1179 batch loss 1.16949773 epoch total loss 1.14774752
Trained batch 1180 batch loss 1.17113328 epoch total loss 1.14776731
Trained batch 1181 batch loss 1.10489285 epoch total loss 1.14773107
Trained batch 1182 batch loss 1.08516014 epoch total loss 1.14767814
Trained batch 1183 batch loss 1.18326139 epoch total loss 1.14770818
Trained batch 1184 batch loss 1.15904784 epoch total loss 1.14771771
Trained batch 1185 batch loss 1.13452089 epoch total loss 1.14770663
Trained batch 1186 batch loss 1.25902629 epoch total loss 1.14780045
Trained batch 1187 batch loss 1.05432153 epoch total loss 1.14772177
Trained batch 1188 batch loss 0.931644082 epoch total loss 1.14753985
Trained batch 1189 batch loss 0.872953057 epoch total loss 1.14730895
Trained batch 1190 batch loss 0.878623486 epoch total loss 1.14708316
Trained batch 1191 batch loss 0.990422 epoch total loss 1.14695168
Trained batch 1192 batch loss 1.12212288 epoch total loss 1.14693081
Trained batch 1193 batch loss 1.44340706 epoch total loss 1.14717925
Trained batch 1194 batch loss 1.43650889 epoch total loss 1.1474216
Trained batch 1195 batch loss 1.13171411 epoch total loss 1.14740849
Trained batch 1196 batch loss 1.08572447 epoch total loss 1.14735687
Trained batch 1197 batch loss 0.984701514 epoch total loss 1.14722097
Trained batch 1198 batch loss 1.19254577 epoch total loss 1.14725876
Trained batch 1199 batch loss 0.983700275 epoch total loss 1.14712226
Trained batch 1200 batch loss 1.17054343 epoch total loss 1.14714181
Trained batch 1201 batch loss 1.33325553 epoch total loss 1.14729679
Trained batch 1202 batch loss 1.1494174 epoch total loss 1.14729857
Trained batch 1203 batch loss 0.938309908 epoch total loss 1.14712489
Trained batch 1204 batch loss 1.06243145 epoch total loss 1.14705443
Trained batch 1205 batch loss 1.12888098 epoch total loss 1.14703941
Trained batch 1206 batch loss 1.1360575 epoch total loss 1.14703035
Trained batch 1207 batch loss 1.05849814 epoch total loss 1.14695704
Trained batch 1208 batch loss 1.00939929 epoch total loss 1.14684308
Trained batch 1209 batch loss 0.941680372 epoch total loss 1.14667344
Trained batch 1210 batch loss 1.12054884 epoch total loss 1.14665186
Trained batch 1211 batch loss 1.03717613 epoch total loss 1.1465615
Trained batch 1212 batch loss 1.03565872 epoch total loss 1.14647
Trained batch 1213 batch loss 0.963510275 epoch total loss 1.14631915
Trained batch 1214 batch loss 0.893693924 epoch total loss 1.14611101
Trained batch 1215 batch loss 0.960154116 epoch total loss 1.14595807
Trained batch 1216 batch loss 0.861362338 epoch total loss 1.14572394
Trained batch 1217 batch loss 0.90731883 epoch total loss 1.14552808
Trained batch 1218 batch loss 0.899950862 epoch total loss 1.14532638
Trained batch 1219 batch loss 0.880637 epoch total loss 1.1451093
Trained batch 1220 batch loss 0.856318235 epoch total loss 1.14487255
Trained batch 1221 batch loss 0.857798338 epoch total loss 1.14463747
Trained batch 1222 batch loss 0.916127384 epoch total loss 1.14445043
Trained batch 1223 batch loss 1.13859057 epoch total loss 1.14444566
Trained batch 1224 batch loss 1.25162625 epoch total loss 1.14453316
Trained batch 1225 batch loss 1.10103345 epoch total loss 1.14449763
Trained batch 1226 batch loss 1.35860407 epoch total loss 1.14467239
Trained batch 1227 batch loss 1.31706762 epoch total loss 1.14481282
Trained batch 1228 batch loss 1.30733526 epoch total loss 1.14494514
Trained batch 1229 batch loss 1.40374136 epoch total loss 1.14515567
Trained batch 1230 batch loss 1.23781431 epoch total loss 1.14523101
Trained batch 1231 batch loss 1.0828439 epoch total loss 1.14518034
Trained batch 1232 batch loss 1.12246954 epoch total loss 1.14516187
Trained batch 1233 batch loss 1.14701962 epoch total loss 1.14516342
Trained batch 1234 batch loss 1.23304629 epoch total loss 1.14523458
Trained batch 1235 batch loss 1.42111647 epoch total loss 1.14545798
Trained batch 1236 batch loss 1.10544634 epoch total loss 1.14542568
Trained batch 1237 batch loss 1.10994244 epoch total loss 1.14539695
Trained batch 1238 batch loss 1.18907619 epoch total loss 1.14543223
Trained batch 1239 batch loss 1.12621188 epoch total loss 1.14541674
Trained batch 1240 batch loss 1.17756677 epoch total loss 1.14544272
Trained batch 1241 batch loss 1.27535868 epoch total loss 1.14554751
Trained batch 1242 batch loss 1.27236295 epoch total loss 1.14564955
Trained batch 1243 batch loss 1.47216773 epoch total loss 1.14591217
Trained batch 1244 batch loss 1.37867224 epoch total loss 1.14609933
Trained batch 1245 batch loss 1.36175418 epoch total loss 1.14627254
Trained batch 1246 batch loss 1.15357804 epoch total loss 1.14627838
Trained batch 1247 batch loss 1.09156251 epoch total loss 1.14623451
Trained batch 1248 batch loss 1.11530674 epoch total loss 1.14620972
Trained batch 1249 batch loss 1.0526154 epoch total loss 1.14613473
Trained batch 1250 batch loss 1.11251283 epoch total loss 1.14610791
Trained batch 1251 batch loss 1.23013842 epoch total loss 1.14617503
Trained batch 1252 batch loss 1.08279657 epoch total loss 1.14612436
Trained batch 1253 batch loss 1.27139306 epoch total loss 1.14622438
Trained batch 1254 batch loss 1.46589613 epoch total loss 1.14647937
Trained batch 1255 batch loss 1.10851598 epoch total loss 1.14644909
Trained batch 1256 batch loss 1.17854667 epoch total loss 1.1464746
Trained batch 1257 batch loss 1.25150299 epoch total loss 1.14655817
Trained batch 1258 batch loss 1.40195358 epoch total loss 1.14676118
Trained batch 1259 batch loss 1.27804947 epoch total loss 1.14686549
Trained batch 1260 batch loss 1.12124968 epoch total loss 1.1468451
Trained batch 1261 batch loss 0.951711416 epoch total loss 1.14669037
Trained batch 1262 batch loss 1.08727741 epoch total loss 1.14664328
Trained batch 1263 batch loss 1.31880784 epoch total loss 1.14677966
Trained batch 1264 batch loss 1.1122669 epoch total loss 1.14675236
Trained batch 1265 batch loss 1.11395144 epoch total loss 1.14672637
Trained batch 1266 batch loss 0.868759036 epoch total loss 1.14650679
Trained batch 1267 batch loss 0.911641479 epoch total loss 1.14632142
Trained batch 1268 batch loss 0.978061199 epoch total loss 1.14618874
Trained batch 1269 batch loss 1.02148533 epoch total loss 1.14609051
Trained batch 1270 batch loss 1.03155208 epoch total loss 1.14600027
Trained batch 1271 batch loss 1.03865576 epoch total loss 1.14591575
Trained batch 1272 batch loss 0.950891 epoch total loss 1.14576256
Trained batch 1273 batch loss 0.794083476 epoch total loss 1.14548624
Trained batch 1274 batch loss 0.805228114 epoch total loss 1.14521909
Trained batch 1275 batch loss 0.729202747 epoch total loss 1.14489281
Trained batch 1276 batch loss 0.790566325 epoch total loss 1.14461517
Trained batch 1277 batch loss 1.04742 epoch total loss 1.144539
Trained batch 1278 batch loss 1.029181 epoch total loss 1.14444876
Trained batch 1279 batch loss 0.937400341 epoch total loss 1.14428687
Trained batch 1280 batch loss 1.18908155 epoch total loss 1.1443218
Trained batch 1281 batch loss 1.18427849 epoch total loss 1.14435303
Trained batch 1282 batch loss 1.20454693 epoch total loss 1.1444
Trained batch 1283 batch loss 1.27955091 epoch total loss 1.14450538
Trained batch 1284 batch loss 1.21490467 epoch total loss 1.1445601
Trained batch 1285 batch loss 0.993968427 epoch total loss 1.14444304
Trained batch 1286 batch loss 1.36618662 epoch total loss 1.14461541
Trained batch 1287 batch loss 1.12432313 epoch total loss 1.14459968
Trained batch 1288 batch loss 1.22141242 epoch total loss 1.14465928
Trained batch 1289 batch loss 1.08595943 epoch total loss 1.14461374
Trained batch 1290 batch loss 1.21180189 epoch total loss 1.14466584
Trained batch 1291 batch loss 1.38401067 epoch total loss 1.14485121
Trained batch 1292 batch loss 0.926999032 epoch total loss 1.14468265
Trained batch 1293 batch loss 1.28561091 epoch total loss 1.1447916
Trained batch 1294 batch loss 1.20845222 epoch total loss 1.14484084
Trained batch 1295 batch loss 1.20391953 epoch total loss 1.14488649
Trained batch 1296 batch loss 1.23536658 epoch total loss 1.14495635
Trained batch 1297 batch loss 1.24679291 epoch total loss 1.14503491
Trained batch 1298 batch loss 1.12114012 epoch total loss 1.14501643
Trained batch 1299 batch loss 1.21284866 epoch total loss 1.14506865
Trained batch 1300 batch loss 0.950074136 epoch total loss 1.14491868
Trained batch 1301 batch loss 1.07981086 epoch total loss 1.14486861
Trained batch 1302 batch loss 1.13223815 epoch total loss 1.14485896
Trained batch 1303 batch loss 1.26073062 epoch total loss 1.14494789
Trained batch 1304 batch loss 1.23867583 epoch total loss 1.14501977
Trained batch 1305 batch loss 1.22706175 epoch total loss 1.14508259
Trained batch 1306 batch loss 1.22042727 epoch total loss 1.14514029
Trained batch 1307 batch loss 1.06151438 epoch total loss 1.14507627
Trained batch 1308 batch loss 1.09305668 epoch total loss 1.14503646
Trained batch 1309 batch loss 0.884878933 epoch total loss 1.14483774
Trained batch 1310 batch loss 1.09494472 epoch total loss 1.14479971
Trained batch 1311 batch loss 1.06405449 epoch total loss 1.1447382
Trained batch 1312 batch loss 1.32254446 epoch total loss 1.14487362
Trained batch 1313 batch loss 1.1343869 epoch total loss 1.14486563
Trained batch 1314 batch loss 0.979228497 epoch total loss 1.14473963
Trained batch 1315 batch loss 1.21316457 epoch total loss 1.1447916
Trained batch 1316 batch loss 1.16085315 epoch total loss 1.14480388
Trained batch 1317 batch loss 1.06540012 epoch total loss 1.14474356
Trained batch 1318 batch loss 1.16391158 epoch total loss 1.14475811
Trained batch 1319 batch loss 1.2937839 epoch total loss 1.14487123
Trained batch 1320 batch loss 1.12392187 epoch total loss 1.14485526
Trained batch 1321 batch loss 1.08358467 epoch total loss 1.14480889
Trained batch 1322 batch loss 1.10903549 epoch total loss 1.14478183
Trained batch 1323 batch loss 1.14984727 epoch total loss 1.14478576
Trained batch 1324 batch loss 1.03349149 epoch total loss 1.1447016
Trained batch 1325 batch loss 1.07956886 epoch total loss 1.14465249
Trained batch 1326 batch loss 1.20675373 epoch total loss 1.14469934
Trained batch 1327 batch loss 1.03926969 epoch total loss 1.14462
Trained batch 1328 batch loss 1.04608428 epoch total loss 1.14454579
Trained batch 1329 batch loss 0.851148188 epoch total loss 1.14432502
Trained batch 1330 batch loss 1.01544666 epoch total loss 1.14422822
Trained batch 1331 batch loss 1.32128227 epoch total loss 1.14436126
Trained batch 1332 batch loss 1.17442143 epoch total loss 1.14438379
Trained batch 1333 batch loss 1.11461782 epoch total loss 1.1443615
Trained batch 1334 batch loss 0.952210724 epoch total loss 1.14421749
Trained batch 1335 batch loss 1.03942454 epoch total loss 1.14413893
Trained batch 1336 batch loss 0.999299288 epoch total loss 1.14403057
Trained batch 1337 batch loss 1.02554345 epoch total loss 1.14394188
Trained batch 1338 batch loss 1.0841732 epoch total loss 1.14389729
Trained batch 1339 batch loss 1.12353802 epoch total loss 1.14388204
Trained batch 1340 batch loss 1.01159 epoch total loss 1.14378333
Trained batch 1341 batch loss 0.934473634 epoch total loss 1.14362729
Trained batch 1342 batch loss 1.08789909 epoch total loss 1.14358568
Trained batch 1343 batch loss 1.18735147 epoch total loss 1.14361835
Trained batch 1344 batch loss 1.03936231 epoch total loss 1.14354074
Trained batch 1345 batch loss 1.14416718 epoch total loss 1.14354122
Trained batch 1346 batch loss 1.44546151 epoch total loss 1.14376545
Trained batch 1347 batch loss 1.23835707 epoch total loss 1.14383566
Trained batch 1348 batch loss 1.16184223 epoch total loss 1.14384913
Trained batch 1349 batch loss 1.08693731 epoch total loss 1.14380693
Trained batch 1350 batch loss 1.30058432 epoch total loss 1.14392292
Trained batch 1351 batch loss 1.29724276 epoch total loss 1.14403641
Trained batch 1352 batch loss 1.26986456 epoch total loss 1.14412951
Trained batch 1353 batch loss 1.02515185 epoch total loss 1.14404166
Trained batch 1354 batch loss 1.19305658 epoch total loss 1.1440779
Trained batch 1355 batch loss 1.14842916 epoch total loss 1.14408112
Trained batch 1356 batch loss 1.19447517 epoch total loss 1.14411819
Trained batch 1357 batch loss 0.98529768 epoch total loss 1.14400125
Trained batch 1358 batch loss 1.15768814 epoch total loss 1.14401138
Trained batch 1359 batch loss 1.26888633 epoch total loss 1.14410329
Trained batch 1360 batch loss 1.13179135 epoch total loss 1.14409423
Trained batch 1361 batch loss 1.22131205 epoch total loss 1.14415097
Trained batch 1362 batch loss 1.29046178 epoch total loss 1.14425838
Trained batch 1363 batch loss 1.09037375 epoch total loss 1.1442188
Trained batch 1364 batch loss 1.17334712 epoch total loss 1.14424014
Trained batch 1365 batch loss 1.30735207 epoch total loss 1.14435959
Trained batch 1366 batch loss 1.19954 epoch total loss 1.14440012
Trained batch 1367 batch loss 1.0204196 epoch total loss 1.1443094
Trained batch 1368 batch loss 1.13069415 epoch total loss 1.14429939
Trained batch 1369 batch loss 1.19183016 epoch total loss 1.14433408
Trained batch 1370 batch loss 0.995096862 epoch total loss 1.14422524
Trained batch 1371 batch loss 0.977828562 epoch total loss 1.14410377
Trained batch 1372 batch loss 1.03950703 epoch total loss 1.14402759
Trained batch 1373 batch loss 1.16612709 epoch total loss 1.14404368
Trained batch 1374 batch loss 1.35813689 epoch total loss 1.14419949
Trained batch 1375 batch loss 0.808196187 epoch total loss 1.14395511
Trained batch 1376 batch loss 0.942727685 epoch total loss 1.14380896
Trained batch 1377 batch loss 1.24299145 epoch total loss 1.14388096
Trained batch 1378 batch loss 1.11055446 epoch total loss 1.14385688
Trained batch 1379 batch loss 1.01955748 epoch total loss 1.14376664
Trained batch 1380 batch loss 1.22577989 epoch total loss 1.14382613
Trained batch 1381 batch loss 1.20476437 epoch total loss 1.14387023
Trained batch 1382 batch loss 0.831190467 epoch total loss 1.14364398
Trained batch 1383 batch loss 0.822315872 epoch total loss 1.14341164
Trained batch 1384 batch loss 0.881094337 epoch total loss 1.14322209
Trained batch 1385 batch loss 0.957687259 epoch total loss 1.1430881
Trained batch 1386 batch loss 1.04951096 epoch total loss 1.14302063
Trained batch 1387 batch loss 1.17047477 epoch total loss 1.14304042
Trained batch 1388 batch loss 1.33042467 epoch total loss 1.14317548
Trained batch 1389 batch loss 1.19306397 epoch total loss 1.14321136
Trained batch 1390 batch loss 1.04456115 epoch total loss 1.14314044
Trained batch 1391 batch loss 1.13859856 epoch total loss 1.1431371
Trained batch 1392 batch loss 1.11968887 epoch total loss 1.14312029
Trained batch 1393 batch loss 1.06560016 epoch total loss 1.14306462
Trained batch 1394 batch loss 1.24576116 epoch total loss 1.14313817
Trained batch 1395 batch loss 1.27399325 epoch total loss 1.14323211
Trained batch 1396 batch loss 0.945643604 epoch total loss 1.14309049
Trained batch 1397 batch loss 1.18520355 epoch total loss 1.14312065
Trained batch 1398 batch loss 0.967912436 epoch total loss 1.14299536
Trained batch 1399 batch loss 1.20736074 epoch total loss 1.14304137
Trained batch 1400 batch loss 1.18114591 epoch total loss 1.14306855
Trained batch 1401 batch loss 0.806513786 epoch total loss 1.14282835
Trained batch 1402 batch loss 0.829704285 epoch total loss 1.14260507
Trained batch 1403 batch loss 0.957899213 epoch total loss 1.14247334
Trained batch 1404 batch loss 1.01514459 epoch total loss 1.14238262
Trained batch 1405 batch loss 1.0395453 epoch total loss 1.14230943
Trained batch 1406 batch loss 0.971901059 epoch total loss 1.14218831
Trained batch 1407 batch loss 0.942372322 epoch total loss 1.14204633
Trained batch 1408 batch loss 0.980494261 epoch total loss 1.14193153
Trained batch 1409 batch loss 0.892072201 epoch total loss 1.14175427
Trained batch 1410 batch loss 0.882909715 epoch total loss 1.14157069
Trained batch 1411 batch loss 0.901124954 epoch total loss 1.14140022
Trained batch 1412 batch loss 0.702948 epoch total loss 1.1410898
Trained batch 1413 batch loss 1.08630657 epoch total loss 1.14105093
Trained batch 1414 batch loss 1.31262445 epoch total loss 1.14117229
Trained batch 1415 batch loss 1.41009307 epoch total loss 1.14136231
Trained batch 1416 batch loss 1.34369791 epoch total loss 1.14150524
Trained batch 1417 batch loss 1.16299748 epoch total loss 1.14152038
Trained batch 1418 batch loss 1.24543643 epoch total loss 1.14159369
Trained batch 1419 batch loss 1.31270766 epoch total loss 1.14171433
Trained batch 1420 batch loss 1.14145398 epoch total loss 1.14171422
Trained batch 1421 batch loss 1.10420322 epoch total loss 1.14168787
Trained batch 1422 batch loss 1.26844573 epoch total loss 1.14177692
Trained batch 1423 batch loss 1.2820189 epoch total loss 1.14187551
Trained batch 1424 batch loss 1.38284492 epoch total loss 1.14204466
Trained batch 1425 batch loss 1.34931028 epoch total loss 1.1421901
Trained batch 1426 batch loss 1.39045429 epoch total loss 1.14236426
Trained batch 1427 batch loss 1.42123711 epoch total loss 1.14255977
Trained batch 1428 batch loss 1.18113315 epoch total loss 1.14258671
Trained batch 1429 batch loss 1.39150035 epoch total loss 1.14276087
Trained batch 1430 batch loss 1.24864757 epoch total loss 1.14283502
Trained batch 1431 batch loss 1.14081979 epoch total loss 1.14283359
Trained batch 1432 batch loss 1.19391394 epoch total loss 1.14286935
Trained batch 1433 batch loss 1.33119535 epoch total loss 1.14300072
Trained batch 1434 batch loss 1.28177094 epoch total loss 1.14309752
Trained batch 1435 batch loss 1.18763399 epoch total loss 1.14312851
Trained batch 1436 batch loss 1.24000597 epoch total loss 1.14319599
Trained batch 1437 batch loss 1.12169278 epoch total loss 1.14318097
Trained batch 1438 batch loss 1.20899463 epoch total loss 1.14322674
Trained batch 1439 batch loss 1.35303903 epoch total loss 1.14337254
Trained batch 1440 batch loss 1.12785029 epoch total loss 1.14336181
Trained batch 1441 batch loss 1.02418518 epoch total loss 1.14327908
Trained batch 1442 batch loss 0.954933643 epoch total loss 1.14314842
Trained batch 1443 batch loss 1.00179052 epoch total loss 1.14305055
Trained batch 1444 batch loss 0.950330257 epoch total loss 1.14291704
Trained batch 1445 batch loss 1.03660786 epoch total loss 1.14284348
Trained batch 1446 batch loss 1.03164196 epoch total loss 1.14276659
Trained batch 1447 batch loss 0.845549881 epoch total loss 1.1425612
Trained batch 1448 batch loss 1.50329351 epoch total loss 1.14281034
Trained batch 1449 batch loss 1.0394423 epoch total loss 1.14273894
Trained batch 1450 batch loss 1.06837654 epoch total loss 1.14268768
Trained batch 1451 batch loss 0.948280394 epoch total loss 1.14255369
Trained batch 1452 batch loss 1.28815961 epoch total loss 1.14265394
Trained batch 1453 batch loss 1.18455112 epoch total loss 1.14268279
Trained batch 1454 batch loss 1.33726609 epoch total loss 1.14281666
Trained batch 1455 batch loss 1.29333353 epoch total loss 1.14292014
Trained batch 1456 batch loss 1.00124061 epoch total loss 1.14282274
Trained batch 1457 batch loss 1.1188767 epoch total loss 1.14280629
Trained batch 1458 batch loss 1.17293489 epoch total loss 1.14282703
Trained batch 1459 batch loss 1.0525403 epoch total loss 1.14276516
Trained batch 1460 batch loss 1.1040554 epoch total loss 1.14273858
Trained batch 1461 batch loss 1.27082801 epoch total loss 1.14282632
Trained batch 1462 batch loss 1.07603621 epoch total loss 1.14278054
Trained batch 1463 batch loss 1.26750875 epoch total loss 1.14286578
Trained batch 1464 batch loss 1.29161358 epoch total loss 1.14296746
Trained batch 1465 batch loss 1.19064629 epoch total loss 1.143
Trained batch 1466 batch loss 1.04669619 epoch total loss 1.14293432
Trained batch 1467 batch loss 1.1462239 epoch total loss 1.14293659
Trained batch 1468 batch loss 1.17509449 epoch total loss 1.14295852
Trained batch 1469 batch loss 1.15887475 epoch total loss 1.14296937
Trained batch 1470 batch loss 1.2139107 epoch total loss 1.14301753
Trained batch 1471 batch loss 1.20414186 epoch total loss 1.14305913
Trained batch 1472 batch loss 1.12188411 epoch total loss 1.14304471
Trained batch 1473 batch loss 0.946361065 epoch total loss 1.1429112
Trained batch 1474 batch loss 1.12869322 epoch total loss 1.14290154
Trained batch 1475 batch loss 1.42887199 epoch total loss 1.14309537
Trained batch 1476 batch loss 1.40619266 epoch total loss 1.14327371
Trained batch 1477 batch loss 1.46228 epoch total loss 1.1434896
Trained batch 1478 batch loss 1.28741217 epoch total loss 1.14358699
Trained batch 1479 batch loss 1.19760394 epoch total loss 1.14362347
Trained batch 1480 batch loss 1.32865548 epoch total loss 1.14374852
Trained batch 1481 batch loss 1.24886918 epoch total loss 1.14381957
Trained batch 1482 batch loss 1.29756212 epoch total loss 1.14392328
Trained batch 1483 batch loss 0.968810439 epoch total loss 1.14380515
Trained batch 1484 batch loss 1.06314671 epoch total loss 1.14375079
Trained batch 1485 batch loss 1.05744886 epoch total loss 1.14369273
Trained batch 1486 batch loss 1.09691405 epoch total loss 1.14366126
Trained batch 1487 batch loss 0.937100887 epoch total loss 1.14352238
Trained batch 1488 batch loss 0.956653595 epoch total loss 1.14339674
Trained batch 1489 batch loss 0.992538452 epoch total loss 1.14329541
Trained batch 1490 batch loss 0.909620523 epoch total loss 1.14313865
Trained batch 1491 batch loss 0.709937215 epoch total loss 1.14284813
Trained batch 1492 batch loss 1.17342401 epoch total loss 1.14286864
Trained batch 1493 batch loss 1.20251727 epoch total loss 1.14290857
Trained batch 1494 batch loss 1.24986315 epoch total loss 1.14298022
Trained batch 1495 batch loss 1.3965416 epoch total loss 1.14314973
Trained batch 1496 batch loss 1.25521398 epoch total loss 1.14322472
Trained batch 1497 batch loss 1.33376288 epoch total loss 1.14335191
Trained batch 1498 batch loss 1.16847324 epoch total loss 1.14336872
Trained batch 1499 batch loss 1.27065933 epoch total loss 1.1434536
Trained batch 1500 batch loss 1.37634659 epoch total loss 1.14360893
Trained batch 1501 batch loss 1.22909892 epoch total loss 1.14366591
Trained batch 1502 batch loss 1.3021791 epoch total loss 1.14377141
Trained batch 1503 batch loss 1.20532751 epoch total loss 1.1438123
Trained batch 1504 batch loss 1.24341106 epoch total loss 1.14387858
Trained batch 1505 batch loss 1.12800765 epoch total loss 1.14386797
Trained batch 1506 batch loss 1.22292614 epoch total loss 1.14392054
Trained batch 1507 batch loss 1.3101 epoch total loss 1.14403069
Trained batch 1508 batch loss 0.922833622 epoch total loss 1.14388406
Trained batch 1509 batch loss 1.16029263 epoch total loss 1.14389491
Trained batch 1510 batch loss 1.16029394 epoch total loss 1.14390576
Trained batch 1511 batch loss 1.29856849 epoch total loss 1.14400816
Trained batch 1512 batch loss 1.13082385 epoch total loss 1.14399946
Trained batch 1513 batch loss 1.17611086 epoch total loss 1.14402068
Trained batch 1514 batch loss 1.17912173 epoch total loss 1.1440438
Trained batch 1515 batch loss 1.32070851 epoch total loss 1.14416039
Trained batch 1516 batch loss 1.13336504 epoch total loss 1.14415336
Trained batch 1517 batch loss 1.16447008 epoch total loss 1.14416671
Trained batch 1518 batch loss 1.10311246 epoch total loss 1.14413977
Trained batch 1519 batch loss 1.01157045 epoch total loss 1.14405251
Trained batch 1520 batch loss 1.09139228 epoch total loss 1.14401782
Trained batch 1521 batch loss 1.16925025 epoch total loss 1.14403439
Trained batch 1522 batch loss 1.11123204 epoch total loss 1.14401281
Trained batch 1523 batch loss 1.25912118 epoch total loss 1.14408839
Trained batch 1524 batch loss 1.33788443 epoch total loss 1.14421558
Trained batch 1525 batch loss 0.961131215 epoch total loss 1.14409554
Trained batch 1526 batch loss 1.22546 epoch total loss 1.14414883
Trained batch 1527 batch loss 1.08723319 epoch total loss 1.14411163
Trained batch 1528 batch loss 0.914450169 epoch total loss 1.14396131
Trained batch 1529 batch loss 1.16325092 epoch total loss 1.14397395
Trained batch 1530 batch loss 1.24562573 epoch total loss 1.14404035
Trained batch 1531 batch loss 1.10372066 epoch total loss 1.144014
Trained batch 1532 batch loss 1.15393782 epoch total loss 1.14402056
Trained batch 1533 batch loss 1.09905338 epoch total loss 1.14399111
Trained batch 1534 batch loss 1.14859235 epoch total loss 1.14399409
Trained batch 1535 batch loss 1.2708838 epoch total loss 1.14407682
Trained batch 1536 batch loss 1.08729029 epoch total loss 1.14403975
Trained batch 1537 batch loss 1.1119113 epoch total loss 1.14401889
Trained batch 1538 batch loss 1.22755885 epoch total loss 1.14407325
Trained batch 1539 batch loss 1.07721257 epoch total loss 1.14402986
Trained batch 1540 batch loss 1.27351451 epoch total loss 1.1441139
Trained batch 1541 batch loss 1.21467686 epoch total loss 1.14415967
Trained batch 1542 batch loss 1.14799464 epoch total loss 1.14416218
Trained batch 1543 batch loss 1.15194297 epoch total loss 1.1441673
Trained batch 1544 batch loss 1.13854122 epoch total loss 1.14416361
Trained batch 1545 batch loss 1.16489792 epoch total loss 1.14417708
Trained batch 1546 batch loss 1.12742424 epoch total loss 1.14416623
Trained batch 1547 batch loss 1.17128158 epoch total loss 1.14418375
Trained batch 1548 batch loss 1.08273673 epoch total loss 1.14414406
Trained batch 1549 batch loss 1.19010079 epoch total loss 1.14417374
Trained batch 1550 batch loss 1.17986298 epoch total loss 1.14419675
Trained batch 1551 batch loss 1.18334925 epoch total loss 1.1442219
Trained batch 1552 batch loss 1.14640331 epoch total loss 1.14422333
Trained batch 1553 batch loss 1.2686975 epoch total loss 1.14430344
Trained batch 1554 batch loss 1.28068292 epoch total loss 1.14439118
Trained batch 1555 batch loss 1.30492902 epoch total loss 1.14449441
Trained batch 1556 batch loss 1.25665855 epoch total loss 1.14456654
Trained batch 1557 batch loss 1.12496412 epoch total loss 1.14455402
Trained batch 1558 batch loss 1.15311289 epoch total loss 1.1445595
Trained batch 1559 batch loss 1.24452364 epoch total loss 1.14462352
Trained batch 1560 batch loss 1.15733075 epoch total loss 1.14463174
Trained batch 1561 batch loss 1.18498731 epoch total loss 1.14465749
Trained batch 1562 batch loss 1.18579936 epoch total loss 1.14468384
Trained batch 1563 batch loss 1.05897975 epoch total loss 1.144629
Trained batch 1564 batch loss 1.00503349 epoch total loss 1.14453971
Trained batch 1565 batch loss 1.45759284 epoch total loss 1.14473987
Trained batch 1566 batch loss 1.27054548 epoch total loss 1.14482009
Trained batch 1567 batch loss 1.24777555 epoch total loss 1.1448859
Trained batch 1568 batch loss 1.33958673 epoch total loss 1.14501
Trained batch 1569 batch loss 1.17534661 epoch total loss 1.14502931
Trained batch 1570 batch loss 0.852816939 epoch total loss 1.14484322
Trained batch 1571 batch loss 0.956764042 epoch total loss 1.14472353
Trained batch 1572 batch loss 1.03102124 epoch total loss 1.14465117
Trained batch 1573 batch loss 1.14602244 epoch total loss 1.14465201
Trained batch 1574 batch loss 1.1724515 epoch total loss 1.14466965
Trained batch 1575 batch loss 1.14457953 epoch total loss 1.14466965
Trained batch 1576 batch loss 1.14769042 epoch total loss 1.14467156
Trained batch 1577 batch loss 1.33503592 epoch total loss 1.14479232
Trained batch 1578 batch loss 0.957177758 epoch total loss 1.14467335
Trained batch 1579 batch loss 1.46159673 epoch total loss 1.1448741
Trained batch 1580 batch loss 1.3526541 epoch total loss 1.14500558
Trained batch 1581 batch loss 1.11958623 epoch total loss 1.14498949
Trained batch 1582 batch loss 0.967261672 epoch total loss 1.1448772
Trained batch 1583 batch loss 0.73054111 epoch total loss 1.14461541
Trained batch 1584 batch loss 0.894422114 epoch total loss 1.14445746
Trained batch 1585 batch loss 0.96019268 epoch total loss 1.14434123
Trained batch 1586 batch loss 0.968707383 epoch total loss 1.14423048
Trained batch 1587 batch loss 1.0730381 epoch total loss 1.14418566
Trained batch 1588 batch loss 1.4865396 epoch total loss 1.14440131
Trained batch 1589 batch loss 1.28446293 epoch total loss 1.14448941
Trained batch 1590 batch loss 1.39596033 epoch total loss 1.1446476
Trained batch 1591 batch loss 1.21620297 epoch total loss 1.14469254
Trained batch 1592 batch loss 1.27951789 epoch total loss 1.14477718
Trained batch 1593 batch loss 1.36605048 epoch total loss 1.14491618
Trained batch 1594 batch loss 1.3468678 epoch total loss 1.1450429
Trained batch 1595 batch loss 1.22215605 epoch total loss 1.1450913
Trained batch 1596 batch loss 1.29089117 epoch total loss 1.14518261
Trained batch 1597 batch loss 1.21959949 epoch total loss 1.14522922
Trained batch 1598 batch loss 1.08734512 epoch total loss 1.14519298
Trained batch 1599 batch loss 1.00347745 epoch total loss 1.14510429
Trained batch 1600 batch loss 0.955833733 epoch total loss 1.14498603
Trained batch 1601 batch loss 0.942065239 epoch total loss 1.14485931
Trained batch 1602 batch loss 0.972977638 epoch total loss 1.14475203
Trained batch 1603 batch loss 0.958357036 epoch total loss 1.14463568
Trained batch 1604 batch loss 0.915536761 epoch total loss 1.14449286
Trained batch 1605 batch loss 0.823496759 epoch total loss 1.14429283
Trained batch 1606 batch loss 1.00391078 epoch total loss 1.14420545
Trained batch 1607 batch loss 0.834409952 epoch total loss 1.14401269
Trained batch 1608 batch loss 1.0149467 epoch total loss 1.14393234
Trained batch 1609 batch loss 0.941630602 epoch total loss 1.1438067
Trained batch 1610 batch loss 1.2203815 epoch total loss 1.14385414
Trained batch 1611 batch loss 1.12868655 epoch total loss 1.14384472
Trained batch 1612 batch loss 0.831373572 epoch total loss 1.14365089
Trained batch 1613 batch loss 0.955517054 epoch total loss 1.1435343
Trained batch 1614 batch loss 0.993926287 epoch total loss 1.14344156
Trained batch 1615 batch loss 0.94611907 epoch total loss 1.14331949
Trained batch 1616 batch loss 0.817629933 epoch total loss 1.1431179
Trained batch 1617 batch loss 1.0861038 epoch total loss 1.14308262
Trained batch 1618 batch loss 0.890270352 epoch total loss 1.14292634
Trained batch 1619 batch loss 1.22564924 epoch total loss 1.14297748
Trained batch 1620 batch loss 1.10826802 epoch total loss 1.14295614
Trained batch 1621 batch loss 0.870793462 epoch total loss 1.14278817
Trained batch 1622 batch loss 0.895978928 epoch total loss 1.14263606
Trained batch 1623 batch loss 1.09122467 epoch total loss 1.14260435
Trained batch 1624 batch loss 1.07221746 epoch total loss 1.14256108
Trained batch 1625 batch loss 0.931989431 epoch total loss 1.1424315
Trained batch 1626 batch loss 1.0665915 epoch total loss 1.14238489
Trained batch 1627 batch loss 1.09921026 epoch total loss 1.14235842
Trained batch 1628 batch loss 1.01218987 epoch total loss 1.14227843
Trained batch 1629 batch loss 1.25361252 epoch total loss 1.14234674
Trained batch 1630 batch loss 1.1628468 epoch total loss 1.14235938
Trained batch 1631 batch loss 0.995187521 epoch total loss 1.14226913
Trained batch 1632 batch loss 1.07259655 epoch total loss 1.14222646
Trained batch 1633 batch loss 1.05404162 epoch total loss 1.14217257
Trained batch 1634 batch loss 1.1373291 epoch total loss 1.14216959
Trained batch 1635 batch loss 1.20871472 epoch total loss 1.14221025
Trained batch 1636 batch loss 1.12298012 epoch total loss 1.14219844
Trained batch 1637 batch loss 1.19274449 epoch total loss 1.14222932
Trained batch 1638 batch loss 1.2558248 epoch total loss 1.1422987
Trained batch 1639 batch loss 1.07578897 epoch total loss 1.14225817
Trained batch 1640 batch loss 1.18468022 epoch total loss 1.14228404
Trained batch 1641 batch loss 1.1051352 epoch total loss 1.14226139
Trained batch 1642 batch loss 1.26380062 epoch total loss 1.14233541
Trained batch 1643 batch loss 1.00118661 epoch total loss 1.14224946
Trained batch 1644 batch loss 1.20235634 epoch total loss 1.14228606
Trained batch 1645 batch loss 1.22958851 epoch total loss 1.14233923
Trained batch 1646 batch loss 1.11677063 epoch total loss 1.14232373
Trained batch 1647 batch loss 1.06746864 epoch total loss 1.14227819
Trained batch 1648 batch loss 0.893938899 epoch total loss 1.14212751
Trained batch 1649 batch loss 1.07883525 epoch total loss 1.14208913
Trained batch 1650 batch loss 0.955590487 epoch total loss 1.14197612
Trained batch 1651 batch loss 1.24412537 epoch total loss 1.14203799
Trained batch 1652 batch loss 1.16003156 epoch total loss 1.14204895
Trained batch 1653 batch loss 0.94373107 epoch total loss 1.14192891
Trained batch 1654 batch loss 1.03879642 epoch total loss 1.14186656
Trained batch 1655 batch loss 1.35386324 epoch total loss 1.14199471
Trained batch 1656 batch loss 1.1307956 epoch total loss 1.14198792
Trained batch 1657 batch loss 1.4183991 epoch total loss 1.14215469
Trained batch 1658 batch loss 1.16212165 epoch total loss 1.14216673
Trained batch 1659 batch loss 1.5141418 epoch total loss 1.14239097
Trained batch 1660 batch loss 1.27108073 epoch total loss 1.14246857
Trained batch 1661 batch loss 1.49498367 epoch total loss 1.14268076
Trained batch 1662 batch loss 1.47459292 epoch total loss 1.14288056
Trained batch 1663 batch loss 1.00589514 epoch total loss 1.14279807
Trained batch 1664 batch loss 1.05075777 epoch total loss 1.14274287
Trained batch 1665 batch loss 1.14998364 epoch total loss 1.14274716
Trained batch 1666 batch loss 1.19282031 epoch total loss 1.14277732
Trained batch 1667 batch loss 1.27372098 epoch total loss 1.14285576
Trained batch 1668 batch loss 1.10663927 epoch total loss 1.14283407
Trained batch 1669 batch loss 1.02110767 epoch total loss 1.14276123
Trained batch 1670 batch loss 0.957616329 epoch total loss 1.14265037
Trained batch 1671 batch loss 1.30605519 epoch total loss 1.14274812
Trained batch 1672 batch loss 1.11583555 epoch total loss 1.14273202
Trained batch 1673 batch loss 1.12079787 epoch total loss 1.14271891
Trained batch 1674 batch loss 0.923947 epoch total loss 1.14258826
Trained batch 1675 batch loss 0.989062488 epoch total loss 1.14249659
Trained batch 1676 batch loss 1.00436115 epoch total loss 1.14241421
Trained batch 1677 batch loss 1.37166739 epoch total loss 1.14255095
Trained batch 1678 batch loss 1.0765146 epoch total loss 1.14251161
Trained batch 1679 batch loss 1.2669996 epoch total loss 1.14258564
Trained batch 1680 batch loss 0.956474185 epoch total loss 1.14247489
Trained batch 1681 batch loss 0.854886532 epoch total loss 1.14230382
Trained batch 1682 batch loss 1.03089833 epoch total loss 1.14223754
Trained batch 1683 batch loss 0.825666308 epoch total loss 1.14204943
Trained batch 1684 batch loss 1.21228313 epoch total loss 1.14209116
Trained batch 1685 batch loss 1.31727457 epoch total loss 1.14219511
Trained batch 1686 batch loss 1.3049432 epoch total loss 1.14229167
Trained batch 1687 batch loss 1.1932373 epoch total loss 1.14232183
Trained batch 1688 batch loss 0.998162806 epoch total loss 1.14223647
Trained batch 1689 batch loss 1.14613342 epoch total loss 1.14223874
Trained batch 1690 batch loss 1.04626513 epoch total loss 1.14218199
Trained batch 1691 batch loss 1.27073443 epoch total loss 1.14225793
Trained batch 1692 batch loss 1.03807569 epoch total loss 1.14219642
Trained batch 1693 batch loss 1.07037187 epoch total loss 1.14215398
Trained batch 1694 batch loss 0.954657078 epoch total loss 1.14204335
Trained batch 1695 batch loss 0.784817636 epoch total loss 1.14183247
Trained batch 1696 batch loss 0.960760117 epoch total loss 1.14172578
Trained batch 1697 batch loss 1.07793486 epoch total loss 1.14168823
Trained batch 1698 batch loss 1.00722492 epoch total loss 1.14160895
Trained batch 1699 batch loss 0.933018923 epoch total loss 1.14148617
Trained batch 1700 batch loss 0.842935741 epoch total loss 1.14131057
Trained batch 1701 batch loss 0.83144486 epoch total loss 1.1411283
Trained batch 1702 batch loss 1.0007838 epoch total loss 1.14104581
Trained batch 1703 batch loss 0.994731486 epoch total loss 1.14096
Trained batch 1704 batch loss 0.842492521 epoch total loss 1.14078486
Trained batch 1705 batch loss 0.82422334 epoch total loss 1.14059913
Trained batch 1706 batch loss 0.896550655 epoch total loss 1.14045608
Trained batch 1707 batch loss 0.849019527 epoch total loss 1.14028537
Trained batch 1708 batch loss 0.887965083 epoch total loss 1.14013767
Trained batch 1709 batch loss 1.0635879 epoch total loss 1.14009285
Trained batch 1710 batch loss 1.20352769 epoch total loss 1.14012992
Trained batch 1711 batch loss 1.1747036 epoch total loss 1.14015019
Trained batch 1712 batch loss 1.39157081 epoch total loss 1.14029706
Trained batch 1713 batch loss 1.17761564 epoch total loss 1.14031875
Trained batch 1714 batch loss 1.53907371 epoch total loss 1.14055145
Trained batch 1715 batch loss 1.48050594 epoch total loss 1.14074957
Trained batch 1716 batch loss 1.2995131 epoch total loss 1.1408422
Trained batch 1717 batch loss 1.28731298 epoch total loss 1.14092755
Trained batch 1718 batch loss 1.34118891 epoch total loss 1.14104402
Trained batch 1719 batch loss 1.22895682 epoch total loss 1.14109528
Trained batch 1720 batch loss 1.31582785 epoch total loss 1.14119685
Trained batch 1721 batch loss 1.27625608 epoch total loss 1.14127529
Trained batch 1722 batch loss 1.4481256 epoch total loss 1.1414535
Trained batch 1723 batch loss 1.21573257 epoch total loss 1.14149654
Trained batch 1724 batch loss 1.20720983 epoch total loss 1.14153469
Trained batch 1725 batch loss 0.955746651 epoch total loss 1.14142692
Trained batch 1726 batch loss 1.06052041 epoch total loss 1.14138007
Trained batch 1727 batch loss 1.14706099 epoch total loss 1.14138341
Trained batch 1728 batch loss 1.48418915 epoch total loss 1.14158165
Trained batch 1729 batch loss 1.11296809 epoch total loss 1.14156508
Trained batch 1730 batch loss 1.33776903 epoch total loss 1.14167857
Trained batch 1731 batch loss 1.26061666 epoch total loss 1.14174724
Trained batch 1732 batch loss 1.42270422 epoch total loss 1.14190948
Trained batch 1733 batch loss 1.38200891 epoch total loss 1.142048
Trained batch 1734 batch loss 1.30891299 epoch total loss 1.1421442
Trained batch 1735 batch loss 1.20650542 epoch total loss 1.1421814
Trained batch 1736 batch loss 1.10814667 epoch total loss 1.14216173
Trained batch 1737 batch loss 1.15571904 epoch total loss 1.14216959
Trained batch 1738 batch loss 1.23084855 epoch total loss 1.14222062
Trained batch 1739 batch loss 1.12197161 epoch total loss 1.14220893
Trained batch 1740 batch loss 1.02746964 epoch total loss 1.14214301
Trained batch 1741 batch loss 1.03189301 epoch total loss 1.14207971
Trained batch 1742 batch loss 1.26570773 epoch total loss 1.14215064
Trained batch 1743 batch loss 1.21460533 epoch total loss 1.14219224
Trained batch 1744 batch loss 1.00556123 epoch total loss 1.14211392
Trained batch 1745 batch loss 1.48140705 epoch total loss 1.14230835
Trained batch 1746 batch loss 0.884402275 epoch total loss 1.14216065
Trained batch 1747 batch loss 1.00706172 epoch total loss 1.14208329
Trained batch 1748 batch loss 1.04683697 epoch total loss 1.14202893
Trained batch 1749 batch loss 0.711449146 epoch total loss 1.14178264
Trained batch 1750 batch loss 0.77331996 epoch total loss 1.14157212
Trained batch 1751 batch loss 0.844724417 epoch total loss 1.1414026
Trained batch 1752 batch loss 1.0085578 epoch total loss 1.14132679
Trained batch 1753 batch loss 1.02606201 epoch total loss 1.1412611
Trained batch 1754 batch loss 0.882587552 epoch total loss 1.14111352
Trained batch 1755 batch loss 0.896191955 epoch total loss 1.14097404
Trained batch 1756 batch loss 1.1237179 epoch total loss 1.14096415
Trained batch 1757 batch loss 1.03549564 epoch total loss 1.14090419
Trained batch 1758 batch loss 1.16063201 epoch total loss 1.14091539
Trained batch 1759 batch loss 0.928088248 epoch total loss 1.1407944
Trained batch 1760 batch loss 1.09592664 epoch total loss 1.14076889
Trained batch 1761 batch loss 1.03665102 epoch total loss 1.14070976
Trained batch 1762 batch loss 1.1520766 epoch total loss 1.1407162
Trained batch 1763 batch loss 1.10505795 epoch total loss 1.14069605
Trained batch 1764 batch loss 1.11654091 epoch total loss 1.14068234
Trained batch 1765 batch loss 0.961411417 epoch total loss 1.14058077
Trained batch 1766 batch loss 1.07344341 epoch total loss 1.14054286
Trained batch 1767 batch loss 0.939636528 epoch total loss 1.14042914
Trained batch 1768 batch loss 1.21952915 epoch total loss 1.14047384
Trained batch 1769 batch loss 1.15407419 epoch total loss 1.14048159
Trained batch 1770 batch loss 0.880404472 epoch total loss 1.14033461
Trained batch 1771 batch loss 1.0597719 epoch total loss 1.14028907
Trained batch 1772 batch loss 1.14630008 epoch total loss 1.14029253
Trained batch 1773 batch loss 0.949158549 epoch total loss 1.14018476
Trained batch 1774 batch loss 1.2533704 epoch total loss 1.14024854
Trained batch 1775 batch loss 1.1208806 epoch total loss 1.14023757
Trained batch 1776 batch loss 1.30836797 epoch total loss 1.14033222
Trained batch 1777 batch loss 1.13172197 epoch total loss 1.14032745
Trained batch 1778 batch loss 1.41127682 epoch total loss 1.1404798
Trained batch 1779 batch loss 1.09181857 epoch total loss 1.14045238
Trained batch 1780 batch loss 1.1607008 epoch total loss 1.14046383
Trained batch 1781 batch loss 1.2202791 epoch total loss 1.14050865
Trained batch 1782 batch loss 1.09938312 epoch total loss 1.14048553
Trained batch 1783 batch loss 1.23526073 epoch total loss 1.14053869
Trained batch 1784 batch loss 1.26292777 epoch total loss 1.14060724
Trained batch 1785 batch loss 1.32447219 epoch total loss 1.14071023
Trained batch 1786 batch loss 1.41057074 epoch total loss 1.14086139
Trained batch 1787 batch loss 1.31764531 epoch total loss 1.14096022
Trained batch 1788 batch loss 1.20880914 epoch total loss 1.14099824
Trained batch 1789 batch loss 0.823755383 epoch total loss 1.14082086
Trained batch 1790 batch loss 0.938151717 epoch total loss 1.14070761
Trained batch 1791 batch loss 0.904484391 epoch total loss 1.14057577
Trained batch 1792 batch loss 1.03808379 epoch total loss 1.14051855
Trained batch 1793 batch loss 1.03161192 epoch total loss 1.14045787
Trained batch 1794 batch loss 0.996055961 epoch total loss 1.1403774
Trained batch 1795 batch loss 1.11331153 epoch total loss 1.14036226
Trained batch 1796 batch loss 1.11031091 epoch total loss 1.14034557
Trained batch 1797 batch loss 1.0526886 epoch total loss 1.14029682
Trained batch 1798 batch loss 1.135813 epoch total loss 1.14029419
Trained batch 1799 batch loss 1.15851712 epoch total loss 1.14030433
Trained batch 1800 batch loss 1.20835245 epoch total loss 1.14034212
Trained batch 1801 batch loss 1.2205584 epoch total loss 1.14038658
Trained batch 1802 batch loss 1.27665 epoch total loss 1.14046216
Trained batch 1803 batch loss 1.14787626 epoch total loss 1.14046633
Trained batch 1804 batch loss 1.35805345 epoch total loss 1.14058697
Trained batch 1805 batch loss 1.15850186 epoch total loss 1.14059687
Trained batch 1806 batch loss 1.3983115 epoch total loss 1.14073944
Trained batch 1807 batch loss 1.16968942 epoch total loss 1.14075553
Trained batch 1808 batch loss 1.41153312 epoch total loss 1.14090538
Trained batch 1809 batch loss 1.3136456 epoch total loss 1.14100087
Trained batch 1810 batch loss 1.13989806 epoch total loss 1.14100027
Trained batch 1811 batch loss 1.09232 epoch total loss 1.14097333
Trained batch 1812 batch loss 1.12752604 epoch total loss 1.14096594
Trained batch 1813 batch loss 1.13968027 epoch total loss 1.1409651
Trained batch 1814 batch loss 1.20554543 epoch total loss 1.14100075
Trained batch 1815 batch loss 1.18364692 epoch total loss 1.14102423
Trained batch 1816 batch loss 1.21151769 epoch total loss 1.14106297
Trained batch 1817 batch loss 1.04821253 epoch total loss 1.14101183
Trained batch 1818 batch loss 0.973011851 epoch total loss 1.14091933
Trained batch 1819 batch loss 1.10817623 epoch total loss 1.14090133
Trained batch 1820 batch loss 0.998350739 epoch total loss 1.14082301
Trained batch 1821 batch loss 1.13181138 epoch total loss 1.14081812
Trained batch 1822 batch loss 0.98235482 epoch total loss 1.1407311
Trained batch 1823 batch loss 1.17277694 epoch total loss 1.14074874
Trained batch 1824 batch loss 1.03581834 epoch total loss 1.14069128
Trained batch 1825 batch loss 1.22461605 epoch total loss 1.1407373
Trained batch 1826 batch loss 1.30323899 epoch total loss 1.14082623
Trained batch 1827 batch loss 1.19152021 epoch total loss 1.14085388
Trained batch 1828 batch loss 1.20280397 epoch total loss 1.14088786
Trained batch 1829 batch loss 1.29083228 epoch total loss 1.14096975
Trained batch 1830 batch loss 1.0937767 epoch total loss 1.140944
Trained batch 1831 batch loss 1.43220043 epoch total loss 1.14110303
Trained batch 1832 batch loss 1.25487876 epoch total loss 1.14116514
Trained batch 1833 batch loss 1.18817949 epoch total loss 1.14119077
Trained batch 1834 batch loss 1.25178933 epoch total loss 1.14125109
Trained batch 1835 batch loss 1.36858404 epoch total loss 1.14137495
Trained batch 1836 batch loss 1.11749935 epoch total loss 1.14136195
Trained batch 1837 batch loss 1.04921281 epoch total loss 1.14131188
Trained batch 1838 batch loss 1.14618361 epoch total loss 1.14131451
Trained batch 1839 batch loss 1.01209939 epoch total loss 1.14124429
Trained batch 1840 batch loss 1.05245495 epoch total loss 1.14119613
Trained batch 1841 batch loss 1.03793073 epoch total loss 1.14114
Trained batch 1842 batch loss 1.03905928 epoch total loss 1.14108455
Trained batch 1843 batch loss 1.28682482 epoch total loss 1.14116359
Trained batch 1844 batch loss 1.09819674 epoch total loss 1.14114034
Trained batch 1845 batch loss 1.17308879 epoch total loss 1.14115763
Trained batch 1846 batch loss 1.00188625 epoch total loss 1.14108217
Trained batch 1847 batch loss 1.13665855 epoch total loss 1.14107978
Trained batch 1848 batch loss 1.01479149 epoch total loss 1.1410116
Trained batch 1849 batch loss 1.00493693 epoch total loss 1.14093792
Trained batch 1850 batch loss 1.13907564 epoch total loss 1.14093697
Trained batch 1851 batch loss 0.807129741 epoch total loss 1.14075661
Trained batch 1852 batch loss 0.90995872 epoch total loss 1.14063203
Trained batch 1853 batch loss 1.12839258 epoch total loss 1.14062536
Trained batch 1854 batch loss 0.983440101 epoch total loss 1.1405406
Trained batch 1855 batch loss 1.1971072 epoch total loss 1.140571
Trained batch 1856 batch loss 1.35952568 epoch total loss 1.14068902
Trained batch 1857 batch loss 1.14838743 epoch total loss 1.14069319
Trained batch 1858 batch loss 1.15173459 epoch total loss 1.14069927
Trained batch 1859 batch loss 0.987395704 epoch total loss 1.14061677
Trained batch 1860 batch loss 1.04270089 epoch total loss 1.14056408
Trained batch 1861 batch loss 1.08523655 epoch total loss 1.1405344
Trained batch 1862 batch loss 1.21774042 epoch total loss 1.14057589
Trained batch 1863 batch loss 0.949695051 epoch total loss 1.14047337
Trained batch 1864 batch loss 0.94700861 epoch total loss 1.14036965
Trained batch 1865 batch loss 0.828692555 epoch total loss 1.1402024
Trained batch 1866 batch loss 1.27228 epoch total loss 1.14027321
Trained batch 1867 batch loss 1.13571453 epoch total loss 1.14027071
Trained batch 1868 batch loss 1.02833152 epoch total loss 1.14021087
Trained batch 1869 batch loss 1.01444852 epoch total loss 1.14014351
Trained batch 1870 batch loss 1.1979605 epoch total loss 1.14017451
Trained batch 1871 batch loss 1.07606983 epoch total loss 1.1401403
Trained batch 1872 batch loss 1.10160303 epoch total loss 1.14011967
Trained batch 1873 batch loss 1.07588744 epoch total loss 1.14008534
Trained batch 1874 batch loss 0.998889327 epoch total loss 1.14001
Trained batch 1875 batch loss 1.04916978 epoch total loss 1.13996148
Trained batch 1876 batch loss 1.04650152 epoch total loss 1.13991153
Trained batch 1877 batch loss 0.849588215 epoch total loss 1.13975692
Trained batch 1878 batch loss 1.06628752 epoch total loss 1.13971782
Trained batch 1879 batch loss 1.27435625 epoch total loss 1.13978958
Trained batch 1880 batch loss 1.2428658 epoch total loss 1.13984442
Trained batch 1881 batch loss 1.02053094 epoch total loss 1.139781
Trained batch 1882 batch loss 1.00105023 epoch total loss 1.13970721
Trained batch 1883 batch loss 1.1017741 epoch total loss 1.13968706
Trained batch 1884 batch loss 1.16951406 epoch total loss 1.13970292
Trained batch 1885 batch loss 1.092749 epoch total loss 1.139678
Trained batch 1886 batch loss 1.23969352 epoch total loss 1.13973105
Trained batch 1887 batch loss 1.20966458 epoch total loss 1.13976812
Trained batch 1888 batch loss 1.15962553 epoch total loss 1.13977861
Trained batch 1889 batch loss 1.12144375 epoch total loss 1.13976884
Trained batch 1890 batch loss 0.939171433 epoch total loss 1.13966274
Trained batch 1891 batch loss 0.911480427 epoch total loss 1.1395421
Trained batch 1892 batch loss 1.14495432 epoch total loss 1.13954496
Trained batch 1893 batch loss 1.19565129 epoch total loss 1.13957453
Trained batch 1894 batch loss 1.16709828 epoch total loss 1.13958907
Trained batch 1895 batch loss 1.11056447 epoch total loss 1.13957369
Trained batch 1896 batch loss 1.17239499 epoch total loss 1.13959098
Trained batch 1897 batch loss 1.13735485 epoch total loss 1.13958991
Trained batch 1898 batch loss 1.16900134 epoch total loss 1.1396054
Trained batch 1899 batch loss 1.19551873 epoch total loss 1.13963485
Trained batch 1900 batch loss 0.72600019 epoch total loss 1.13941717
Trained batch 1901 batch loss 1.20829618 epoch total loss 1.13945341
Trained batch 1902 batch loss 1.22425199 epoch total loss 1.139498
Trained batch 1903 batch loss 1.23803246 epoch total loss 1.13954973
Trained batch 1904 batch loss 1.14555168 epoch total loss 1.13955295
Trained batch 1905 batch loss 1.12899172 epoch total loss 1.13954735
Trained batch 1906 batch loss 1.27465749 epoch total loss 1.13961816
Trained batch 1907 batch loss 1.18412018 epoch total loss 1.13964152
Trained batch 1908 batch loss 1.28068924 epoch total loss 1.13971543
Trained batch 1909 batch loss 1.14924693 epoch total loss 1.13972044
Trained batch 1910 batch loss 1.22650087 epoch total loss 1.13976586
Trained batch 1911 batch loss 1.17795801 epoch total loss 1.13978589
Trained batch 1912 batch loss 1.03048193 epoch total loss 1.13972878
Trained batch 1913 batch loss 1.16597891 epoch total loss 1.13974249
Trained batch 1914 batch loss 0.948783398 epoch total loss 1.13964272
Trained batch 1915 batch loss 1.10434639 epoch total loss 1.13962424
Trained batch 1916 batch loss 1.0451386 epoch total loss 1.13957489
Trained batch 1917 batch loss 0.960725248 epoch total loss 1.13948154
Trained batch 1918 batch loss 1.07373667 epoch total loss 1.13944733
Trained batch 1919 batch loss 1.11580479 epoch total loss 1.13943493
Trained batch 1920 batch loss 1.22174859 epoch total loss 1.13947785
Trained batch 1921 batch loss 0.947710514 epoch total loss 1.13937795
Trained batch 1922 batch loss 0.944201887 epoch total loss 1.13927639
Trained batch 1923 batch loss 1.03443575 epoch total loss 1.13922191
Trained batch 1924 batch loss 1.17070043 epoch total loss 1.13923824
Trained batch 1925 batch loss 0.9354285 epoch total loss 1.13913238
Trained batch 1926 batch loss 1.17623305 epoch total loss 1.13915169
Trained batch 1927 batch loss 1.11645532 epoch total loss 1.13913989
Trained batch 1928 batch loss 0.983696 epoch total loss 1.13905919
Trained batch 1929 batch loss 1.10973072 epoch total loss 1.13904393
Trained batch 1930 batch loss 0.932981849 epoch total loss 1.13893712
Trained batch 1931 batch loss 0.96096009 epoch total loss 1.13884497
Trained batch 1932 batch loss 1.04243767 epoch total loss 1.13879514
Trained batch 1933 batch loss 1.3003118 epoch total loss 1.13887858
Trained batch 1934 batch loss 1.17833543 epoch total loss 1.13889897
Trained batch 1935 batch loss 1.28301883 epoch total loss 1.13897347
Trained batch 1936 batch loss 1.11559677 epoch total loss 1.13896132
Trained batch 1937 batch loss 0.836509943 epoch total loss 1.13880515
Trained batch 1938 batch loss 1.08252609 epoch total loss 1.13877606
Trained batch 1939 batch loss 0.914309204 epoch total loss 1.13866031
Trained batch 1940 batch loss 1.12322783 epoch total loss 1.13865232
Trained batch 1941 batch loss 1.04147172 epoch total loss 1.13860238
Trained batch 1942 batch loss 0.899173081 epoch total loss 1.13847899
Trained batch 1943 batch loss 1.19478393 epoch total loss 1.13850808
Trained batch 1944 batch loss 0.996620059 epoch total loss 1.13843501
Trained batch 1945 batch loss 0.977547884 epoch total loss 1.13835227
Trained batch 1946 batch loss 0.842054844 epoch total loss 1.1382
Trained batch 1947 batch loss 0.793585062 epoch total loss 1.13802314
Trained batch 1948 batch loss 0.651286483 epoch total loss 1.13777328
Trained batch 1949 batch loss 0.651224196 epoch total loss 1.13752353
Trained batch 1950 batch loss 0.775181711 epoch total loss 1.13733768
Trained batch 1951 batch loss 0.92100513 epoch total loss 1.13722682
Trained batch 1952 batch loss 1.02656746 epoch total loss 1.13717008
Trained batch 1953 batch loss 1.05764461 epoch total loss 1.13712943
Trained batch 1954 batch loss 1.2360096 epoch total loss 1.13718009
Trained batch 1955 batch loss 1.24867237 epoch total loss 1.13723707
Trained batch 1956 batch loss 1.10574293 epoch total loss 1.13722098
Trained batch 1957 batch loss 1.34330988 epoch total loss 1.13732624
Trained batch 1958 batch loss 1.22887266 epoch total loss 1.13737297
Trained batch 1959 batch loss 1.11222982 epoch total loss 1.13736022
Trained batch 1960 batch loss 1.00092423 epoch total loss 1.1372906
Trained batch 1961 batch loss 1.1227386 epoch total loss 1.13728321
Trained batch 1962 batch loss 1.22109962 epoch total loss 1.137326
Trained batch 1963 batch loss 1.05812168 epoch total loss 1.13728559
Trained batch 1964 batch loss 0.943058372 epoch total loss 1.13718677
Trained batch 1965 batch loss 1.10211134 epoch total loss 1.13716888
Trained batch 1966 batch loss 1.33585739 epoch total loss 1.13727
Trained batch 1967 batch loss 1.21379304 epoch total loss 1.13730896
Trained batch 1968 batch loss 0.906702876 epoch total loss 1.13719177
Trained batch 1969 batch loss 1.0636102 epoch total loss 1.13715446
Trained batch 1970 batch loss 1.01081562 epoch total loss 1.13709033
Trained batch 1971 batch loss 0.983311355 epoch total loss 1.13701236
Trained batch 1972 batch loss 1.11868787 epoch total loss 1.13700294
Trained batch 1973 batch loss 1.06519675 epoch total loss 1.13696659
Trained batch 1974 batch loss 0.984207153 epoch total loss 1.13688922
Trained batch 1975 batch loss 0.822967112 epoch total loss 1.13673019
Trained batch 1976 batch loss 0.964550614 epoch total loss 1.13664317
Trained batch 1977 batch loss 0.940532804 epoch total loss 1.13654387
Trained batch 1978 batch loss 1.07053697 epoch total loss 1.13651049
Trained batch 1979 batch loss 0.934221745 epoch total loss 1.13640833
Trained batch 1980 batch loss 0.84954834 epoch total loss 1.13626349
Trained batch 1981 batch loss 1.03019881 epoch total loss 1.13621
Trained batch 1982 batch loss 1.20230854 epoch total loss 1.13624334
Trained batch 1983 batch loss 0.966209173 epoch total loss 1.13615775
Trained batch 1984 batch loss 0.994196773 epoch total loss 1.13608611
Trained batch 1985 batch loss 1.07138562 epoch total loss 1.13605344
Trained batch 1986 batch loss 1.13228536 epoch total loss 1.13605165
Trained batch 1987 batch loss 0.942956328 epoch total loss 1.13595438
Trained batch 1988 batch loss 1.32755899 epoch total loss 1.13605082
Trained batch 1989 batch loss 1.07051396 epoch total loss 1.13601792
Trained batch 1990 batch loss 1.14554024 epoch total loss 1.13602269
Trained batch 1991 batch loss 0.976173401 epoch total loss 1.13594234
Trained batch 1992 batch loss 1.29803848 epoch total loss 1.13602376
Trained batch 1993 batch loss 0.997899055 epoch total loss 1.13595438
Trained batch 1994 batch loss 1.25740647 epoch total loss 1.13601518
Trained batch 1995 batch loss 1.04673731 epoch total loss 1.13597047
Trained batch 1996 batch loss 1.23034191 epoch total loss 1.13601768
Trained batch 1997 batch loss 1.20798612 epoch total loss 1.13605368
Trained batch 1998 batch loss 1.16249967 epoch total loss 1.13606703
Trained batch 1999 batch loss 1.12724459 epoch total loss 1.1360625
Trained batch 2000 batch loss 1.16290617 epoch total loss 1.13607597
Trained batch 2001 batch loss 1.12304187 epoch total loss 1.13606942
Trained batch 2002 batch loss 1.012995 epoch total loss 1.13600791
Trained batch 2003 batch loss 1.16242695 epoch total loss 1.13602102
Trained batch 2004 batch loss 1.11863613 epoch total loss 1.13601243
Trained batch 2005 batch loss 1.03768849 epoch total loss 1.13596332
Trained batch 2006 batch loss 1.18098211 epoch total loss 1.13598573
Trained batch 2007 batch loss 1.51154101 epoch total loss 1.13617277
Trained batch 2008 batch loss 1.1505028 epoch total loss 1.13617992
Trained batch 2009 batch loss 1.41905189 epoch total loss 1.13632059
Trained batch 2010 batch loss 1.27323914 epoch total loss 1.13638878
Trained batch 2011 batch loss 1.15078378 epoch total loss 1.13639593
Trained batch 2012 batch loss 0.960706 epoch total loss 1.13630867
Trained batch 2013 batch loss 0.882916927 epoch total loss 1.13618267
Trained batch 2014 batch loss 1.30967963 epoch total loss 1.13626873
Trained batch 2015 batch loss 1.21223199 epoch total loss 1.13630641
Trained batch 2016 batch loss 1.30586326 epoch total loss 1.13639057
Trained batch 2017 batch loss 1.20722413 epoch total loss 1.13642573
Trained batch 2018 batch loss 1.27993393 epoch total loss 1.1364969
Trained batch 2019 batch loss 1.0665307 epoch total loss 1.13646233
Trained batch 2020 batch loss 1.13395095 epoch total loss 1.13646102
Trained batch 2021 batch loss 1.20617795 epoch total loss 1.13649559
Trained batch 2022 batch loss 1.08752489 epoch total loss 1.13647151
Trained batch 2023 batch loss 1.09552801 epoch total loss 1.13645124
Trained batch 2024 batch loss 1.11438155 epoch total loss 1.1364404
Trained batch 2025 batch loss 1.13774049 epoch total loss 1.13644099
Trained batch 2026 batch loss 1.34621096 epoch total loss 1.13654447
Trained batch 2027 batch loss 1.12979043 epoch total loss 1.13654125
Trained batch 2028 batch loss 1.46810734 epoch total loss 1.13670468
Trained batch 2029 batch loss 1.33686721 epoch total loss 1.13680339
Trained batch 2030 batch loss 1.29622567 epoch total loss 1.13688183
Trained batch 2031 batch loss 1.30698109 epoch total loss 1.13696551
Trained batch 2032 batch loss 0.985681891 epoch total loss 1.13689101
Trained batch 2033 batch loss 0.804814816 epoch total loss 1.13672781
Trained batch 2034 batch loss 0.89841187 epoch total loss 1.13661063
Trained batch 2035 batch loss 0.797099 epoch total loss 1.13644373
Trained batch 2036 batch loss 0.882986903 epoch total loss 1.13631928
Trained batch 2037 batch loss 0.904048741 epoch total loss 1.13620532
Trained batch 2038 batch loss 0.810931921 epoch total loss 1.13604569
Trained batch 2039 batch loss 0.782025874 epoch total loss 1.13587213
Trained batch 2040 batch loss 1.02460611 epoch total loss 1.13581753
Trained batch 2041 batch loss 0.832432449 epoch total loss 1.13566899
Trained batch 2042 batch loss 1.31043553 epoch total loss 1.13575459
Trained batch 2043 batch loss 1.32632256 epoch total loss 1.13584793
Trained batch 2044 batch loss 1.06825852 epoch total loss 1.13581491
Trained batch 2045 batch loss 1.01750815 epoch total loss 1.13575709
Trained batch 2046 batch loss 1.15351367 epoch total loss 1.13576579
Trained batch 2047 batch loss 1.18603837 epoch total loss 1.13579035
Trained batch 2048 batch loss 1.27651238 epoch total loss 1.13585913
Trained batch 2049 batch loss 1.06870317 epoch total loss 1.13582635
Trained batch 2050 batch loss 0.875918746 epoch total loss 1.13569951
Trained batch 2051 batch loss 1.0230571 epoch total loss 1.13564456
Trained batch 2052 batch loss 1.07415915 epoch total loss 1.13561463
Trained batch 2053 batch loss 0.988365412 epoch total loss 1.13554287
Trained batch 2054 batch loss 1.02250159 epoch total loss 1.13548779
Trained batch 2055 batch loss 1.24068475 epoch total loss 1.13553905
Trained batch 2056 batch loss 1.11889672 epoch total loss 1.13553095
Trained batch 2057 batch loss 1.32736742 epoch total loss 1.13562417
Trained batch 2058 batch loss 0.973255634 epoch total loss 1.13554525
Trained batch 2059 batch loss 1.10213923 epoch total loss 1.13552904
Trained batch 2060 batch loss 1.06284595 epoch total loss 1.13549364
Trained batch 2061 batch loss 1.31216431 epoch total loss 1.13557947
Trained batch 2062 batch loss 1.1878736 epoch total loss 1.13560486
Trained batch 2063 batch loss 1.05380654 epoch total loss 1.13556516
Trained batch 2064 batch loss 1.1041553 epoch total loss 1.13555
Trained batch 2065 batch loss 1.31872308 epoch total loss 1.13563859
Trained batch 2066 batch loss 1.34848487 epoch total loss 1.13574159
Trained batch 2067 batch loss 1.31063819 epoch total loss 1.13582611
Trained batch 2068 batch loss 1.07874382 epoch total loss 1.13579857
Trained batch 2069 batch loss 1.26337707 epoch total loss 1.13586032
Trained batch 2070 batch loss 1.0585072 epoch total loss 1.13582301
Trained batch 2071 batch loss 1.08591592 epoch total loss 1.13579893
Trained batch 2072 batch loss 1.04468322 epoch total loss 1.13575494
Trained batch 2073 batch loss 1.1406219 epoch total loss 1.13575721
Trained batch 2074 batch loss 1.23811412 epoch total loss 1.13580656
Trained batch 2075 batch loss 1.33547664 epoch total loss 1.13590276
Trained batch 2076 batch loss 1.3078444 epoch total loss 1.13598561
Trained batch 2077 batch loss 1.33072031 epoch total loss 1.13607943
Trained batch 2078 batch loss 1.4657414 epoch total loss 1.1362381
Trained batch 2079 batch loss 1.15214729 epoch total loss 1.13624573
Trained batch 2080 batch loss 1.35867596 epoch total loss 1.13635266
Trained batch 2081 batch loss 1.4159894 epoch total loss 1.13648701
Trained batch 2082 batch loss 1.41751099 epoch total loss 1.13662195
Trained batch 2083 batch loss 1.15141451 epoch total loss 1.1366291
Trained batch 2084 batch loss 1.14498496 epoch total loss 1.13663316
Trained batch 2085 batch loss 1.07040775 epoch total loss 1.13660133
Trained batch 2086 batch loss 1.13647127 epoch total loss 1.13660121
Trained batch 2087 batch loss 1.23657656 epoch total loss 1.13664913
Trained batch 2088 batch loss 1.12297916 epoch total loss 1.13664258
Trained batch 2089 batch loss 1.20413649 epoch total loss 1.13667488
Trained batch 2090 batch loss 1.18744433 epoch total loss 1.1366992
Trained batch 2091 batch loss 1.11081481 epoch total loss 1.13668692
Trained batch 2092 batch loss 1.2257967 epoch total loss 1.13672948
Trained batch 2093 batch loss 1.18798614 epoch total loss 1.13675404
Trained batch 2094 batch loss 1.16625631 epoch total loss 1.1367681
Trained batch 2095 batch loss 0.942439675 epoch total loss 1.13667524
Trained batch 2096 batch loss 0.88624692 epoch total loss 1.13655579
Trained batch 2097 batch loss 1.08808637 epoch total loss 1.13653266
Trained batch 2098 batch loss 0.79078126 epoch total loss 1.13636792
Trained batch 2099 batch loss 1.02214718 epoch total loss 1.13631356
Trained batch 2100 batch loss 0.855922699 epoch total loss 1.13618
Trained batch 2101 batch loss 1.03387499 epoch total loss 1.13613141
Trained batch 2102 batch loss 0.994316339 epoch total loss 1.13606393
Trained batch 2103 batch loss 1.11306107 epoch total loss 1.13605297
Trained batch 2104 batch loss 1.05877662 epoch total loss 1.13601625
Trained batch 2105 batch loss 1.28059435 epoch total loss 1.13608491
Trained batch 2106 batch loss 1.04536271 epoch total loss 1.13604188
Trained batch 2107 batch loss 1.13700855 epoch total loss 1.13604224
Trained batch 2108 batch loss 0.944626749 epoch total loss 1.13595152
Trained batch 2109 batch loss 0.917465091 epoch total loss 1.13584793
Trained batch 2110 batch loss 1.3797642 epoch total loss 1.13596356
Trained batch 2111 batch loss 1.22336245 epoch total loss 1.13600492
Trained batch 2112 batch loss 1.25545752 epoch total loss 1.13606143
Trained batch 2113 batch loss 1.27446377 epoch total loss 1.136127
Trained batch 2114 batch loss 1.24973202 epoch total loss 1.13618064
Trained batch 2115 batch loss 1.21319711 epoch total loss 1.13621712
Trained batch 2116 batch loss 1.20002317 epoch total loss 1.13624716
Trained batch 2117 batch loss 1.02571249 epoch total loss 1.13619494
Trained batch 2118 batch loss 1.07748723 epoch total loss 1.13616717
Trained batch 2119 batch loss 1.2851007 epoch total loss 1.1362375
Trained batch 2120 batch loss 1.11648762 epoch total loss 1.1362282
Trained batch 2121 batch loss 1.12392759 epoch total loss 1.13622236
Trained batch 2122 batch loss 1.11524045 epoch total loss 1.13621247
Trained batch 2123 batch loss 0.886730492 epoch total loss 1.13609505
Trained batch 2124 batch loss 0.994641721 epoch total loss 1.13602841
Trained batch 2125 batch loss 1.12808824 epoch total loss 1.13602471
Trained batch 2126 batch loss 1.0119642 epoch total loss 1.1359663
Trained batch 2127 batch loss 1.11097741 epoch total loss 1.13595462
Trained batch 2128 batch loss 1.38680291 epoch total loss 1.13607252
Trained batch 2129 batch loss 1.35252893 epoch total loss 1.1361742
Trained batch 2130 batch loss 1.22338295 epoch total loss 1.13621509
Trained batch 2131 batch loss 1.22314405 epoch total loss 1.13625586
Trained batch 2132 batch loss 1.20475936 epoch total loss 1.13628805
Trained batch 2133 batch loss 1.07922626 epoch total loss 1.13626134
Trained batch 2134 batch loss 1.14741683 epoch total loss 1.13626659
Trained batch 2135 batch loss 1.22437453 epoch total loss 1.13630784
Trained batch 2136 batch loss 1.05168056 epoch total loss 1.13626826
Trained batch 2137 batch loss 1.22763371 epoch total loss 1.13631105
Trained batch 2138 batch loss 1.08100855 epoch total loss 1.13628519
Trained batch 2139 batch loss 1.15882313 epoch total loss 1.1362958
Trained batch 2140 batch loss 1.08525515 epoch total loss 1.13627183
Trained batch 2141 batch loss 1.21808171 epoch total loss 1.1363101
Trained batch 2142 batch loss 1.12768126 epoch total loss 1.13630605
Trained batch 2143 batch loss 1.07150185 epoch total loss 1.13627577
Trained batch 2144 batch loss 1.183707 epoch total loss 1.13629782
Trained batch 2145 batch loss 1.13640165 epoch total loss 1.13629794
Trained batch 2146 batch loss 1.26793671 epoch total loss 1.13635921
Trained batch 2147 batch loss 0.941674471 epoch total loss 1.13626862
Trained batch 2148 batch loss 1.09607017 epoch total loss 1.1362499
Trained batch 2149 batch loss 1.05128813 epoch total loss 1.13621032
Trained batch 2150 batch loss 1.11993885 epoch total loss 1.13620281
Trained batch 2151 batch loss 0.924973428 epoch total loss 1.13610458
Trained batch 2152 batch loss 1.16564202 epoch total loss 1.13611829
Trained batch 2153 batch loss 1.08581281 epoch total loss 1.13609481
Trained batch 2154 batch loss 0.955316484 epoch total loss 1.13601089
Trained batch 2155 batch loss 1.10965061 epoch total loss 1.13599873
Trained batch 2156 batch loss 1.16555321 epoch total loss 1.13601232
Trained batch 2157 batch loss 1.18586159 epoch total loss 1.13603544
Trained batch 2158 batch loss 1.12999821 epoch total loss 1.13603258
Trained batch 2159 batch loss 1.22876906 epoch total loss 1.1360755
Trained batch 2160 batch loss 1.26583958 epoch total loss 1.1361357
Trained batch 2161 batch loss 1.30440402 epoch total loss 1.13621354
Trained batch 2162 batch loss 1.04700589 epoch total loss 1.13617229
Trained batch 2163 batch loss 1.00415802 epoch total loss 1.13611126
Trained batch 2164 batch loss 1.15575373 epoch total loss 1.13612032
Trained batch 2165 batch loss 1.26889992 epoch total loss 1.13618159
Trained batch 2166 batch loss 1.18736124 epoch total loss 1.1362052
Trained batch 2167 batch loss 1.15558207 epoch total loss 1.13621414
Trained batch 2168 batch loss 0.893531799 epoch total loss 1.1361022
Trained batch 2169 batch loss 1.14188266 epoch total loss 1.13610482
Trained batch 2170 batch loss 1.03995538 epoch total loss 1.1360606
Trained batch 2171 batch loss 1.0294075 epoch total loss 1.13601136
Trained batch 2172 batch loss 1.07661748 epoch total loss 1.13598406
Trained batch 2173 batch loss 1.09453273 epoch total loss 1.13596499
Trained batch 2174 batch loss 1.03334963 epoch total loss 1.13591778
Trained batch 2175 batch loss 0.861045 epoch total loss 1.13579142
Trained batch 2176 batch loss 0.942232609 epoch total loss 1.13570249
Trained batch 2177 batch loss 1.02358854 epoch total loss 1.13565099
Trained batch 2178 batch loss 1.02291918 epoch total loss 1.13559926
Trained batch 2179 batch loss 1.07201123 epoch total loss 1.13557
Trained batch 2180 batch loss 1.11385298 epoch total loss 1.13556
Trained batch 2181 batch loss 1.13712192 epoch total loss 1.13556087
Trained batch 2182 batch loss 1.15161371 epoch total loss 1.13556814
Trained batch 2183 batch loss 1.16380644 epoch total loss 1.13558114
Trained batch 2184 batch loss 1.32696819 epoch total loss 1.13566875
Trained batch 2185 batch loss 1.09615541 epoch total loss 1.13565063
Trained batch 2186 batch loss 1.11282063 epoch total loss 1.13564026
Trained batch 2187 batch loss 1.1724093 epoch total loss 1.13565695
Trained batch 2188 batch loss 0.931086361 epoch total loss 1.13556349
Trained batch 2189 batch loss 1.10141325 epoch total loss 1.13554788
Trained batch 2190 batch loss 1.3069793 epoch total loss 1.13562608
Trained batch 2191 batch loss 1.08614159 epoch total loss 1.13560355
Trained batch 2192 batch loss 1.25601304 epoch total loss 1.1356585
Trained batch 2193 batch loss 1.43542206 epoch total loss 1.13579524
Trained batch 2194 batch loss 1.09316921 epoch total loss 1.1357758
Trained batch 2195 batch loss 1.05924439 epoch total loss 1.135741
Trained batch 2196 batch loss 1.269912 epoch total loss 1.13580215
Trained batch 2197 batch loss 1.0497086 epoch total loss 1.13576293
Trained batch 2198 batch loss 1.26559341 epoch total loss 1.13582206
Trained batch 2199 batch loss 1.42171383 epoch total loss 1.135952
Trained batch 2200 batch loss 1.30085731 epoch total loss 1.13602698
Trained batch 2201 batch loss 1.30385208 epoch total loss 1.13610327
Trained batch 2202 batch loss 1.30788505 epoch total loss 1.13618124
Trained batch 2203 batch loss 1.28495598 epoch total loss 1.13624871
Trained batch 2204 batch loss 1.34629869 epoch total loss 1.13634396
Trained batch 2205 batch loss 1.38217151 epoch total loss 1.13645542
Trained batch 2206 batch loss 1.14899778 epoch total loss 1.13646114
Trained batch 2207 batch loss 1.43908787 epoch total loss 1.13659823
Trained batch 2208 batch loss 1.32116127 epoch total loss 1.1366818
Trained batch 2209 batch loss 1.4278425 epoch total loss 1.13681352
Trained batch 2210 batch loss 1.26947284 epoch total loss 1.1368736
Trained batch 2211 batch loss 1.2775209 epoch total loss 1.13693726
Trained batch 2212 batch loss 0.949801087 epoch total loss 1.13685262
Trained batch 2213 batch loss 1.14140153 epoch total loss 1.13685465
Trained batch 2214 batch loss 1.12624478 epoch total loss 1.13684988
Trained batch 2215 batch loss 1.08435035 epoch total loss 1.13682616
Trained batch 2216 batch loss 1.02895415 epoch total loss 1.13677752
Trained batch 2217 batch loss 0.981491685 epoch total loss 1.13670743
Trained batch 2218 batch loss 0.927371621 epoch total loss 1.13661313
Trained batch 2219 batch loss 1.07261276 epoch total loss 1.13658416
Trained batch 2220 batch loss 1.24077606 epoch total loss 1.13663113
Trained batch 2221 batch loss 1.26946449 epoch total loss 1.13669097
Trained batch 2222 batch loss 1.34041262 epoch total loss 1.13678265
Trained batch 2223 batch loss 1.23882461 epoch total loss 1.13682842
Trained batch 2224 batch loss 1.06382883 epoch total loss 1.13679564
Trained batch 2225 batch loss 1.62314796 epoch total loss 1.13701415
Trained batch 2226 batch loss 1.26109064 epoch total loss 1.13706982
Trained batch 2227 batch loss 1.32736361 epoch total loss 1.13715529
Trained batch 2228 batch loss 0.890201807 epoch total loss 1.13704443
Trained batch 2229 batch loss 1.05869126 epoch total loss 1.13700926
Trained batch 2230 batch loss 0.968367338 epoch total loss 1.13693357
Trained batch 2231 batch loss 1.11668444 epoch total loss 1.13692451
Trained batch 2232 batch loss 1.03259778 epoch total loss 1.13687778
Trained batch 2233 batch loss 0.941440523 epoch total loss 1.13679028
Trained batch 2234 batch loss 1.21455085 epoch total loss 1.13682508
Trained batch 2235 batch loss 1.02519262 epoch total loss 1.13677514
Trained batch 2236 batch loss 0.970014811 epoch total loss 1.13670051
Trained batch 2237 batch loss 0.996159852 epoch total loss 1.13663769
Trained batch 2238 batch loss 1.12923193 epoch total loss 1.13663435
Trained batch 2239 batch loss 1.16552973 epoch total loss 1.13664722
Trained batch 2240 batch loss 0.998303771 epoch total loss 1.13658547
Trained batch 2241 batch loss 1.09955466 epoch total loss 1.1365689
Trained batch 2242 batch loss 1.08246303 epoch total loss 1.13654482
Trained batch 2243 batch loss 1.01584446 epoch total loss 1.13649106
Trained batch 2244 batch loss 0.814538 epoch total loss 1.13634753
Trained batch 2245 batch loss 1.04710138 epoch total loss 1.13630784
Trained batch 2246 batch loss 1.05950785 epoch total loss 1.13627362
Trained batch 2247 batch loss 1.02158237 epoch total loss 1.13622248
Trained batch 2248 batch loss 1.08198571 epoch total loss 1.1361984
Trained batch 2249 batch loss 1.10709691 epoch total loss 1.13618553
Trained batch 2250 batch loss 1.07172287 epoch total loss 1.13615692
Trained batch 2251 batch loss 1.25316441 epoch total loss 1.13620889
Trained batch 2252 batch loss 0.988967419 epoch total loss 1.13614357
Trained batch 2253 batch loss 1.05222726 epoch total loss 1.13610625
Trained batch 2254 batch loss 1.27817535 epoch total loss 1.13616931
Trained batch 2255 batch loss 0.973839283 epoch total loss 1.13609731
Trained batch 2256 batch loss 1.09415579 epoch total loss 1.13607872
Trained batch 2257 batch loss 1.2325716 epoch total loss 1.13612151
Trained batch 2258 batch loss 1.09751546 epoch total loss 1.13610435
Trained batch 2259 batch loss 1.24737859 epoch total loss 1.13615358
Trained batch 2260 batch loss 1.27827501 epoch total loss 1.13621652
Trained batch 2261 batch loss 0.985980511 epoch total loss 1.13615012
Trained batch 2262 batch loss 1.1594671 epoch total loss 1.13616037
Trained batch 2263 batch loss 1.08087146 epoch total loss 1.13613594
Trained batch 2264 batch loss 1.06361628 epoch total loss 1.13610399
Trained batch 2265 batch loss 1.12338424 epoch total loss 1.13609827
Trained batch 2266 batch loss 1.19076991 epoch total loss 1.13612235
Trained batch 2267 batch loss 1.25464833 epoch total loss 1.13617468
Trained batch 2268 batch loss 1.26614809 epoch total loss 1.13623202
Trained batch 2269 batch loss 1.15767 epoch total loss 1.13624144
Trained batch 2270 batch loss 1.1662457 epoch total loss 1.13625467
Trained batch 2271 batch loss 0.879837573 epoch total loss 1.13614178
Trained batch 2272 batch loss 0.933309555 epoch total loss 1.13605249
Trained batch 2273 batch loss 1.02721214 epoch total loss 1.13600457
Trained batch 2274 batch loss 1.24066496 epoch total loss 1.13605058
Trained batch 2275 batch loss 1.08629978 epoch total loss 1.13602877
Trained batch 2276 batch loss 1.22911453 epoch total loss 1.13606954
Trained batch 2277 batch loss 1.18210757 epoch total loss 1.1360898
Trained batch 2278 batch loss 1.2035799 epoch total loss 1.13611948
Trained batch 2279 batch loss 1.04045403 epoch total loss 1.13607752
Trained batch 2280 batch loss 1.23609436 epoch total loss 1.13612139
Trained batch 2281 batch loss 0.920157671 epoch total loss 1.13602662
Trained batch 2282 batch loss 1.13273335 epoch total loss 1.13602531
Trained batch 2283 batch loss 0.962833941 epoch total loss 1.13594949
Trained batch 2284 batch loss 0.94411552 epoch total loss 1.13586545
Trained batch 2285 batch loss 1.01160467 epoch total loss 1.13581109
Trained batch 2286 batch loss 1.18509686 epoch total loss 1.13583267
Trained batch 2287 batch loss 0.982042551 epoch total loss 1.13576531
Trained batch 2288 batch loss 1.04735649 epoch total loss 1.13572669
Trained batch 2289 batch loss 1.11793947 epoch total loss 1.13571894
Trained batch 2290 batch loss 1.32766795 epoch total loss 1.13580275
Trained batch 2291 batch loss 1.11536098 epoch total loss 1.13579392
Trained batch 2292 batch loss 1.0144248 epoch total loss 1.13574088
Trained batch 2293 batch loss 1.51388443 epoch total loss 1.13590586
Trained batch 2294 batch loss 1.53015971 epoch total loss 1.13607776
Trained batch 2295 batch loss 1.12440646 epoch total loss 1.13607275
Trained batch 2296 batch loss 0.868748724 epoch total loss 1.13595629
Trained batch 2297 batch loss 1.17439687 epoch total loss 1.13597298
Trained batch 2298 batch loss 1.2211169 epoch total loss 1.13601
Trained batch 2299 batch loss 1.15749967 epoch total loss 1.13601935
Trained batch 2300 batch loss 1.14369965 epoch total loss 1.13602269
Trained batch 2301 batch loss 1.36460423 epoch total loss 1.13612199
Trained batch 2302 batch loss 1.14227772 epoch total loss 1.13612473
Trained batch 2303 batch loss 1.21013832 epoch total loss 1.13615692
Trained batch 2304 batch loss 1.11720574 epoch total loss 1.13614869
Trained batch 2305 batch loss 1.33111072 epoch total loss 1.13623321
Trained batch 2306 batch loss 1.24349988 epoch total loss 1.1362797
Trained batch 2307 batch loss 1.11809325 epoch total loss 1.13627183
Trained batch 2308 batch loss 1.0866605 epoch total loss 1.13625038
Trained batch 2309 batch loss 1.09823823 epoch total loss 1.13623381
Trained batch 2310 batch loss 1.0781759 epoch total loss 1.13620865
Trained batch 2311 batch loss 1.44359446 epoch total loss 1.13634169
Trained batch 2312 batch loss 1.11950207 epoch total loss 1.13633442
Trained batch 2313 batch loss 1.21352196 epoch total loss 1.1363678
Trained batch 2314 batch loss 1.11037815 epoch total loss 1.13635659
Trained batch 2315 batch loss 1.32932782 epoch total loss 1.13643992
Trained batch 2316 batch loss 1.36939168 epoch total loss 1.13654053
Trained batch 2317 batch loss 1.29643404 epoch total loss 1.13660944
Trained batch 2318 batch loss 1.1851207 epoch total loss 1.13663042
Trained batch 2319 batch loss 1.2016753 epoch total loss 1.13665843
Trained batch 2320 batch loss 1.04170084 epoch total loss 1.13661754
Trained batch 2321 batch loss 1.04698753 epoch total loss 1.1365788
Trained batch 2322 batch loss 1.2008549 epoch total loss 1.13660657
Trained batch 2323 batch loss 1.09595394 epoch total loss 1.13658905
Trained batch 2324 batch loss 1.16443944 epoch total loss 1.13660109
Trained batch 2325 batch loss 1.2484014 epoch total loss 1.13664913
Trained batch 2326 batch loss 1.1238445 epoch total loss 1.13664365
Trained batch 2327 batch loss 0.987659097 epoch total loss 1.13657951
Trained batch 2328 batch loss 1.03539491 epoch total loss 1.13653612
Trained batch 2329 batch loss 1.10265017 epoch total loss 1.13652146
Trained batch 2330 batch loss 1.16780829 epoch total loss 1.13653481
Trained batch 2331 batch loss 1.19215441 epoch total loss 1.13655877
Trained batch 2332 batch loss 1.03723788 epoch total loss 1.13651621
Trained batch 2333 batch loss 0.879502296 epoch total loss 1.13640594
Trained batch 2334 batch loss 1.02797151 epoch total loss 1.13635957
Trained batch 2335 batch loss 0.899024 epoch total loss 1.13625789
Trained batch 2336 batch loss 1.10610759 epoch total loss 1.13624501
Trained batch 2337 batch loss 0.970948458 epoch total loss 1.13617432
Trained batch 2338 batch loss 0.837511837 epoch total loss 1.13604653
Trained batch 2339 batch loss 0.703834653 epoch total loss 1.13586175
Trained batch 2340 batch loss 1.27960706 epoch total loss 1.13592315
Trained batch 2341 batch loss 1.13147759 epoch total loss 1.13592124
Trained batch 2342 batch loss 1.02836871 epoch total loss 1.13587534
Trained batch 2343 batch loss 1.27126169 epoch total loss 1.13593304
Trained batch 2344 batch loss 1.27425563 epoch total loss 1.13599205
Trained batch 2345 batch loss 1.09642506 epoch total loss 1.13597524
Trained batch 2346 batch loss 1.32321763 epoch total loss 1.13605499
Trained batch 2347 batch loss 0.975280285 epoch total loss 1.13598657
Trained batch 2348 batch loss 1.0242976 epoch total loss 1.135939
Trained batch 2349 batch loss 1.25697851 epoch total loss 1.13599062
Trained batch 2350 batch loss 1.06025612 epoch total loss 1.13595843
Trained batch 2351 batch loss 1.12739921 epoch total loss 1.13595474
Trained batch 2352 batch loss 1.0545826 epoch total loss 1.13592017
Trained batch 2353 batch loss 1.23844314 epoch total loss 1.1359638
Trained batch 2354 batch loss 1.02192211 epoch total loss 1.1359154
Trained batch 2355 batch loss 1.13794196 epoch total loss 1.13591623
Trained batch 2356 batch loss 1.10373676 epoch total loss 1.13590264
Trained batch 2357 batch loss 1.13999295 epoch total loss 1.13590431
Trained batch 2358 batch loss 1.16140723 epoch total loss 1.13591504
Trained batch 2359 batch loss 1.25571704 epoch total loss 1.13596582
Trained batch 2360 batch loss 1.09012485 epoch total loss 1.13594639
Trained batch 2361 batch loss 1.10643744 epoch total loss 1.13593388
Trained batch 2362 batch loss 1.22330034 epoch total loss 1.13597095
Trained batch 2363 batch loss 1.30798101 epoch total loss 1.13604367
Trained batch 2364 batch loss 1.10348415 epoch total loss 1.13603
Trained batch 2365 batch loss 1.02237654 epoch total loss 1.13598192
Trained batch 2366 batch loss 1.40603614 epoch total loss 1.136096
Trained batch 2367 batch loss 1.39038754 epoch total loss 1.13620341
Trained batch 2368 batch loss 1.55481327 epoch total loss 1.13638031
Trained batch 2369 batch loss 1.1937325 epoch total loss 1.13640451
Trained batch 2370 batch loss 1.24313807 epoch total loss 1.13644958
Trained batch 2371 batch loss 1.23320794 epoch total loss 1.13649035
Trained batch 2372 batch loss 1.354671 epoch total loss 1.13658237
Trained batch 2373 batch loss 1.36474872 epoch total loss 1.13667858
Trained batch 2374 batch loss 1.04865611 epoch total loss 1.13664138
Trained batch 2375 batch loss 1.05569553 epoch total loss 1.13660729
Trained batch 2376 batch loss 0.818139911 epoch total loss 1.1364733
Trained batch 2377 batch loss 1.09978485 epoch total loss 1.13645792
Trained batch 2378 batch loss 1.17238319 epoch total loss 1.13647294
Trained batch 2379 batch loss 1.19533908 epoch total loss 1.13649774
Trained batch 2380 batch loss 1.18289208 epoch total loss 1.13651717
Trained batch 2381 batch loss 1.13320196 epoch total loss 1.13651586
Trained batch 2382 batch loss 1.2749002 epoch total loss 1.13657391
Trained batch 2383 batch loss 0.923218131 epoch total loss 1.1364845
Trained batch 2384 batch loss 1.18955302 epoch total loss 1.13650668
Trained batch 2385 batch loss 1.44843781 epoch total loss 1.13663745
Trained batch 2386 batch loss 1.31268156 epoch total loss 1.13671124
Trained batch 2387 batch loss 1.04233479 epoch total loss 1.13667166
Trained batch 2388 batch loss 1.06281066 epoch total loss 1.13664079
Trained batch 2389 batch loss 1.11248446 epoch total loss 1.13663065
Trained batch 2390 batch loss 1.11854076 epoch total loss 1.13662314
Trained batch 2391 batch loss 1.18496966 epoch total loss 1.13664341
Trained batch 2392 batch loss 1.49525583 epoch total loss 1.13679338
Trained batch 2393 batch loss 1.0266813 epoch total loss 1.13674736
Trained batch 2394 batch loss 1.06418324 epoch total loss 1.13671696
Trained batch 2395 batch loss 1.11619401 epoch total loss 1.1367085
Trained batch 2396 batch loss 1.02690911 epoch total loss 1.1366626
Trained batch 2397 batch loss 1.15911937 epoch total loss 1.13667202
Trained batch 2398 batch loss 1.11434317 epoch total loss 1.1366626
Trained batch 2399 batch loss 1.00819695 epoch total loss 1.1366092
Trained batch 2400 batch loss 1.18295729 epoch total loss 1.13662839
Trained batch 2401 batch loss 1.14368463 epoch total loss 1.13663137
Trained batch 2402 batch loss 1.17794955 epoch total loss 1.13664865
Trained batch 2403 batch loss 1.19195676 epoch total loss 1.13667166
Trained batch 2404 batch loss 1.38866138 epoch total loss 1.13677645
Trained batch 2405 batch loss 1.15098023 epoch total loss 1.13678229
Trained batch 2406 batch loss 0.97755748 epoch total loss 1.13671613
Trained batch 2407 batch loss 1.20283771 epoch total loss 1.13674355
Trained batch 2408 batch loss 1.17745101 epoch total loss 1.13676047
Trained batch 2409 batch loss 1.46948814 epoch total loss 1.13689864
Trained batch 2410 batch loss 1.19814026 epoch total loss 1.13692415
Trained batch 2411 batch loss 1.45022953 epoch total loss 1.13705397
Trained batch 2412 batch loss 1.05335534 epoch total loss 1.1370194
Trained batch 2413 batch loss 1.19763327 epoch total loss 1.13704455
Trained batch 2414 batch loss 1.17052102 epoch total loss 1.13705838
Trained batch 2415 batch loss 1.16644621 epoch total loss 1.13707054
Trained batch 2416 batch loss 1.16049671 epoch total loss 1.13708019
Trained batch 2417 batch loss 1.35021234 epoch total loss 1.13716829
Trained batch 2418 batch loss 1.14400721 epoch total loss 1.13717115
Trained batch 2419 batch loss 1.41098976 epoch total loss 1.1372844
Trained batch 2420 batch loss 1.03977573 epoch total loss 1.13724411
Trained batch 2421 batch loss 1.113837 epoch total loss 1.13723433
Trained batch 2422 batch loss 1.04301369 epoch total loss 1.13719547
Trained batch 2423 batch loss 1.3532964 epoch total loss 1.13728464
Trained batch 2424 batch loss 1.32129562 epoch total loss 1.13736057
Trained batch 2425 batch loss 1.30068445 epoch total loss 1.13742793
Trained batch 2426 batch loss 1.27761531 epoch total loss 1.13748574
Trained batch 2427 batch loss 0.983719707 epoch total loss 1.13742232
Trained batch 2428 batch loss 1.08471847 epoch total loss 1.13740063
Trained batch 2429 batch loss 0.987284899 epoch total loss 1.13733876
Trained batch 2430 batch loss 0.804809 epoch total loss 1.13720191
Trained batch 2431 batch loss 1.05129385 epoch total loss 1.1371665
Trained batch 2432 batch loss 1.16777968 epoch total loss 1.13717914
Trained batch 2433 batch loss 1.17654943 epoch total loss 1.13719535
Trained batch 2434 batch loss 1.32311082 epoch total loss 1.13727164
Trained batch 2435 batch loss 1.25761425 epoch total loss 1.137321
Trained batch 2436 batch loss 1.20332456 epoch total loss 1.13734818
Trained batch 2437 batch loss 1.25832009 epoch total loss 1.13739777
Trained batch 2438 batch loss 1.25034761 epoch total loss 1.13744402
Trained batch 2439 batch loss 1.28651357 epoch total loss 1.13750517
Trained batch 2440 batch loss 1.4600122 epoch total loss 1.13763738
Trained batch 2441 batch loss 1.11783838 epoch total loss 1.13762927
Trained batch 2442 batch loss 1.21328068 epoch total loss 1.13766026
Trained batch 2443 batch loss 1.09597588 epoch total loss 1.13764322
Trained batch 2444 batch loss 1.12727952 epoch total loss 1.13763893
Trained batch 2445 batch loss 1.06570029 epoch total loss 1.13760948
Trained batch 2446 batch loss 0.94247973 epoch total loss 1.13752973
Trained batch 2447 batch loss 1.34566092 epoch total loss 1.13761485
Trained batch 2448 batch loss 1.37604284 epoch total loss 1.13771212
Trained batch 2449 batch loss 1.27321506 epoch total loss 1.13776743
Trained batch 2450 batch loss 1.19658518 epoch total loss 1.13779151
Trained batch 2451 batch loss 1.29858446 epoch total loss 1.13785708
Trained batch 2452 batch loss 1.05230021 epoch total loss 1.13782215
Trained batch 2453 batch loss 1.14160657 epoch total loss 1.1378237
Trained batch 2454 batch loss 1.0908941 epoch total loss 1.13780451
Trained batch 2455 batch loss 1.27238035 epoch total loss 1.13785934
Trained batch 2456 batch loss 1.18480515 epoch total loss 1.13787854
Trained batch 2457 batch loss 1.22038758 epoch total loss 1.13791215
Trained batch 2458 batch loss 1.08715272 epoch total loss 1.13789153
Trained batch 2459 batch loss 1.02729058 epoch total loss 1.13784647
Trained batch 2460 batch loss 1.44166172 epoch total loss 1.13797
Trained batch 2461 batch loss 1.18182051 epoch total loss 1.13798785
Trained batch 2462 batch loss 1.26302803 epoch total loss 1.13803864
Trained batch 2463 batch loss 1.19921899 epoch total loss 1.13806343
Trained batch 2464 batch loss 1.31805754 epoch total loss 1.13813651
Trained batch 2465 batch loss 1.36480927 epoch total loss 1.13822842
Trained batch 2466 batch loss 1.34246576 epoch total loss 1.13831127
Trained batch 2467 batch loss 1.46013474 epoch total loss 1.1384418
Trained batch 2468 batch loss 1.27568614 epoch total loss 1.13849735
Trained batch 2469 batch loss 1.3734566 epoch total loss 1.1385926
Trained batch 2470 batch loss 1.23243594 epoch total loss 1.13863051
Trained batch 2471 batch loss 1.09006143 epoch total loss 1.13861096
Trained batch 2472 batch loss 1.12541616 epoch total loss 1.13860559
Trained batch 2473 batch loss 0.969026566 epoch total loss 1.13853705
Trained batch 2474 batch loss 0.875116348 epoch total loss 1.13843048
Trained batch 2475 batch loss 1.16098738 epoch total loss 1.13843954
Trained batch 2476 batch loss 1.06165099 epoch total loss 1.13840866
Trained batch 2477 batch loss 1.48259604 epoch total loss 1.13854754
Trained batch 2478 batch loss 1.31808782 epoch total loss 1.13862
Trained batch 2479 batch loss 1.17769027 epoch total loss 1.13863587
Trained batch 2480 batch loss 1.20026588 epoch total loss 1.13866067
Trained batch 2481 batch loss 1.08868146 epoch total loss 1.13864052
Trained batch 2482 batch loss 1.24590409 epoch total loss 1.13868368
Trained batch 2483 batch loss 0.751743 epoch total loss 1.13852787
Trained batch 2484 batch loss 1.21570683 epoch total loss 1.13855898
Trained batch 2485 batch loss 1.14925718 epoch total loss 1.13856316
Trained batch 2486 batch loss 1.28253555 epoch total loss 1.13862109
Trained batch 2487 batch loss 1.31468177 epoch total loss 1.1386919
Trained batch 2488 batch loss 1.28365588 epoch total loss 1.1387502
Trained batch 2489 batch loss 1.06449294 epoch total loss 1.13872027
Trained batch 2490 batch loss 1.19993258 epoch total loss 1.13874495
Trained batch 2491 batch loss 1.19386578 epoch total loss 1.138767
Trained batch 2492 batch loss 1.1408813 epoch total loss 1.13876784
Trained batch 2493 batch loss 1.11980629 epoch total loss 1.13876033
Trained batch 2494 batch loss 1.10868907 epoch total loss 1.13874829
Trained batch 2495 batch loss 1.10057056 epoch total loss 1.13873291
Trained batch 2496 batch loss 1.16930723 epoch total loss 1.13874519
Trained batch 2497 batch loss 1.14983463 epoch total loss 1.1387496
Trained batch 2498 batch loss 1.17345357 epoch total loss 1.13876343
Trained batch 2499 batch loss 1.36533046 epoch total loss 1.13885403
Trained batch 2500 batch loss 1.18556499 epoch total loss 1.13887274
Trained batch 2501 batch loss 1.15496445 epoch total loss 1.13887918
Trained batch 2502 batch loss 1.06714833 epoch total loss 1.13885057
Trained batch 2503 batch loss 0.952394724 epoch total loss 1.13877606
Trained batch 2504 batch loss 1.14768445 epoch total loss 1.13877964
Trained batch 2505 batch loss 1.01876891 epoch total loss 1.13873172
Trained batch 2506 batch loss 1.34384251 epoch total loss 1.1388135
Trained batch 2507 batch loss 1.37656987 epoch total loss 1.13890827
Trained batch 2508 batch loss 1.33696938 epoch total loss 1.1389873
Trained batch 2509 batch loss 1.22106028 epoch total loss 1.13902
Trained batch 2510 batch loss 1.09848928 epoch total loss 1.13900375
Trained batch 2511 batch loss 1.16431165 epoch total loss 1.13901389
Trained batch 2512 batch loss 1.22139609 epoch total loss 1.13904667
Trained batch 2513 batch loss 0.980319798 epoch total loss 1.13898349
Trained batch 2514 batch loss 1.25385547 epoch total loss 1.13902915
Trained batch 2515 batch loss 0.925743699 epoch total loss 1.13894439
Trained batch 2516 batch loss 0.882727325 epoch total loss 1.13884258
Trained batch 2517 batch loss 1.18455744 epoch total loss 1.1388607
Trained batch 2518 batch loss 1.24429393 epoch total loss 1.13890266
Trained batch 2519 batch loss 1.23533249 epoch total loss 1.13894093
Trained batch 2520 batch loss 1.07613266 epoch total loss 1.13891602
Trained batch 2521 batch loss 1.24743617 epoch total loss 1.13895905
Trained batch 2522 batch loss 1.28943038 epoch total loss 1.13901877
Trained batch 2523 batch loss 1.24845171 epoch total loss 1.13906217
Trained batch 2524 batch loss 0.993116856 epoch total loss 1.13900435
Trained batch 2525 batch loss 1.28495789 epoch total loss 1.13906217
Trained batch 2526 batch loss 1.25503564 epoch total loss 1.13910806
Trained batch 2527 batch loss 0.989290297 epoch total loss 1.13904881
Trained batch 2528 batch loss 1.12280595 epoch total loss 1.13904238
Trained batch 2529 batch loss 1.04155219 epoch total loss 1.13900375
Trained batch 2530 batch loss 1.00718296 epoch total loss 1.13895166
Trained batch 2531 batch loss 1.11650932 epoch total loss 1.13894272
Trained batch 2532 batch loss 1.16100299 epoch total loss 1.13895142
Trained batch 2533 batch loss 0.95509851 epoch total loss 1.13887882
Trained batch 2534 batch loss 1.17798233 epoch total loss 1.1388942
Trained batch 2535 batch loss 0.986243486 epoch total loss 1.138834
Trained batch 2536 batch loss 0.880319953 epoch total loss 1.13873219
Trained batch 2537 batch loss 0.998583496 epoch total loss 1.13867688
Trained batch 2538 batch loss 0.847082615 epoch total loss 1.13856196
Trained batch 2539 batch loss 0.967370629 epoch total loss 1.13849461
Trained batch 2540 batch loss 0.975183368 epoch total loss 1.13843024
Trained batch 2541 batch loss 0.980156183 epoch total loss 1.13836801
Trained batch 2542 batch loss 1.05622518 epoch total loss 1.13833559
Trained batch 2543 batch loss 1.2246871 epoch total loss 1.13836956
Trained batch 2544 batch loss 1.00977576 epoch total loss 1.13831902
Trained batch 2545 batch loss 1.01702285 epoch total loss 1.13827133
Trained batch 2546 batch loss 0.983284235 epoch total loss 1.13821054
Trained batch 2547 batch loss 1.03746581 epoch total loss 1.13817096
Trained batch 2548 batch loss 0.993670702 epoch total loss 1.13811421
Trained batch 2549 batch loss 1.14145947 epoch total loss 1.13811553
Trained batch 2550 batch loss 0.856184661 epoch total loss 1.1380049
Trained batch 2551 batch loss 0.972461641 epoch total loss 1.13794
Trained batch 2552 batch loss 1.02395487 epoch total loss 1.13789535
Trained batch 2553 batch loss 1.16351581 epoch total loss 1.13790536
Trained batch 2554 batch loss 1.1320945 epoch total loss 1.13790309
Trained batch 2555 batch loss 0.97383374 epoch total loss 1.13783896
Trained batch 2556 batch loss 0.981654286 epoch total loss 1.13777781
Trained batch 2557 batch loss 0.912852287 epoch total loss 1.13768983
Trained batch 2558 batch loss 0.799987197 epoch total loss 1.13755786
Trained batch 2559 batch loss 0.894643545 epoch total loss 1.13746285
Trained batch 2560 batch loss 1.23370099 epoch total loss 1.13750052
Trained batch 2561 batch loss 1.2682054 epoch total loss 1.13755155
Trained batch 2562 batch loss 1.01942241 epoch total loss 1.13750553
Trained batch 2563 batch loss 0.820565939 epoch total loss 1.13738179
Trained batch 2564 batch loss 0.882726133 epoch total loss 1.13728249
Trained batch 2565 batch loss 1.10850739 epoch total loss 1.13727129
Trained batch 2566 batch loss 1.00463498 epoch total loss 1.13721955
Trained batch 2567 batch loss 1.18412828 epoch total loss 1.13723779
Trained batch 2568 batch loss 1.21504736 epoch total loss 1.13726819
Trained batch 2569 batch loss 1.36794388 epoch total loss 1.13735795
Trained batch 2570 batch loss 1.08313251 epoch total loss 1.13733685
Trained batch 2571 batch loss 0.879171 epoch total loss 1.13723648
Trained batch 2572 batch loss 1.5993253 epoch total loss 1.13741612
Trained batch 2573 batch loss 1.24265444 epoch total loss 1.13745701
Trained batch 2574 batch loss 1.17607951 epoch total loss 1.13747203
Trained batch 2575 batch loss 1.26616693 epoch total loss 1.13752198
Trained batch 2576 batch loss 0.943471074 epoch total loss 1.13744664
Trained batch 2577 batch loss 0.925660253 epoch total loss 1.13736451
Trained batch 2578 batch loss 1.17842889 epoch total loss 1.13738048
Trained batch 2579 batch loss 1.08790755 epoch total loss 1.13736129
Trained batch 2580 batch loss 1.00930023 epoch total loss 1.13731158
Trained batch 2581 batch loss 1.04551172 epoch total loss 1.13727593
Trained batch 2582 batch loss 1.16515481 epoch total loss 1.13728678
Trained batch 2583 batch loss 1.38117635 epoch total loss 1.13738108
Trained batch 2584 batch loss 0.992209136 epoch total loss 1.13732493
Trained batch 2585 batch loss 1.16264796 epoch total loss 1.1373347
Trained batch 2586 batch loss 1.17114127 epoch total loss 1.13734782
Trained batch 2587 batch loss 1.1228385 epoch total loss 1.13734221
Trained batch 2588 batch loss 1.05677915 epoch total loss 1.1373111
Trained batch 2589 batch loss 1.09377396 epoch total loss 1.13729429
Trained batch 2590 batch loss 1.03253078 epoch total loss 1.13725376
Trained batch 2591 batch loss 0.808902621 epoch total loss 1.13712704
Trained batch 2592 batch loss 1.04467118 epoch total loss 1.1370914
Trained batch 2593 batch loss 1.00280499 epoch total loss 1.13703954
Trained batch 2594 batch loss 1.03706837 epoch total loss 1.13700104
Trained batch 2595 batch loss 1.33480096 epoch total loss 1.13707721
Trained batch 2596 batch loss 1.08065796 epoch total loss 1.1370554
Trained batch 2597 batch loss 1.34403658 epoch total loss 1.13713515
Trained batch 2598 batch loss 1.12371969 epoch total loss 1.13713
Trained batch 2599 batch loss 1.20936322 epoch total loss 1.1371578
Trained batch 2600 batch loss 1.31875229 epoch total loss 1.13722765
Trained batch 2601 batch loss 1.01538599 epoch total loss 1.13718081
Trained batch 2602 batch loss 1.07774878 epoch total loss 1.13715792
Trained batch 2603 batch loss 1.10307777 epoch total loss 1.1371448
Trained batch 2604 batch loss 0.957911253 epoch total loss 1.13707602
Trained batch 2605 batch loss 0.993685722 epoch total loss 1.13702095
Trained batch 2606 batch loss 1.33354092 epoch total loss 1.13709641
Trained batch 2607 batch loss 0.895172 epoch total loss 1.13700366
Trained batch 2608 batch loss 0.887975812 epoch total loss 1.13690817
Trained batch 2609 batch loss 0.878788829 epoch total loss 1.13680923
Trained batch 2610 batch loss 1.04955435 epoch total loss 1.13677585
Trained batch 2611 batch loss 0.944371283 epoch total loss 1.13670206
Trained batch 2612 batch loss 1.05977714 epoch total loss 1.13667262
Trained batch 2613 batch loss 1.12172914 epoch total loss 1.13666701
Trained batch 2614 batch loss 0.967579246 epoch total loss 1.13660228
Trained batch 2615 batch loss 1.20214832 epoch total loss 1.13662732
Trained batch 2616 batch loss 0.978828073 epoch total loss 1.136567
Trained batch 2617 batch loss 0.983817577 epoch total loss 1.1365087
Trained batch 2618 batch loss 1.10600793 epoch total loss 1.13649702
Trained batch 2619 batch loss 1.14048231 epoch total loss 1.13649845
Trained batch 2620 batch loss 1.05092871 epoch total loss 1.13646591
Trained batch 2621 batch loss 1.30597222 epoch total loss 1.13653052
Trained batch 2622 batch loss 0.969138741 epoch total loss 1.13646674
Trained batch 2623 batch loss 1.2120899 epoch total loss 1.13649559
Trained batch 2624 batch loss 1.07566524 epoch total loss 1.13647234
Trained batch 2625 batch loss 1.07212782 epoch total loss 1.13644779
Trained batch 2626 batch loss 1.0755924 epoch total loss 1.13642466
Trained batch 2627 batch loss 1.04328799 epoch total loss 1.13638926
Trained batch 2628 batch loss 1.14785063 epoch total loss 1.13639355
Trained batch 2629 batch loss 1.36461067 epoch total loss 1.13648033
Trained batch 2630 batch loss 1.49170971 epoch total loss 1.1366154
Trained batch 2631 batch loss 1.15979171 epoch total loss 1.13662434
Trained batch 2632 batch loss 1.23661828 epoch total loss 1.13666224
Trained batch 2633 batch loss 1.04065812 epoch total loss 1.13662589
Trained batch 2634 batch loss 1.26369727 epoch total loss 1.13667405
Trained batch 2635 batch loss 1.13445866 epoch total loss 1.13667321
Trained batch 2636 batch loss 1.35252035 epoch total loss 1.13675511
Trained batch 2637 batch loss 1.16590023 epoch total loss 1.1367662
Trained batch 2638 batch loss 1.18693066 epoch total loss 1.13678527
Trained batch 2639 batch loss 0.899422884 epoch total loss 1.13669538
Trained batch 2640 batch loss 0.952425718 epoch total loss 1.13662553
Trained batch 2641 batch loss 1.37525463 epoch total loss 1.13671589
Trained batch 2642 batch loss 1.08170843 epoch total loss 1.13669515
Trained batch 2643 batch loss 1.28899348 epoch total loss 1.13675272
Trained batch 2644 batch loss 1.31959796 epoch total loss 1.13682187
Trained batch 2645 batch loss 0.892242432 epoch total loss 1.13672948
Trained batch 2646 batch loss 1.12493491 epoch total loss 1.13672507
Trained batch 2647 batch loss 1.13819242 epoch total loss 1.13672554
Trained batch 2648 batch loss 0.965383172 epoch total loss 1.13666081
Trained batch 2649 batch loss 1.0758034 epoch total loss 1.13663781
Trained batch 2650 batch loss 1.17217636 epoch total loss 1.13665128
Trained batch 2651 batch loss 1.04118013 epoch total loss 1.13661528
Trained batch 2652 batch loss 1.0703187 epoch total loss 1.13659024
Trained batch 2653 batch loss 1.20482206 epoch total loss 1.13661599
Trained batch 2654 batch loss 1.19345379 epoch total loss 1.13663733
Trained batch 2655 batch loss 1.29019105 epoch total loss 1.13669527
Trained batch 2656 batch loss 1.22183013 epoch total loss 1.13672733
Trained batch 2657 batch loss 1.1927042 epoch total loss 1.13674831
Trained batch 2658 batch loss 1.20401859 epoch total loss 1.13677371
Trained batch 2659 batch loss 1.36555362 epoch total loss 1.13685966
Trained batch 2660 batch loss 1.27759314 epoch total loss 1.13691258
Trained batch 2661 batch loss 1.18421245 epoch total loss 1.13693047
Trained batch 2662 batch loss 1.2450707 epoch total loss 1.136971
Trained batch 2663 batch loss 1.27980828 epoch total loss 1.13702464
Trained batch 2664 batch loss 1.29488599 epoch total loss 1.13708401
Trained batch 2665 batch loss 1.32267189 epoch total loss 1.13715363
Trained batch 2666 batch loss 0.868620038 epoch total loss 1.13705289
Trained batch 2667 batch loss 1.02316785 epoch total loss 1.13701022
Trained batch 2668 batch loss 1.03931904 epoch total loss 1.13697362
Trained batch 2669 batch loss 1.08854342 epoch total loss 1.1369555
Trained batch 2670 batch loss 1.09875429 epoch total loss 1.13694108
Trained batch 2671 batch loss 1.16320527 epoch total loss 1.13695097
Trained batch 2672 batch loss 1.20865548 epoch total loss 1.13697779
Trained batch 2673 batch loss 1.44290709 epoch total loss 1.13709223
Trained batch 2674 batch loss 1.30920482 epoch total loss 1.13715661
Trained batch 2675 batch loss 1.21661639 epoch total loss 1.13718629
Trained batch 2676 batch loss 1.20974588 epoch total loss 1.13721347
Trained batch 2677 batch loss 1.26589811 epoch total loss 1.13726151
Trained batch 2678 batch loss 1.24048209 epoch total loss 1.1373
Trained batch 2679 batch loss 1.4402895 epoch total loss 1.13741302
Trained batch 2680 batch loss 1.24951553 epoch total loss 1.13745487
Trained batch 2681 batch loss 1.10469103 epoch total loss 1.13744271
Trained batch 2682 batch loss 1.3007834 epoch total loss 1.13750362
Trained batch 2683 batch loss 1.09567857 epoch total loss 1.13748801
Trained batch 2684 batch loss 0.861817837 epoch total loss 1.13738537
Trained batch 2685 batch loss 1.03004181 epoch total loss 1.13734531
Trained batch 2686 batch loss 1.17648566 epoch total loss 1.13735986
Trained batch 2687 batch loss 0.979587615 epoch total loss 1.13730121
Trained batch 2688 batch loss 1.04682446 epoch total loss 1.13726747
Trained batch 2689 batch loss 1.17235744 epoch total loss 1.13728058
Trained batch 2690 batch loss 1.18061209 epoch total loss 1.13729668
Trained batch 2691 batch loss 1.33524036 epoch total loss 1.13737023
Trained batch 2692 batch loss 1.26348805 epoch total loss 1.13741708
Trained batch 2693 batch loss 1.12551975 epoch total loss 1.13741267
Trained batch 2694 batch loss 1.22428572 epoch total loss 1.13744497
Trained batch 2695 batch loss 1.20734811 epoch total loss 1.13747084
Trained batch 2696 batch loss 1.13501453 epoch total loss 1.13746989
Trained batch 2697 batch loss 1.12182212 epoch total loss 1.13746417
Trained batch 2698 batch loss 1.10904717 epoch total loss 1.13745356
Trained batch 2699 batch loss 1.07742584 epoch total loss 1.13743138
Trained batch 2700 batch loss 0.986194968 epoch total loss 1.13737535
Trained batch 2701 batch loss 1.04857647 epoch total loss 1.13734245
Trained batch 2702 batch loss 1.1000278 epoch total loss 1.13732862
Trained batch 2703 batch loss 1.02390921 epoch total loss 1.13728666
Trained batch 2704 batch loss 1.14299273 epoch total loss 1.13728881
Trained batch 2705 batch loss 1.23329425 epoch total loss 1.13732433
Trained batch 2706 batch loss 1.30703008 epoch total loss 1.13738716
Trained batch 2707 batch loss 1.18403339 epoch total loss 1.13740432
Trained batch 2708 batch loss 1.26176715 epoch total loss 1.13745022
Trained batch 2709 batch loss 1.21263242 epoch total loss 1.13747799
Trained batch 2710 batch loss 1.22223353 epoch total loss 1.13750923
Trained batch 2711 batch loss 0.959547877 epoch total loss 1.13744366
Trained batch 2712 batch loss 0.987771034 epoch total loss 1.13738847
Trained batch 2713 batch loss 1.19046664 epoch total loss 1.13740802
Trained batch 2714 batch loss 1.23440146 epoch total loss 1.13744366
Trained batch 2715 batch loss 1.41330934 epoch total loss 1.13754535
Trained batch 2716 batch loss 0.977705777 epoch total loss 1.13748646
Trained batch 2717 batch loss 0.969833136 epoch total loss 1.13742471
Trained batch 2718 batch loss 0.956222117 epoch total loss 1.13735807
Trained batch 2719 batch loss 0.970689833 epoch total loss 1.1372968
Trained batch 2720 batch loss 1.26252425 epoch total loss 1.13734281
Trained batch 2721 batch loss 1.28790307 epoch total loss 1.13739812
Trained batch 2722 batch loss 1.21968699 epoch total loss 1.1374284
Trained batch 2723 batch loss 1.12809169 epoch total loss 1.13742495
Trained batch 2724 batch loss 1.10046363 epoch total loss 1.13741136
Trained batch 2725 batch loss 1.1698302 epoch total loss 1.13742328
Trained batch 2726 batch loss 1.03343904 epoch total loss 1.13738513
Trained batch 2727 batch loss 1.10449445 epoch total loss 1.13737309
Trained batch 2728 batch loss 1.0414573 epoch total loss 1.13733792
Trained batch 2729 batch loss 1.07135737 epoch total loss 1.13731372
Trained batch 2730 batch loss 1.12918103 epoch total loss 1.13731074
Trained batch 2731 batch loss 1.16266251 epoch total loss 1.13732
Trained batch 2732 batch loss 1.01562738 epoch total loss 1.13727546
Trained batch 2733 batch loss 1.12067389 epoch total loss 1.13726938
Trained batch 2734 batch loss 1.13752961 epoch total loss 1.1372695
Trained batch 2735 batch loss 1.26225543 epoch total loss 1.13731515
Trained batch 2736 batch loss 1.07691884 epoch total loss 1.1372931
Trained batch 2737 batch loss 1.09238803 epoch total loss 1.13727665
Trained batch 2738 batch loss 1.1661551 epoch total loss 1.13728714
Trained batch 2739 batch loss 1.23088932 epoch total loss 1.13732135
Trained batch 2740 batch loss 1.27822506 epoch total loss 1.13737285
Trained batch 2741 batch loss 1.24192858 epoch total loss 1.137411
Trained batch 2742 batch loss 1.35237753 epoch total loss 1.13748932
Trained batch 2743 batch loss 0.941637456 epoch total loss 1.13741803
Trained batch 2744 batch loss 0.946430802 epoch total loss 1.13734841
Trained batch 2745 batch loss 1.17463899 epoch total loss 1.137362
Trained batch 2746 batch loss 0.936143756 epoch total loss 1.13728869
Trained batch 2747 batch loss 1.03916109 epoch total loss 1.13725293
Trained batch 2748 batch loss 1.13336825 epoch total loss 1.1372515
Trained batch 2749 batch loss 0.908165932 epoch total loss 1.13716817
Trained batch 2750 batch loss 0.95022887 epoch total loss 1.1371001
Trained batch 2751 batch loss 0.918030202 epoch total loss 1.13702047
Trained batch 2752 batch loss 1.02254128 epoch total loss 1.13697886
Trained batch 2753 batch loss 0.998279452 epoch total loss 1.13692844
Trained batch 2754 batch loss 0.927161336 epoch total loss 1.13685238
Trained batch 2755 batch loss 0.856656671 epoch total loss 1.1367507
Trained batch 2756 batch loss 0.968517184 epoch total loss 1.13668966
Trained batch 2757 batch loss 0.920681 epoch total loss 1.13661122
Trained batch 2758 batch loss 1.01963043 epoch total loss 1.13656878
Trained batch 2759 batch loss 0.848558187 epoch total loss 1.13646448
Trained batch 2760 batch loss 1.2760613 epoch total loss 1.13651502
Trained batch 2761 batch loss 1.16251922 epoch total loss 1.13652444
Trained batch 2762 batch loss 0.865581036 epoch total loss 1.13642633
Trained batch 2763 batch loss 0.960994959 epoch total loss 1.13636279
Trained batch 2764 batch loss 1.10902882 epoch total loss 1.13635302
Trained batch 2765 batch loss 1.17518151 epoch total loss 1.13636708
Trained batch 2766 batch loss 1.11419153 epoch total loss 1.1363591
Trained batch 2767 batch loss 1.021891 epoch total loss 1.13631773
Trained batch 2768 batch loss 1.11341238 epoch total loss 1.1363095
Trained batch 2769 batch loss 1.00675082 epoch total loss 1.13626277
Trained batch 2770 batch loss 0.958788276 epoch total loss 1.13619864
Trained batch 2771 batch loss 0.892833471 epoch total loss 1.13611078
Trained batch 2772 batch loss 0.724033833 epoch total loss 1.13596225
Trained batch 2773 batch loss 0.815962 epoch total loss 1.13584673
Trained batch 2774 batch loss 1.03831601 epoch total loss 1.13581169
Trained batch 2775 batch loss 0.972757578 epoch total loss 1.1357528
Trained batch 2776 batch loss 1.02506208 epoch total loss 1.13571298
Trained batch 2777 batch loss 1.21062589 epoch total loss 1.13574
Trained batch 2778 batch loss 1.10706234 epoch total loss 1.13572967
Trained batch 2779 batch loss 1.25204349 epoch total loss 1.13577151
Trained batch 2780 batch loss 0.917079091 epoch total loss 1.13569283
Trained batch 2781 batch loss 1.19335115 epoch total loss 1.13571358
Trained batch 2782 batch loss 1.14050162 epoch total loss 1.13571525
Trained batch 2783 batch loss 1.24566948 epoch total loss 1.1357547
Trained batch 2784 batch loss 1.07183611 epoch total loss 1.1357317
Trained batch 2785 batch loss 0.955789685 epoch total loss 1.1356672
Trained batch 2786 batch loss 0.820155621 epoch total loss 1.13555384
Trained batch 2787 batch loss 0.992819071 epoch total loss 1.1355027
Trained batch 2788 batch loss 0.9498595 epoch total loss 1.13543618
Trained batch 2789 batch loss 0.882521391 epoch total loss 1.13534546
Trained batch 2790 batch loss 1.22752 epoch total loss 1.13537848
Trained batch 2791 batch loss 1.17266929 epoch total loss 1.13539183
Trained batch 2792 batch loss 1.25732398 epoch total loss 1.13543558
Trained batch 2793 batch loss 1.28050399 epoch total loss 1.13548744
Trained batch 2794 batch loss 1.18131828 epoch total loss 1.13550389
Trained batch 2795 batch loss 1.19860935 epoch total loss 1.13552654
Trained batch 2796 batch loss 1.26059306 epoch total loss 1.13557124
Trained batch 2797 batch loss 1.12628698 epoch total loss 1.1355679
Trained batch 2798 batch loss 1.30895078 epoch total loss 1.13562977
Trained batch 2799 batch loss 1.22534585 epoch total loss 1.13566184
Trained batch 2800 batch loss 1.1306833 epoch total loss 1.13566
Trained batch 2801 batch loss 1.21754789 epoch total loss 1.13568926
Trained batch 2802 batch loss 1.25751889 epoch total loss 1.13573277
Trained batch 2803 batch loss 1.04782093 epoch total loss 1.13570142
Trained batch 2804 batch loss 1.13625908 epoch total loss 1.13570166
Trained batch 2805 batch loss 1.06077862 epoch total loss 1.13567495
Trained batch 2806 batch loss 1.06918049 epoch total loss 1.13565123
Trained batch 2807 batch loss 1.11759901 epoch total loss 1.13564479
Trained batch 2808 batch loss 1.15666962 epoch total loss 1.1356523
Trained batch 2809 batch loss 1.27071428 epoch total loss 1.13570035
Trained batch 2810 batch loss 1.1703192 epoch total loss 1.13571274
Trained batch 2811 batch loss 1.13882184 epoch total loss 1.13571382
Trained batch 2812 batch loss 1.12769151 epoch total loss 1.13571107
Trained batch 2813 batch loss 1.22370148 epoch total loss 1.13574231
Trained batch 2814 batch loss 1.24432302 epoch total loss 1.13578093
Trained batch 2815 batch loss 1.16446471 epoch total loss 1.13579106
Trained batch 2816 batch loss 1.27389145 epoch total loss 1.13584018
Trained batch 2817 batch loss 1.23543131 epoch total loss 1.13587546
Trained batch 2818 batch loss 1.25828791 epoch total loss 1.13591897
Trained batch 2819 batch loss 1.30465245 epoch total loss 1.13597882
Trained batch 2820 batch loss 0.953702211 epoch total loss 1.13591409
Trained batch 2821 batch loss 1.16301513 epoch total loss 1.13592374
Trained batch 2822 batch loss 1.04734397 epoch total loss 1.13589239
Trained batch 2823 batch loss 0.988315821 epoch total loss 1.13584
Trained batch 2824 batch loss 0.973287 epoch total loss 1.1357826
Trained batch 2825 batch loss 1.00373721 epoch total loss 1.13573575
Trained batch 2826 batch loss 1.0930903 epoch total loss 1.13572073
Trained batch 2827 batch loss 1.13062918 epoch total loss 1.13571882
Trained batch 2828 batch loss 1.08118498 epoch total loss 1.13569963
Trained batch 2829 batch loss 1.05461061 epoch total loss 1.13567102
Trained batch 2830 batch loss 1.04844 epoch total loss 1.13564014
Trained batch 2831 batch loss 1.03830063 epoch total loss 1.13560581
Trained batch 2832 batch loss 1.08450007 epoch total loss 1.13558769
Trained batch 2833 batch loss 1.11023879 epoch total loss 1.13557875
Trained batch 2834 batch loss 1.05964577 epoch total loss 1.13555193
Trained batch 2835 batch loss 1.23516321 epoch total loss 1.1355871
Trained batch 2836 batch loss 0.95743382 epoch total loss 1.13552427
Trained batch 2837 batch loss 0.858598351 epoch total loss 1.13542676
Trained batch 2838 batch loss 0.747853637 epoch total loss 1.13529015
Trained batch 2839 batch loss 1.04127753 epoch total loss 1.13525701
Trained batch 2840 batch loss 0.871458054 epoch total loss 1.13516402
Trained batch 2841 batch loss 1.22165501 epoch total loss 1.13519454
Trained batch 2842 batch loss 1.11941838 epoch total loss 1.13518894
Trained batch 2843 batch loss 1.15943491 epoch total loss 1.13519752
Trained batch 2844 batch loss 0.969162583 epoch total loss 1.13513911
Trained batch 2845 batch loss 1.31759071 epoch total loss 1.13520324
Trained batch 2846 batch loss 1.15348375 epoch total loss 1.13520968
Trained batch 2847 batch loss 1.06066179 epoch total loss 1.13518345
Trained batch 2848 batch loss 0.906036377 epoch total loss 1.13510299
Trained batch 2849 batch loss 0.793526649 epoch total loss 1.13498306
Trained batch 2850 batch loss 0.987923861 epoch total loss 1.13493156
Trained batch 2851 batch loss 1.22086787 epoch total loss 1.13496172
Trained batch 2852 batch loss 1.16755569 epoch total loss 1.13497317
Trained batch 2853 batch loss 1.05605841 epoch total loss 1.13494551
Trained batch 2854 batch loss 1.18923867 epoch total loss 1.13496447
Trained batch 2855 batch loss 0.928887486 epoch total loss 1.13489234
Trained batch 2856 batch loss 0.869184 epoch total loss 1.13479936
Trained batch 2857 batch loss 1.0395112 epoch total loss 1.13476598
Trained batch 2858 batch loss 0.850837052 epoch total loss 1.13466656
Trained batch 2859 batch loss 0.971397 epoch total loss 1.13460958
Trained batch 2860 batch loss 1.14318562 epoch total loss 1.13461244
Trained batch 2861 batch loss 1.06442904 epoch total loss 1.134588
Trained batch 2862 batch loss 1.08116627 epoch total loss 1.13456929
Trained batch 2863 batch loss 1.2453177 epoch total loss 1.13460791
Trained batch 2864 batch loss 1.03313756 epoch total loss 1.13457251
Trained batch 2865 batch loss 0.923653841 epoch total loss 1.13449895
Trained batch 2866 batch loss 1.03805542 epoch total loss 1.13446522
Trained batch 2867 batch loss 0.939860582 epoch total loss 1.13439739
Trained batch 2868 batch loss 0.940368891 epoch total loss 1.1343298
Trained batch 2869 batch loss 1.14111352 epoch total loss 1.13433218
Trained batch 2870 batch loss 1.51079655 epoch total loss 1.13446331
Trained batch 2871 batch loss 1.33936357 epoch total loss 1.13453472
Trained batch 2872 batch loss 1.32970762 epoch total loss 1.13460255
Trained batch 2873 batch loss 1.34790623 epoch total loss 1.13467681
Trained batch 2874 batch loss 1.62444162 epoch total loss 1.13484728
Trained batch 2875 batch loss 1.4805057 epoch total loss 1.13496745
Trained batch 2876 batch loss 1.41366947 epoch total loss 1.13506436
Trained batch 2877 batch loss 0.925592244 epoch total loss 1.13499153
Trained batch 2878 batch loss 0.893994629 epoch total loss 1.13490784
Trained batch 2879 batch loss 0.983263552 epoch total loss 1.13485503
Trained batch 2880 batch loss 1.16938436 epoch total loss 1.13486707
Trained batch 2881 batch loss 1.09289908 epoch total loss 1.13485253
Trained batch 2882 batch loss 0.906322777 epoch total loss 1.13477325
Trained batch 2883 batch loss 1.12633133 epoch total loss 1.13477027
Trained batch 2884 batch loss 0.793910146 epoch total loss 1.13465214
Trained batch 2885 batch loss 0.780551672 epoch total loss 1.13452935
Trained batch 2886 batch loss 0.766299188 epoch total loss 1.1344018
Trained batch 2887 batch loss 0.985353827 epoch total loss 1.13435018
Trained batch 2888 batch loss 1.03719139 epoch total loss 1.13431644
Trained batch 2889 batch loss 0.989840746 epoch total loss 1.1342665
Trained batch 2890 batch loss 1.25541162 epoch total loss 1.13430834
Trained batch 2891 batch loss 1.20122778 epoch total loss 1.13433146
Trained batch 2892 batch loss 1.10583591 epoch total loss 1.13432169
Trained batch 2893 batch loss 1.14997125 epoch total loss 1.13432705
Trained batch 2894 batch loss 1.08410978 epoch total loss 1.13430977
Trained batch 2895 batch loss 1.14828753 epoch total loss 1.13431454
Trained batch 2896 batch loss 1.32199192 epoch total loss 1.13437939
Trained batch 2897 batch loss 1.30871594 epoch total loss 1.13443959
Trained batch 2898 batch loss 1.59002697 epoch total loss 1.13459682
Trained batch 2899 batch loss 1.34799719 epoch total loss 1.13467038
Trained batch 2900 batch loss 1.07628226 epoch total loss 1.13465023
Trained batch 2901 batch loss 1.15943408 epoch total loss 1.13465869
Trained batch 2902 batch loss 1.05822897 epoch total loss 1.13463247
Trained batch 2903 batch loss 1.31440926 epoch total loss 1.13469434
Trained batch 2904 batch loss 1.23164368 epoch total loss 1.13472784
Trained batch 2905 batch loss 1.07791281 epoch total loss 1.13470817
Trained batch 2906 batch loss 1.07421815 epoch total loss 1.13468742
Trained batch 2907 batch loss 1.08520806 epoch total loss 1.13467038
Trained batch 2908 batch loss 1.19143033 epoch total loss 1.13468993
Trained batch 2909 batch loss 1.2398808 epoch total loss 1.13472605
Trained batch 2910 batch loss 1.1734376 epoch total loss 1.1347394
Trained batch 2911 batch loss 1.29005337 epoch total loss 1.13479269
Trained batch 2912 batch loss 0.952865183 epoch total loss 1.13473022
Trained batch 2913 batch loss 0.964766324 epoch total loss 1.13467193
Trained batch 2914 batch loss 0.941038966 epoch total loss 1.13460541
Trained batch 2915 batch loss 1.1725446 epoch total loss 1.13461852
Trained batch 2916 batch loss 1.1789397 epoch total loss 1.13463366
Trained batch 2917 batch loss 1.19820237 epoch total loss 1.13465548
Trained batch 2918 batch loss 1.04192877 epoch total loss 1.13462377
Trained batch 2919 batch loss 1.08432102 epoch total loss 1.13460648
Trained batch 2920 batch loss 1.17829549 epoch total loss 1.13462138
Trained batch 2921 batch loss 1.09184027 epoch total loss 1.13460672
Trained batch 2922 batch loss 0.917773426 epoch total loss 1.13453257
Trained batch 2923 batch loss 1.11056411 epoch total loss 1.13452435
Trained batch 2924 batch loss 1.08921528 epoch total loss 1.13450885
Trained batch 2925 batch loss 1.4007591 epoch total loss 1.1345998
Trained batch 2926 batch loss 1.28657675 epoch total loss 1.13465178
Trained batch 2927 batch loss 1.37224817 epoch total loss 1.13473296
Trained batch 2928 batch loss 1.37171698 epoch total loss 1.13481402
Trained batch 2929 batch loss 1.26537216 epoch total loss 1.13485861
Trained batch 2930 batch loss 1.05823374 epoch total loss 1.1348325
Trained batch 2931 batch loss 1.25997233 epoch total loss 1.13487518
Trained batch 2932 batch loss 1.27973008 epoch total loss 1.13492453
Trained batch 2933 batch loss 1.16105199 epoch total loss 1.13493347
Trained batch 2934 batch loss 1.21555495 epoch total loss 1.13496101
Trained batch 2935 batch loss 0.946060598 epoch total loss 1.13489664
Trained batch 2936 batch loss 0.812609315 epoch total loss 1.13478684
Trained batch 2937 batch loss 0.831889093 epoch total loss 1.13468361
Trained batch 2938 batch loss 0.98510015 epoch total loss 1.13463271
Trained batch 2939 batch loss 1.07307494 epoch total loss 1.13461173
Trained batch 2940 batch loss 1.23996222 epoch total loss 1.13464761
Trained batch 2941 batch loss 0.989814639 epoch total loss 1.13459837
Trained batch 2942 batch loss 0.994139552 epoch total loss 1.13455057
Trained batch 2943 batch loss 0.87140274 epoch total loss 1.13446116
Trained batch 2944 batch loss 0.883598089 epoch total loss 1.13437593
Trained batch 2945 batch loss 0.849064 epoch total loss 1.13427913
Trained batch 2946 batch loss 1.1627779 epoch total loss 1.13428879
Trained batch 2947 batch loss 1.04173815 epoch total loss 1.13425744
Trained batch 2948 batch loss 1.24019861 epoch total loss 1.13429332
Trained batch 2949 batch loss 1.35442793 epoch total loss 1.13436794
Trained batch 2950 batch loss 1.57939529 epoch total loss 1.13451886
Trained batch 2951 batch loss 1.52452 epoch total loss 1.13465095
Trained batch 2952 batch loss 1.41453409 epoch total loss 1.13474572
Trained batch 2953 batch loss 1.42473531 epoch total loss 1.13484395
Trained batch 2954 batch loss 1.46409965 epoch total loss 1.13495553
Trained batch 2955 batch loss 1.521451 epoch total loss 1.1350863
Trained batch 2956 batch loss 1.34358382 epoch total loss 1.13515675
Trained batch 2957 batch loss 1.33722591 epoch total loss 1.13522506
Trained batch 2958 batch loss 1.39658 epoch total loss 1.13531339
Trained batch 2959 batch loss 1.38468957 epoch total loss 1.13539767
Trained batch 2960 batch loss 1.28840077 epoch total loss 1.13544941
Trained batch 2961 batch loss 1.15516806 epoch total loss 1.13545609
Trained batch 2962 batch loss 0.895089507 epoch total loss 1.1353749
Trained batch 2963 batch loss 0.901051879 epoch total loss 1.13529587
Trained batch 2964 batch loss 1.12620091 epoch total loss 1.13529277
Trained batch 2965 batch loss 1.12813878 epoch total loss 1.13529038
Trained batch 2966 batch loss 1.20507121 epoch total loss 1.13531387
Trained batch 2967 batch loss 1.17295671 epoch total loss 1.1353265
Trained batch 2968 batch loss 1.01609564 epoch total loss 1.13528645
Trained batch 2969 batch loss 0.997078896 epoch total loss 1.13523984
Trained batch 2970 batch loss 0.878397 epoch total loss 1.13515341
Trained batch 2971 batch loss 1.04806328 epoch total loss 1.13512409
Trained batch 2972 batch loss 1.08683622 epoch total loss 1.13510787
Trained batch 2973 batch loss 1.20096874 epoch total loss 1.13513
Trained batch 2974 batch loss 1.39855123 epoch total loss 1.1352185
Trained batch 2975 batch loss 1.20620358 epoch total loss 1.13524246
Trained batch 2976 batch loss 1.18289924 epoch total loss 1.13525844
Trained batch 2977 batch loss 1.27619612 epoch total loss 1.13530576
Trained batch 2978 batch loss 1.13464808 epoch total loss 1.13530552
Trained batch 2979 batch loss 1.12604856 epoch total loss 1.13530242
Trained batch 2980 batch loss 1.21876717 epoch total loss 1.13533044
Trained batch 2981 batch loss 1.14958501 epoch total loss 1.13533521
Trained batch 2982 batch loss 1.05081952 epoch total loss 1.13530684
Trained batch 2983 batch loss 1.3832469 epoch total loss 1.13539
Trained batch 2984 batch loss 1.1478138 epoch total loss 1.1353941
Trained batch 2985 batch loss 1.18386912 epoch total loss 1.13541043
Trained batch 2986 batch loss 1.32945347 epoch total loss 1.13547528
Trained batch 2987 batch loss 1.03620911 epoch total loss 1.13544202
Trained batch 2988 batch loss 1.21398032 epoch total loss 1.13546836
Trained batch 2989 batch loss 1.34526169 epoch total loss 1.13553846
Trained batch 2990 batch loss 1.40266013 epoch total loss 1.13562775
Trained batch 2991 batch loss 1.40022111 epoch total loss 1.1357162
Trained batch 2992 batch loss 1.2879777 epoch total loss 1.1357671
Trained batch 2993 batch loss 1.28640866 epoch total loss 1.13581753
Trained batch 2994 batch loss 1.36142123 epoch total loss 1.13589275
Trained batch 2995 batch loss 1.13246429 epoch total loss 1.13589168
Trained batch 2996 batch loss 1.38867 epoch total loss 1.13597608
Trained batch 2997 batch loss 1.42968798 epoch total loss 1.13607407
Trained batch 2998 batch loss 1.51476359 epoch total loss 1.13620031
Trained batch 2999 batch loss 1.17110348 epoch total loss 1.13621199
Trained batch 3000 batch loss 1.23411965 epoch total loss 1.13624465
Trained batch 3001 batch loss 0.922164202 epoch total loss 1.13617325
Trained batch 3002 batch loss 1.19126892 epoch total loss 1.13619161
Trained batch 3003 batch loss 1.16376138 epoch total loss 1.13620079
Trained batch 3004 batch loss 1.20005798 epoch total loss 1.136222
Trained batch 3005 batch loss 1.04372382 epoch total loss 1.13619125
Trained batch 3006 batch loss 1.17167366 epoch total loss 1.13620305
Trained batch 3007 batch loss 1.15147591 epoch total loss 1.13620806
Trained batch 3008 batch loss 1.03991222 epoch total loss 1.13617599
Trained batch 3009 batch loss 1.07134187 epoch total loss 1.13615441
Trained batch 3010 batch loss 1.05907965 epoch total loss 1.13612878
Trained batch 3011 batch loss 0.872311175 epoch total loss 1.13604116
Trained batch 3012 batch loss 1.17101908 epoch total loss 1.13605285
Trained batch 3013 batch loss 1.26622689 epoch total loss 1.136096
Trained batch 3014 batch loss 1.23040855 epoch total loss 1.13612723
Trained batch 3015 batch loss 1.45601964 epoch total loss 1.13623333
Trained batch 3016 batch loss 1.36156774 epoch total loss 1.13630807
Trained batch 3017 batch loss 1.30982137 epoch total loss 1.13636565
Trained batch 3018 batch loss 1.03784013 epoch total loss 1.13633299
Trained batch 3019 batch loss 1.07489812 epoch total loss 1.1363126
Trained batch 3020 batch loss 1.06040835 epoch total loss 1.13628745
Trained batch 3021 batch loss 1.20795584 epoch total loss 1.13631117
Trained batch 3022 batch loss 1.05969405 epoch total loss 1.1362859
Trained batch 3023 batch loss 1.11092865 epoch total loss 1.13627744
Trained batch 3024 batch loss 1.10041797 epoch total loss 1.13626564
Trained batch 3025 batch loss 1.08051515 epoch total loss 1.13624716
Trained batch 3026 batch loss 1.14834368 epoch total loss 1.13625121
Trained batch 3027 batch loss 1.15661442 epoch total loss 1.13625789
Trained batch 3028 batch loss 1.0923506 epoch total loss 1.13624334
Trained batch 3029 batch loss 0.871858597 epoch total loss 1.13615608
Trained batch 3030 batch loss 1.11224031 epoch total loss 1.13614821
Trained batch 3031 batch loss 1.1690805 epoch total loss 1.13615906
Trained batch 3032 batch loss 1.11963117 epoch total loss 1.1361537
Trained batch 3033 batch loss 1.08467782 epoch total loss 1.13613665
Trained batch 3034 batch loss 1.09768414 epoch total loss 1.13612401
Trained batch 3035 batch loss 1.1035372 epoch total loss 1.13611329
Trained batch 3036 batch loss 1.11316323 epoch total loss 1.13610578
Trained batch 3037 batch loss 1.0896275 epoch total loss 1.1360904
Trained batch 3038 batch loss 1.02793 epoch total loss 1.13605475
Trained batch 3039 batch loss 1.09047031 epoch total loss 1.13603985
Trained batch 3040 batch loss 0.983546 epoch total loss 1.13598967
Trained batch 3041 batch loss 1.37225807 epoch total loss 1.13606739
Trained batch 3042 batch loss 1.2531898 epoch total loss 1.1361059
Trained batch 3043 batch loss 1.25481665 epoch total loss 1.136145
Trained batch 3044 batch loss 1.24060202 epoch total loss 1.13617933
Trained batch 3045 batch loss 1.24326015 epoch total loss 1.13621438
Trained batch 3046 batch loss 1.01273108 epoch total loss 1.13617384
Trained batch 3047 batch loss 1.18908906 epoch total loss 1.13619125
Trained batch 3048 batch loss 1.24241877 epoch total loss 1.13622618
Trained batch 3049 batch loss 1.11136794 epoch total loss 1.13621795
Trained batch 3050 batch loss 1.20631647 epoch total loss 1.13624096
Trained batch 3051 batch loss 1.09160244 epoch total loss 1.1362263
Trained batch 3052 batch loss 1.2085433 epoch total loss 1.13625
Trained batch 3053 batch loss 1.18131077 epoch total loss 1.1362648
Trained batch 3054 batch loss 1.13766968 epoch total loss 1.13626528
Trained batch 3055 batch loss 1.54206896 epoch total loss 1.13639808
Trained batch 3056 batch loss 1.53340507 epoch total loss 1.13652802
Trained batch 3057 batch loss 1.49334896 epoch total loss 1.13664472
Trained batch 3058 batch loss 1.39294076 epoch total loss 1.13672853
Trained batch 3059 batch loss 1.33685136 epoch total loss 1.13679397
Trained batch 3060 batch loss 1.19044423 epoch total loss 1.13681149
Trained batch 3061 batch loss 1.33868289 epoch total loss 1.13687742
Trained batch 3062 batch loss 1.52883291 epoch total loss 1.13700533
Trained batch 3063 batch loss 1.3264488 epoch total loss 1.1370672
Trained batch 3064 batch loss 1.10870194 epoch total loss 1.1370579
Trained batch 3065 batch loss 1.07868743 epoch total loss 1.13703883
Trained batch 3066 batch loss 0.894051731 epoch total loss 1.13695967
Trained batch 3067 batch loss 1.06682324 epoch total loss 1.13693678
Trained batch 3068 batch loss 1.29971802 epoch total loss 1.13698983
Trained batch 3069 batch loss 1.05154133 epoch total loss 1.13696206
Trained batch 3070 batch loss 1.02527094 epoch total loss 1.1369257
Trained batch 3071 batch loss 1.19308209 epoch total loss 1.13694394
Trained batch 3072 batch loss 0.973789155 epoch total loss 1.13689089
Trained batch 3073 batch loss 0.823205 epoch total loss 1.13678885
Trained batch 3074 batch loss 0.771544337 epoch total loss 1.13667
Trained batch 3075 batch loss 0.833332658 epoch total loss 1.13657129
Trained batch 3076 batch loss 0.71823597 epoch total loss 1.13643527
Trained batch 3077 batch loss 0.687273383 epoch total loss 1.13628936
Trained batch 3078 batch loss 0.986968458 epoch total loss 1.13624084
Trained batch 3079 batch loss 0.942495525 epoch total loss 1.1361779
Trained batch 3080 batch loss 1.31071162 epoch total loss 1.13623464
Trained batch 3081 batch loss 0.972506225 epoch total loss 1.13618147
Trained batch 3082 batch loss 1.27326989 epoch total loss 1.13622582
Trained batch 3083 batch loss 1.16578913 epoch total loss 1.13623548
Trained batch 3084 batch loss 0.983021379 epoch total loss 1.13618577
Trained batch 3085 batch loss 1.25586605 epoch total loss 1.13622451
Trained batch 3086 batch loss 0.974713564 epoch total loss 1.13617218
Trained batch 3087 batch loss 0.709848821 epoch total loss 1.13603413
Trained batch 3088 batch loss 0.65476 epoch total loss 1.13587821
Trained batch 3089 batch loss 0.731810212 epoch total loss 1.13574743
Trained batch 3090 batch loss 0.726415038 epoch total loss 1.13561487
Trained batch 3091 batch loss 0.776067257 epoch total loss 1.13549864
Trained batch 3092 batch loss 0.820515394 epoch total loss 1.13539672
Trained batch 3093 batch loss 0.948584139 epoch total loss 1.13533628
Trained batch 3094 batch loss 0.820403218 epoch total loss 1.13523448
Trained batch 3095 batch loss 0.992663 epoch total loss 1.13518846
Trained batch 3096 batch loss 0.767347693 epoch total loss 1.13506961
Trained batch 3097 batch loss 0.983076811 epoch total loss 1.13502061
Trained batch 3098 batch loss 0.693784356 epoch total loss 1.13487816
Trained batch 3099 batch loss 1.20680022 epoch total loss 1.1349014
Trained batch 3100 batch loss 1.02059114 epoch total loss 1.13486445
Trained batch 3101 batch loss 0.812069535 epoch total loss 1.13476038
Trained batch 3102 batch loss 1.21720803 epoch total loss 1.13478696
Trained batch 3103 batch loss 1.1286006 epoch total loss 1.13478494
Trained batch 3104 batch loss 1.38481617 epoch total loss 1.13486552
Trained batch 3105 batch loss 1.08851397 epoch total loss 1.13485062
Trained batch 3106 batch loss 0.853727221 epoch total loss 1.13476014
Trained batch 3107 batch loss 0.971783876 epoch total loss 1.13470769
Trained batch 3108 batch loss 1.11941075 epoch total loss 1.13470268
Trained batch 3109 batch loss 1.17953801 epoch total loss 1.13471711
Trained batch 3110 batch loss 1.30064845 epoch total loss 1.13477039
Trained batch 3111 batch loss 1.13662732 epoch total loss 1.13477099
Trained batch 3112 batch loss 1.00691795 epoch total loss 1.13473
Trained batch 3113 batch loss 1.26900959 epoch total loss 1.13477302
Trained batch 3114 batch loss 0.906465173 epoch total loss 1.13469982
Trained batch 3115 batch loss 1.09595692 epoch total loss 1.1346873
Trained batch 3116 batch loss 1.06676042 epoch total loss 1.13466549
Trained batch 3117 batch loss 1.08045053 epoch total loss 1.13464808
Trained batch 3118 batch loss 1.34648395 epoch total loss 1.13471603
Trained batch 3119 batch loss 1.11456311 epoch total loss 1.1347096
Trained batch 3120 batch loss 1.06763887 epoch total loss 1.13468802
Trained batch 3121 batch loss 1.23035717 epoch total loss 1.13471878
Trained batch 3122 batch loss 1.09550524 epoch total loss 1.13470614
Trained batch 3123 batch loss 1.29821682 epoch total loss 1.13475847
Trained batch 3124 batch loss 1.16115308 epoch total loss 1.13476694
Trained batch 3125 batch loss 1.36312294 epoch total loss 1.13484
Trained batch 3126 batch loss 1.55708599 epoch total loss 1.13497508
Trained batch 3127 batch loss 1.38386679 epoch total loss 1.13505471
Trained batch 3128 batch loss 1.38889384 epoch total loss 1.13513577
Trained batch 3129 batch loss 1.33336139 epoch total loss 1.13519919
Trained batch 3130 batch loss 1.35668302 epoch total loss 1.13526988
Trained batch 3131 batch loss 1.02538395 epoch total loss 1.13523483
Trained batch 3132 batch loss 1.21313095 epoch total loss 1.13525963
Trained batch 3133 batch loss 1.23208809 epoch total loss 1.13529062
Trained batch 3134 batch loss 1.24226582 epoch total loss 1.13532472
Trained batch 3135 batch loss 1.25642776 epoch total loss 1.13536334
Trained batch 3136 batch loss 1.26340318 epoch total loss 1.13540411
Trained batch 3137 batch loss 0.98618108 epoch total loss 1.13535655
Trained batch 3138 batch loss 1.04389715 epoch total loss 1.13532746
Trained batch 3139 batch loss 0.905728698 epoch total loss 1.13525426
Trained batch 3140 batch loss 0.873603106 epoch total loss 1.13517094
Trained batch 3141 batch loss 1.03666258 epoch total loss 1.13513958
Trained batch 3142 batch loss 1.27949595 epoch total loss 1.13518548
Trained batch 3143 batch loss 1.11489141 epoch total loss 1.13517916
Trained batch 3144 batch loss 1.10434067 epoch total loss 1.13516927
Trained batch 3145 batch loss 1.24164367 epoch total loss 1.13520312
Trained batch 3146 batch loss 1.31933618 epoch total loss 1.13526165
Trained batch 3147 batch loss 1.07833636 epoch total loss 1.13524354
Trained batch 3148 batch loss 1.13794887 epoch total loss 1.13524449
Trained batch 3149 batch loss 1.09364104 epoch total loss 1.13523126
Trained batch 3150 batch loss 1.37937808 epoch total loss 1.13530874
Trained batch 3151 batch loss 1.11522245 epoch total loss 1.13530242
Trained batch 3152 batch loss 0.977125287 epoch total loss 1.13525224
Trained batch 3153 batch loss 0.869784355 epoch total loss 1.13516808
Trained batch 3154 batch loss 0.947862387 epoch total loss 1.13510859
Trained batch 3155 batch loss 1.05241179 epoch total loss 1.13508248
Trained batch 3156 batch loss 0.937584 epoch total loss 1.13501978
Trained batch 3157 batch loss 0.910639763 epoch total loss 1.13494873
Trained batch 3158 batch loss 0.779467762 epoch total loss 1.1348362
Trained batch 3159 batch loss 0.931338787 epoch total loss 1.13477182
Trained batch 3160 batch loss 0.955298483 epoch total loss 1.13471496
Trained batch 3161 batch loss 0.844721317 epoch total loss 1.13462329
Trained batch 3162 batch loss 0.978194058 epoch total loss 1.13457382
Trained batch 3163 batch loss 1.09317064 epoch total loss 1.13456082
Trained batch 3164 batch loss 1.06264675 epoch total loss 1.13453805
Trained batch 3165 batch loss 1.06916261 epoch total loss 1.13451743
Trained batch 3166 batch loss 1.2473731 epoch total loss 1.13455307
Trained batch 3167 batch loss 1.09205961 epoch total loss 1.1345396
Trained batch 3168 batch loss 1.09808862 epoch total loss 1.13452816
Trained batch 3169 batch loss 1.31541848 epoch total loss 1.13458514
Trained batch 3170 batch loss 0.898191035 epoch total loss 1.13451064
Trained batch 3171 batch loss 0.78470397 epoch total loss 1.13440025
Trained batch 3172 batch loss 0.860472441 epoch total loss 1.13431394
Trained batch 3173 batch loss 1.04902422 epoch total loss 1.134287
Trained batch 3174 batch loss 0.898474395 epoch total loss 1.13421273
Trained batch 3175 batch loss 0.809543371 epoch total loss 1.13411045
Trained batch 3176 batch loss 1.2042073 epoch total loss 1.1341325
Trained batch 3177 batch loss 1.21764803 epoch total loss 1.13415873
Trained batch 3178 batch loss 1.16965079 epoch total loss 1.13416994
Trained batch 3179 batch loss 1.15301633 epoch total loss 1.1341759
Trained batch 3180 batch loss 1.08553398 epoch total loss 1.13416052
Trained batch 3181 batch loss 1.12783122 epoch total loss 1.13415861
Trained batch 3182 batch loss 1.04956913 epoch total loss 1.13413203
Trained batch 3183 batch loss 1.10297251 epoch total loss 1.13412225
Trained batch 3184 batch loss 1.10353613 epoch total loss 1.1341126
Trained batch 3185 batch loss 1.2034986 epoch total loss 1.13413441
Trained batch 3186 batch loss 1.09789503 epoch total loss 1.13412309
Trained batch 3187 batch loss 1.30201161 epoch total loss 1.13417578
Trained batch 3188 batch loss 1.06968904 epoch total loss 1.13415551
Trained batch 3189 batch loss 0.849625707 epoch total loss 1.13406622
Trained batch 3190 batch loss 1.08980358 epoch total loss 1.1340524
Trained batch 3191 batch loss 1.23297989 epoch total loss 1.13408339
Trained batch 3192 batch loss 0.982650518 epoch total loss 1.13403594
Trained batch 3193 batch loss 0.932018876 epoch total loss 1.13397276
Trained batch 3194 batch loss 0.861988246 epoch total loss 1.13388765
Trained batch 3195 batch loss 0.979389071 epoch total loss 1.13383925
Trained batch 3196 batch loss 1.18823993 epoch total loss 1.1338563
Trained batch 3197 batch loss 1.34129024 epoch total loss 1.13392115
Trained batch 3198 batch loss 1.15186238 epoch total loss 1.13392675
Trained batch 3199 batch loss 1.32320702 epoch total loss 1.133986
Trained batch 3200 batch loss 1.26897848 epoch total loss 1.1340282
Trained batch 3201 batch loss 1.37546 epoch total loss 1.13410366
Trained batch 3202 batch loss 1.40502715 epoch total loss 1.13418818
Trained batch 3203 batch loss 1.13681114 epoch total loss 1.13418901
Trained batch 3204 batch loss 1.29114091 epoch total loss 1.134238
Trained batch 3205 batch loss 1.10568237 epoch total loss 1.13422918
Trained batch 3206 batch loss 1.15169787 epoch total loss 1.13423455
Trained batch 3207 batch loss 1.10458136 epoch total loss 1.13422525
Trained batch 3208 batch loss 1.16425943 epoch total loss 1.13423467
Trained batch 3209 batch loss 1.00868845 epoch total loss 1.13419557
Trained batch 3210 batch loss 1.00850677 epoch total loss 1.13415647
Trained batch 3211 batch loss 0.918239653 epoch total loss 1.13408911
Trained batch 3212 batch loss 0.914952636 epoch total loss 1.13402092
Trained batch 3213 batch loss 0.858968139 epoch total loss 1.13393533
Trained batch 3214 batch loss 0.85434854 epoch total loss 1.13384831
Trained batch 3215 batch loss 0.741488755 epoch total loss 1.13372624
Trained batch 3216 batch loss 0.919942141 epoch total loss 1.13365984
Trained batch 3217 batch loss 0.922773957 epoch total loss 1.13359427
Trained batch 3218 batch loss 0.763292789 epoch total loss 1.13347912
Trained batch 3219 batch loss 0.844317794 epoch total loss 1.13338923
Trained batch 3220 batch loss 0.934285164 epoch total loss 1.13332748
Trained batch 3221 batch loss 1.15531373 epoch total loss 1.13333428
Trained batch 3222 batch loss 1.04140902 epoch total loss 1.13330579
Trained batch 3223 batch loss 1.34934008 epoch total loss 1.13337278
Trained batch 3224 batch loss 1.23484921 epoch total loss 1.13340425
Trained batch 3225 batch loss 1.222399 epoch total loss 1.13343191
Trained batch 3226 batch loss 1.30914938 epoch total loss 1.13348639
Trained batch 3227 batch loss 1.24153638 epoch total loss 1.13351977
Trained batch 3228 batch loss 1.27325344 epoch total loss 1.13356304
Trained batch 3229 batch loss 1.38729429 epoch total loss 1.1336416
Trained batch 3230 batch loss 1.38418818 epoch total loss 1.13371921
Trained batch 3231 batch loss 1.55410349 epoch total loss 1.13384938
Trained batch 3232 batch loss 1.44779992 epoch total loss 1.13394654
Trained batch 3233 batch loss 1.48065388 epoch total loss 1.13405371
Trained batch 3234 batch loss 1.25278616 epoch total loss 1.13409042
Trained batch 3235 batch loss 0.986155748 epoch total loss 1.13404465
Trained batch 3236 batch loss 0.937534034 epoch total loss 1.13398397
Trained batch 3237 batch loss 1.03834629 epoch total loss 1.13395441
Trained batch 3238 batch loss 1.2429738 epoch total loss 1.13398802
Trained batch 3239 batch loss 1.02582455 epoch total loss 1.13395464
Trained batch 3240 batch loss 0.984288752 epoch total loss 1.13390851
Trained batch 3241 batch loss 0.826560736 epoch total loss 1.13381374
Trained batch 3242 batch loss 1.17514133 epoch total loss 1.13382638
Trained batch 3243 batch loss 0.973085761 epoch total loss 1.1337769
Trained batch 3244 batch loss 1.25322914 epoch total loss 1.13381362
Trained batch 3245 batch loss 1.1302464 epoch total loss 1.13381255
Trained batch 3246 batch loss 1.30121136 epoch total loss 1.13386416
Trained batch 3247 batch loss 1.23345959 epoch total loss 1.1338948
Trained batch 3248 batch loss 1.23591137 epoch total loss 1.13392615
Trained batch 3249 batch loss 1.09119439 epoch total loss 1.13391304
Trained batch 3250 batch loss 1.20879328 epoch total loss 1.13393605
Trained batch 3251 batch loss 1.11275697 epoch total loss 1.13392961
Trained batch 3252 batch loss 1.1652844 epoch total loss 1.13393927
Trained batch 3253 batch loss 1.28080821 epoch total loss 1.13398433
Trained batch 3254 batch loss 1.17382801 epoch total loss 1.13399661
Trained batch 3255 batch loss 1.11710358 epoch total loss 1.13399148
Trained batch 3256 batch loss 1.20270371 epoch total loss 1.13401246
Trained batch 3257 batch loss 1.25002456 epoch total loss 1.1340481
Trained batch 3258 batch loss 1.2224735 epoch total loss 1.13407528
Trained batch 3259 batch loss 1.0629431 epoch total loss 1.13405347
Trained batch 3260 batch loss 1.18012786 epoch total loss 1.13406754
Trained batch 3261 batch loss 1.05151463 epoch total loss 1.13404226
Trained batch 3262 batch loss 1.10117435 epoch total loss 1.13403213
Trained batch 3263 batch loss 1.15109158 epoch total loss 1.13403738
Trained batch 3264 batch loss 1.26879883 epoch total loss 1.13407862
Trained batch 3265 batch loss 1.22120631 epoch total loss 1.13410532
Trained batch 3266 batch loss 1.26908743 epoch total loss 1.13414669
Trained batch 3267 batch loss 1.15712154 epoch total loss 1.13415372
Trained batch 3268 batch loss 1.25413191 epoch total loss 1.13419044
Trained batch 3269 batch loss 0.922685742 epoch total loss 1.13412571
Trained batch 3270 batch loss 1.00887132 epoch total loss 1.13408744
Trained batch 3271 batch loss 1.08593249 epoch total loss 1.13407266
Trained batch 3272 batch loss 1.22066236 epoch total loss 1.13409913
Trained batch 3273 batch loss 1.17826629 epoch total loss 1.1341126
Trained batch 3274 batch loss 1.1186825 epoch total loss 1.13410795
Trained batch 3275 batch loss 0.924732089 epoch total loss 1.13404405
Trained batch 3276 batch loss 1.04981053 epoch total loss 1.1340183
Trained batch 3277 batch loss 0.908257 epoch total loss 1.1339494
Trained batch 3278 batch loss 1.00290847 epoch total loss 1.13390946
Trained batch 3279 batch loss 0.907671213 epoch total loss 1.13384044
Trained batch 3280 batch loss 1.25681591 epoch total loss 1.13387799
Trained batch 3281 batch loss 1.05671072 epoch total loss 1.13385439
Trained batch 3282 batch loss 0.916292608 epoch total loss 1.13378811
Trained batch 3283 batch loss 1.06701374 epoch total loss 1.13376772
Trained batch 3284 batch loss 0.992694676 epoch total loss 1.13372481
Trained batch 3285 batch loss 1.11784172 epoch total loss 1.13371992
Trained batch 3286 batch loss 1.16078913 epoch total loss 1.13372827
Trained batch 3287 batch loss 1.41404986 epoch total loss 1.1338135
Trained batch 3288 batch loss 1.19911599 epoch total loss 1.13383341
Trained batch 3289 batch loss 1.22247338 epoch total loss 1.13386035
Trained batch 3290 batch loss 0.909160614 epoch total loss 1.13379204
Trained batch 3291 batch loss 1.23358512 epoch total loss 1.13382232
Trained batch 3292 batch loss 0.876990438 epoch total loss 1.13374436
Trained batch 3293 batch loss 1.01018739 epoch total loss 1.13370681
Trained batch 3294 batch loss 0.909862161 epoch total loss 1.13363886
Trained batch 3295 batch loss 0.784342408 epoch total loss 1.13353288
Trained batch 3296 batch loss 0.715342164 epoch total loss 1.13340604
Trained batch 3297 batch loss 1.03449059 epoch total loss 1.133376
Trained batch 3298 batch loss 1.06475401 epoch total loss 1.13335514
Trained batch 3299 batch loss 1.00188422 epoch total loss 1.13331532
Trained batch 3300 batch loss 1.20952821 epoch total loss 1.13333845
Trained batch 3301 batch loss 1.02169514 epoch total loss 1.1333046
Trained batch 3302 batch loss 1.03488851 epoch total loss 1.13327479
Trained batch 3303 batch loss 1.1563499 epoch total loss 1.13328183
Trained batch 3304 batch loss 1.12348461 epoch total loss 1.13327885
Trained batch 3305 batch loss 1.43356705 epoch total loss 1.13336968
Trained batch 3306 batch loss 1.21291304 epoch total loss 1.13339376
Trained batch 3307 batch loss 1.33785725 epoch total loss 1.13345563
Trained batch 3308 batch loss 1.20444024 epoch total loss 1.13347697
Trained batch 3309 batch loss 1.01455927 epoch total loss 1.13344109
Trained batch 3310 batch loss 1.06473184 epoch total loss 1.13342035
Trained batch 3311 batch loss 1.05446208 epoch total loss 1.13339651
Trained batch 3312 batch loss 1.11964083 epoch total loss 1.13339233
Trained batch 3313 batch loss 1.31632483 epoch total loss 1.13344753
Trained batch 3314 batch loss 1.38819993 epoch total loss 1.13352442
Trained batch 3315 batch loss 1.30885863 epoch total loss 1.13357735
Trained batch 3316 batch loss 1.34071326 epoch total loss 1.13363981
Trained batch 3317 batch loss 1.29147029 epoch total loss 1.13368738
Trained batch 3318 batch loss 1.24970758 epoch total loss 1.13372242
Trained batch 3319 batch loss 1.2163372 epoch total loss 1.13374734
Trained batch 3320 batch loss 1.24756742 epoch total loss 1.13378155
Trained batch 3321 batch loss 1.42013359 epoch total loss 1.13386774
Trained batch 3322 batch loss 1.30109286 epoch total loss 1.13391817
Trained batch 3323 batch loss 1.65697169 epoch total loss 1.13407552
Trained batch 3324 batch loss 1.39175391 epoch total loss 1.13415313
Trained batch 3325 batch loss 1.4326061 epoch total loss 1.13424289
Trained batch 3326 batch loss 1.41811728 epoch total loss 1.13432825
Trained batch 3327 batch loss 1.13776612 epoch total loss 1.1343292
Trained batch 3328 batch loss 1.12288308 epoch total loss 1.13432574
Trained batch 3329 batch loss 0.963794887 epoch total loss 1.1342746
Trained batch 3330 batch loss 0.935553074 epoch total loss 1.13421488
Trained batch 3331 batch loss 0.863997102 epoch total loss 1.13413382
Trained batch 3332 batch loss 0.881019771 epoch total loss 1.13405788
Trained batch 3333 batch loss 0.914612651 epoch total loss 1.13399196
Trained batch 3334 batch loss 1.0821749 epoch total loss 1.13397646
Trained batch 3335 batch loss 1.12497 epoch total loss 1.13397372
Trained batch 3336 batch loss 1.22632694 epoch total loss 1.13400149
Trained batch 3337 batch loss 1.34054101 epoch total loss 1.13406336
Trained batch 3338 batch loss 1.04846525 epoch total loss 1.13403773
Trained batch 3339 batch loss 1.14645767 epoch total loss 1.13404143
Trained batch 3340 batch loss 1.21266794 epoch total loss 1.13406503
Trained batch 3341 batch loss 0.997678876 epoch total loss 1.13402414
Trained batch 3342 batch loss 0.903465569 epoch total loss 1.13395524
Trained batch 3343 batch loss 0.8511253 epoch total loss 1.1338706
Trained batch 3344 batch loss 0.944843173 epoch total loss 1.13381398
Trained batch 3345 batch loss 1.07526469 epoch total loss 1.13379645
Trained batch 3346 batch loss 0.884884596 epoch total loss 1.13372207
Trained batch 3347 batch loss 0.817922831 epoch total loss 1.13362765
Trained batch 3348 batch loss 0.927941799 epoch total loss 1.13356626
Trained batch 3349 batch loss 1.0544498 epoch total loss 1.13354266
Trained batch 3350 batch loss 0.846973538 epoch total loss 1.13345706
Trained batch 3351 batch loss 0.802555859 epoch total loss 1.13335836
Trained batch 3352 batch loss 1.2576685 epoch total loss 1.13339543
Trained batch 3353 batch loss 0.88117671 epoch total loss 1.13332009
Trained batch 3354 batch loss 0.990666151 epoch total loss 1.13327765
Trained batch 3355 batch loss 1.18382382 epoch total loss 1.13329268
Trained batch 3356 batch loss 0.912308514 epoch total loss 1.13322687
Trained batch 3357 batch loss 1.00254762 epoch total loss 1.13318789
Trained batch 3358 batch loss 0.941728294 epoch total loss 1.13313091
Trained batch 3359 batch loss 0.886186242 epoch total loss 1.13305736
Trained batch 3360 batch loss 0.846892297 epoch total loss 1.13297224
Trained batch 3361 batch loss 0.974559784 epoch total loss 1.13292503
Trained batch 3362 batch loss 0.710400462 epoch total loss 1.13279939
Trained batch 3363 batch loss 0.893320262 epoch total loss 1.13272822
Trained batch 3364 batch loss 1.01884854 epoch total loss 1.13269436
Trained batch 3365 batch loss 1.00250721 epoch total loss 1.13265562
Trained batch 3366 batch loss 0.844717562 epoch total loss 1.13257015
Trained batch 3367 batch loss 0.777523935 epoch total loss 1.13246465
Trained batch 3368 batch loss 1.15969408 epoch total loss 1.13247275
Trained batch 3369 batch loss 1.18461514 epoch total loss 1.13248825
Trained batch 3370 batch loss 1.01122844 epoch total loss 1.13245225
Trained batch 3371 batch loss 1.07478428 epoch total loss 1.13243508
Trained batch 3372 batch loss 1.40529108 epoch total loss 1.13251603
Trained batch 3373 batch loss 1.24512911 epoch total loss 1.13254941
Trained batch 3374 batch loss 0.841335416 epoch total loss 1.1324631
Trained batch 3375 batch loss 1.04941988 epoch total loss 1.13243842
Trained batch 3376 batch loss 0.984442711 epoch total loss 1.13239455
Trained batch 3377 batch loss 0.850914955 epoch total loss 1.13231122
Trained batch 3378 batch loss 0.825656 epoch total loss 1.13222039
Trained batch 3379 batch loss 0.934887767 epoch total loss 1.13216197
Trained batch 3380 batch loss 1.29187894 epoch total loss 1.1322093
Trained batch 3381 batch loss 0.926028967 epoch total loss 1.13214827
Trained batch 3382 batch loss 1.06327879 epoch total loss 1.13212788
Trained batch 3383 batch loss 0.952900529 epoch total loss 1.13207495
Trained batch 3384 batch loss 1.10220456 epoch total loss 1.13206613
Trained batch 3385 batch loss 1.37394929 epoch total loss 1.13213766
Trained batch 3386 batch loss 1.30542314 epoch total loss 1.1321888
Trained batch 3387 batch loss 0.977114856 epoch total loss 1.13214302
Trained batch 3388 batch loss 0.991134405 epoch total loss 1.13210142
Trained batch 3389 batch loss 1.1486429 epoch total loss 1.1321063
Trained batch 3390 batch loss 1.12981439 epoch total loss 1.13210559
Trained batch 3391 batch loss 1.10390651 epoch total loss 1.13209736
Trained batch 3392 batch loss 1.27830863 epoch total loss 1.13214052
Trained batch 3393 batch loss 1.25343037 epoch total loss 1.13217616
Trained batch 3394 batch loss 1.28675842 epoch total loss 1.13222182
Trained batch 3395 batch loss 1.34404922 epoch total loss 1.13228416
Trained batch 3396 batch loss 1.31650901 epoch total loss 1.1323384
Trained batch 3397 batch loss 1.09729755 epoch total loss 1.13232815
Trained batch 3398 batch loss 1.05273366 epoch total loss 1.13230467
Trained batch 3399 batch loss 1.16742229 epoch total loss 1.13231504
Trained batch 3400 batch loss 1.14424729 epoch total loss 1.1323185
Trained batch 3401 batch loss 1.15131259 epoch total loss 1.1323241
Trained batch 3402 batch loss 0.952938557 epoch total loss 1.13227141
Trained batch 3403 batch loss 0.957612634 epoch total loss 1.13222
Trained batch 3404 batch loss 1.29866219 epoch total loss 1.13226891
Trained batch 3405 batch loss 1.37233806 epoch total loss 1.13233948
Trained batch 3406 batch loss 1.37743759 epoch total loss 1.13241136
Trained batch 3407 batch loss 1.31125975 epoch total loss 1.13246393
Trained batch 3408 batch loss 1.19769931 epoch total loss 1.13248301
Trained batch 3409 batch loss 0.983969092 epoch total loss 1.13243949
Trained batch 3410 batch loss 0.984198928 epoch total loss 1.13239598
Trained batch 3411 batch loss 1.16184378 epoch total loss 1.13240457
Trained batch 3412 batch loss 1.00218487 epoch total loss 1.13236642
Trained batch 3413 batch loss 1.05642402 epoch total loss 1.13234413
Trained batch 3414 batch loss 1.18751287 epoch total loss 1.13236034
Trained batch 3415 batch loss 0.77855444 epoch total loss 1.13225675
Trained batch 3416 batch loss 0.934457898 epoch total loss 1.13219881
Trained batch 3417 batch loss 1.17638803 epoch total loss 1.1322118
Trained batch 3418 batch loss 1.01929414 epoch total loss 1.13217866
Trained batch 3419 batch loss 1.08347392 epoch total loss 1.13216448
Trained batch 3420 batch loss 1.22862208 epoch total loss 1.13219261
Trained batch 3421 batch loss 1.37356544 epoch total loss 1.13226318
Trained batch 3422 batch loss 1.28640759 epoch total loss 1.13230824
Trained batch 3423 batch loss 1.46789253 epoch total loss 1.13240623
Trained batch 3424 batch loss 1.42342353 epoch total loss 1.13249123
Trained batch 3425 batch loss 1.31916046 epoch total loss 1.13254571
Trained batch 3426 batch loss 1.25597203 epoch total loss 1.13258171
Trained batch 3427 batch loss 1.42334342 epoch total loss 1.13266659
Trained batch 3428 batch loss 1.27151465 epoch total loss 1.132707
Trained batch 3429 batch loss 1.21472037 epoch total loss 1.13273096
Trained batch 3430 batch loss 0.934263706 epoch total loss 1.13267303
Trained batch 3431 batch loss 1.18751764 epoch total loss 1.132689
Trained batch 3432 batch loss 1.12495399 epoch total loss 1.13268685
Trained batch 3433 batch loss 1.18297744 epoch total loss 1.1327014
Trained batch 3434 batch loss 1.14805901 epoch total loss 1.13270581
Trained batch 3435 batch loss 1.0963707 epoch total loss 1.13269532
Trained batch 3436 batch loss 0.923610747 epoch total loss 1.1326344
Trained batch 3437 batch loss 0.97497 epoch total loss 1.13258851
Trained batch 3438 batch loss 1.33372927 epoch total loss 1.13264704
Trained batch 3439 batch loss 1.01753557 epoch total loss 1.13261354
Trained batch 3440 batch loss 1.26253319 epoch total loss 1.13265133
Trained batch 3441 batch loss 1.33598638 epoch total loss 1.13271046
Trained batch 3442 batch loss 1.24605465 epoch total loss 1.13274336
Trained batch 3443 batch loss 1.29037619 epoch total loss 1.13278913
Trained batch 3444 batch loss 1.09229112 epoch total loss 1.13277733
Trained batch 3445 batch loss 0.818489194 epoch total loss 1.13268614
Trained batch 3446 batch loss 1.00911438 epoch total loss 1.13265026
Trained batch 3447 batch loss 1.12748241 epoch total loss 1.13264871
Trained batch 3448 batch loss 1.43302798 epoch total loss 1.13273585
Trained batch 3449 batch loss 1.11601496 epoch total loss 1.13273108
Trained batch 3450 batch loss 1.30495405 epoch total loss 1.13278091
Trained batch 3451 batch loss 1.28495955 epoch total loss 1.13282502
Trained batch 3452 batch loss 1.37653792 epoch total loss 1.13289559
Trained batch 3453 batch loss 1.21496761 epoch total loss 1.13291943
Trained batch 3454 batch loss 1.19053829 epoch total loss 1.132936
Trained batch 3455 batch loss 1.22988749 epoch total loss 1.13296413
Trained batch 3456 batch loss 1.38072991 epoch total loss 1.13303578
Trained batch 3457 batch loss 1.12955391 epoch total loss 1.13303483
Trained batch 3458 batch loss 1.13639164 epoch total loss 1.13303578
Trained batch 3459 batch loss 1.3481977 epoch total loss 1.13309801
Trained batch 3460 batch loss 1.11470234 epoch total loss 1.13309264
Trained batch 3461 batch loss 1.21181941 epoch total loss 1.13311553
Trained batch 3462 batch loss 1.08577013 epoch total loss 1.13310182
Trained batch 3463 batch loss 0.821512461 epoch total loss 1.13301182
Trained batch 3464 batch loss 0.960216 epoch total loss 1.13296187
Trained batch 3465 batch loss 0.898762941 epoch total loss 1.13289428
Trained batch 3466 batch loss 0.963476181 epoch total loss 1.1328454
Trained batch 3467 batch loss 0.960085273 epoch total loss 1.13279557
Trained batch 3468 batch loss 0.923447907 epoch total loss 1.13273525
Trained batch 3469 batch loss 0.826664925 epoch total loss 1.13264692
Trained batch 3470 batch loss 1.08748984 epoch total loss 1.13263392
Trained batch 3471 batch loss 1.11174679 epoch total loss 1.13262796
Trained batch 3472 batch loss 1.13581562 epoch total loss 1.1326288
Trained batch 3473 batch loss 1.24091721 epoch total loss 1.13266
Trained batch 3474 batch loss 1.25901008 epoch total loss 1.13269639
Trained batch 3475 batch loss 1.26985013 epoch total loss 1.13273585
Trained batch 3476 batch loss 1.19308829 epoch total loss 1.13275325
Trained batch 3477 batch loss 1.30390167 epoch total loss 1.13280249
Trained batch 3478 batch loss 1.36316931 epoch total loss 1.13286877
Trained batch 3479 batch loss 1.25015521 epoch total loss 1.1329025
Trained batch 3480 batch loss 0.947086155 epoch total loss 1.1328491
Trained batch 3481 batch loss 0.966369271 epoch total loss 1.13280118
Trained batch 3482 batch loss 1.17454505 epoch total loss 1.13281322
Trained batch 3483 batch loss 1.13493502 epoch total loss 1.13281381
Trained batch 3484 batch loss 1.11908245 epoch total loss 1.13280988
Trained batch 3485 batch loss 1.04180956 epoch total loss 1.13278377
Trained batch 3486 batch loss 1.10777116 epoch total loss 1.13277662
Trained batch 3487 batch loss 1.31988668 epoch total loss 1.13283026
Trained batch 3488 batch loss 1.22384167 epoch total loss 1.13285637
Trained batch 3489 batch loss 1.33699894 epoch total loss 1.13291478
Trained batch 3490 batch loss 1.31411028 epoch total loss 1.13296676
Trained batch 3491 batch loss 1.23206115 epoch total loss 1.13299513
Trained batch 3492 batch loss 1.13819861 epoch total loss 1.13299668
Trained batch 3493 batch loss 1.08402956 epoch total loss 1.13298261
Trained batch 3494 batch loss 0.889228225 epoch total loss 1.13291287
Trained batch 3495 batch loss 1.08181119 epoch total loss 1.13289821
Trained batch 3496 batch loss 1.02574444 epoch total loss 1.13286757
Trained batch 3497 batch loss 1.25281465 epoch total loss 1.13290191
Trained batch 3498 batch loss 1.10135126 epoch total loss 1.13289285
Trained batch 3499 batch loss 1.16469026 epoch total loss 1.13290191
Trained batch 3500 batch loss 1.16477644 epoch total loss 1.13291109
Trained batch 3501 batch loss 1.14464641 epoch total loss 1.13291442
Trained batch 3502 batch loss 1.17841327 epoch total loss 1.13292742
Trained batch 3503 batch loss 1.10110641 epoch total loss 1.13291824
Trained batch 3504 batch loss 0.920274556 epoch total loss 1.13285756
Trained batch 3505 batch loss 1.26748586 epoch total loss 1.13289607
Trained batch 3506 batch loss 1.13488925 epoch total loss 1.13289666
Trained batch 3507 batch loss 1.12872648 epoch total loss 1.13289547
Trained batch 3508 batch loss 1.28040659 epoch total loss 1.13293755
Trained batch 3509 batch loss 1.1153307 epoch total loss 1.13293242
Trained batch 3510 batch loss 0.875296652 epoch total loss 1.13285899
Trained batch 3511 batch loss 1.08127165 epoch total loss 1.13284433
Trained batch 3512 batch loss 1.10681057 epoch total loss 1.13283694
Trained batch 3513 batch loss 1.07333791 epoch total loss 1.13281989
Trained batch 3514 batch loss 1.03254032 epoch total loss 1.1327914
Trained batch 3515 batch loss 1.18172455 epoch total loss 1.13280523
Trained batch 3516 batch loss 1.07923245 epoch total loss 1.13279009
Trained batch 3517 batch loss 1.14966679 epoch total loss 1.13279486
Trained batch 3518 batch loss 1.17686725 epoch total loss 1.13280737
Trained batch 3519 batch loss 1.05118322 epoch total loss 1.13278425
Trained batch 3520 batch loss 1.24962771 epoch total loss 1.13281739
Trained batch 3521 batch loss 1.22773886 epoch total loss 1.13284433
Trained batch 3522 batch loss 1.28251982 epoch total loss 1.13288677
Trained batch 3523 batch loss 1.21877909 epoch total loss 1.13291121
Trained batch 3524 batch loss 1.30674672 epoch total loss 1.13296044
Trained batch 3525 batch loss 1.3235836 epoch total loss 1.13301456
Trained batch 3526 batch loss 1.52992415 epoch total loss 1.13312709
Trained batch 3527 batch loss 1.27132404 epoch total loss 1.13316631
Trained batch 3528 batch loss 1.31367207 epoch total loss 1.13321745
Trained batch 3529 batch loss 1.42531931 epoch total loss 1.13330019
Trained batch 3530 batch loss 1.17745852 epoch total loss 1.1333127
Trained batch 3531 batch loss 1.34896147 epoch total loss 1.13337374
Trained batch 3532 batch loss 1.39642787 epoch total loss 1.13344824
Trained batch 3533 batch loss 1.20872664 epoch total loss 1.13346958
Trained batch 3534 batch loss 1.26937079 epoch total loss 1.13350809
Trained batch 3535 batch loss 1.28836012 epoch total loss 1.13355184
Trained batch 3536 batch loss 1.16484153 epoch total loss 1.13356066
Trained batch 3537 batch loss 1.28128552 epoch total loss 1.13360238
Trained batch 3538 batch loss 1.34158325 epoch total loss 1.13366115
Trained batch 3539 batch loss 1.01550424 epoch total loss 1.13362789
Trained batch 3540 batch loss 1.12361 epoch total loss 1.13362503
Trained batch 3541 batch loss 0.974086761 epoch total loss 1.13358
Trained batch 3542 batch loss 0.935346603 epoch total loss 1.13352394
Trained batch 3543 batch loss 0.88373816 epoch total loss 1.13345349
Trained batch 3544 batch loss 0.975614607 epoch total loss 1.1334089
Trained batch 3545 batch loss 0.826888442 epoch total loss 1.13332248
Trained batch 3546 batch loss 0.930706441 epoch total loss 1.13326538
Trained batch 3547 batch loss 0.894352794 epoch total loss 1.1331979
Trained batch 3548 batch loss 0.885250032 epoch total loss 1.13312805
Trained batch 3549 batch loss 0.947848678 epoch total loss 1.13307583
Trained batch 3550 batch loss 0.825929463 epoch total loss 1.13298929
Trained batch 3551 batch loss 0.738476038 epoch total loss 1.13287818
Trained batch 3552 batch loss 0.893638968 epoch total loss 1.13281083
Trained batch 3553 batch loss 0.923154771 epoch total loss 1.13275182
Trained batch 3554 batch loss 0.764984965 epoch total loss 1.13264835
Trained batch 3555 batch loss 0.952315 epoch total loss 1.13259757
Trained batch 3556 batch loss 0.989931941 epoch total loss 1.13255751
Trained batch 3557 batch loss 1.23523808 epoch total loss 1.13258636
Trained batch 3558 batch loss 1.11452496 epoch total loss 1.13258135
Trained batch 3559 batch loss 1.40172577 epoch total loss 1.13265693
Trained batch 3560 batch loss 1.13537145 epoch total loss 1.13265765
Trained batch 3561 batch loss 1.17981517 epoch total loss 1.13267088
Trained batch 3562 batch loss 1.37016678 epoch total loss 1.13273764
Trained batch 3563 batch loss 1.07744312 epoch total loss 1.13272202
Trained batch 3564 batch loss 1.17028689 epoch total loss 1.13273251
Trained batch 3565 batch loss 1.23585403 epoch total loss 1.13276148
Trained batch 3566 batch loss 1.05983961 epoch total loss 1.13274097
Trained batch 3567 batch loss 1.42298365 epoch total loss 1.13282239
Trained batch 3568 batch loss 1.14108062 epoch total loss 1.13282478
Trained batch 3569 batch loss 1.10793018 epoch total loss 1.13281775
Trained batch 3570 batch loss 1.18656445 epoch total loss 1.13283277
Trained batch 3571 batch loss 1.11002803 epoch total loss 1.13282645
Trained batch 3572 batch loss 1.30631495 epoch total loss 1.13287508
Trained batch 3573 batch loss 1.1526047 epoch total loss 1.13288057
Trained batch 3574 batch loss 1.09413564 epoch total loss 1.13286972
Trained batch 3575 batch loss 1.25757754 epoch total loss 1.13290465
Trained batch 3576 batch loss 1.28278065 epoch total loss 1.13294649
Trained batch 3577 batch loss 1.14297795 epoch total loss 1.13294935
Trained batch 3578 batch loss 1.19304776 epoch total loss 1.13296616
Trained batch 3579 batch loss 1.30259717 epoch total loss 1.13301349
Trained batch 3580 batch loss 1.40794396 epoch total loss 1.13309038
Trained batch 3581 batch loss 1.1126771 epoch total loss 1.13308465
Trained batch 3582 batch loss 0.942266107 epoch total loss 1.13303137
Trained batch 3583 batch loss 1.0711441 epoch total loss 1.13301408
Trained batch 3584 batch loss 0.871977746 epoch total loss 1.13294137
Trained batch 3585 batch loss 0.945862889 epoch total loss 1.13288915
Trained batch 3586 batch loss 1.04034817 epoch total loss 1.13286328
Trained batch 3587 batch loss 1.05708313 epoch total loss 1.13284218
Trained batch 3588 batch loss 1.15908217 epoch total loss 1.13284957
Trained batch 3589 batch loss 1.14415622 epoch total loss 1.13285267
Trained batch 3590 batch loss 1.03467774 epoch total loss 1.13282526
Trained batch 3591 batch loss 0.922037125 epoch total loss 1.1327666
Trained batch 3592 batch loss 1.03277218 epoch total loss 1.13273871
Trained batch 3593 batch loss 1.01963878 epoch total loss 1.13270724
Trained batch 3594 batch loss 0.916476 epoch total loss 1.13264704
Trained batch 3595 batch loss 0.798566759 epoch total loss 1.13255417
Trained batch 3596 batch loss 0.809005141 epoch total loss 1.13246417
Trained batch 3597 batch loss 1.23880947 epoch total loss 1.13249373
Trained batch 3598 batch loss 1.05409908 epoch total loss 1.13247204
Trained batch 3599 batch loss 0.71250248 epoch total loss 1.13235533
Trained batch 3600 batch loss 0.874760747 epoch total loss 1.13228369
Trained batch 3601 batch loss 0.955649495 epoch total loss 1.13223469
Trained batch 3602 batch loss 0.859549582 epoch total loss 1.13215899
Trained batch 3603 batch loss 1.29617727 epoch total loss 1.13220453
Trained batch 3604 batch loss 0.916719437 epoch total loss 1.13214469
Trained batch 3605 batch loss 1.01676142 epoch total loss 1.13211274
Trained batch 3606 batch loss 1.13191152 epoch total loss 1.13211262
Trained batch 3607 batch loss 0.849818349 epoch total loss 1.13203442
Trained batch 3608 batch loss 1.05646777 epoch total loss 1.13201344
Trained batch 3609 batch loss 0.796251774 epoch total loss 1.13192034
Trained batch 3610 batch loss 0.754402637 epoch total loss 1.13181579
Trained batch 3611 batch loss 0.774104655 epoch total loss 1.13171673
Trained batch 3612 batch loss 0.722232342 epoch total loss 1.13160336
Trained batch 3613 batch loss 0.744372487 epoch total loss 1.13149619
Trained batch 3614 batch loss 0.710228682 epoch total loss 1.1313796
Trained batch 3615 batch loss 0.842454135 epoch total loss 1.13129973
Trained batch 3616 batch loss 0.808936238 epoch total loss 1.13121057
Trained batch 3617 batch loss 0.945703387 epoch total loss 1.13115931
Trained batch 3618 batch loss 0.795235693 epoch total loss 1.13106644
Trained batch 3619 batch loss 0.678584456 epoch total loss 1.13094139
Trained batch 3620 batch loss 0.709294796 epoch total loss 1.1308248
Trained batch 3621 batch loss 0.692671657 epoch total loss 1.13070381
Trained batch 3622 batch loss 0.67889142 epoch total loss 1.13057911
Trained batch 3623 batch loss 1.24453402 epoch total loss 1.13061059
Trained batch 3624 batch loss 1.07309747 epoch total loss 1.13059473
Trained batch 3625 batch loss 0.999810934 epoch total loss 1.13055873
Trained batch 3626 batch loss 1.03678453 epoch total loss 1.13053286
Trained batch 3627 batch loss 1.2261126 epoch total loss 1.13055921
Trained batch 3628 batch loss 1.28155947 epoch total loss 1.13060081
Trained batch 3629 batch loss 1.26422691 epoch total loss 1.13063765
Trained batch 3630 batch loss 1.02755547 epoch total loss 1.13060915
Trained batch 3631 batch loss 0.934442639 epoch total loss 1.13055515
Trained batch 3632 batch loss 1.08130944 epoch total loss 1.13054168
Trained batch 3633 batch loss 1.20081842 epoch total loss 1.13056099
Trained batch 3634 batch loss 1.20604026 epoch total loss 1.13058174
Trained batch 3635 batch loss 0.991072536 epoch total loss 1.13054347
Trained batch 3636 batch loss 1.10705948 epoch total loss 1.13053691
Trained batch 3637 batch loss 1.27656412 epoch total loss 1.13057709
Trained batch 3638 batch loss 0.78057158 epoch total loss 1.13048089
Trained batch 3639 batch loss 0.894252062 epoch total loss 1.13041592
Trained batch 3640 batch loss 0.975994706 epoch total loss 1.13037348
Trained batch 3641 batch loss 1.05766451 epoch total loss 1.13035357
Trained batch 3642 batch loss 1.10899937 epoch total loss 1.13034761
Trained batch 3643 batch loss 1.20984197 epoch total loss 1.13036954
Trained batch 3644 batch loss 1.10914564 epoch total loss 1.1303637
Trained batch 3645 batch loss 1.19771051 epoch total loss 1.13038218
Trained batch 3646 batch loss 1.20810652 epoch total loss 1.13040352
Trained batch 3647 batch loss 0.996565104 epoch total loss 1.1303668
Trained batch 3648 batch loss 1.22765815 epoch total loss 1.13039351
Trained batch 3649 batch loss 1.32475281 epoch total loss 1.13044667
Trained batch 3650 batch loss 1.11939728 epoch total loss 1.13044369
Trained batch 3651 batch loss 1.33906293 epoch total loss 1.13050079
Trained batch 3652 batch loss 1.07740974 epoch total loss 1.13048637
Trained batch 3653 batch loss 1.02357483 epoch total loss 1.13045704
Trained batch 3654 batch loss 1.22304547 epoch total loss 1.13048244
Trained batch 3655 batch loss 1.08359408 epoch total loss 1.13046956
Trained batch 3656 batch loss 0.88318032 epoch total loss 1.13040197
Trained batch 3657 batch loss 1.00831389 epoch total loss 1.13036859
Trained batch 3658 batch loss 0.81464076 epoch total loss 1.13028216
Trained batch 3659 batch loss 1.18122411 epoch total loss 1.13029611
Trained batch 3660 batch loss 1.14292288 epoch total loss 1.13029957
Trained batch 3661 batch loss 1.00159264 epoch total loss 1.1302644
Trained batch 3662 batch loss 1.00687492 epoch total loss 1.13023067
Trained batch 3663 batch loss 1.03046227 epoch total loss 1.13020337
Trained batch 3664 batch loss 0.832667589 epoch total loss 1.13012218
Trained batch 3665 batch loss 1.06007528 epoch total loss 1.13010299
Trained batch 3666 batch loss 0.950799584 epoch total loss 1.13005412
Trained batch 3667 batch loss 1.19320798 epoch total loss 1.1300714
Trained batch 3668 batch loss 1.03524518 epoch total loss 1.13004553
Trained batch 3669 batch loss 1.04311371 epoch total loss 1.13002181
Trained batch 3670 batch loss 1.15241337 epoch total loss 1.13002789
Trained batch 3671 batch loss 1.03040063 epoch total loss 1.13000071
Trained batch 3672 batch loss 0.815619946 epoch total loss 1.129915
Trained batch 3673 batch loss 0.990859866 epoch total loss 1.12987709
Trained batch 3674 batch loss 0.797099888 epoch total loss 1.12978649
Trained batch 3675 batch loss 1.20884919 epoch total loss 1.12980807
Trained batch 3676 batch loss 0.910363078 epoch total loss 1.12974823
Trained batch 3677 batch loss 0.887732863 epoch total loss 1.12968242
Trained batch 3678 batch loss 1.08966303 epoch total loss 1.12967157
Trained batch 3679 batch loss 1.03200006 epoch total loss 1.12964511
Trained batch 3680 batch loss 0.924355388 epoch total loss 1.12958932
Trained batch 3681 batch loss 1.01718771 epoch total loss 1.1295588
Trained batch 3682 batch loss 0.96040082 epoch total loss 1.12951279
Trained batch 3683 batch loss 1.23654795 epoch total loss 1.12954187
Trained batch 3684 batch loss 1.13256907 epoch total loss 1.12954271
Trained batch 3685 batch loss 1.05333114 epoch total loss 1.12952197
Trained batch 3686 batch loss 1.14210939 epoch total loss 1.12952542
Trained batch 3687 batch loss 1.04028845 epoch total loss 1.12950122
Trained batch 3688 batch loss 1.01237726 epoch total loss 1.12946951
Trained batch 3689 batch loss 0.943358362 epoch total loss 1.12941897
Trained batch 3690 batch loss 1.07378173 epoch total loss 1.12940395
Trained batch 3691 batch loss 0.812836647 epoch total loss 1.12931824
Trained batch 3692 batch loss 0.949180603 epoch total loss 1.12926936
Trained batch 3693 batch loss 1.09061074 epoch total loss 1.12925899
Trained batch 3694 batch loss 1.28524852 epoch total loss 1.12930119
Trained batch 3695 batch loss 1.07367575 epoch total loss 1.12928617
Trained batch 3696 batch loss 1.23082924 epoch total loss 1.12931371
Trained batch 3697 batch loss 1.16933942 epoch total loss 1.12932456
Trained batch 3698 batch loss 1.02372193 epoch total loss 1.12929606
Trained batch 3699 batch loss 1.02571285 epoch total loss 1.12926805
Trained batch 3700 batch loss 1.13874531 epoch total loss 1.12927067
Trained batch 3701 batch loss 1.20776701 epoch total loss 1.12929189
Trained batch 3702 batch loss 1.31282914 epoch total loss 1.12934148
Trained batch 3703 batch loss 1.23065543 epoch total loss 1.12936878
Trained batch 3704 batch loss 1.26042032 epoch total loss 1.12940419
Trained batch 3705 batch loss 1.00951266 epoch total loss 1.12937176
Trained batch 3706 batch loss 1.21117234 epoch total loss 1.1293937
Trained batch 3707 batch loss 1.26731038 epoch total loss 1.12943089
Trained batch 3708 batch loss 1.19044781 epoch total loss 1.12944734
Trained batch 3709 batch loss 1.30909228 epoch total loss 1.12949574
Trained batch 3710 batch loss 1.3190937 epoch total loss 1.12954688
Trained batch 3711 batch loss 1.1105566 epoch total loss 1.12954175
Trained batch 3712 batch loss 1.09519362 epoch total loss 1.12953258
Trained batch 3713 batch loss 1.18820858 epoch total loss 1.12954831
Trained batch 3714 batch loss 0.972436786 epoch total loss 1.12950599
Trained batch 3715 batch loss 1.16532016 epoch total loss 1.12951577
Trained batch 3716 batch loss 1.01603699 epoch total loss 1.12948525
Trained batch 3717 batch loss 1.31836152 epoch total loss 1.12953603
Trained batch 3718 batch loss 0.994450688 epoch total loss 1.12949967
Trained batch 3719 batch loss 1.17798769 epoch total loss 1.12951279
Trained batch 3720 batch loss 1.02961755 epoch total loss 1.12948596
Trained batch 3721 batch loss 1.02082288 epoch total loss 1.12945688
Trained batch 3722 batch loss 1.047544 epoch total loss 1.12943482
Trained batch 3723 batch loss 1.29452252 epoch total loss 1.12947917
Trained batch 3724 batch loss 1.28282261 epoch total loss 1.1295203
Trained batch 3725 batch loss 1.1409936 epoch total loss 1.1295234
Trained batch 3726 batch loss 1.03887928 epoch total loss 1.12949908
Trained batch 3727 batch loss 0.942641675 epoch total loss 1.12944901
Trained batch 3728 batch loss 1.18888378 epoch total loss 1.12946498
Trained batch 3729 batch loss 1.00869894 epoch total loss 1.12943268
Trained batch 3730 batch loss 0.947193265 epoch total loss 1.1293838
Trained batch 3731 batch loss 0.908422232 epoch total loss 1.12932456
Trained batch 3732 batch loss 0.893421292 epoch total loss 1.12926137
Trained batch 3733 batch loss 1.27378297 epoch total loss 1.12930012
Trained batch 3734 batch loss 1.25476432 epoch total loss 1.12933373
Trained batch 3735 batch loss 1.11708772 epoch total loss 1.12933052
Trained batch 3736 batch loss 1.21972466 epoch total loss 1.12935472
Trained batch 3737 batch loss 1.23832178 epoch total loss 1.1293838
Trained batch 3738 batch loss 1.27233648 epoch total loss 1.12942207
Trained batch 3739 batch loss 1.18062615 epoch total loss 1.12943578
Trained batch 3740 batch loss 1.11965084 epoch total loss 1.12943316
Trained batch 3741 batch loss 1.16846812 epoch total loss 1.12944365
Trained batch 3742 batch loss 1.1605823 epoch total loss 1.12945199
Trained batch 3743 batch loss 1.20329046 epoch total loss 1.12947166
Trained batch 3744 batch loss 1.18805182 epoch total loss 1.12948728
Trained batch 3745 batch loss 1.1793648 epoch total loss 1.12950051
Trained batch 3746 batch loss 1.43955088 epoch total loss 1.12958324
Trained batch 3747 batch loss 1.29729784 epoch total loss 1.12962806
Trained batch 3748 batch loss 1.13181055 epoch total loss 1.12962866
Trained batch 3749 batch loss 1.14889646 epoch total loss 1.12963378
Trained batch 3750 batch loss 1.0541923 epoch total loss 1.12961364
Trained batch 3751 batch loss 0.823631167 epoch total loss 1.1295321
Trained batch 3752 batch loss 1.07986522 epoch total loss 1.12951899
Trained batch 3753 batch loss 0.916585922 epoch total loss 1.12946224
Trained batch 3754 batch loss 0.988043368 epoch total loss 1.12942457
Trained batch 3755 batch loss 0.908449531 epoch total loss 1.1293658
Trained batch 3756 batch loss 0.938268423 epoch total loss 1.12931502
Trained batch 3757 batch loss 0.879647076 epoch total loss 1.12924862
Trained batch 3758 batch loss 0.745500088 epoch total loss 1.12914646
Trained batch 3759 batch loss 1.15173268 epoch total loss 1.12915254
Trained batch 3760 batch loss 1.2352525 epoch total loss 1.12918079
Trained batch 3761 batch loss 1.28584075 epoch total loss 1.12922239
Trained batch 3762 batch loss 1.1633321 epoch total loss 1.12923145
Trained batch 3763 batch loss 1.2674185 epoch total loss 1.12926829
Trained batch 3764 batch loss 1.38527024 epoch total loss 1.12933624
Trained batch 3765 batch loss 1.3863579 epoch total loss 1.12940454
Trained batch 3766 batch loss 1.11504459 epoch total loss 1.12940073
Trained batch 3767 batch loss 1.1777755 epoch total loss 1.1294136
Trained batch 3768 batch loss 1.44393206 epoch total loss 1.12949705
Trained batch 3769 batch loss 1.27715802 epoch total loss 1.12953627
Trained batch 3770 batch loss 1.32894158 epoch total loss 1.1295892
Trained batch 3771 batch loss 1.3803035 epoch total loss 1.12965572
Trained batch 3772 batch loss 1.06999397 epoch total loss 1.12963986
Trained batch 3773 batch loss 1.11494362 epoch total loss 1.12963593
Trained batch 3774 batch loss 1.13188791 epoch total loss 1.12963653
Trained batch 3775 batch loss 1.46958327 epoch total loss 1.12972653
Trained batch 3776 batch loss 1.48492801 epoch total loss 1.12982059
Trained batch 3777 batch loss 1.4363358 epoch total loss 1.12990177
Trained batch 3778 batch loss 1.22007895 epoch total loss 1.12992573
Trained batch 3779 batch loss 1.25459456 epoch total loss 1.12995863
Trained batch 3780 batch loss 1.14245725 epoch total loss 1.12996197
Trained batch 3781 batch loss 1.14588749 epoch total loss 1.12996626
Trained batch 3782 batch loss 1.23403311 epoch total loss 1.12999368
Trained batch 3783 batch loss 1.07584143 epoch total loss 1.12997937
Trained batch 3784 batch loss 1.17449689 epoch total loss 1.12999105
Trained batch 3785 batch loss 1.19417596 epoch total loss 1.1300081
Trained batch 3786 batch loss 1.37058663 epoch total loss 1.13007164
Trained batch 3787 batch loss 1.01902032 epoch total loss 1.13004231
Trained batch 3788 batch loss 1.18714976 epoch total loss 1.13005733
Trained batch 3789 batch loss 1.15327525 epoch total loss 1.13006353
Trained batch 3790 batch loss 1.31601596 epoch total loss 1.13011253
Trained batch 3791 batch loss 1.17707658 epoch total loss 1.13012493
Trained batch 3792 batch loss 1.12511206 epoch total loss 1.13012362
Trained batch 3793 batch loss 1.31618786 epoch total loss 1.13017273
Trained batch 3794 batch loss 1.18941593 epoch total loss 1.13018835
Trained batch 3795 batch loss 1.21589875 epoch total loss 1.13021088
Trained batch 3796 batch loss 1.10126948 epoch total loss 1.13020325
Trained batch 3797 batch loss 1.19602966 epoch total loss 1.13022053
Trained batch 3798 batch loss 1.4216888 epoch total loss 1.1302973
Trained batch 3799 batch loss 1.16278696 epoch total loss 1.13030577
Trained batch 3800 batch loss 1.25710487 epoch total loss 1.13033926
Trained batch 3801 batch loss 1.07257521 epoch total loss 1.13032413
Trained batch 3802 batch loss 1.11649 epoch total loss 1.13032055
Trained batch 3803 batch loss 1.23338127 epoch total loss 1.13034761
Trained batch 3804 batch loss 1.2777729 epoch total loss 1.13038635
Trained batch 3805 batch loss 1.10917509 epoch total loss 1.13038087
Trained batch 3806 batch loss 1.40590334 epoch total loss 1.13045323
Trained batch 3807 batch loss 1.3170079 epoch total loss 1.13050222
Trained batch 3808 batch loss 1.20466185 epoch total loss 1.13052166
Trained batch 3809 batch loss 1.17101526 epoch total loss 1.13053226
Trained batch 3810 batch loss 1.28479648 epoch total loss 1.13057268
Trained batch 3811 batch loss 1.14522481 epoch total loss 1.13057649
Trained batch 3812 batch loss 1.10437107 epoch total loss 1.13056958
Trained batch 3813 batch loss 1.03956115 epoch total loss 1.13054574
Trained batch 3814 batch loss 1.14045143 epoch total loss 1.13054836
Trained batch 3815 batch loss 1.3895961 epoch total loss 1.13061631
Trained batch 3816 batch loss 1.29621208 epoch total loss 1.13065982
Trained batch 3817 batch loss 1.14633417 epoch total loss 1.13066387
Trained batch 3818 batch loss 1.25325549 epoch total loss 1.13069606
Trained batch 3819 batch loss 1.1748836 epoch total loss 1.13070762
Trained batch 3820 batch loss 1.13822532 epoch total loss 1.13070953
Trained batch 3821 batch loss 0.977825284 epoch total loss 1.13066959
Trained batch 3822 batch loss 1.01528072 epoch total loss 1.13063943
Trained batch 3823 batch loss 1.01223421 epoch total loss 1.13060844
Trained batch 3824 batch loss 0.962099612 epoch total loss 1.13056433
Trained batch 3825 batch loss 1.15302658 epoch total loss 1.13057
Trained batch 3826 batch loss 1.2519685 epoch total loss 1.13060188
Trained batch 3827 batch loss 1.26979733 epoch total loss 1.13063824
Trained batch 3828 batch loss 1.1840235 epoch total loss 1.13065219
Trained batch 3829 batch loss 1.0535959 epoch total loss 1.13063216
Trained batch 3830 batch loss 1.19549799 epoch total loss 1.13064897
Trained batch 3831 batch loss 1.4850812 epoch total loss 1.13074148
Trained batch 3832 batch loss 1.17199421 epoch total loss 1.13075221
Trained batch 3833 batch loss 1.15715694 epoch total loss 1.13075912
Trained batch 3834 batch loss 1.38339591 epoch total loss 1.13082504
Trained batch 3835 batch loss 1.00806546 epoch total loss 1.13079309
Trained batch 3836 batch loss 0.996692955 epoch total loss 1.13075805
Trained batch 3837 batch loss 1.39642429 epoch total loss 1.13082731
Trained batch 3838 batch loss 0.853007317 epoch total loss 1.13075495
Trained batch 3839 batch loss 1.08665586 epoch total loss 1.13074338
Trained batch 3840 batch loss 0.986063242 epoch total loss 1.1307056
Trained batch 3841 batch loss 1.18099594 epoch total loss 1.13071883
Trained batch 3842 batch loss 1.05678356 epoch total loss 1.13069952
Trained batch 3843 batch loss 1.08311439 epoch total loss 1.13068712
Trained batch 3844 batch loss 1.02226233 epoch total loss 1.13065898
Trained batch 3845 batch loss 0.862574816 epoch total loss 1.13058925
Trained batch 3846 batch loss 0.913459 epoch total loss 1.13053286
Trained batch 3847 batch loss 1.18320346 epoch total loss 1.13054645
Trained batch 3848 batch loss 0.959451556 epoch total loss 1.1305021
Trained batch 3849 batch loss 0.810405135 epoch total loss 1.1304189
Trained batch 3850 batch loss 0.847440779 epoch total loss 1.13034546
Trained batch 3851 batch loss 1.09378207 epoch total loss 1.13033593
Trained batch 3852 batch loss 1.05131698 epoch total loss 1.13031542
Trained batch 3853 batch loss 1.10157537 epoch total loss 1.13030803
Trained batch 3854 batch loss 1.14354897 epoch total loss 1.13031137
Trained batch 3855 batch loss 1.14428771 epoch total loss 1.13031507
Trained batch 3856 batch loss 0.958396673 epoch total loss 1.1302706
Trained batch 3857 batch loss 1.15521181 epoch total loss 1.13027704
Trained batch 3858 batch loss 1.07790208 epoch total loss 1.13026357
Trained batch 3859 batch loss 1.14463425 epoch total loss 1.13026726
Trained batch 3860 batch loss 1.24816895 epoch total loss 1.13029778
Trained batch 3861 batch loss 1.1887573 epoch total loss 1.13031292
Trained batch 3862 batch loss 1.14268398 epoch total loss 1.13031614
Trained batch 3863 batch loss 1.21854782 epoch total loss 1.13033903
Trained batch 3864 batch loss 0.923090696 epoch total loss 1.13028526
Trained batch 3865 batch loss 0.969897628 epoch total loss 1.13024378
Trained batch 3866 batch loss 0.789844632 epoch total loss 1.1301558
Trained batch 3867 batch loss 0.963078618 epoch total loss 1.13011253
Trained batch 3868 batch loss 0.94201839 epoch total loss 1.13006389
Trained batch 3869 batch loss 1.06764126 epoch total loss 1.1300478
Trained batch 3870 batch loss 1.03316283 epoch total loss 1.13002276
Trained batch 3871 batch loss 1.06088912 epoch total loss 1.13000488
Trained batch 3872 batch loss 0.90840435 epoch total loss 1.12994766
Trained batch 3873 batch loss 0.916695654 epoch total loss 1.12989247
Trained batch 3874 batch loss 1.09286737 epoch total loss 1.12988293
Trained batch 3875 batch loss 0.984633327 epoch total loss 1.1298455
Trained batch 3876 batch loss 1.3250525 epoch total loss 1.12989593
Trained batch 3877 batch loss 1.45575404 epoch total loss 1.12998
Trained batch 3878 batch loss 1.23033071 epoch total loss 1.13000584
Trained batch 3879 batch loss 1.50864625 epoch total loss 1.13010347
Trained batch 3880 batch loss 1.40909123 epoch total loss 1.13017535
Trained batch 3881 batch loss 1.13276887 epoch total loss 1.13017607
Trained batch 3882 batch loss 1.2167809 epoch total loss 1.13019836
Trained batch 3883 batch loss 0.966635406 epoch total loss 1.13015628
Trained batch 3884 batch loss 1.02294803 epoch total loss 1.13012874
Trained batch 3885 batch loss 0.987754881 epoch total loss 1.13009202
Trained batch 3886 batch loss 1.1712296 epoch total loss 1.13010275
Trained batch 3887 batch loss 1.11532199 epoch total loss 1.13009882
Trained batch 3888 batch loss 1.18769944 epoch total loss 1.1301136
Trained batch 3889 batch loss 1.05883288 epoch total loss 1.13009524
Trained batch 3890 batch loss 1.05276132 epoch total loss 1.13007534
Trained batch 3891 batch loss 0.681791425 epoch total loss 1.12996006
Trained batch 3892 batch loss 0.851093292 epoch total loss 1.12988842
Trained batch 3893 batch loss 0.864727855 epoch total loss 1.12982035
Trained batch 3894 batch loss 0.835150719 epoch total loss 1.12974465
Trained batch 3895 batch loss 0.597936392 epoch total loss 1.12960815
Trained batch 3896 batch loss 0.661337793 epoch total loss 1.12948787
Trained batch 3897 batch loss 0.651979446 epoch total loss 1.12936532
Trained batch 3898 batch loss 0.75111866 epoch total loss 1.12926829
Trained batch 3899 batch loss 0.526897311 epoch total loss 1.12911379
Trained batch 3900 batch loss 0.820943952 epoch total loss 1.12903476
Trained batch 3901 batch loss 0.91420722 epoch total loss 1.12897956
Trained batch 3902 batch loss 0.977434397 epoch total loss 1.12894082
Trained batch 3903 batch loss 0.912130356 epoch total loss 1.12888527
Trained batch 3904 batch loss 0.806955814 epoch total loss 1.12880278
Trained batch 3905 batch loss 0.796621799 epoch total loss 1.12871766
Trained batch 3906 batch loss 1.15899873 epoch total loss 1.12872553
Trained batch 3907 batch loss 1.12831664 epoch total loss 1.12872541
Trained batch 3908 batch loss 0.991458654 epoch total loss 1.12869036
Trained batch 3909 batch loss 1.11905801 epoch total loss 1.12868786
Trained batch 3910 batch loss 1.06947827 epoch total loss 1.12867272
Trained batch 3911 batch loss 1.053828 epoch total loss 1.12865353
Trained batch 3912 batch loss 1.0808053 epoch total loss 1.12864125
Trained batch 3913 batch loss 0.910865545 epoch total loss 1.12858558
Trained batch 3914 batch loss 1.03007591 epoch total loss 1.12856042
Trained batch 3915 batch loss 0.889457822 epoch total loss 1.12849939
Trained batch 3916 batch loss 0.973936558 epoch total loss 1.12845993
Trained batch 3917 batch loss 1.11891341 epoch total loss 1.12845767
Trained batch 3918 batch loss 0.947952509 epoch total loss 1.12841153
Trained batch 3919 batch loss 1.07987118 epoch total loss 1.12839913
Trained batch 3920 batch loss 0.96325016 epoch total loss 1.12835705
Trained batch 3921 batch loss 0.954742551 epoch total loss 1.12831271
Trained batch 3922 batch loss 0.894642234 epoch total loss 1.1282531
Trained batch 3923 batch loss 0.877859116 epoch total loss 1.12818933
Trained batch 3924 batch loss 1.06242478 epoch total loss 1.12817264
Trained batch 3925 batch loss 1.07242966 epoch total loss 1.12815833
Trained batch 3926 batch loss 1.09194088 epoch total loss 1.12814903
Trained batch 3927 batch loss 0.696418703 epoch total loss 1.12803912
Trained batch 3928 batch loss 0.833261 epoch total loss 1.12796414
Trained batch 3929 batch loss 0.922232032 epoch total loss 1.12791181
Trained batch 3930 batch loss 0.902494848 epoch total loss 1.12785435
Trained batch 3931 batch loss 0.981893897 epoch total loss 1.12781727
Trained batch 3932 batch loss 1.25354218 epoch total loss 1.12784922
Trained batch 3933 batch loss 1.06489372 epoch total loss 1.12783325
Trained batch 3934 batch loss 0.971277952 epoch total loss 1.12779343
Trained batch 3935 batch loss 1.08149576 epoch total loss 1.12778163
Trained batch 3936 batch loss 1.14769936 epoch total loss 1.12778664
Trained batch 3937 batch loss 1.03058124 epoch total loss 1.12776196
Trained batch 3938 batch loss 1.03789949 epoch total loss 1.12773919
Trained batch 3939 batch loss 0.912515521 epoch total loss 1.12768459
Trained batch 3940 batch loss 1.0402385 epoch total loss 1.12766242
Trained batch 3941 batch loss 1.11022866 epoch total loss 1.12765801
Trained batch 3942 batch loss 0.762578845 epoch total loss 1.12756538
Trained batch 3943 batch loss 0.877111137 epoch total loss 1.12750185
Trained batch 3944 batch loss 1.16152549 epoch total loss 1.12751055
Trained batch 3945 batch loss 0.865549803 epoch total loss 1.12744415
Trained batch 3946 batch loss 0.912034154 epoch total loss 1.12738955
Trained batch 3947 batch loss 0.857590377 epoch total loss 1.12732112
Trained batch 3948 batch loss 0.971417367 epoch total loss 1.12728167
Trained batch 3949 batch loss 1.15012741 epoch total loss 1.12728739
Trained batch 3950 batch loss 1.17519414 epoch total loss 1.12729955
Trained batch 3951 batch loss 0.984156609 epoch total loss 1.12726331
Trained batch 3952 batch loss 1.10454178 epoch total loss 1.12725759
Trained batch 3953 batch loss 0.985283256 epoch total loss 1.1272217
Trained batch 3954 batch loss 0.885559678 epoch total loss 1.12716055
Trained batch 3955 batch loss 0.946151137 epoch total loss 1.12711489
Trained batch 3956 batch loss 1.46414435 epoch total loss 1.12720013
Trained batch 3957 batch loss 1.25089622 epoch total loss 1.12723136
Trained batch 3958 batch loss 1.30954111 epoch total loss 1.12727749
Trained batch 3959 batch loss 1.29734659 epoch total loss 1.12732041
Trained batch 3960 batch loss 1.55227041 epoch total loss 1.1274277
Trained batch 3961 batch loss 1.45153832 epoch total loss 1.12750959
Trained batch 3962 batch loss 1.27862763 epoch total loss 1.12754774
Trained batch 3963 batch loss 1.15510738 epoch total loss 1.12755477
Trained batch 3964 batch loss 1.33913159 epoch total loss 1.12760818
Trained batch 3965 batch loss 1.18459153 epoch total loss 1.1276226
Trained batch 3966 batch loss 0.781576514 epoch total loss 1.12753534
Trained batch 3967 batch loss 1.07849252 epoch total loss 1.12752306
Trained batch 3968 batch loss 1.04088163 epoch total loss 1.12750125
Trained batch 3969 batch loss 0.986666799 epoch total loss 1.12746572
Trained batch 3970 batch loss 1.17832816 epoch total loss 1.1274786
Trained batch 3971 batch loss 1.08253932 epoch total loss 1.12746727
Trained batch 3972 batch loss 1.30848479 epoch total loss 1.12751281
Trained batch 3973 batch loss 1.42543149 epoch total loss 1.1275878
Trained batch 3974 batch loss 1.28977358 epoch total loss 1.12762856
Trained batch 3975 batch loss 1.31748343 epoch total loss 1.12767625
Trained batch 3976 batch loss 1.08423829 epoch total loss 1.1276654
Trained batch 3977 batch loss 1.24791598 epoch total loss 1.12769568
Trained batch 3978 batch loss 1.19032788 epoch total loss 1.12771142
Trained batch 3979 batch loss 1.1700573 epoch total loss 1.12772202
Trained batch 3980 batch loss 1.16305447 epoch total loss 1.12773097
Trained batch 3981 batch loss 1.14027596 epoch total loss 1.12773407
Trained batch 3982 batch loss 0.932052433 epoch total loss 1.12768495
Trained batch 3983 batch loss 1.16856301 epoch total loss 1.1276952
Trained batch 3984 batch loss 1.32986355 epoch total loss 1.12774599
Trained batch 3985 batch loss 1.2563746 epoch total loss 1.12777829
Trained batch 3986 batch loss 0.897652149 epoch total loss 1.12772048
Trained batch 3987 batch loss 0.900517702 epoch total loss 1.12766349
Trained batch 3988 batch loss 1.14647651 epoch total loss 1.12766814
Trained batch 3989 batch loss 0.875953555 epoch total loss 1.12760508
Trained batch 3990 batch loss 1.12257993 epoch total loss 1.12760377
Trained batch 3991 batch loss 1.18921018 epoch total loss 1.12761927
Trained batch 3992 batch loss 1.37788939 epoch total loss 1.12768197
Trained batch 3993 batch loss 1.3961401 epoch total loss 1.1277492
Trained batch 3994 batch loss 1.10853195 epoch total loss 1.12774432
Trained batch 3995 batch loss 1.17252803 epoch total loss 1.12775552
Trained batch 3996 batch loss 1.22440517 epoch total loss 1.12777972
Trained batch 3997 batch loss 0.979745269 epoch total loss 1.12774277
Trained batch 3998 batch loss 1.02493453 epoch total loss 1.12771702
Trained batch 3999 batch loss 1.05823398 epoch total loss 1.12769961
Trained batch 4000 batch loss 1.11023045 epoch total loss 1.12769532
Trained batch 4001 batch loss 1.34456098 epoch total loss 1.12774956
Trained batch 4002 batch loss 1.35061216 epoch total loss 1.12780523
Trained batch 4003 batch loss 1.17506504 epoch total loss 1.12781715
Trained batch 4004 batch loss 1.22647846 epoch total loss 1.12784171
Trained batch 4005 batch loss 1.16222405 epoch total loss 1.12785029
Trained batch 4006 batch loss 1.25883651 epoch total loss 1.12788296
Trained batch 4007 batch loss 1.18561292 epoch total loss 1.12789738
Trained batch 4008 batch loss 1.06489944 epoch total loss 1.12788165
Trained batch 4009 batch loss 1.13831401 epoch total loss 1.12788427
Trained batch 4010 batch loss 1.1100738 epoch total loss 1.12787974
Trained batch 4011 batch loss 1.05705595 epoch total loss 1.1278621
Trained batch 4012 batch loss 0.925340772 epoch total loss 1.12781167
Trained batch 4013 batch loss 1.05187023 epoch total loss 1.12779272
Trained batch 4014 batch loss 0.995833874 epoch total loss 1.1277597
Trained batch 4015 batch loss 0.845184684 epoch total loss 1.12768936
Trained batch 4016 batch loss 0.931399345 epoch total loss 1.1276406
Trained batch 4017 batch loss 1.36614442 epoch total loss 1.1277
Trained batch 4018 batch loss 0.888255596 epoch total loss 1.12764037
Trained batch 4019 batch loss 1.20094132 epoch total loss 1.12765861
Trained batch 4020 batch loss 1.26351023 epoch total loss 1.12769246
Trained batch 4021 batch loss 1.11177504 epoch total loss 1.12768853
Trained batch 4022 batch loss 1.36954403 epoch total loss 1.12774873
Trained batch 4023 batch loss 1.1699152 epoch total loss 1.12775922
Trained batch 4024 batch loss 1.3479073 epoch total loss 1.12781394
Trained batch 4025 batch loss 1.18931413 epoch total loss 1.12782919
Trained batch 4026 batch loss 1.03186 epoch total loss 1.12780535
Trained batch 4027 batch loss 1.02059984 epoch total loss 1.12777877
Trained batch 4028 batch loss 1.24053311 epoch total loss 1.12780678
Trained batch 4029 batch loss 0.900493503 epoch total loss 1.12775028
Trained batch 4030 batch loss 1.05925953 epoch total loss 1.12773323
Trained batch 4031 batch loss 1.1702013 epoch total loss 1.12774384
Trained batch 4032 batch loss 1.02433348 epoch total loss 1.12771821
Trained batch 4033 batch loss 1.10235357 epoch total loss 1.12771201
Trained batch 4034 batch loss 1.05828655 epoch total loss 1.12769473
Trained batch 4035 batch loss 1.23381758 epoch total loss 1.12772107
Trained batch 4036 batch loss 1.43777692 epoch total loss 1.12779796
Trained batch 4037 batch loss 1.06679296 epoch total loss 1.12778282
Trained batch 4038 batch loss 1.42521751 epoch total loss 1.12785649
Trained batch 4039 batch loss 1.25444031 epoch total loss 1.12788785
Trained batch 4040 batch loss 1.30491364 epoch total loss 1.12793159
Trained batch 4041 batch loss 1.06915474 epoch total loss 1.12791717
Trained batch 4042 batch loss 0.949527085 epoch total loss 1.12787306
Trained batch 4043 batch loss 0.905993581 epoch total loss 1.12781811
Trained batch 4044 batch loss 0.847320855 epoch total loss 1.12774873
Trained batch 4045 batch loss 1.05416143 epoch total loss 1.12773049
Trained batch 4046 batch loss 1.07731605 epoch total loss 1.12771797
Trained batch 4047 batch loss 1.12761521 epoch total loss 1.12771797
Trained batch 4048 batch loss 1.13866043 epoch total loss 1.12772059
Trained batch 4049 batch loss 1.16869569 epoch total loss 1.12773073
Trained batch 4050 batch loss 1.09229422 epoch total loss 1.12772191
Trained batch 4051 batch loss 1.32965732 epoch total loss 1.12777174
Trained batch 4052 batch loss 1.33053112 epoch total loss 1.1278218
Trained batch 4053 batch loss 1.0339067 epoch total loss 1.12779856
Trained batch 4054 batch loss 0.952419281 epoch total loss 1.1277554
Trained batch 4055 batch loss 0.956880867 epoch total loss 1.12771332
Trained batch 4056 batch loss 1.19978166 epoch total loss 1.12773108
Trained batch 4057 batch loss 1.27267098 epoch total loss 1.12776673
Trained batch 4058 batch loss 1.15325189 epoch total loss 1.12777305
Trained batch 4059 batch loss 1.0455122 epoch total loss 1.12775278
Trained batch 4060 batch loss 1.34362793 epoch total loss 1.12780595
Trained batch 4061 batch loss 1.13244891 epoch total loss 1.12780702
Trained batch 4062 batch loss 1.33938169 epoch total loss 1.12785912
Trained batch 4063 batch loss 1.13463569 epoch total loss 1.12786078
Trained batch 4064 batch loss 1.09390736 epoch total loss 1.12785244
Trained batch 4065 batch loss 1.02453136 epoch total loss 1.12782693
Trained batch 4066 batch loss 1.0266825 epoch total loss 1.12780213
Trained batch 4067 batch loss 0.946058095 epoch total loss 1.12775755
Trained batch 4068 batch loss 0.918682694 epoch total loss 1.12770605
Trained batch 4069 batch loss 0.764770269 epoch total loss 1.12761688
Trained batch 4070 batch loss 0.940341055 epoch total loss 1.12757087
Trained batch 4071 batch loss 0.938940167 epoch total loss 1.1275245
Trained batch 4072 batch loss 1.35018885 epoch total loss 1.12757921
Trained batch 4073 batch loss 1.10923 epoch total loss 1.12757468
Trained batch 4074 batch loss 1.35189891 epoch total loss 1.12762976
Trained batch 4075 batch loss 1.36191785 epoch total loss 1.12768734
Trained batch 4076 batch loss 1.28303885 epoch total loss 1.12772548
Trained batch 4077 batch loss 1.18475688 epoch total loss 1.12773943
Trained batch 4078 batch loss 1.36145711 epoch total loss 1.12779665
Trained batch 4079 batch loss 1.3390187 epoch total loss 1.12784839
Trained batch 4080 batch loss 0.951858521 epoch total loss 1.12780523
Trained batch 4081 batch loss 1.06619263 epoch total loss 1.12779021
Trained batch 4082 batch loss 1.39039254 epoch total loss 1.12785459
Trained batch 4083 batch loss 1.11230218 epoch total loss 1.12785077
Trained batch 4084 batch loss 1.34127951 epoch total loss 1.12790298
Trained batch 4085 batch loss 1.17720199 epoch total loss 1.12791514
Trained batch 4086 batch loss 1.10109639 epoch total loss 1.12790859
Trained batch 4087 batch loss 1.09073 epoch total loss 1.12789941
Trained batch 4088 batch loss 1.19139898 epoch total loss 1.12791502
Trained batch 4089 batch loss 1.06107795 epoch total loss 1.12789869
Trained batch 4090 batch loss 0.924496174 epoch total loss 1.12784886
Trained batch 4091 batch loss 0.891898632 epoch total loss 1.12779129
Trained batch 4092 batch loss 0.795063436 epoch total loss 1.12770987
Trained batch 4093 batch loss 0.916446626 epoch total loss 1.12765825
Trained batch 4094 batch loss 0.930434108 epoch total loss 1.12761021
Trained batch 4095 batch loss 0.785778642 epoch total loss 1.12752664
Trained batch 4096 batch loss 0.982531071 epoch total loss 1.12749124
Trained batch 4097 batch loss 0.995653331 epoch total loss 1.12745905
Trained batch 4098 batch loss 1.08112133 epoch total loss 1.12744772
Trained batch 4099 batch loss 0.931481361 epoch total loss 1.12739992
Trained batch 4100 batch loss 1.00646269 epoch total loss 1.12737048
Trained batch 4101 batch loss 1.37977362 epoch total loss 1.12743199
Trained batch 4102 batch loss 1.33417726 epoch total loss 1.1274823
Trained batch 4103 batch loss 1.4413743 epoch total loss 1.12755883
Trained batch 4104 batch loss 1.6002866 epoch total loss 1.12767398
Trained batch 4105 batch loss 1.47450137 epoch total loss 1.1277585
Trained batch 4106 batch loss 1.08198833 epoch total loss 1.12774742
Trained batch 4107 batch loss 1.12683654 epoch total loss 1.12774718
Trained batch 4108 batch loss 1.32989991 epoch total loss 1.12779641
Trained batch 4109 batch loss 1.04576981 epoch total loss 1.1277765
Trained batch 4110 batch loss 1.08344662 epoch total loss 1.12776577
Trained batch 4111 batch loss 1.01149249 epoch total loss 1.12773752
Trained batch 4112 batch loss 1.0982132 epoch total loss 1.12773037
Trained batch 4113 batch loss 0.866354287 epoch total loss 1.12766671
Trained batch 4114 batch loss 1.1032846 epoch total loss 1.12766087
Trained batch 4115 batch loss 1.05032229 epoch total loss 1.12764204
Trained batch 4116 batch loss 0.968864799 epoch total loss 1.12760341
Trained batch 4117 batch loss 1.05443025 epoch total loss 1.12758565
Trained batch 4118 batch loss 1.03673077 epoch total loss 1.12756348
Trained batch 4119 batch loss 1.00563121 epoch total loss 1.12753403
Trained batch 4120 batch loss 1.03684163 epoch total loss 1.12751198
Trained batch 4121 batch loss 1.33127749 epoch total loss 1.12756133
Trained batch 4122 batch loss 1.05750585 epoch total loss 1.1275444
Trained batch 4123 batch loss 0.837745309 epoch total loss 1.12747407
Trained batch 4124 batch loss 1.03757012 epoch total loss 1.12745225
Trained batch 4125 batch loss 1.15950799 epoch total loss 1.12746012
Trained batch 4126 batch loss 1.17444193 epoch total loss 1.12747145
Trained batch 4127 batch loss 0.876473188 epoch total loss 1.12741065
Trained batch 4128 batch loss 1.03309119 epoch total loss 1.12738788
Trained batch 4129 batch loss 1.10452759 epoch total loss 1.12738228
Trained batch 4130 batch loss 1.14070153 epoch total loss 1.1273855
Trained batch 4131 batch loss 0.987395883 epoch total loss 1.12735152
Trained batch 4132 batch loss 1.03532 epoch total loss 1.12732923
Trained batch 4133 batch loss 1.26335204 epoch total loss 1.12736213
Trained batch 4134 batch loss 1.15686536 epoch total loss 1.12736928
Trained batch 4135 batch loss 1.14615679 epoch total loss 1.1273737
Trained batch 4136 batch loss 1.03165329 epoch total loss 1.12735057
Trained batch 4137 batch loss 1.17046165 epoch total loss 1.12736106
Trained batch 4138 batch loss 1.08603883 epoch total loss 1.12735105
Trained batch 4139 batch loss 1.03527689 epoch total loss 1.12732875
Trained batch 4140 batch loss 1.04957867 epoch total loss 1.12731
Trained batch 4141 batch loss 1.2490145 epoch total loss 1.12733936
Trained batch 4142 batch loss 1.21816528 epoch total loss 1.12736142
Trained batch 4143 batch loss 1.04933453 epoch total loss 1.12734258
Trained batch 4144 batch loss 1.12290394 epoch total loss 1.12734151
Trained batch 4145 batch loss 1.22224557 epoch total loss 1.1273644
Trained batch 4146 batch loss 0.994638383 epoch total loss 1.12733233
Trained batch 4147 batch loss 1.28410459 epoch total loss 1.12737012
Trained batch 4148 batch loss 1.12853956 epoch total loss 1.12737048
Trained batch 4149 batch loss 1.31517982 epoch total loss 1.12741566
Trained batch 4150 batch loss 1.05787635 epoch total loss 1.12739897
Trained batch 4151 batch loss 1.37040448 epoch total loss 1.1274575
Trained batch 4152 batch loss 1.04932737 epoch total loss 1.12743866
Trained batch 4153 batch loss 0.909405649 epoch total loss 1.12738609
Trained batch 4154 batch loss 1.09422803 epoch total loss 1.12737823
Trained batch 4155 batch loss 0.973876715 epoch total loss 1.12734115
Trained batch 4156 batch loss 0.947454572 epoch total loss 1.12729788
Trained batch 4157 batch loss 1.21331882 epoch total loss 1.1273185
Trained batch 4158 batch loss 1.18644333 epoch total loss 1.12733281
Trained batch 4159 batch loss 1.05225635 epoch total loss 1.12731469
Trained batch 4160 batch loss 1.08091915 epoch total loss 1.1273036
Trained batch 4161 batch loss 0.99529922 epoch total loss 1.12727189
Trained batch 4162 batch loss 1.00065017 epoch total loss 1.12724137
Trained batch 4163 batch loss 1.25434399 epoch total loss 1.12727189
Trained batch 4164 batch loss 1.04254556 epoch total loss 1.12725151
Trained batch 4165 batch loss 1.28028464 epoch total loss 1.12728834
Trained batch 4166 batch loss 1.36122656 epoch total loss 1.12734449
Trained batch 4167 batch loss 1.28272831 epoch total loss 1.1273818
Trained batch 4168 batch loss 1.03833711 epoch total loss 1.12736046
Trained batch 4169 batch loss 1.19797683 epoch total loss 1.12737739
Trained batch 4170 batch loss 0.980106831 epoch total loss 1.12734199
Trained batch 4171 batch loss 1.07487905 epoch total loss 1.12732935
Trained batch 4172 batch loss 1.05401695 epoch total loss 1.12731183
Trained batch 4173 batch loss 1.10621238 epoch total loss 1.12730682
Trained batch 4174 batch loss 1.24068594 epoch total loss 1.127334
Trained batch 4175 batch loss 1.14495265 epoch total loss 1.12733829
Trained batch 4176 batch loss 1.23860729 epoch total loss 1.12736499
Trained batch 4177 batch loss 1.10390186 epoch total loss 1.12735939
Trained batch 4178 batch loss 1.19647217 epoch total loss 1.12737584
Trained batch 4179 batch loss 1.43918431 epoch total loss 1.12745035
Trained batch 4180 batch loss 1.16238952 epoch total loss 1.12745881
Trained batch 4181 batch loss 1.09412682 epoch total loss 1.12745082
Trained batch 4182 batch loss 1.09701633 epoch total loss 1.12744367
Trained batch 4183 batch loss 0.843405306 epoch total loss 1.12737572
Trained batch 4184 batch loss 0.963414 epoch total loss 1.1273365
Trained batch 4185 batch loss 1.02971554 epoch total loss 1.12731314
Trained batch 4186 batch loss 1.15587831 epoch total loss 1.12731993
Trained batch 4187 batch loss 1.02266502 epoch total loss 1.1272949
Trained batch 4188 batch loss 1.0808059 epoch total loss 1.12728381
Trained batch 4189 batch loss 1.21240139 epoch total loss 1.12730408
Trained batch 4190 batch loss 1.09778261 epoch total loss 1.12729704
Trained batch 4191 batch loss 1.17414784 epoch total loss 1.12730825
Trained batch 4192 batch loss 1.01391017 epoch total loss 1.12728119
Trained batch 4193 batch loss 0.973636 epoch total loss 1.12724447
Trained batch 4194 batch loss 0.945393085 epoch total loss 1.12720108
Trained batch 4195 batch loss 1.24763751 epoch total loss 1.12722981
Trained batch 4196 batch loss 1.0786227 epoch total loss 1.12721825
Trained batch 4197 batch loss 1.02260804 epoch total loss 1.12719321
Trained batch 4198 batch loss 1.03854096 epoch total loss 1.12717211
Trained batch 4199 batch loss 0.960045159 epoch total loss 1.1271323
Trained batch 4200 batch loss 0.796164751 epoch total loss 1.12705362
Trained batch 4201 batch loss 0.869598 epoch total loss 1.12699234
Trained batch 4202 batch loss 0.895286441 epoch total loss 1.12693715
Trained batch 4203 batch loss 0.927927732 epoch total loss 1.12688982
Trained batch 4204 batch loss 0.829281509 epoch total loss 1.12681901
Trained batch 4205 batch loss 0.95351404 epoch total loss 1.12677777
Trained batch 4206 batch loss 0.979704499 epoch total loss 1.12674272
Trained batch 4207 batch loss 0.8244946 epoch total loss 1.12667096
Trained batch 4208 batch loss 1.04585671 epoch total loss 1.12665176
Trained batch 4209 batch loss 1.0062871 epoch total loss 1.12662315
Trained batch 4210 batch loss 0.824075341 epoch total loss 1.12655139
Trained batch 4211 batch loss 0.957482874 epoch total loss 1.12651122
Trained batch 4212 batch loss 1.31039715 epoch total loss 1.12655497
Trained batch 4213 batch loss 1.16621399 epoch total loss 1.12656426
Trained batch 4214 batch loss 0.979712844 epoch total loss 1.12652934
Trained batch 4215 batch loss 1.00012052 epoch total loss 1.12649941
Trained batch 4216 batch loss 1.13648748 epoch total loss 1.1265018
Trained batch 4217 batch loss 0.979002953 epoch total loss 1.12646687
Trained batch 4218 batch loss 1.00928092 epoch total loss 1.12643898
Trained batch 4219 batch loss 0.946721256 epoch total loss 1.12639642
Trained batch 4220 batch loss 0.846044183 epoch total loss 1.12633
Trained batch 4221 batch loss 1.17172873 epoch total loss 1.12634087
Trained batch 4222 batch loss 0.910698891 epoch total loss 1.12628973
Trained batch 4223 batch loss 1.11050224 epoch total loss 1.12628603
Trained batch 4224 batch loss 0.894753218 epoch total loss 1.12623107
Trained batch 4225 batch loss 1.11597967 epoch total loss 1.12622869
Trained batch 4226 batch loss 1.19623911 epoch total loss 1.12624526
Trained batch 4227 batch loss 1.01757193 epoch total loss 1.12621963
Trained batch 4228 batch loss 0.999110103 epoch total loss 1.12618947
Trained batch 4229 batch loss 0.978752196 epoch total loss 1.12615466
Trained batch 4230 batch loss 0.839774191 epoch total loss 1.12608695
Trained batch 4231 batch loss 0.909960628 epoch total loss 1.12603593
Trained batch 4232 batch loss 1.25183249 epoch total loss 1.12606561
Trained batch 4233 batch loss 1.37592292 epoch total loss 1.12612462
Trained batch 4234 batch loss 1.21282232 epoch total loss 1.12614512
Trained batch 4235 batch loss 1.09513068 epoch total loss 1.12613785
Trained batch 4236 batch loss 1.13844705 epoch total loss 1.12614083
Trained batch 4237 batch loss 1.12099 epoch total loss 1.12613964
Trained batch 4238 batch loss 1.25953674 epoch total loss 1.12617111
Trained batch 4239 batch loss 1.38124752 epoch total loss 1.12623131
Trained batch 4240 batch loss 1.03628242 epoch total loss 1.12621009
Trained batch 4241 batch loss 1.32979846 epoch total loss 1.12625802
Trained batch 4242 batch loss 1.22024369 epoch total loss 1.12628019
Trained batch 4243 batch loss 1.22430801 epoch total loss 1.12630332
Trained batch 4244 batch loss 1.07781661 epoch total loss 1.12629175
Trained batch 4245 batch loss 1.19999623 epoch total loss 1.12630916
Trained batch 4246 batch loss 1.13318682 epoch total loss 1.12631083
Trained batch 4247 batch loss 1.36544645 epoch total loss 1.12636709
Trained batch 4248 batch loss 1.28731322 epoch total loss 1.126405
Trained batch 4249 batch loss 1.34084392 epoch total loss 1.12645543
Trained batch 4250 batch loss 0.957145452 epoch total loss 1.12641561
Trained batch 4251 batch loss 1.04015243 epoch total loss 1.12639523
Trained batch 4252 batch loss 1.08429432 epoch total loss 1.12638533
Trained batch 4253 batch loss 0.910200655 epoch total loss 1.12633455
Trained batch 4254 batch loss 1.02777958 epoch total loss 1.12631142
Trained batch 4255 batch loss 1.02857649 epoch total loss 1.12628841
Trained batch 4256 batch loss 1.0395087 epoch total loss 1.12626803
Trained batch 4257 batch loss 1.12583447 epoch total loss 1.12626803
Trained batch 4258 batch loss 0.945692658 epoch total loss 1.12622559
Trained batch 4259 batch loss 0.829056263 epoch total loss 1.12615585
Trained batch 4260 batch loss 1.01883566 epoch total loss 1.1261307
Trained batch 4261 batch loss 1.15081215 epoch total loss 1.12613654
Trained batch 4262 batch loss 1.39234316 epoch total loss 1.12619901
Trained batch 4263 batch loss 1.18767786 epoch total loss 1.12621343
Trained batch 4264 batch loss 1.01845598 epoch total loss 1.12618816
Trained batch 4265 batch loss 1.12915635 epoch total loss 1.12618887
Trained batch 4266 batch loss 1.08713865 epoch total loss 1.1261797
Trained batch 4267 batch loss 0.942636371 epoch total loss 1.12613678
Trained batch 4268 batch loss 0.877150178 epoch total loss 1.12607837
Trained batch 4269 batch loss 1.0985781 epoch total loss 1.12607193
Trained batch 4270 batch loss 0.77586627 epoch total loss 1.12598991
Trained batch 4271 batch loss 1.05725658 epoch total loss 1.12597382
Trained batch 4272 batch loss 1.07411087 epoch total loss 1.12596166
Trained batch 4273 batch loss 1.1437254 epoch total loss 1.12596583
Trained batch 4274 batch loss 1.06505871 epoch total loss 1.12595153
Trained batch 4275 batch loss 1.03280187 epoch total loss 1.12592971
Trained batch 4276 batch loss 1.09669757 epoch total loss 1.12592292
Trained batch 4277 batch loss 1.05137324 epoch total loss 1.12590539
Trained batch 4278 batch loss 1.04514647 epoch total loss 1.12588656
Trained batch 4279 batch loss 0.934444368 epoch total loss 1.12584186
Trained batch 4280 batch loss 0.938025951 epoch total loss 1.12579787
Trained batch 4281 batch loss 1.18695235 epoch total loss 1.12581217
Trained batch 4282 batch loss 1.22340345 epoch total loss 1.12583506
Trained batch 4283 batch loss 1.08769202 epoch total loss 1.12582624
Trained batch 4284 batch loss 0.808489084 epoch total loss 1.12575209
Trained batch 4285 batch loss 1.07159972 epoch total loss 1.12573957
Trained batch 4286 batch loss 1.15904427 epoch total loss 1.12574732
Trained batch 4287 batch loss 1.27124786 epoch total loss 1.1257813
Trained batch 4288 batch loss 1.00544596 epoch total loss 1.12575328
Trained batch 4289 batch loss 0.948159933 epoch total loss 1.12571192
Trained batch 4290 batch loss 1.04255342 epoch total loss 1.12569249
Trained batch 4291 batch loss 1.19196212 epoch total loss 1.12570786
Trained batch 4292 batch loss 1.09101629 epoch total loss 1.12569976
Trained batch 4293 batch loss 1.08796501 epoch total loss 1.12569094
Trained batch 4294 batch loss 0.902705729 epoch total loss 1.12563908
Trained batch 4295 batch loss 1.34704304 epoch total loss 1.1256907
Trained batch 4296 batch loss 1.09826672 epoch total loss 1.12568426
Trained batch 4297 batch loss 1.09003258 epoch total loss 1.12567592
Trained batch 4298 batch loss 0.963458896 epoch total loss 1.12563813
Trained batch 4299 batch loss 0.71248889 epoch total loss 1.12554204
Trained batch 4300 batch loss 0.892546892 epoch total loss 1.1254878
Trained batch 4301 batch loss 1.25234771 epoch total loss 1.12551737
Trained batch 4302 batch loss 1.16109443 epoch total loss 1.12552559
Trained batch 4303 batch loss 1.19684601 epoch total loss 1.12554216
Trained batch 4304 batch loss 1.17309403 epoch total loss 1.12555313
Trained batch 4305 batch loss 1.28056049 epoch total loss 1.12558925
Trained batch 4306 batch loss 1.10785723 epoch total loss 1.12558508
Trained batch 4307 batch loss 1.09319985 epoch total loss 1.12557757
Trained batch 4308 batch loss 0.978221536 epoch total loss 1.12554336
Trained batch 4309 batch loss 0.781386256 epoch total loss 1.12546349
Trained batch 4310 batch loss 0.98606 epoch total loss 1.12543106
Trained batch 4311 batch loss 1.24106693 epoch total loss 1.12545788
Trained batch 4312 batch loss 1.10835 epoch total loss 1.12545395
Trained batch 4313 batch loss 1.05442226 epoch total loss 1.1254375
Trained batch 4314 batch loss 1.08122706 epoch total loss 1.12542713
Trained batch 4315 batch loss 1.07382178 epoch total loss 1.12541521
Trained batch 4316 batch loss 1.28717303 epoch total loss 1.12545264
Trained batch 4317 batch loss 1.33678854 epoch total loss 1.12550163
Trained batch 4318 batch loss 1.10872781 epoch total loss 1.12549782
Trained batch 4319 batch loss 1.19388688 epoch total loss 1.12551355
Trained batch 4320 batch loss 1.27633083 epoch total loss 1.12554848
Trained batch 4321 batch loss 0.904633284 epoch total loss 1.12549746
Trained batch 4322 batch loss 0.927031398 epoch total loss 1.12545156
Trained batch 4323 batch loss 1.13995719 epoch total loss 1.1254549
Trained batch 4324 batch loss 1.03406477 epoch total loss 1.1254338
Trained batch 4325 batch loss 1.22779703 epoch total loss 1.12545753
Trained batch 4326 batch loss 1.17415118 epoch total loss 1.12546885
Trained batch 4327 batch loss 1.27259779 epoch total loss 1.12550282
Trained batch 4328 batch loss 1.19650543 epoch total loss 1.12551916
Trained batch 4329 batch loss 1.09555304 epoch total loss 1.12551236
Trained batch 4330 batch loss 0.822820425 epoch total loss 1.12544239
Trained batch 4331 batch loss 0.898705542 epoch total loss 1.12539
Trained batch 4332 batch loss 0.93367672 epoch total loss 1.12534583
Trained batch 4333 batch loss 1.18941331 epoch total loss 1.12536061
Trained batch 4334 batch loss 0.869352639 epoch total loss 1.12530148
Trained batch 4335 batch loss 1.14491248 epoch total loss 1.12530601
Trained batch 4336 batch loss 1.19563651 epoch total loss 1.12532234
Trained batch 4337 batch loss 1.31536222 epoch total loss 1.12536609
Trained batch 4338 batch loss 1.14530611 epoch total loss 1.12537074
Trained batch 4339 batch loss 1.27129662 epoch total loss 1.12540448
Trained batch 4340 batch loss 1.17662978 epoch total loss 1.12541628
Trained batch 4341 batch loss 1.28667033 epoch total loss 1.12545335
Trained batch 4342 batch loss 1.07050097 epoch total loss 1.12544072
Trained batch 4343 batch loss 0.990482926 epoch total loss 1.12540972
Trained batch 4344 batch loss 1.13968897 epoch total loss 1.12541294
Trained batch 4345 batch loss 1.16369128 epoch total loss 1.12542176
Trained batch 4346 batch loss 1.11994529 epoch total loss 1.12542057
Trained batch 4347 batch loss 0.97909373 epoch total loss 1.12538683
Trained batch 4348 batch loss 1.25795221 epoch total loss 1.12541735
Trained batch 4349 batch loss 1.05375504 epoch total loss 1.12540078
Trained batch 4350 batch loss 1.28154039 epoch total loss 1.12543678
Trained batch 4351 batch loss 1.13306427 epoch total loss 1.12543857
Trained batch 4352 batch loss 1.09487724 epoch total loss 1.12543154
Trained batch 4353 batch loss 1.02017915 epoch total loss 1.12540734
Trained batch 4354 batch loss 1.2657125 epoch total loss 1.12543952
Trained batch 4355 batch loss 1.17104423 epoch total loss 1.1254499
Trained batch 4356 batch loss 1.18080735 epoch total loss 1.12546265
Trained batch 4357 batch loss 1.20339537 epoch total loss 1.12548053
Trained batch 4358 batch loss 1.12828231 epoch total loss 1.12548125
Trained batch 4359 batch loss 1.27163744 epoch total loss 1.12551475
Trained batch 4360 batch loss 1.12722635 epoch total loss 1.1255151
Trained batch 4361 batch loss 1.10941887 epoch total loss 1.12551141
Trained batch 4362 batch loss 1.3756721 epoch total loss 1.12556875
Trained batch 4363 batch loss 0.866724968 epoch total loss 1.12550938
Trained batch 4364 batch loss 0.959639728 epoch total loss 1.12547135
Trained batch 4365 batch loss 0.991379619 epoch total loss 1.1254406
Trained batch 4366 batch loss 0.771678209 epoch total loss 1.12535954
Trained batch 4367 batch loss 1.12228537 epoch total loss 1.12535882
Trained batch 4368 batch loss 1.30075741 epoch total loss 1.12539899
Trained batch 4369 batch loss 0.955850363 epoch total loss 1.12536025
Trained batch 4370 batch loss 1.22668672 epoch total loss 1.12538338
Trained batch 4371 batch loss 1.03783751 epoch total loss 1.12536323
Trained batch 4372 batch loss 0.70863986 epoch total loss 1.12526798
Trained batch 4373 batch loss 1.09984994 epoch total loss 1.12526202
Trained batch 4374 batch loss 0.949972391 epoch total loss 1.12522209
Trained batch 4375 batch loss 0.956416786 epoch total loss 1.12518346
Trained batch 4376 batch loss 1.05905414 epoch total loss 1.12516832
Trained batch 4377 batch loss 0.816687703 epoch total loss 1.12509799
Trained batch 4378 batch loss 0.853566587 epoch total loss 1.12503588
Trained batch 4379 batch loss 0.900481462 epoch total loss 1.12498462
Trained batch 4380 batch loss 1.00031853 epoch total loss 1.12495613
Trained batch 4381 batch loss 0.937187791 epoch total loss 1.12491333
Trained batch 4382 batch loss 1.03172445 epoch total loss 1.124892
Trained batch 4383 batch loss 1.14843321 epoch total loss 1.12489736
Trained batch 4384 batch loss 1.16811824 epoch total loss 1.12490726
Trained batch 4385 batch loss 0.924322 epoch total loss 1.12486148
Trained batch 4386 batch loss 1.10187244 epoch total loss 1.12485623
Trained batch 4387 batch loss 0.996447325 epoch total loss 1.12482703
Trained batch 4388 batch loss 1.05059636 epoch total loss 1.12481022
Trained batch 4389 batch loss 1.2125355 epoch total loss 1.12483013
Trained batch 4390 batch loss 1.10074043 epoch total loss 1.12482464
Trained batch 4391 batch loss 1.29657495 epoch total loss 1.12486362
Trained batch 4392 batch loss 0.972493887 epoch total loss 1.12482905
Trained batch 4393 batch loss 1.04078531 epoch total loss 1.12481
Trained batch 4394 batch loss 0.958684206 epoch total loss 1.12477207
Trained batch 4395 batch loss 0.886777222 epoch total loss 1.12471795
Trained batch 4396 batch loss 1.16706157 epoch total loss 1.12472749
Trained batch 4397 batch loss 0.845239639 epoch total loss 1.12466395
Trained batch 4398 batch loss 1.08324218 epoch total loss 1.12465453
Trained batch 4399 batch loss 1.12280595 epoch total loss 1.12465417
Trained batch 4400 batch loss 1.1351912 epoch total loss 1.12465656
Trained batch 4401 batch loss 1.05781436 epoch total loss 1.1246413
Trained batch 4402 batch loss 1.11482918 epoch total loss 1.12463903
Trained batch 4403 batch loss 0.962741494 epoch total loss 1.12460232
Trained batch 4404 batch loss 0.945388436 epoch total loss 1.12456167
Trained batch 4405 batch loss 0.897689 epoch total loss 1.12451
Trained batch 4406 batch loss 0.871417642 epoch total loss 1.12445271
Trained batch 4407 batch loss 1.18337131 epoch total loss 1.12446606
Trained batch 4408 batch loss 1.04414225 epoch total loss 1.12444782
Trained batch 4409 batch loss 1.12140703 epoch total loss 1.12444711
Trained batch 4410 batch loss 1.2391119 epoch total loss 1.12447321
Trained batch 4411 batch loss 1.41738236 epoch total loss 1.12453961
Trained batch 4412 batch loss 1.30302596 epoch total loss 1.12458014
Trained batch 4413 batch loss 1.15022767 epoch total loss 1.12458599
Trained batch 4414 batch loss 1.13908577 epoch total loss 1.1245892
Trained batch 4415 batch loss 1.12438941 epoch total loss 1.1245892
Trained batch 4416 batch loss 1.29801726 epoch total loss 1.12462842
Trained batch 4417 batch loss 1.252774 epoch total loss 1.12465751
Trained batch 4418 batch loss 1.11150515 epoch total loss 1.12465453
Trained batch 4419 batch loss 1.13773263 epoch total loss 1.12465751
Trained batch 4420 batch loss 1.16179502 epoch total loss 1.12466586
Trained batch 4421 batch loss 1.14785314 epoch total loss 1.1246711
Trained batch 4422 batch loss 0.993464112 epoch total loss 1.12464142
Trained batch 4423 batch loss 1.14420199 epoch total loss 1.12464583
Trained batch 4424 batch loss 1.14035153 epoch total loss 1.12464941
Trained batch 4425 batch loss 1.30144739 epoch total loss 1.12468922
Trained batch 4426 batch loss 0.997752666 epoch total loss 1.12466049
Trained batch 4427 batch loss 1.01507473 epoch total loss 1.12463582
Trained batch 4428 batch loss 1.21043658 epoch total loss 1.12465513
Trained batch 4429 batch loss 1.03915477 epoch total loss 1.12463582
Trained batch 4430 batch loss 1.13321948 epoch total loss 1.12463784
Trained batch 4431 batch loss 1.19965744 epoch total loss 1.12465477
Trained batch 4432 batch loss 1.01904523 epoch total loss 1.12463093
Trained batch 4433 batch loss 0.898526192 epoch total loss 1.12457991
Trained batch 4434 batch loss 1.09444439 epoch total loss 1.12457311
Trained batch 4435 batch loss 1.38216925 epoch total loss 1.12463117
Trained batch 4436 batch loss 1.18632233 epoch total loss 1.12464511
Trained batch 4437 batch loss 1.14382648 epoch total loss 1.12464952
Trained batch 4438 batch loss 1.0411731 epoch total loss 1.12463069
Trained batch 4439 batch loss 0.823091686 epoch total loss 1.12456274
Trained batch 4440 batch loss 1.10541892 epoch total loss 1.12455845
Trained batch 4441 batch loss 1.07445538 epoch total loss 1.12454712
Trained batch 4442 batch loss 1.10545564 epoch total loss 1.12454283
Trained batch 4443 batch loss 1.22566652 epoch total loss 1.1245656
Trained batch 4444 batch loss 1.02235198 epoch total loss 1.12454259
Trained batch 4445 batch loss 0.941462159 epoch total loss 1.12450135
Trained batch 4446 batch loss 0.901408792 epoch total loss 1.12445116
Trained batch 4447 batch loss 1.09222674 epoch total loss 1.12444401
Trained batch 4448 batch loss 1.3069855 epoch total loss 1.12448502
Trained batch 4449 batch loss 1.30031705 epoch total loss 1.12452459
Trained batch 4450 batch loss 1.14505613 epoch total loss 1.12452912
Trained batch 4451 batch loss 0.93977648 epoch total loss 1.12448764
Trained batch 4452 batch loss 1.04274607 epoch total loss 1.1244694
Trained batch 4453 batch loss 0.9300704 epoch total loss 1.12442577
Trained batch 4454 batch loss 1.13916636 epoch total loss 1.12442911
Trained batch 4455 batch loss 0.839029074 epoch total loss 1.12436497
Trained batch 4456 batch loss 0.990626574 epoch total loss 1.12433493
Trained batch 4457 batch loss 0.89924556 epoch total loss 1.12428451
Trained batch 4458 batch loss 1.15950704 epoch total loss 1.12429249
Trained batch 4459 batch loss 1.04131758 epoch total loss 1.1242739
Trained batch 4460 batch loss 1.1854142 epoch total loss 1.12428761
Trained batch 4461 batch loss 1.15691352 epoch total loss 1.12429488
Trained batch 4462 batch loss 0.989701748 epoch total loss 1.12426472
Trained batch 4463 batch loss 0.951517701 epoch total loss 1.12422609
Trained batch 4464 batch loss 1.08343291 epoch total loss 1.12421691
Trained batch 4465 batch loss 1.03858352 epoch total loss 1.12419772
Trained batch 4466 batch loss 1.05945778 epoch total loss 1.1241833
Trained batch 4467 batch loss 0.900858641 epoch total loss 1.12413335
Trained batch 4468 batch loss 1.11654925 epoch total loss 1.12413168
Trained batch 4469 batch loss 1.03131676 epoch total loss 1.12411082
Trained batch 4470 batch loss 1.06349277 epoch total loss 1.12409723
Trained batch 4471 batch loss 1.14842653 epoch total loss 1.12410271
Trained batch 4472 batch loss 0.974880457 epoch total loss 1.12406945
Trained batch 4473 batch loss 1.07394969 epoch total loss 1.12405813
Trained batch 4474 batch loss 0.83991313 epoch total loss 1.12399459
Trained batch 4475 batch loss 0.993098378 epoch total loss 1.12396538
Trained batch 4476 batch loss 0.89524585 epoch total loss 1.12391424
Trained batch 4477 batch loss 1.26052952 epoch total loss 1.12394476
Trained batch 4478 batch loss 1.07624221 epoch total loss 1.12393415
Trained batch 4479 batch loss 1.01400185 epoch total loss 1.12390959
Trained batch 4480 batch loss 1.11127961 epoch total loss 1.12390685
Trained batch 4481 batch loss 1.20390391 epoch total loss 1.12392473
Trained batch 4482 batch loss 1.18918049 epoch total loss 1.12393928
Trained batch 4483 batch loss 1.44008636 epoch total loss 1.12400973
Trained batch 4484 batch loss 1.1588304 epoch total loss 1.12401748
Trained batch 4485 batch loss 1.04544747 epoch total loss 1.124
Trained batch 4486 batch loss 1.18124413 epoch total loss 1.12401271
Trained batch 4487 batch loss 1.2192862 epoch total loss 1.12403393
Trained batch 4488 batch loss 1.05254412 epoch total loss 1.12401795
Trained batch 4489 batch loss 1.07422686 epoch total loss 1.12400687
Trained batch 4490 batch loss 1.09957051 epoch total loss 1.1240015
Trained batch 4491 batch loss 1.08746767 epoch total loss 1.12399328
Trained batch 4492 batch loss 1.0439384 epoch total loss 1.12397552
Trained batch 4493 batch loss 1.19321465 epoch total loss 1.12399089
Trained batch 4494 batch loss 1.1896379 epoch total loss 1.12400556
Trained batch 4495 batch loss 1.34856343 epoch total loss 1.1240555
Trained batch 4496 batch loss 1.26426494 epoch total loss 1.12408662
Trained batch 4497 batch loss 1.34694576 epoch total loss 1.12413621
Trained batch 4498 batch loss 1.09067917 epoch total loss 1.12412882
Trained batch 4499 batch loss 1.37813902 epoch total loss 1.1241852
Trained batch 4500 batch loss 1.03618586 epoch total loss 1.12416565
Trained batch 4501 batch loss 1.17065966 epoch total loss 1.12417603
Trained batch 4502 batch loss 1.31684577 epoch total loss 1.12421882
Trained batch 4503 batch loss 1.20592904 epoch total loss 1.12423706
Trained batch 4504 batch loss 1.19939303 epoch total loss 1.12425375
Trained batch 4505 batch loss 1.38075829 epoch total loss 1.12431061
Trained batch 4506 batch loss 1.24720383 epoch total loss 1.12433791
Trained batch 4507 batch loss 1.1990025 epoch total loss 1.12435448
Trained batch 4508 batch loss 1.13065529 epoch total loss 1.12435591
Trained batch 4509 batch loss 1.19355643 epoch total loss 1.12437129
Trained batch 4510 batch loss 1.0479604 epoch total loss 1.12435424
Trained batch 4511 batch loss 1.1891309 epoch total loss 1.12436867
Trained batch 4512 batch loss 1.27668357 epoch total loss 1.1244024
Trained batch 4513 batch loss 1.34424627 epoch total loss 1.12445116
Trained batch 4514 batch loss 0.984548032 epoch total loss 1.12442
Trained batch 4515 batch loss 1.18475366 epoch total loss 1.1244334
Trained batch 4516 batch loss 1.35463321 epoch total loss 1.12448442
Trained batch 4517 batch loss 1.22354889 epoch total loss 1.12450635
Trained batch 4518 batch loss 1.0943948 epoch total loss 1.12449956
Trained batch 4519 batch loss 1.01948452 epoch total loss 1.12447643
Trained batch 4520 batch loss 1.17259121 epoch total loss 1.12448692
Trained batch 4521 batch loss 1.14197612 epoch total loss 1.12449086
Trained batch 4522 batch loss 1.34505916 epoch total loss 1.12453973
Trained batch 4523 batch loss 1.21737731 epoch total loss 1.12456024
Trained batch 4524 batch loss 1.25376487 epoch total loss 1.12458873
Trained batch 4525 batch loss 1.21143055 epoch total loss 1.12460792
Trained batch 4526 batch loss 1.02659202 epoch total loss 1.12458622
Trained batch 4527 batch loss 1.06575131 epoch total loss 1.12457335
Trained batch 4528 batch loss 1.08325279 epoch total loss 1.12456429
Trained batch 4529 batch loss 1.18038201 epoch total loss 1.12457657
Trained batch 4530 batch loss 1.3946569 epoch total loss 1.12463605
Trained batch 4531 batch loss 1.45558023 epoch total loss 1.12470913
Trained batch 4532 batch loss 1.35051441 epoch total loss 1.12475896
Trained batch 4533 batch loss 1.3918612 epoch total loss 1.12481797
Trained batch 4534 batch loss 1.27506125 epoch total loss 1.12485111
Trained batch 4535 batch loss 1.18637705 epoch total loss 1.1248647
Trained batch 4536 batch loss 1.04578435 epoch total loss 1.12484729
Trained batch 4537 batch loss 1.02257335 epoch total loss 1.12482464
Trained batch 4538 batch loss 0.952199101 epoch total loss 1.12478662
Trained batch 4539 batch loss 1.08453155 epoch total loss 1.12477779
Trained batch 4540 batch loss 1.45028329 epoch total loss 1.12484944
Trained batch 4541 batch loss 1.05090809 epoch total loss 1.12483311
Trained batch 4542 batch loss 1.10017633 epoch total loss 1.12482762
Trained batch 4543 batch loss 1.4587754 epoch total loss 1.12490118
Trained batch 4544 batch loss 1.48362446 epoch total loss 1.12498009
Trained batch 4545 batch loss 1.29173768 epoch total loss 1.12501681
Trained batch 4546 batch loss 1.23119366 epoch total loss 1.12504
Trained batch 4547 batch loss 1.39723742 epoch total loss 1.1251
Trained batch 4548 batch loss 1.17589 epoch total loss 1.1251111
Trained batch 4549 batch loss 1.24814463 epoch total loss 1.12513816
Trained batch 4550 batch loss 1.30429721 epoch total loss 1.1251775
Trained batch 4551 batch loss 1.14847207 epoch total loss 1.12518263
Trained batch 4552 batch loss 1.29503894 epoch total loss 1.12522
Trained batch 4553 batch loss 1.11129856 epoch total loss 1.12521684
Trained batch 4554 batch loss 1.11966944 epoch total loss 1.12521565
Trained batch 4555 batch loss 0.966970742 epoch total loss 1.12518084
Trained batch 4556 batch loss 1.17340732 epoch total loss 1.12519145
Trained batch 4557 batch loss 1.43230653 epoch total loss 1.1252588
Trained batch 4558 batch loss 1.16536403 epoch total loss 1.12526762
Trained batch 4559 batch loss 0.925749719 epoch total loss 1.12522388
Trained batch 4560 batch loss 0.960970283 epoch total loss 1.12518787
Trained batch 4561 batch loss 1.04582012 epoch total loss 1.12517047
Trained batch 4562 batch loss 1.07264423 epoch total loss 1.12515891
Trained batch 4563 batch loss 1.01740527 epoch total loss 1.12513542
Trained batch 4564 batch loss 1.1020422 epoch total loss 1.1251303
Trained batch 4565 batch loss 0.880250931 epoch total loss 1.12507665
Trained batch 4566 batch loss 1.14294302 epoch total loss 1.12508059
Trained batch 4567 batch loss 1.18012023 epoch total loss 1.12509274
Trained batch 4568 batch loss 1.26341891 epoch total loss 1.1251229
Trained batch 4569 batch loss 1.25401461 epoch total loss 1.12515116
Trained batch 4570 batch loss 1.09237409 epoch total loss 1.12514389
Trained batch 4571 batch loss 1.09037435 epoch total loss 1.12513626
Trained batch 4572 batch loss 1.14060712 epoch total loss 1.12513971
Trained batch 4573 batch loss 1.2362318 epoch total loss 1.12516403
Trained batch 4574 batch loss 1.09067 epoch total loss 1.12515652
Trained batch 4575 batch loss 1.14749813 epoch total loss 1.12516141
Trained batch 4576 batch loss 1.210742 epoch total loss 1.12518013
Trained batch 4577 batch loss 1.28550673 epoch total loss 1.12521517
Trained batch 4578 batch loss 1.20349157 epoch total loss 1.12523234
Trained batch 4579 batch loss 1.21541405 epoch total loss 1.12525201
Trained batch 4580 batch loss 1.05957317 epoch total loss 1.12523758
Trained batch 4581 batch loss 0.972885907 epoch total loss 1.12520432
Trained batch 4582 batch loss 0.84781003 epoch total loss 1.12514377
Trained batch 4583 batch loss 1.1219542 epoch total loss 1.12514305
Trained batch 4584 batch loss 1.24474871 epoch total loss 1.12516916
Trained batch 4585 batch loss 1.16464162 epoch total loss 1.12517774
Trained batch 4586 batch loss 0.988602877 epoch total loss 1.12514794
Trained batch 4587 batch loss 1.26230717 epoch total loss 1.12517786
Trained batch 4588 batch loss 1.04918265 epoch total loss 1.12516129
Trained batch 4589 batch loss 1.19150841 epoch total loss 1.12517583
Trained batch 4590 batch loss 0.923723102 epoch total loss 1.12513196
Trained batch 4591 batch loss 1.07476163 epoch total loss 1.12512088
Trained batch 4592 batch loss 1.10593235 epoch total loss 1.12511671
Trained batch 4593 batch loss 1.09208274 epoch total loss 1.12510955
Trained batch 4594 batch loss 1.2824831 epoch total loss 1.12514389
Trained batch 4595 batch loss 1.26606941 epoch total loss 1.12517464
Trained batch 4596 batch loss 0.99031055 epoch total loss 1.1251452
Trained batch 4597 batch loss 1.01561272 epoch total loss 1.12512136
Trained batch 4598 batch loss 1.06730676 epoch total loss 1.12510884
Trained batch 4599 batch loss 1.06150484 epoch total loss 1.12509501
Trained batch 4600 batch loss 1.10229194 epoch total loss 1.12509
Trained batch 4601 batch loss 1.19260645 epoch total loss 1.12510467
Trained batch 4602 batch loss 1.42210436 epoch total loss 1.12516916
Trained batch 4603 batch loss 1.0867219 epoch total loss 1.12516081
Trained batch 4604 batch loss 1.27638066 epoch total loss 1.12519372
Trained batch 4605 batch loss 1.38766503 epoch total loss 1.1252507
Trained batch 4606 batch loss 1.20394814 epoch total loss 1.12526774
Trained batch 4607 batch loss 1.18003106 epoch total loss 1.12527966
Trained batch 4608 batch loss 1.09215975 epoch total loss 1.12527251
Trained batch 4609 batch loss 1.05267119 epoch total loss 1.12525678
Trained batch 4610 batch loss 1.02537167 epoch total loss 1.12523508
Trained batch 4611 batch loss 1.14815521 epoch total loss 1.12524009
Trained batch 4612 batch loss 0.946475148 epoch total loss 1.12520123
Trained batch 4613 batch loss 1.02958977 epoch total loss 1.1251806
Trained batch 4614 batch loss 1.14057779 epoch total loss 1.12518394
Trained batch 4615 batch loss 0.916232049 epoch total loss 1.12513864
Trained batch 4616 batch loss 0.956606627 epoch total loss 1.12510204
Trained batch 4617 batch loss 1.1358161 epoch total loss 1.12510443
Trained batch 4618 batch loss 1.09088802 epoch total loss 1.12509692
Trained batch 4619 batch loss 0.933690667 epoch total loss 1.12505555
Trained batch 4620 batch loss 1.10993195 epoch total loss 1.12505221
Trained batch 4621 batch loss 1.34131432 epoch total loss 1.12509906
Trained batch 4622 batch loss 1.16216862 epoch total loss 1.12510705
Trained batch 4623 batch loss 1.2697506 epoch total loss 1.12513828
Trained batch 4624 batch loss 1.25009513 epoch total loss 1.12516522
Trained batch 4625 batch loss 1.19879305 epoch total loss 1.1251812
Trained batch 4626 batch loss 1.13815641 epoch total loss 1.12518394
Trained batch 4627 batch loss 1.06034851 epoch total loss 1.12517
Trained batch 4628 batch loss 1.07266021 epoch total loss 1.12515867
Trained batch 4629 batch loss 1.26747012 epoch total loss 1.12518942
Trained batch 4630 batch loss 1.32868755 epoch total loss 1.12523341
Trained batch 4631 batch loss 1.14138603 epoch total loss 1.12523687
Trained batch 4632 batch loss 1.08915782 epoch total loss 1.12522912
Trained batch 4633 batch loss 1.08807373 epoch total loss 1.12522113
Trained batch 4634 batch loss 1.24984241 epoch total loss 1.12524807
Trained batch 4635 batch loss 1.16979241 epoch total loss 1.12525773
Trained batch 4636 batch loss 1.23957515 epoch total loss 1.12528241
Trained batch 4637 batch loss 1.22099 epoch total loss 1.12530303
Trained batch 4638 batch loss 1.25477314 epoch total loss 1.12533104
Trained batch 4639 batch loss 1.29643548 epoch total loss 1.12536788
Trained batch 4640 batch loss 1.29436898 epoch total loss 1.12540436
Trained batch 4641 batch loss 1.22159743 epoch total loss 1.1254251
Trained batch 4642 batch loss 1.44544458 epoch total loss 1.125494
Trained batch 4643 batch loss 1.19112837 epoch total loss 1.12550807
Trained batch 4644 batch loss 1.25761557 epoch total loss 1.12553656
Trained batch 4645 batch loss 1.12755227 epoch total loss 1.12553692
Trained batch 4646 batch loss 1.19024837 epoch total loss 1.12555087
Trained batch 4647 batch loss 1.07820201 epoch total loss 1.12554073
Trained batch 4648 batch loss 1.30689943 epoch total loss 1.12557983
Trained batch 4649 batch loss 1.24683523 epoch total loss 1.12560594
Trained batch 4650 batch loss 1.33971989 epoch total loss 1.12565196
Trained batch 4651 batch loss 1.27369797 epoch total loss 1.1256839
Trained batch 4652 batch loss 1.31878543 epoch total loss 1.12572539
Trained batch 4653 batch loss 1.23408902 epoch total loss 1.12574863
Trained batch 4654 batch loss 1.27180207 epoch total loss 1.12578011
Trained batch 4655 batch loss 1.38913095 epoch total loss 1.12583661
Trained batch 4656 batch loss 1.33648872 epoch total loss 1.12588191
Trained batch 4657 batch loss 1.43246067 epoch total loss 1.12594771
Trained batch 4658 batch loss 1.20386505 epoch total loss 1.12596452
Trained batch 4659 batch loss 0.830531776 epoch total loss 1.1259011
Trained batch 4660 batch loss 0.982250094 epoch total loss 1.12587035
Trained batch 4661 batch loss 1.09936774 epoch total loss 1.12586462
Trained batch 4662 batch loss 1.0949676 epoch total loss 1.12585795
Trained batch 4663 batch loss 1.04980016 epoch total loss 1.12584174
Trained batch 4664 batch loss 1.09318066 epoch total loss 1.1258347
Trained batch 4665 batch loss 1.04949141 epoch total loss 1.12581825
Trained batch 4666 batch loss 1.40856588 epoch total loss 1.12587893
Trained batch 4667 batch loss 1.14325953 epoch total loss 1.12588263
Trained batch 4668 batch loss 1.22552109 epoch total loss 1.12590396
Trained batch 4669 batch loss 0.990541935 epoch total loss 1.125875
Trained batch 4670 batch loss 1.0748632 epoch total loss 1.12586403
Trained batch 4671 batch loss 1.28522515 epoch total loss 1.12589812
Trained batch 4672 batch loss 0.947209239 epoch total loss 1.12586
Trained batch 4673 batch loss 0.942930281 epoch total loss 1.12582076
Trained batch 4674 batch loss 1.0496223 epoch total loss 1.12580454
Trained batch 4675 batch loss 1.0951941 epoch total loss 1.12579799
Trained batch 4676 batch loss 0.832330942 epoch total loss 1.12573528
Trained batch 4677 batch loss 1.16613245 epoch total loss 1.12574387
Trained batch 4678 batch loss 0.833138227 epoch total loss 1.12568128
Trained batch 4679 batch loss 1.17600381 epoch total loss 1.12569201
Trained batch 4680 batch loss 1.16397583 epoch total loss 1.12570024
Trained batch 4681 batch loss 1.3290503 epoch total loss 1.12574363
Trained batch 4682 batch loss 1.15044117 epoch total loss 1.12574887
Trained batch 4683 batch loss 0.88668263 epoch total loss 1.12569785
Trained batch 4684 batch loss 1.19577312 epoch total loss 1.12571287
Trained batch 4685 batch loss 1.01058626 epoch total loss 1.12568831
Trained batch 4686 batch loss 0.723946452 epoch total loss 1.1256026
Trained batch 4687 batch loss 0.847145319 epoch total loss 1.12554324
Trained batch 4688 batch loss 0.897554398 epoch total loss 1.12549448
Trained batch 4689 batch loss 0.917405844 epoch total loss 1.12545013
Trained batch 4690 batch loss 0.756382227 epoch total loss 1.12537146
Trained batch 4691 batch loss 1.06145334 epoch total loss 1.12535787
Trained batch 4692 batch loss 0.975668848 epoch total loss 1.12532592
Trained batch 4693 batch loss 1.35772836 epoch total loss 1.12537551
Trained batch 4694 batch loss 1.30420065 epoch total loss 1.12541354
Trained batch 4695 batch loss 1.34802556 epoch total loss 1.12546098
Trained batch 4696 batch loss 1.4130367 epoch total loss 1.12552226
Trained batch 4697 batch loss 1.1211642 epoch total loss 1.1255213
Trained batch 4698 batch loss 1.13789606 epoch total loss 1.12552392
Trained batch 4699 batch loss 1.13250577 epoch total loss 1.12552536
Trained batch 4700 batch loss 1.19717801 epoch total loss 1.12554061
Trained batch 4701 batch loss 1.33239305 epoch total loss 1.12558472
Trained batch 4702 batch loss 1.23008466 epoch total loss 1.12560689
Trained batch 4703 batch loss 1.14948702 epoch total loss 1.1256119
Trained batch 4704 batch loss 1.01978791 epoch total loss 1.12558949
Trained batch 4705 batch loss 1.10143864 epoch total loss 1.12558436
Trained batch 4706 batch loss 1.29695487 epoch total loss 1.12562072
Trained batch 4707 batch loss 1.30382419 epoch total loss 1.12565863
Trained batch 4708 batch loss 1.17885208 epoch total loss 1.12566984
Trained batch 4709 batch loss 1.21737039 epoch total loss 1.12568939
Trained batch 4710 batch loss 1.22291136 epoch total loss 1.12571
Trained batch 4711 batch loss 1.29982042 epoch total loss 1.12574697
Trained batch 4712 batch loss 1.07050824 epoch total loss 1.12573516
Trained batch 4713 batch loss 1.08835721 epoch total loss 1.1257273
Trained batch 4714 batch loss 1.05869365 epoch total loss 1.12571311
Trained batch 4715 batch loss 0.993082047 epoch total loss 1.12568498
Trained batch 4716 batch loss 1.1612289 epoch total loss 1.12569249
Trained batch 4717 batch loss 0.915655136 epoch total loss 1.1256479
Trained batch 4718 batch loss 0.904661059 epoch total loss 1.12560105
Trained batch 4719 batch loss 0.837948918 epoch total loss 1.12554014
Trained batch 4720 batch loss 0.887551308 epoch total loss 1.12548971
Trained batch 4721 batch loss 1.13894844 epoch total loss 1.12549257
Trained batch 4722 batch loss 1.11506379 epoch total loss 1.12549043
Trained batch 4723 batch loss 1.05428994 epoch total loss 1.12547541
Trained batch 4724 batch loss 1.02999735 epoch total loss 1.12545514
Trained batch 4725 batch loss 1.09029555 epoch total loss 1.12544763
Trained batch 4726 batch loss 1.20446122 epoch total loss 1.12546444
Trained batch 4727 batch loss 1.12586439 epoch total loss 1.12546456
Trained batch 4728 batch loss 1.10262787 epoch total loss 1.12545967
Trained batch 4729 batch loss 1.15398371 epoch total loss 1.12546563
Trained batch 4730 batch loss 0.972297192 epoch total loss 1.12543321
Trained batch 4731 batch loss 1.10010862 epoch total loss 1.12542796
Trained batch 4732 batch loss 1.11235785 epoch total loss 1.1254251
Trained batch 4733 batch loss 1.18461776 epoch total loss 1.12543762
Trained batch 4734 batch loss 0.938813686 epoch total loss 1.12539828
Trained batch 4735 batch loss 1.21287084 epoch total loss 1.12541676
Trained batch 4736 batch loss 1.31962442 epoch total loss 1.12545776
Trained batch 4737 batch loss 1.17111576 epoch total loss 1.1254673
Trained batch 4738 batch loss 1.46133769 epoch total loss 1.12553823
Trained batch 4739 batch loss 1.41464198 epoch total loss 1.12559927
Trained batch 4740 batch loss 1.29546189 epoch total loss 1.12563503
Trained batch 4741 batch loss 1.17861509 epoch total loss 1.12564623
Trained batch 4742 batch loss 1.21124899 epoch total loss 1.12566435
Trained batch 4743 batch loss 1.07098985 epoch total loss 1.12565279
Trained batch 4744 batch loss 1.0436554 epoch total loss 1.1256355
Trained batch 4745 batch loss 1.1186285 epoch total loss 1.12563396
Trained batch 4746 batch loss 1.09970534 epoch total loss 1.12562847
Trained batch 4747 batch loss 1.40306783 epoch total loss 1.12568688
Trained batch 4748 batch loss 1.21074581 epoch total loss 1.12570488
Trained batch 4749 batch loss 1.29916859 epoch total loss 1.12574136
Trained batch 4750 batch loss 1.13235044 epoch total loss 1.12574279
Trained batch 4751 batch loss 1.24548948 epoch total loss 1.12576807
Trained batch 4752 batch loss 1.18654442 epoch total loss 1.12578082
Trained batch 4753 batch loss 1.31089413 epoch total loss 1.1258198
Trained batch 4754 batch loss 1.26229239 epoch total loss 1.12584853
Trained batch 4755 batch loss 1.33084416 epoch total loss 1.12589169
Trained batch 4756 batch loss 1.36984062 epoch total loss 1.12594295
Trained batch 4757 batch loss 1.32563138 epoch total loss 1.12598491
Trained batch 4758 batch loss 1.22803557 epoch total loss 1.12600636
Trained batch 4759 batch loss 1.06924558 epoch total loss 1.12599444
Trained batch 4760 batch loss 1.19174695 epoch total loss 1.12600827
Trained batch 4761 batch loss 1.15615797 epoch total loss 1.12601459
Trained batch 4762 batch loss 1.34850478 epoch total loss 1.12606132
Trained batch 4763 batch loss 1.26470256 epoch total loss 1.12609041
Trained batch 4764 batch loss 1.37540054 epoch total loss 1.12614286
Trained batch 4765 batch loss 1.3680501 epoch total loss 1.12619364
Trained batch 4766 batch loss 1.36172926 epoch total loss 1.126243
Trained batch 4767 batch loss 1.11934161 epoch total loss 1.12624156
Trained batch 4768 batch loss 1.18962657 epoch total loss 1.1262548
Trained batch 4769 batch loss 1.20017052 epoch total loss 1.12627029
Trained batch 4770 batch loss 1.19203746 epoch total loss 1.12628412
Trained batch 4771 batch loss 1.18884957 epoch total loss 1.12629724
Trained batch 4772 batch loss 1.11695266 epoch total loss 1.12629533
Trained batch 4773 batch loss 1.11376882 epoch total loss 1.12629271
Trained batch 4774 batch loss 1.06226814 epoch total loss 1.12627935
Trained batch 4775 batch loss 1.10062623 epoch total loss 1.12627387
Trained batch 4776 batch loss 1.16709101 epoch total loss 1.12628245
Trained batch 4777 batch loss 0.866066456 epoch total loss 1.12622797
Trained batch 4778 batch loss 0.84929359 epoch total loss 1.12617
Trained batch 4779 batch loss 1.09355068 epoch total loss 1.12616324
Trained batch 4780 batch loss 1.0164001 epoch total loss 1.12614036
Trained batch 4781 batch loss 1.15002263 epoch total loss 1.12614524
Trained batch 4782 batch loss 1.16002989 epoch total loss 1.1261524
Trained batch 4783 batch loss 1.22009671 epoch total loss 1.12617207
Trained batch 4784 batch loss 1.34851694 epoch total loss 1.12621856
Trained batch 4785 batch loss 1.08410108 epoch total loss 1.12620974
Trained batch 4786 batch loss 1.38738537 epoch total loss 1.12626421
Trained batch 4787 batch loss 1.12751 epoch total loss 1.12626457
Trained batch 4788 batch loss 0.954520404 epoch total loss 1.12622869
Trained batch 4789 batch loss 1.02162361 epoch total loss 1.12620676
Trained batch 4790 batch loss 0.985370398 epoch total loss 1.12617743
Trained batch 4791 batch loss 1.21830487 epoch total loss 1.12619662
Trained batch 4792 batch loss 1.18735266 epoch total loss 1.12620938
Trained batch 4793 batch loss 1.17828536 epoch total loss 1.12622023
Trained batch 4794 batch loss 1.15353954 epoch total loss 1.12622595
Trained batch 4795 batch loss 1.24425375 epoch total loss 1.12625051
Trained batch 4796 batch loss 1.36796522 epoch total loss 1.12630093
Trained batch 4797 batch loss 1.00448668 epoch total loss 1.12627554
Trained batch 4798 batch loss 1.11200809 epoch total loss 1.12627256
Trained batch 4799 batch loss 1.13301516 epoch total loss 1.12627387
Trained batch 4800 batch loss 1.00968122 epoch total loss 1.12624955
Trained batch 4801 batch loss 0.75705111 epoch total loss 1.12617266
Trained batch 4802 batch loss 1.01344919 epoch total loss 1.12614918
Trained batch 4803 batch loss 1.13419878 epoch total loss 1.12615097
Trained batch 4804 batch loss 1.01130223 epoch total loss 1.126127
Trained batch 4805 batch loss 1.18879342 epoch total loss 1.12614012
Trained batch 4806 batch loss 1.2722162 epoch total loss 1.1261704
Trained batch 4807 batch loss 1.17503476 epoch total loss 1.12618053
Trained batch 4808 batch loss 0.997232795 epoch total loss 1.12615371
Trained batch 4809 batch loss 1.00088358 epoch total loss 1.1261276
Trained batch 4810 batch loss 1.09496176 epoch total loss 1.12612116
Trained batch 4811 batch loss 1.34201825 epoch total loss 1.12616599
Trained batch 4812 batch loss 1.01573813 epoch total loss 1.12614298
Trained batch 4813 batch loss 1.1182065 epoch total loss 1.12614131
Trained batch 4814 batch loss 0.978821635 epoch total loss 1.12611079
Trained batch 4815 batch loss 0.941593051 epoch total loss 1.12607241
Trained batch 4816 batch loss 0.989059687 epoch total loss 1.12604403
Trained batch 4817 batch loss 1.04920077 epoch total loss 1.12602806
Trained batch 4818 batch loss 0.952317595 epoch total loss 1.12599194
Trained batch 4819 batch loss 1.06507909 epoch total loss 1.1259793
Trained batch 4820 batch loss 0.868054569 epoch total loss 1.12592578
Trained batch 4821 batch loss 0.763958395 epoch total loss 1.1258508
Trained batch 4822 batch loss 1.05527472 epoch total loss 1.12583613
Trained batch 4823 batch loss 1.08603573 epoch total loss 1.12582779
Trained batch 4824 batch loss 1.23569584 epoch total loss 1.12585068
Trained batch 4825 batch loss 1.25569868 epoch total loss 1.12587762
Trained batch 4826 batch loss 1.05531251 epoch total loss 1.12586296
Trained batch 4827 batch loss 1.18456841 epoch total loss 1.12587512
Trained batch 4828 batch loss 1.54301453 epoch total loss 1.12596154
Trained batch 4829 batch loss 1.04626656 epoch total loss 1.12594497
Trained batch 4830 batch loss 1.1287539 epoch total loss 1.12594569
Trained batch 4831 batch loss 1.09168267 epoch total loss 1.12593853
Trained batch 4832 batch loss 1.22717023 epoch total loss 1.12595952
Trained batch 4833 batch loss 1.11763215 epoch total loss 1.12595773
Trained batch 4834 batch loss 1.14704204 epoch total loss 1.12596214
Trained batch 4835 batch loss 1.1432389 epoch total loss 1.12596571
Trained batch 4836 batch loss 0.980184674 epoch total loss 1.12593544
Trained batch 4837 batch loss 1.06238246 epoch total loss 1.12592232
Trained batch 4838 batch loss 1.03778827 epoch total loss 1.12590408
Trained batch 4839 batch loss 0.997524142 epoch total loss 1.12587762
Trained batch 4840 batch loss 1.0167129 epoch total loss 1.12585497
Trained batch 4841 batch loss 0.891499519 epoch total loss 1.12580657
Trained batch 4842 batch loss 0.724704087 epoch total loss 1.12572372
Trained batch 4843 batch loss 0.960606694 epoch total loss 1.12568963
Trained batch 4844 batch loss 1.09542394 epoch total loss 1.12568331
Trained batch 4845 batch loss 0.741028309 epoch total loss 1.12560403
Trained batch 4846 batch loss 0.841547489 epoch total loss 1.12554526
Trained batch 4847 batch loss 0.909150422 epoch total loss 1.12550068
Trained batch 4848 batch loss 0.855884194 epoch total loss 1.12544513
Trained batch 4849 batch loss 0.753275335 epoch total loss 1.12536836
Trained batch 4850 batch loss 0.788125813 epoch total loss 1.12529886
Trained batch 4851 batch loss 0.839129031 epoch total loss 1.12523985
Trained batch 4852 batch loss 0.823392749 epoch total loss 1.12517762
Trained batch 4853 batch loss 0.869599581 epoch total loss 1.12512493
Trained batch 4854 batch loss 0.922136068 epoch total loss 1.12508321
Trained batch 4855 batch loss 0.932302952 epoch total loss 1.12504339
Trained batch 4856 batch loss 1.28272879 epoch total loss 1.12507594
Trained batch 4857 batch loss 0.859869957 epoch total loss 1.12502134
Trained batch 4858 batch loss 0.902934 epoch total loss 1.12497556
Trained batch 4859 batch loss 1.0398221 epoch total loss 1.12495804
Trained batch 4860 batch loss 1.21716607 epoch total loss 1.12497711
Trained batch 4861 batch loss 1.07460797 epoch total loss 1.12496674
Trained batch 4862 batch loss 1.21381283 epoch total loss 1.12498498
Trained batch 4863 batch loss 1.35875416 epoch total loss 1.12503314
Trained batch 4864 batch loss 1.26463127 epoch total loss 1.12506187
Trained batch 4865 batch loss 1.1382854 epoch total loss 1.12506449
Trained batch 4866 batch loss 0.951038837 epoch total loss 1.12502885
Trained batch 4867 batch loss 0.840390086 epoch total loss 1.12497032
Trained batch 4868 batch loss 0.937057495 epoch total loss 1.12493169
Trained batch 4869 batch loss 0.954972565 epoch total loss 1.12489676
Trained batch 4870 batch loss 0.929283 epoch total loss 1.12485659
Trained batch 4871 batch loss 0.837577224 epoch total loss 1.12479758
Trained batch 4872 batch loss 0.85542345 epoch total loss 1.12474239
Trained batch 4873 batch loss 1.06999648 epoch total loss 1.12473106
Trained batch 4874 batch loss 0.861454964 epoch total loss 1.12467706
Trained batch 4875 batch loss 0.877155185 epoch total loss 1.12462616
Trained batch 4876 batch loss 0.802107275 epoch total loss 1.12456012
Trained batch 4877 batch loss 0.910548151 epoch total loss 1.12451625
Trained batch 4878 batch loss 0.86587739 epoch total loss 1.1244632
Trained batch 4879 batch loss 0.896747351 epoch total loss 1.12441659
Trained batch 4880 batch loss 1.18898213 epoch total loss 1.12442982
Trained batch 4881 batch loss 1.25378418 epoch total loss 1.12445629
Trained batch 4882 batch loss 1.34107304 epoch total loss 1.12450075
Trained batch 4883 batch loss 1.25373769 epoch total loss 1.12452722
Trained batch 4884 batch loss 1.20751143 epoch total loss 1.12454426
Trained batch 4885 batch loss 1.18562174 epoch total loss 1.12455666
Trained batch 4886 batch loss 1.25707436 epoch total loss 1.12458372
Trained batch 4887 batch loss 1.09571671 epoch total loss 1.12457788
Trained batch 4888 batch loss 1.27641809 epoch total loss 1.12460887
Trained batch 4889 batch loss 1.22070265 epoch total loss 1.12462854
Trained batch 4890 batch loss 1.38807666 epoch total loss 1.12468243
Trained batch 4891 batch loss 1.30348301 epoch total loss 1.12471902
Trained batch 4892 batch loss 1.11026633 epoch total loss 1.12471616
Trained batch 4893 batch loss 1.33257961 epoch total loss 1.1247586
Trained batch 4894 batch loss 1.13894713 epoch total loss 1.12476158
Trained batch 4895 batch loss 1.18586671 epoch total loss 1.1247741
Trained batch 4896 batch loss 0.956574917 epoch total loss 1.12473965
Trained batch 4897 batch loss 0.867059469 epoch total loss 1.12468708
Trained batch 4898 batch loss 0.991487741 epoch total loss 1.12466
Trained batch 4899 batch loss 0.972872078 epoch total loss 1.1246289
Trained batch 4900 batch loss 1.13349 epoch total loss 1.12463069
Trained batch 4901 batch loss 1.1012361 epoch total loss 1.12462592
Trained batch 4902 batch loss 0.823996425 epoch total loss 1.12456465
Trained batch 4903 batch loss 0.901277244 epoch total loss 1.12451911
Trained batch 4904 batch loss 1.04691839 epoch total loss 1.12450325
Trained batch 4905 batch loss 1.04164767 epoch total loss 1.12448633
Trained batch 4906 batch loss 1.07692862 epoch total loss 1.12447667
Trained batch 4907 batch loss 1.23200786 epoch total loss 1.12449861
Trained batch 4908 batch loss 1.24319828 epoch total loss 1.12452281
Trained batch 4909 batch loss 1.41158497 epoch total loss 1.12458122
Trained batch 4910 batch loss 1.03009105 epoch total loss 1.12456203
Trained batch 4911 batch loss 1.13735342 epoch total loss 1.12456465
Trained batch 4912 batch loss 1.05183268 epoch total loss 1.12454975
Trained batch 4913 batch loss 1.17469192 epoch total loss 1.12456
Trained batch 4914 batch loss 1.33416963 epoch total loss 1.12460268
Trained batch 4915 batch loss 1.35832381 epoch total loss 1.12465024
Trained batch 4916 batch loss 1.25525773 epoch total loss 1.12467682
Trained batch 4917 batch loss 0.970048189 epoch total loss 1.12464535
Trained batch 4918 batch loss 1.14857721 epoch total loss 1.12465024
Trained batch 4919 batch loss 1.08658028 epoch total loss 1.12464249
Trained batch 4920 batch loss 1.07725573 epoch total loss 1.12463284
Trained batch 4921 batch loss 1.13272214 epoch total loss 1.1246345
Trained batch 4922 batch loss 1.25035095 epoch total loss 1.12466
Trained batch 4923 batch loss 1.339849 epoch total loss 1.12470376
Trained batch 4924 batch loss 1.47537303 epoch total loss 1.12477505
Trained batch 4925 batch loss 1.30348063 epoch total loss 1.12481129
Trained batch 4926 batch loss 1.33199501 epoch total loss 1.12485337
Trained batch 4927 batch loss 1.25439978 epoch total loss 1.12487972
Trained batch 4928 batch loss 1.23058236 epoch total loss 1.12490106
Trained batch 4929 batch loss 1.10409474 epoch total loss 1.12489688
Trained batch 4930 batch loss 1.0534972 epoch total loss 1.12488246
Trained batch 4931 batch loss 1.06372499 epoch total loss 1.12487006
Trained batch 4932 batch loss 1.38601661 epoch total loss 1.12492311
Trained batch 4933 batch loss 1.0939275 epoch total loss 1.12491679
Trained batch 4934 batch loss 1.22393548 epoch total loss 1.12493682
Trained batch 4935 batch loss 1.15063977 epoch total loss 1.12494206
Trained batch 4936 batch loss 1.05548143 epoch total loss 1.12492812
Trained batch 4937 batch loss 1.33211565 epoch total loss 1.12497008
Trained batch 4938 batch loss 1.02623177 epoch total loss 1.12495
Trained batch 4939 batch loss 0.957408309 epoch total loss 1.1249162
Trained batch 4940 batch loss 0.842219114 epoch total loss 1.12485898
Trained batch 4941 batch loss 1.00918841 epoch total loss 1.12483561
Trained batch 4942 batch loss 0.941236436 epoch total loss 1.12479842
Trained batch 4943 batch loss 0.975324512 epoch total loss 1.12476814
Trained batch 4944 batch loss 1.02810717 epoch total loss 1.12474871
Trained batch 4945 batch loss 0.893315315 epoch total loss 1.12470186
Trained batch 4946 batch loss 0.938885093 epoch total loss 1.12466431
Trained batch 4947 batch loss 0.954050362 epoch total loss 1.12462986
Trained batch 4948 batch loss 0.94970119 epoch total loss 1.12459457
Trained batch 4949 batch loss 1.18305826 epoch total loss 1.12460637
Trained batch 4950 batch loss 1.15590405 epoch total loss 1.12461269
Trained batch 4951 batch loss 1.31306565 epoch total loss 1.12465072
Trained batch 4952 batch loss 1.13802779 epoch total loss 1.12465346
Trained batch 4953 batch loss 1.11676943 epoch total loss 1.12465179
Trained batch 4954 batch loss 1.34672308 epoch total loss 1.12469661
Trained batch 4955 batch loss 1.29174757 epoch total loss 1.12473023
Trained batch 4956 batch loss 1.30504167 epoch total loss 1.12476671
Trained batch 4957 batch loss 1.30023265 epoch total loss 1.12480211
Trained batch 4958 batch loss 1.39748526 epoch total loss 1.12485707
Trained batch 4959 batch loss 1.30268347 epoch total loss 1.12489295
Trained batch 4960 batch loss 1.28136158 epoch total loss 1.12492454
Trained batch 4961 batch loss 1.41763926 epoch total loss 1.12498343
Trained batch 4962 batch loss 1.35735393 epoch total loss 1.12503028
Trained batch 4963 batch loss 1.33291757 epoch total loss 1.12507224
Trained batch 4964 batch loss 1.28068614 epoch total loss 1.12510359
Trained batch 4965 batch loss 1.34649587 epoch total loss 1.12514818
Trained batch 4966 batch loss 1.32444096 epoch total loss 1.12518835
Trained batch 4967 batch loss 1.09743392 epoch total loss 1.12518275
Trained batch 4968 batch loss 0.919480681 epoch total loss 1.12514138
Trained batch 4969 batch loss 1.28637671 epoch total loss 1.12517369
Trained batch 4970 batch loss 1.20123315 epoch total loss 1.12518907
Trained batch 4971 batch loss 1.300578 epoch total loss 1.12522435
Trained batch 4972 batch loss 1.33251095 epoch total loss 1.12526608
Trained batch 4973 batch loss 1.28241658 epoch total loss 1.12529755
Trained batch 4974 batch loss 1.20504332 epoch total loss 1.12531364
Trained batch 4975 batch loss 1.25331616 epoch total loss 1.12533939
Trained batch 4976 batch loss 1.08045912 epoch total loss 1.12533045
Trained batch 4977 batch loss 1.20645976 epoch total loss 1.12534666
Trained batch 4978 batch loss 1.10434031 epoch total loss 1.12534249
Trained batch 4979 batch loss 1.02993321 epoch total loss 1.1253233
Trained batch 4980 batch loss 1.05608439 epoch total loss 1.12530947
Trained batch 4981 batch loss 1.02964914 epoch total loss 1.12529027
Trained batch 4982 batch loss 0.860037565 epoch total loss 1.12523699
Trained batch 4983 batch loss 0.814564288 epoch total loss 1.12517464
Trained batch 4984 batch loss 0.881860614 epoch total loss 1.12512577
Trained batch 4985 batch loss 1.04157555 epoch total loss 1.12510908
Trained batch 4986 batch loss 1.14878368 epoch total loss 1.12511384
Trained batch 4987 batch loss 1.1808753 epoch total loss 1.12512493
Trained batch 4988 batch loss 1.10260534 epoch total loss 1.1251204
Trained batch 4989 batch loss 1.236835 epoch total loss 1.12514281
Trained batch 4990 batch loss 1.17717648 epoch total loss 1.12515318
Trained batch 4991 batch loss 1.09113955 epoch total loss 1.12514651
Trained batch 4992 batch loss 1.24929523 epoch total loss 1.12517142
Trained batch 4993 batch loss 1.32536435 epoch total loss 1.12521148
Trained batch 4994 batch loss 1.33421779 epoch total loss 1.1252532
Trained batch 4995 batch loss 1.36077249 epoch total loss 1.12530041
Trained batch 4996 batch loss 1.08755064 epoch total loss 1.12529278
Trained batch 4997 batch loss 1.12148404 epoch total loss 1.12529206
Trained batch 4998 batch loss 1.14997 epoch total loss 1.12529695
Trained batch 4999 batch loss 1.07046664 epoch total loss 1.12528598
Trained batch 5000 batch loss 1.24194467 epoch total loss 1.12530935
Trained batch 5001 batch loss 1.02384305 epoch total loss 1.12528908
Trained batch 5002 batch loss 1.11472714 epoch total loss 1.12528694
Trained batch 5003 batch loss 0.923051238 epoch total loss 1.12524652
Trained batch 5004 batch loss 0.950019062 epoch total loss 1.1252116
Trained batch 5005 batch loss 1.05820811 epoch total loss 1.12519813
Trained batch 5006 batch loss 0.904162645 epoch total loss 1.12515402
Trained batch 5007 batch loss 1.02566051 epoch total loss 1.12513423
Trained batch 5008 batch loss 1.18960857 epoch total loss 1.12514699
Trained batch 5009 batch loss 1.01697743 epoch total loss 1.12512541
Trained batch 5010 batch loss 0.885941148 epoch total loss 1.12507772
Trained batch 5011 batch loss 0.877424121 epoch total loss 1.12502825
Trained batch 5012 batch loss 0.945471704 epoch total loss 1.12499237
Trained batch 5013 batch loss 0.919920862 epoch total loss 1.12495148
Trained batch 5014 batch loss 0.948007584 epoch total loss 1.1249162
Trained batch 5015 batch loss 0.966647327 epoch total loss 1.12488472
Trained batch 5016 batch loss 1.04335809 epoch total loss 1.12486851
Trained batch 5017 batch loss 1.11609602 epoch total loss 1.12486672
Trained batch 5018 batch loss 1.10062313 epoch total loss 1.12486196
Trained batch 5019 batch loss 1.02289879 epoch total loss 1.12484157
Trained batch 5020 batch loss 0.99618113 epoch total loss 1.12481594
Trained batch 5021 batch loss 1.00190496 epoch total loss 1.1247915
Trained batch 5022 batch loss 1.04748678 epoch total loss 1.12477612
Trained batch 5023 batch loss 0.991382 epoch total loss 1.12474954
Trained batch 5024 batch loss 1.17422867 epoch total loss 1.12475932
Trained batch 5025 batch loss 0.868839502 epoch total loss 1.12470841
Trained batch 5026 batch loss 0.918746769 epoch total loss 1.12466741
Trained batch 5027 batch loss 0.956871 epoch total loss 1.12463415
Trained batch 5028 batch loss 1.23389196 epoch total loss 1.12465584
Trained batch 5029 batch loss 1.05859613 epoch total loss 1.12464273
Trained batch 5030 batch loss 1.21126151 epoch total loss 1.1246599
Trained batch 5031 batch loss 1.14007962 epoch total loss 1.124663
Trained batch 5032 batch loss 1.11474133 epoch total loss 1.12466109
Trained batch 5033 batch loss 1.1143682 epoch total loss 1.12465894
Trained batch 5034 batch loss 1.24032021 epoch total loss 1.12468195
Trained batch 5035 batch loss 1.13228202 epoch total loss 1.1246835
Trained batch 5036 batch loss 1.20167327 epoch total loss 1.12469876
Trained batch 5037 batch loss 1.3044312 epoch total loss 1.1247344
Trained batch 5038 batch loss 1.10243738 epoch total loss 1.12473
Trained batch 5039 batch loss 1.13783455 epoch total loss 1.12473261
Trained batch 5040 batch loss 1.17355227 epoch total loss 1.12474215
Trained batch 5041 batch loss 1.11838949 epoch total loss 1.12474084
Trained batch 5042 batch loss 1.16367555 epoch total loss 1.12474859
Trained batch 5043 batch loss 1.17822313 epoch total loss 1.1247592
Trained batch 5044 batch loss 1.13029349 epoch total loss 1.12476027
Trained batch 5045 batch loss 1.34989619 epoch total loss 1.12480497
Trained batch 5046 batch loss 1.30326641 epoch total loss 1.12484038
Trained batch 5047 batch loss 1.23202038 epoch total loss 1.1248616
Trained batch 5048 batch loss 1.31753874 epoch total loss 1.12489974
Trained batch 5049 batch loss 1.06860113 epoch total loss 1.12488854
Trained batch 5050 batch loss 1.18962157 epoch total loss 1.12490129
Trained batch 5051 batch loss 1.33216619 epoch total loss 1.1249423
Trained batch 5052 batch loss 1.07915735 epoch total loss 1.12493324
Trained batch 5053 batch loss 1.0510962 epoch total loss 1.12491858
Trained batch 5054 batch loss 1.25690961 epoch total loss 1.12494469
Trained batch 5055 batch loss 1.01951098 epoch total loss 1.12492383
Trained batch 5056 batch loss 1.27898073 epoch total loss 1.12495434
Trained batch 5057 batch loss 1.14876735 epoch total loss 1.12495911
Trained batch 5058 batch loss 1.23476553 epoch total loss 1.12498081
Trained batch 5059 batch loss 1.1747936 epoch total loss 1.12499058
Trained batch 5060 batch loss 1.16825891 epoch total loss 1.12499928
Trained batch 5061 batch loss 1.14273858 epoch total loss 1.12500274
Trained batch 5062 batch loss 1.23032141 epoch total loss 1.12502348
Trained batch 5063 batch loss 1.11578047 epoch total loss 1.1250217
Trained batch 5064 batch loss 1.22284353 epoch total loss 1.12504101
Trained batch 5065 batch loss 0.952062249 epoch total loss 1.12500679
Trained batch 5066 batch loss 1.09096932 epoch total loss 1.12500012
Trained batch 5067 batch loss 1.10073805 epoch total loss 1.12499523
Trained batch 5068 batch loss 1.02398241 epoch total loss 1.12497532
Trained batch 5069 batch loss 1.0835731 epoch total loss 1.1249671
Trained batch 5070 batch loss 1.19133377 epoch total loss 1.12498021
Trained batch 5071 batch loss 1.06513238 epoch total loss 1.12496841
Trained batch 5072 batch loss 1.07080603 epoch total loss 1.12495768
Trained batch 5073 batch loss 1.15143013 epoch total loss 1.12496293
Trained batch 5074 batch loss 1.01443 epoch total loss 1.12494123
Trained batch 5075 batch loss 1.06178331 epoch total loss 1.12492883
Trained batch 5076 batch loss 0.938118339 epoch total loss 1.124892
Trained batch 5077 batch loss 1.2617594 epoch total loss 1.12491894
Trained batch 5078 batch loss 1.07242477 epoch total loss 1.12490857
Trained batch 5079 batch loss 1.17696834 epoch total loss 1.12491882
Trained batch 5080 batch loss 1.18377066 epoch total loss 1.12493026
Trained batch 5081 batch loss 1.18341851 epoch total loss 1.12494183
Trained batch 5082 batch loss 1.11197436 epoch total loss 1.12493932
Trained batch 5083 batch loss 1.01997828 epoch total loss 1.12491858
Trained batch 5084 batch loss 1.08052385 epoch total loss 1.12490988
Trained batch 5085 batch loss 1.10875154 epoch total loss 1.12490678
Trained batch 5086 batch loss 0.957457423 epoch total loss 1.12487388
Trained batch 5087 batch loss 1.1562798 epoch total loss 1.12488008
Trained batch 5088 batch loss 1.03231 epoch total loss 1.12486184
Trained batch 5089 batch loss 1.00342262 epoch total loss 1.12483799
Trained batch 5090 batch loss 1.02420545 epoch total loss 1.12481821
Trained batch 5091 batch loss 0.99373585 epoch total loss 1.12479246
Trained batch 5092 batch loss 0.95973444 epoch total loss 1.12476
Trained batch 5093 batch loss 0.958763719 epoch total loss 1.12472749
Trained batch 5094 batch loss 0.970671535 epoch total loss 1.12469733
Trained batch 5095 batch loss 0.956214845 epoch total loss 1.12466419
Trained batch 5096 batch loss 0.877272129 epoch total loss 1.12461567
Trained batch 5097 batch loss 0.959854 epoch total loss 1.12458336
Trained batch 5098 batch loss 1.01071012 epoch total loss 1.12456107
Trained batch 5099 batch loss 1.02653837 epoch total loss 1.12454176
Trained batch 5100 batch loss 1.15391493 epoch total loss 1.12454748
Trained batch 5101 batch loss 1.10559022 epoch total loss 1.12454379
Trained batch 5102 batch loss 1.01710606 epoch total loss 1.12452269
Trained batch 5103 batch loss 1.15742993 epoch total loss 1.12452912
Trained batch 5104 batch loss 1.13139868 epoch total loss 1.12453043
Trained batch 5105 batch loss 1.09818971 epoch total loss 1.12452531
Trained batch 5106 batch loss 1.38817549 epoch total loss 1.12457693
Trained batch 5107 batch loss 1.0953269 epoch total loss 1.1245712
Trained batch 5108 batch loss 1.17245126 epoch total loss 1.1245805
Trained batch 5109 batch loss 1.10527062 epoch total loss 1.12457681
Trained batch 5110 batch loss 0.912946463 epoch total loss 1.12453544
Trained batch 5111 batch loss 1.25989747 epoch total loss 1.12456191
Trained batch 5112 batch loss 1.03000033 epoch total loss 1.12454331
Trained batch 5113 batch loss 1.23742127 epoch total loss 1.12456536
Trained batch 5114 batch loss 1.13026547 epoch total loss 1.12456656
Trained batch 5115 batch loss 1.21108162 epoch total loss 1.12458336
Trained batch 5116 batch loss 1.25939274 epoch total loss 1.12460971
Trained batch 5117 batch loss 1.2876296 epoch total loss 1.12464154
Trained batch 5118 batch loss 1.12054408 epoch total loss 1.12464082
Trained batch 5119 batch loss 1.39169657 epoch total loss 1.12469292
Trained batch 5120 batch loss 1.37204742 epoch total loss 1.12474132
Trained batch 5121 batch loss 1.3891046 epoch total loss 1.12479293
Trained batch 5122 batch loss 1.19507635 epoch total loss 1.12480664
Trained batch 5123 batch loss 1.34075761 epoch total loss 1.12484884
Trained batch 5124 batch loss 1.12311351 epoch total loss 1.12484848
Trained batch 5125 batch loss 1.31592345 epoch total loss 1.1248858
Trained batch 5126 batch loss 1.02002645 epoch total loss 1.12486529
Trained batch 5127 batch loss 0.923654318 epoch total loss 1.12482607
Trained batch 5128 batch loss 1.12001073 epoch total loss 1.12482512
Trained batch 5129 batch loss 1.20643258 epoch total loss 1.12484109
Trained batch 5130 batch loss 1.03515267 epoch total loss 1.12482357
Trained batch 5131 batch loss 1.27283216 epoch total loss 1.12485254
Trained batch 5132 batch loss 1.1383934 epoch total loss 1.12485504
Trained batch 5133 batch loss 1.29417396 epoch total loss 1.12488806
Trained batch 5134 batch loss 1.02136338 epoch total loss 1.12486792
Trained batch 5135 batch loss 1.07669473 epoch total loss 1.1248585
Trained batch 5136 batch loss 1.14459884 epoch total loss 1.12486231
Trained batch 5137 batch loss 1.21473861 epoch total loss 1.12487984
Trained batch 5138 batch loss 1.16382682 epoch total loss 1.12488747
Trained batch 5139 batch loss 1.27265167 epoch total loss 1.1249162
Trained batch 5140 batch loss 1.13938487 epoch total loss 1.12491894
Trained batch 5141 batch loss 0.988609374 epoch total loss 1.12489247
Trained batch 5142 batch loss 1.06598878 epoch total loss 1.12488103
Trained batch 5143 batch loss 1.16052973 epoch total loss 1.12488794
Trained batch 5144 batch loss 1.29385769 epoch total loss 1.12492085
Trained batch 5145 batch loss 1.24814951 epoch total loss 1.12494481
Trained batch 5146 batch loss 1.09706855 epoch total loss 1.12493932
Trained batch 5147 batch loss 1.31529474 epoch total loss 1.1249764
Trained batch 5148 batch loss 1.28203273 epoch total loss 1.12500691
Trained batch 5149 batch loss 1.22621334 epoch total loss 1.12502658
Trained batch 5150 batch loss 1.209041 epoch total loss 1.1250428
Trained batch 5151 batch loss 1.12368238 epoch total loss 1.12504256
Trained batch 5152 batch loss 1.33717012 epoch total loss 1.1250838
Trained batch 5153 batch loss 1.34233224 epoch total loss 1.12512589
Trained batch 5154 batch loss 1.27023578 epoch total loss 1.12515402
Trained batch 5155 batch loss 1.24883676 epoch total loss 1.1251781
Trained batch 5156 batch loss 1.26315093 epoch total loss 1.1252048
Trained batch 5157 batch loss 1.21632469 epoch total loss 1.12522256
Trained batch 5158 batch loss 1.26752627 epoch total loss 1.1252501
Trained batch 5159 batch loss 1.2333324 epoch total loss 1.12527108
Trained batch 5160 batch loss 1.28369009 epoch total loss 1.12530172
Trained batch 5161 batch loss 1.36827862 epoch total loss 1.12534881
Trained batch 5162 batch loss 1.35785186 epoch total loss 1.12539387
Trained batch 5163 batch loss 1.19334829 epoch total loss 1.1254071
Trained batch 5164 batch loss 1.20170927 epoch total loss 1.12542176
Trained batch 5165 batch loss 1.15624905 epoch total loss 1.12542772
Trained batch 5166 batch loss 1.34510016 epoch total loss 1.12547028
Trained batch 5167 batch loss 1.05255604 epoch total loss 1.12545621
Trained batch 5168 batch loss 1.39616227 epoch total loss 1.12550855
Trained batch 5169 batch loss 1.17122233 epoch total loss 1.12551749
Trained batch 5170 batch loss 1.06275415 epoch total loss 1.12550533
Trained batch 5171 batch loss 1.05314636 epoch total loss 1.12549138
Trained batch 5172 batch loss 1.08571529 epoch total loss 1.12548375
Trained batch 5173 batch loss 1.1216346 epoch total loss 1.12548304
Trained batch 5174 batch loss 1.0626483 epoch total loss 1.12547088
Trained batch 5175 batch loss 1.02758431 epoch total loss 1.1254518
Trained batch 5176 batch loss 1.14293098 epoch total loss 1.12545526
Trained batch 5177 batch loss 1.3634479 epoch total loss 1.12550116
Trained batch 5178 batch loss 1.22987103 epoch total loss 1.12552142
Trained batch 5179 batch loss 1.14628398 epoch total loss 1.12552547
Trained batch 5180 batch loss 1.03814507 epoch total loss 1.12550855
Trained batch 5181 batch loss 1.1072216 epoch total loss 1.12550509
Trained batch 5182 batch loss 1.14510643 epoch total loss 1.12550879
Trained batch 5183 batch loss 1.17284417 epoch total loss 1.12551796
Trained batch 5184 batch loss 1.22087932 epoch total loss 1.12553632
Trained batch 5185 batch loss 1.21720958 epoch total loss 1.12555397
Trained batch 5186 batch loss 1.10148644 epoch total loss 1.12554944
Trained batch 5187 batch loss 1.03568721 epoch total loss 1.12553203
Trained batch 5188 batch loss 1.09019339 epoch total loss 1.12552524
Trained batch 5189 batch loss 1.12712693 epoch total loss 1.12552559
Trained batch 5190 batch loss 1.14229274 epoch total loss 1.12552869
Trained batch 5191 batch loss 0.997920036 epoch total loss 1.12550414
Trained batch 5192 batch loss 1.18427348 epoch total loss 1.12551546
Trained batch 5193 batch loss 1.17687762 epoch total loss 1.12552536
Trained batch 5194 batch loss 1.31132376 epoch total loss 1.12556112
Trained batch 5195 batch loss 1.22927117 epoch total loss 1.12558115
Trained batch 5196 batch loss 1.16576767 epoch total loss 1.12558877
Trained batch 5197 batch loss 1.0771786 epoch total loss 1.12557948
Trained batch 5198 batch loss 1.05966902 epoch total loss 1.12556684
Trained batch 5199 batch loss 1.16154015 epoch total loss 1.12557375
Trained batch 5200 batch loss 1.14110124 epoch total loss 1.12557673
Trained batch 5201 batch loss 1.032686 epoch total loss 1.12555885
Trained batch 5202 batch loss 1.08891511 epoch total loss 1.12555182
Trained batch 5203 batch loss 0.975589156 epoch total loss 1.12552297
Trained batch 5204 batch loss 1.23773861 epoch total loss 1.12554455
Trained batch 5205 batch loss 1.29887962 epoch total loss 1.12557793
Trained batch 5206 batch loss 1.17904377 epoch total loss 1.12558818
Trained batch 5207 batch loss 1.24056649 epoch total loss 1.12561023
Trained batch 5208 batch loss 1.0755949 epoch total loss 1.1256007
Trained batch 5209 batch loss 0.977248609 epoch total loss 1.1255722
Trained batch 5210 batch loss 1.10992467 epoch total loss 1.12556911
Trained batch 5211 batch loss 1.01534915 epoch total loss 1.12554801
Trained batch 5212 batch loss 1.07810187 epoch total loss 1.12553883
Trained batch 5213 batch loss 1.16414094 epoch total loss 1.12554622
Trained batch 5214 batch loss 0.956899464 epoch total loss 1.12551391
Trained batch 5215 batch loss 1.22232163 epoch total loss 1.12553251
Trained batch 5216 batch loss 1.03418434 epoch total loss 1.12551498
Trained batch 5217 batch loss 1.11625767 epoch total loss 1.1255132
Trained batch 5218 batch loss 1.20576167 epoch total loss 1.12552857
Trained batch 5219 batch loss 1.04323888 epoch total loss 1.12551284
Trained batch 5220 batch loss 1.05779612 epoch total loss 1.12549984
Trained batch 5221 batch loss 1.14856064 epoch total loss 1.12550414
Trained batch 5222 batch loss 1.02860022 epoch total loss 1.12548566
Trained batch 5223 batch loss 1.02269959 epoch total loss 1.12546599
Trained batch 5224 batch loss 1.2496984 epoch total loss 1.12548971
Trained batch 5225 batch loss 1.07611394 epoch total loss 1.12548029
Trained batch 5226 batch loss 1.07124031 epoch total loss 1.12546992
Trained batch 5227 batch loss 0.996550798 epoch total loss 1.12544525
Trained batch 5228 batch loss 1.12020063 epoch total loss 1.12544417
Trained batch 5229 batch loss 1.25196016 epoch total loss 1.12546837
Trained batch 5230 batch loss 1.285869 epoch total loss 1.12549901
Trained batch 5231 batch loss 1.2617135 epoch total loss 1.12552512
Trained batch 5232 batch loss 1.09851444 epoch total loss 1.12551987
Trained batch 5233 batch loss 1.27616096 epoch total loss 1.12554872
Trained batch 5234 batch loss 1.41432214 epoch total loss 1.12560391
Trained batch 5235 batch loss 1.27889848 epoch total loss 1.12563324
Trained batch 5236 batch loss 1.15584767 epoch total loss 1.12563896
Trained batch 5237 batch loss 1.19170737 epoch total loss 1.1256516
Trained batch 5238 batch loss 1.16805577 epoch total loss 1.1256597
Trained batch 5239 batch loss 1.26952553 epoch total loss 1.12568712
Trained batch 5240 batch loss 1.13574052 epoch total loss 1.12568915
Trained batch 5241 batch loss 1.28522038 epoch total loss 1.12571955
Trained batch 5242 batch loss 1.33736396 epoch total loss 1.12576
Trained batch 5243 batch loss 1.0746063 epoch total loss 1.12575018
Trained batch 5244 batch loss 1.13770461 epoch total loss 1.12575245
Trained batch 5245 batch loss 1.096982 epoch total loss 1.12574697
Trained batch 5246 batch loss 1.16472673 epoch total loss 1.12575436
Trained batch 5247 batch loss 1.14275515 epoch total loss 1.12575758
Trained batch 5248 batch loss 1.11562073 epoch total loss 1.12575567
Trained batch 5249 batch loss 1.08140993 epoch total loss 1.1257472
Trained batch 5250 batch loss 1.03120446 epoch total loss 1.1257292
Trained batch 5251 batch loss 1.13038445 epoch total loss 1.12573016
Trained batch 5252 batch loss 1.1933105 epoch total loss 1.12574303
Trained batch 5253 batch loss 0.871320784 epoch total loss 1.12569451
Trained batch 5254 batch loss 0.87576735 epoch total loss 1.12564707
Trained batch 5255 batch loss 0.840884626 epoch total loss 1.12559283
Trained batch 5256 batch loss 0.913693428 epoch total loss 1.12555242
Trained batch 5257 batch loss 0.910721242 epoch total loss 1.12551165
Trained batch 5258 batch loss 0.921660066 epoch total loss 1.1254729
Trained batch 5259 batch loss 1.11815906 epoch total loss 1.12547147
Trained batch 5260 batch loss 0.978679061 epoch total loss 1.12544358
Trained batch 5261 batch loss 1.13897645 epoch total loss 1.1254462
Trained batch 5262 batch loss 1.14717245 epoch total loss 1.12545025
Trained batch 5263 batch loss 1.34997714 epoch total loss 1.12549293
Trained batch 5264 batch loss 1.07213068 epoch total loss 1.1254828
Trained batch 5265 batch loss 1.08338 epoch total loss 1.12547481
Trained batch 5266 batch loss 1.24684882 epoch total loss 1.12549794
Trained batch 5267 batch loss 1.36958909 epoch total loss 1.12554431
Trained batch 5268 batch loss 1.44156611 epoch total loss 1.12560427
Trained batch 5269 batch loss 1.32731366 epoch total loss 1.12564254
Trained batch 5270 batch loss 1.27222371 epoch total loss 1.12567031
Trained batch 5271 batch loss 1.15360236 epoch total loss 1.12567568
Trained batch 5272 batch loss 1.23089051 epoch total loss 1.12569571
Trained batch 5273 batch loss 1.11771321 epoch total loss 1.12569416
Trained batch 5274 batch loss 1.03147924 epoch total loss 1.12567627
Trained batch 5275 batch loss 1.15305161 epoch total loss 1.1256814
Trained batch 5276 batch loss 1.04621315 epoch total loss 1.12566638
Trained batch 5277 batch loss 1.17205834 epoch total loss 1.12567508
Trained batch 5278 batch loss 0.910531521 epoch total loss 1.12563431
Trained batch 5279 batch loss 1.05104709 epoch total loss 1.12562025
Trained batch 5280 batch loss 1.17053628 epoch total loss 1.12562871
Trained batch 5281 batch loss 1.18359029 epoch total loss 1.12563968
Trained batch 5282 batch loss 0.972945869 epoch total loss 1.12561083
Trained batch 5283 batch loss 1.1276902 epoch total loss 1.12561131
Trained batch 5284 batch loss 1.08581638 epoch total loss 1.1256038
Trained batch 5285 batch loss 1.2322787 epoch total loss 1.12562406
Trained batch 5286 batch loss 1.23973179 epoch total loss 1.12564564
Trained batch 5287 batch loss 1.30387735 epoch total loss 1.12567925
Trained batch 5288 batch loss 0.954090834 epoch total loss 1.12564683
Trained batch 5289 batch loss 0.641155243 epoch total loss 1.12555516
Trained batch 5290 batch loss 1.00108266 epoch total loss 1.12553167
Trained batch 5291 batch loss 0.837035298 epoch total loss 1.12547708
Trained batch 5292 batch loss 1.19426155 epoch total loss 1.12549007
Trained batch 5293 batch loss 1.06227267 epoch total loss 1.12547827
Trained batch 5294 batch loss 0.985580325 epoch total loss 1.1254518
Trained batch 5295 batch loss 1.33765006 epoch total loss 1.12549186
Trained batch 5296 batch loss 1.28813374 epoch total loss 1.12552261
Trained batch 5297 batch loss 1.2492125 epoch total loss 1.12554586
Trained batch 5298 batch loss 1.29460812 epoch total loss 1.12557781
Trained batch 5299 batch loss 1.06681395 epoch total loss 1.12556672
Trained batch 5300 batch loss 1.02879894 epoch total loss 1.12554848
Trained batch 5301 batch loss 0.959237218 epoch total loss 1.12551713
Trained batch 5302 batch loss 1.17229915 epoch total loss 1.12552595
Trained batch 5303 batch loss 1.17377329 epoch total loss 1.12553501
Trained batch 5304 batch loss 1.21197796 epoch total loss 1.12555134
Trained batch 5305 batch loss 1.30594027 epoch total loss 1.12558544
Trained batch 5306 batch loss 1.28524303 epoch total loss 1.12561548
Trained batch 5307 batch loss 0.874179244 epoch total loss 1.12556803
Trained batch 5308 batch loss 1.26021326 epoch total loss 1.12559342
Trained batch 5309 batch loss 1.10868073 epoch total loss 1.12559032
Trained batch 5310 batch loss 1.04070354 epoch total loss 1.12557423
Trained batch 5311 batch loss 1.12676215 epoch total loss 1.12557447
Trained batch 5312 batch loss 1.21748114 epoch total loss 1.12559175
Trained batch 5313 batch loss 1.24936438 epoch total loss 1.12561512
Trained batch 5314 batch loss 1.31662631 epoch total loss 1.125651
Trained batch 5315 batch loss 1.28059924 epoch total loss 1.12568021
Trained batch 5316 batch loss 1.15016532 epoch total loss 1.12568486
Trained batch 5317 batch loss 1.0509541 epoch total loss 1.12567079
Trained batch 5318 batch loss 1.00207829 epoch total loss 1.12564754
Trained batch 5319 batch loss 1.10272861 epoch total loss 1.12564313
Trained batch 5320 batch loss 1.18901026 epoch total loss 1.12565506
Trained batch 5321 batch loss 0.996590495 epoch total loss 1.12563074
Trained batch 5322 batch loss 1.20285511 epoch total loss 1.12564528
Trained batch 5323 batch loss 1.09128201 epoch total loss 1.12563884
Trained batch 5324 batch loss 0.851755321 epoch total loss 1.12558734
Trained batch 5325 batch loss 1.05020988 epoch total loss 1.12557316
Trained batch 5326 batch loss 1.00782633 epoch total loss 1.1255511
Trained batch 5327 batch loss 0.929300964 epoch total loss 1.12551427
Trained batch 5328 batch loss 1.01852298 epoch total loss 1.12549412
Trained batch 5329 batch loss 1.01103592 epoch total loss 1.12547266
Trained batch 5330 batch loss 0.86994046 epoch total loss 1.12542474
Trained batch 5331 batch loss 1.05395985 epoch total loss 1.12541139
Trained batch 5332 batch loss 1.34625328 epoch total loss 1.12545288
Trained batch 5333 batch loss 1.19122386 epoch total loss 1.12546515
Trained batch 5334 batch loss 1.38754416 epoch total loss 1.12551439
Trained batch 5335 batch loss 1.08763599 epoch total loss 1.12550724
Trained batch 5336 batch loss 1.22031569 epoch total loss 1.125525
Trained batch 5337 batch loss 1.05218375 epoch total loss 1.12551129
Trained batch 5338 batch loss 1.23990619 epoch total loss 1.12553263
Trained batch 5339 batch loss 1.23576498 epoch total loss 1.12555325
Trained batch 5340 batch loss 1.40847564 epoch total loss 1.1256063
Trained batch 5341 batch loss 1.33979118 epoch total loss 1.12564647
Trained batch 5342 batch loss 1.18511713 epoch total loss 1.12565756
Trained batch 5343 batch loss 1.07753396 epoch total loss 1.12564862
Trained batch 5344 batch loss 1.09967303 epoch total loss 1.12564373
Trained batch 5345 batch loss 1.17817926 epoch total loss 1.12565351
Trained batch 5346 batch loss 1.1666379 epoch total loss 1.12566113
Trained batch 5347 batch loss 1.02272427 epoch total loss 1.12564194
Trained batch 5348 batch loss 1.07071316 epoch total loss 1.12563169
Trained batch 5349 batch loss 1.13365793 epoch total loss 1.12563324
Trained batch 5350 batch loss 1.07618952 epoch total loss 1.12562394
Trained batch 5351 batch loss 1.13890851 epoch total loss 1.12562644
Trained batch 5352 batch loss 1.06839919 epoch total loss 1.12561572
Trained batch 5353 batch loss 1.09710217 epoch total loss 1.12561047
Trained batch 5354 batch loss 1.32146871 epoch total loss 1.12564695
Trained batch 5355 batch loss 0.991479814 epoch total loss 1.12562191
Trained batch 5356 batch loss 1.13876343 epoch total loss 1.12562442
Trained batch 5357 batch loss 1.23382616 epoch total loss 1.12564456
Trained batch 5358 batch loss 1.26152515 epoch total loss 1.12567
Trained batch 5359 batch loss 0.976113141 epoch total loss 1.12564206
Trained batch 5360 batch loss 1.08552957 epoch total loss 1.12563455
Trained batch 5361 batch loss 0.862686872 epoch total loss 1.12558556
Trained batch 5362 batch loss 0.994076371 epoch total loss 1.125561
Trained batch 5363 batch loss 0.772229791 epoch total loss 1.1254952
Trained batch 5364 batch loss 1.18618941 epoch total loss 1.12550652
Trained batch 5365 batch loss 1.05381811 epoch total loss 1.12549305
Trained batch 5366 batch loss 1.12075663 epoch total loss 1.12549222
Trained batch 5367 batch loss 1.24884951 epoch total loss 1.12551522
Trained batch 5368 batch loss 1.27525747 epoch total loss 1.12554312
Trained batch 5369 batch loss 1.31081784 epoch total loss 1.12557769
Trained batch 5370 batch loss 1.24571991 epoch total loss 1.1256
Trained batch 5371 batch loss 1.19774914 epoch total loss 1.12561345
Trained batch 5372 batch loss 1.33757687 epoch total loss 1.12565291
Trained batch 5373 batch loss 1.22719383 epoch total loss 1.12567174
Trained batch 5374 batch loss 1.06424 epoch total loss 1.12566042
Trained batch 5375 batch loss 1.22575009 epoch total loss 1.12567902
Trained batch 5376 batch loss 1.20245683 epoch total loss 1.12569332
Trained batch 5377 batch loss 1.1948719 epoch total loss 1.12570608
Trained batch 5378 batch loss 1.18113077 epoch total loss 1.12571645
Trained batch 5379 batch loss 1.2008065 epoch total loss 1.1257304
Trained batch 5380 batch loss 1.51878226 epoch total loss 1.12580335
Trained batch 5381 batch loss 1.5338639 epoch total loss 1.12587917
Trained batch 5382 batch loss 1.42130041 epoch total loss 1.12593412
Trained batch 5383 batch loss 1.27538061 epoch total loss 1.1259619
Trained batch 5384 batch loss 1.32953286 epoch total loss 1.12599969
Trained batch 5385 batch loss 1.10750222 epoch total loss 1.12599623
Trained batch 5386 batch loss 1.16746569 epoch total loss 1.12600398
Trained batch 5387 batch loss 1.07440662 epoch total loss 1.12599432
Trained batch 5388 batch loss 1.03460383 epoch total loss 1.1259774
Trained batch 5389 batch loss 1.30168462 epoch total loss 1.12601
Trained batch 5390 batch loss 1.23631382 epoch total loss 1.12603045
Trained batch 5391 batch loss 0.929967 epoch total loss 1.12599409
Trained batch 5392 batch loss 1.16594982 epoch total loss 1.1260016
Trained batch 5393 batch loss 1.26566029 epoch total loss 1.12602746
Trained batch 5394 batch loss 1.39867616 epoch total loss 1.12607789
Trained batch 5395 batch loss 1.48252642 epoch total loss 1.12614405
Trained batch 5396 batch loss 1.39160573 epoch total loss 1.12619317
Trained batch 5397 batch loss 1.37349653 epoch total loss 1.12623906
Trained batch 5398 batch loss 1.15093446 epoch total loss 1.12624359
Trained batch 5399 batch loss 1.24124968 epoch total loss 1.12626493
Trained batch 5400 batch loss 1.23932636 epoch total loss 1.12628579
Trained batch 5401 batch loss 1.37018323 epoch total loss 1.12633097
Trained batch 5402 batch loss 1.14961493 epoch total loss 1.12633526
Trained batch 5403 batch loss 1.23729849 epoch total loss 1.12635577
Trained batch 5404 batch loss 1.04880965 epoch total loss 1.12634146
Trained batch 5405 batch loss 0.94706589 epoch total loss 1.12630832
Trained batch 5406 batch loss 1.12814105 epoch total loss 1.12630856
Trained batch 5407 batch loss 1.20831943 epoch total loss 1.12632382
Trained batch 5408 batch loss 1.04892337 epoch total loss 1.12630951
Trained batch 5409 batch loss 0.875874519 epoch total loss 1.12626314
Trained batch 5410 batch loss 1.31361008 epoch total loss 1.12629783
Trained batch 5411 batch loss 1.13022089 epoch total loss 1.12629855
Trained batch 5412 batch loss 1.14104843 epoch total loss 1.12630129
Trained batch 5413 batch loss 0.972007751 epoch total loss 1.1262728
Trained batch 5414 batch loss 1.63485038 epoch total loss 1.12636673
Trained batch 5415 batch loss 0.907791376 epoch total loss 1.12632632
Trained batch 5416 batch loss 1.0727402 epoch total loss 1.12631643
Trained batch 5417 batch loss 1.0249275 epoch total loss 1.12629771
Trained batch 5418 batch loss 1.00605035 epoch total loss 1.12627554
Trained batch 5419 batch loss 1.26852751 epoch total loss 1.12630177
Trained batch 5420 batch loss 1.27878833 epoch total loss 1.1263299
Trained batch 5421 batch loss 1.22259772 epoch total loss 1.12634766
Trained batch 5422 batch loss 1.15188479 epoch total loss 1.12635231
Trained batch 5423 batch loss 1.25684702 epoch total loss 1.12637639
Trained batch 5424 batch loss 1.13565636 epoch total loss 1.12637818
Trained batch 5425 batch loss 1.15766358 epoch total loss 1.1263839
Trained batch 5426 batch loss 1.28351092 epoch total loss 1.12641287
Trained batch 5427 batch loss 1.31478596 epoch total loss 1.12644768
Trained batch 5428 batch loss 1.22225761 epoch total loss 1.12646532
Trained batch 5429 batch loss 1.18383384 epoch total loss 1.12647581
Trained batch 5430 batch loss 1.30167139 epoch total loss 1.12650812
Trained batch 5431 batch loss 1.32882881 epoch total loss 1.12654531
Trained batch 5432 batch loss 1.17413521 epoch total loss 1.12655413
Trained batch 5433 batch loss 1.25791717 epoch total loss 1.12657821
Trained batch 5434 batch loss 1.21043658 epoch total loss 1.12659371
Trained batch 5435 batch loss 1.03380919 epoch total loss 1.12657666
Trained batch 5436 batch loss 1.15023124 epoch total loss 1.12658095
Trained batch 5437 batch loss 1.05354595 epoch total loss 1.1265676
Trained batch 5438 batch loss 1.24601614 epoch total loss 1.12658954
Trained batch 5439 batch loss 1.30191159 epoch total loss 1.12662172
Trained batch 5440 batch loss 1.25199986 epoch total loss 1.12664485
Trained batch 5441 batch loss 1.26185668 epoch total loss 1.12666965
Trained batch 5442 batch loss 1.09343982 epoch total loss 1.12666345
Trained batch 5443 batch loss 1.16190743 epoch total loss 1.12667
Trained batch 5444 batch loss 0.832739234 epoch total loss 1.126616
Trained batch 5445 batch loss 0.853397369 epoch total loss 1.12656581
Trained batch 5446 batch loss 0.918590486 epoch total loss 1.12652755
Trained batch 5447 batch loss 0.980583489 epoch total loss 1.12650084
Trained batch 5448 batch loss 0.914083421 epoch total loss 1.12646174
Trained batch 5449 batch loss 1.05332756 epoch total loss 1.12644839
Trained batch 5450 batch loss 1.17736 epoch total loss 1.12645769
Trained batch 5451 batch loss 0.993763745 epoch total loss 1.12643325
Trained batch 5452 batch loss 0.837819755 epoch total loss 1.12638044
Trained batch 5453 batch loss 1.17517233 epoch total loss 1.12638938
Trained batch 5454 batch loss 1.16217399 epoch total loss 1.12639594
Trained batch 5455 batch loss 1.14607716 epoch total loss 1.12639952
Trained batch 5456 batch loss 1.13911843 epoch total loss 1.12640178
Trained batch 5457 batch loss 1.19559193 epoch total loss 1.12641454
Trained batch 5458 batch loss 1.37135506 epoch total loss 1.12645948
Trained batch 5459 batch loss 1.46119261 epoch total loss 1.12652087
Trained batch 5460 batch loss 1.01547194 epoch total loss 1.12650049
Trained batch 5461 batch loss 1.10251713 epoch total loss 1.1264962
Trained batch 5462 batch loss 1.09879696 epoch total loss 1.12649107
Trained batch 5463 batch loss 1.06912816 epoch total loss 1.12648058
Trained batch 5464 batch loss 1.05335963 epoch total loss 1.12646711
Trained batch 5465 batch loss 1.0112077 epoch total loss 1.12644613
Trained batch 5466 batch loss 1.0586226 epoch total loss 1.12643361
Trained batch 5467 batch loss 1.11902905 epoch total loss 1.1264323
Trained batch 5468 batch loss 1.10560489 epoch total loss 1.12642848
Trained batch 5469 batch loss 0.92712146 epoch total loss 1.12639213
Trained batch 5470 batch loss 1.04864728 epoch total loss 1.12637794
Trained batch 5471 batch loss 0.993398249 epoch total loss 1.1263535
Trained batch 5472 batch loss 1.01206183 epoch total loss 1.12633264
Trained batch 5473 batch loss 0.925512195 epoch total loss 1.12629592
Trained batch 5474 batch loss 1.05753517 epoch total loss 1.12628341
Trained batch 5475 batch loss 0.98821187 epoch total loss 1.12625825
Trained batch 5476 batch loss 0.774910092 epoch total loss 1.126194
Trained batch 5477 batch loss 1.09704959 epoch total loss 1.12618876
Trained batch 5478 batch loss 0.918015242 epoch total loss 1.12615073
Trained batch 5479 batch loss 0.93744576 epoch total loss 1.12611628
Trained batch 5480 batch loss 1.00648642 epoch total loss 1.12609446
Trained batch 5481 batch loss 1.1626178 epoch total loss 1.12610114
Trained batch 5482 batch loss 1.14314723 epoch total loss 1.12610424
Trained batch 5483 batch loss 1.34006989 epoch total loss 1.12614322
Trained batch 5484 batch loss 1.21486032 epoch total loss 1.12615931
Trained batch 5485 batch loss 0.981531262 epoch total loss 1.12613297
Trained batch 5486 batch loss 1.26811504 epoch total loss 1.12615883
Trained batch 5487 batch loss 1.20258093 epoch total loss 1.12617278
Trained batch 5488 batch loss 1.20194817 epoch total loss 1.12618661
Trained batch 5489 batch loss 1.12920976 epoch total loss 1.12618721
Trained batch 5490 batch loss 1.30641866 epoch total loss 1.12622011
Trained batch 5491 batch loss 1.17161393 epoch total loss 1.12622833
Trained batch 5492 batch loss 0.939674735 epoch total loss 1.12619424
Trained batch 5493 batch loss 0.981220841 epoch total loss 1.12616789
Trained batch 5494 batch loss 1.10172164 epoch total loss 1.12616348
Trained batch 5495 batch loss 1.16853666 epoch total loss 1.12617111
Trained batch 5496 batch loss 0.999107122 epoch total loss 1.12614799
Trained batch 5497 batch loss 1.13439202 epoch total loss 1.12614954
Trained batch 5498 batch loss 1.00160789 epoch total loss 1.12612689
Trained batch 5499 batch loss 0.947079122 epoch total loss 1.12609434
Trained batch 5500 batch loss 0.746067166 epoch total loss 1.1260252
Trained batch 5501 batch loss 1.1095295 epoch total loss 1.12602222
Trained batch 5502 batch loss 0.956445932 epoch total loss 1.12599134
Trained batch 5503 batch loss 1.20940757 epoch total loss 1.1260066
Trained batch 5504 batch loss 1.08913767 epoch total loss 1.12599993
Trained batch 5505 batch loss 0.823611557 epoch total loss 1.12594497
Trained batch 5506 batch loss 1.06025171 epoch total loss 1.12593305
Trained batch 5507 batch loss 1.13331175 epoch total loss 1.12593436
Trained batch 5508 batch loss 1.04930854 epoch total loss 1.12592041
Trained batch 5509 batch loss 1.13565993 epoch total loss 1.1259222
Trained batch 5510 batch loss 1.0090394 epoch total loss 1.1259011
Trained batch 5511 batch loss 1.10227394 epoch total loss 1.12589669
Trained batch 5512 batch loss 1.2517736 epoch total loss 1.12591958
Trained batch 5513 batch loss 1.06567621 epoch total loss 1.12590873
Trained batch 5514 batch loss 1.15790141 epoch total loss 1.12591445
Trained batch 5515 batch loss 1.1921041 epoch total loss 1.12592649
Trained batch 5516 batch loss 1.20172215 epoch total loss 1.1259402
Trained batch 5517 batch loss 1.31120741 epoch total loss 1.1259737
Trained batch 5518 batch loss 1.30967641 epoch total loss 1.12600696
Trained batch 5519 batch loss 1.30898833 epoch total loss 1.12604022
Trained batch 5520 batch loss 1.20672679 epoch total loss 1.12605476
Trained batch 5521 batch loss 1.1799221 epoch total loss 1.12606442
Trained batch 5522 batch loss 1.18520141 epoch total loss 1.12607515
Trained batch 5523 batch loss 1.25979257 epoch total loss 1.12609935
Trained batch 5524 batch loss 1.1924026 epoch total loss 1.12611139
Trained batch 5525 batch loss 1.21761417 epoch total loss 1.12612796
Trained batch 5526 batch loss 1.15666294 epoch total loss 1.12613344
Trained batch 5527 batch loss 1.07886565 epoch total loss 1.12612498
Trained batch 5528 batch loss 1.05447137 epoch total loss 1.1261121
Trained batch 5529 batch loss 1.08041513 epoch total loss 1.12610388
Trained batch 5530 batch loss 1.12948883 epoch total loss 1.12610447
Trained batch 5531 batch loss 1.18994641 epoch total loss 1.12611592
Trained batch 5532 batch loss 1.22400188 epoch total loss 1.12613368
Trained batch 5533 batch loss 0.971583605 epoch total loss 1.12610579
Trained batch 5534 batch loss 1.17156434 epoch total loss 1.12611389
Trained batch 5535 batch loss 1.20118618 epoch total loss 1.12612748
Trained batch 5536 batch loss 1.05328417 epoch total loss 1.12611437
Trained batch 5537 batch loss 1.1364094 epoch total loss 1.12611616
Trained batch 5538 batch loss 1.15326369 epoch total loss 1.12612104
Trained batch 5539 batch loss 0.91142714 epoch total loss 1.1260823
Trained batch 5540 batch loss 1.26853228 epoch total loss 1.12610805
Trained batch 5541 batch loss 1.10486019 epoch total loss 1.12610424
Trained batch 5542 batch loss 1.18640208 epoch total loss 1.1261152
Trained batch 5543 batch loss 1.21518183 epoch total loss 1.1261313
Trained batch 5544 batch loss 0.952051044 epoch total loss 1.12609982
Trained batch 5545 batch loss 1.10599947 epoch total loss 1.12609625
Trained batch 5546 batch loss 1.24192405 epoch total loss 1.12611711
Trained batch 5547 batch loss 1.10038173 epoch total loss 1.12611246
Trained batch 5548 batch loss 1.20364237 epoch total loss 1.12612641
Trained batch 5549 batch loss 1.0533514 epoch total loss 1.1261133
Trained batch 5550 batch loss 1.25892043 epoch total loss 1.12613726
Trained batch 5551 batch loss 0.987044811 epoch total loss 1.1261121
Trained batch 5552 batch loss 1.26755142 epoch total loss 1.12613761
Epoch 4 train loss 1.126137614250183
Validated batch 1 batch loss 1.21752489
Validated batch 2 batch loss 1.13210511
Validated batch 3 batch loss 1.17015457
Validated batch 4 batch loss 1.28451538
Validated batch 5 batch loss 1.0524435
Validated batch 6 batch loss 0.946713269
Validated batch 7 batch loss 1.09251356
Validated batch 8 batch loss 1.13351762
Validated batch 9 batch loss 1.21949863
Validated batch 10 batch loss 1.19899023
Validated batch 11 batch loss 1.17779243
Validated batch 12 batch loss 1.41728091
Validated batch 13 batch loss 1.06775784
Validated batch 14 batch loss 1.01918554
Validated batch 15 batch loss 0.94587332
Validated batch 16 batch loss 1.18213105
Validated batch 17 batch loss 1.19229317
Validated batch 18 batch loss 1.09833407
Validated batch 19 batch loss 0.953603327
Validated batch 20 batch loss 1.30041683
Validated batch 21 batch loss 1.04305732
Validated batch 22 batch loss 1.32202339
Validated batch 23 batch loss 1.30200267
Validated batch 24 batch loss 1.14740276
Validated batch 25 batch loss 0.981590331
Validated batch 26 batch loss 1.20259476
Validated batch 27 batch loss 1.32456291
Validated batch 28 batch loss 1.16645384
Validated batch 29 batch loss 1.24293196
Validated batch 30 batch loss 1.21418715
Validated batch 31 batch loss 1.40248895
Validated batch 32 batch loss 1.32991016
Validated batch 33 batch loss 1.26365817
Validated batch 34 batch loss 1.12578881
Validated batch 35 batch loss 1.19286728
Validated batch 36 batch loss 1.42814493
Validated batch 37 batch loss 1.16407168
Validated batch 38 batch loss 1.11391211
Validated batch 39 batch loss 1.09263206
Validated batch 40 batch loss 1.12696242
Validated batch 41 batch loss 1.2504847
Validated batch 42 batch loss 1.23331082
Validated batch 43 batch loss 1.07010674
Validated batch 44 batch loss 1.39542949
Validated batch 45 batch loss 1.2055316
Validated batch 46 batch loss 1.39856982
Validated batch 47 batch loss 1.35587478
Validated batch 48 batch loss 1.08943295
Validated batch 49 batch loss 1.36515391
Validated batch 50 batch loss 1.25864482
Validated batch 51 batch loss 1.12657046
Validated batch 52 batch loss 1.28103423
Validated batch 53 batch loss 1.19488633
Validated batch 54 batch loss 1.26973557
Validated batch 55 batch loss 1.17263067
Validated batch 56 batch loss 1.33131862
Validated batch 57 batch loss 1.19843984
Validated batch 58 batch loss 1.17383742
Validated batch 59 batch loss 1.37281597
Validated batch 60 batch loss 1.24227417
Validated batch 61 batch loss 1.44581151
Validated batch 62 batch loss 1.31613946
Validated batch 63 batch loss 1.20572066
Validated batch 64 batch loss 1.20528388
Validated batch 65 batch loss 1.45305085
Validated batch 66 batch loss 1.20959818
Validated batch 67 batch loss 1.20356059
Validated batch 68 batch loss 1.18645287
Validated batch 69 batch loss 1.32272112
Validated batch 70 batch loss 0.884377539
Validated batch 71 batch loss 1.04304266
Validated batch 72 batch loss 1.16055882
Validated batch 73 batch loss 1.08961749
Validated batch 74 batch loss 1.2591821
Validated batch 75 batch loss 1.3128854
Validated batch 76 batch loss 1.24210978
Validated batch 77 batch loss 1.40422845
Validated batch 78 batch loss 1.11896634
Validated batch 79 batch loss 1.2655766
Validated batch 80 batch loss 1.38484895
Validated batch 81 batch loss 1.28283
Validated batch 82 batch loss 1.20039678
Validated batch 83 batch loss 1.17104673
Validated batch 84 batch loss 1.14479887
Validated batch 85 batch loss 1.07337487
Validated batch 86 batch loss 1.17455411
Validated batch 87 batch loss 1.23913944
Validated batch 88 batch loss 1.26822984
Validated batch 89 batch loss 1.18501401
Validated batch 90 batch loss 1.1826241
Validated batch 91 batch loss 0.967079401
Validated batch 92 batch loss 1.24086642
Validated batch 93 batch loss 1.19078493
Validated batch 94 batch loss 0.9814803
Validated batch 95 batch loss 0.951304793
Validated batch 96 batch loss 1.12055826
Validated batch 97 batch loss 0.975044966
Validated batch 98 batch loss 1.26630104
Validated batch 99 batch loss 1.11309719
Validated batch 100 batch loss 1.14797497
Validated batch 101 batch loss 1.31656599
Validated batch 102 batch loss 1.17409492
Validated batch 103 batch loss 1.16082573
Validated batch 104 batch loss 1.10125721
Validated batch 105 batch loss 1.21603644
Validated batch 106 batch loss 1.25566769
Validated batch 107 batch loss 0.830729127
Validated batch 108 batch loss 1.16687405
Validated batch 109 batch loss 1.27224016
Validated batch 110 batch loss 1.11057055
Validated batch 111 batch loss 1.26107621
Validated batch 112 batch loss 1.32764244
Validated batch 113 batch loss 1.54746485
Validated batch 114 batch loss 1.3825357
Validated batch 115 batch loss 1.38065553
Validated batch 116 batch loss 1.23407984
Validated batch 117 batch loss 1.03010976
Validated batch 118 batch loss 0.927441
Validated batch 119 batch loss 1.20826304
Validated batch 120 batch loss 1.09305334
Validated batch 121 batch loss 1.26142526
Validated batch 122 batch loss 1.17244422
Validated batch 123 batch loss 1.19020844
Validated batch 124 batch loss 1.29577458
Validated batch 125 batch loss 1.28769684
Validated batch 126 batch loss 1.11431909
Validated batch 127 batch loss 1.06076336
Validated batch 128 batch loss 1.15319324
Validated batch 129 batch loss 1.24085188
Validated batch 130 batch loss 1.4072268
Validated batch 131 batch loss 1.0977118
Validated batch 132 batch loss 1.34899747
Validated batch 133 batch loss 1.11691046
Validated batch 134 batch loss 1.24187374
Validated batch 135 batch loss 1.15772271
Validated batch 136 batch loss 1.19237161
Validated batch 137 batch loss 0.975739479
Validated batch 138 batch loss 1.13175571
Validated batch 139 batch loss 1.11329079
Validated batch 140 batch loss 0.863066673
Validated batch 141 batch loss 0.708707929
Validated batch 142 batch loss 0.840692639
Validated batch 143 batch loss 1.24889565
Validated batch 144 batch loss 1.22736907
Validated batch 145 batch loss 1.12200618
Validated batch 146 batch loss 1.21274209
Validated batch 147 batch loss 1.0901916
Validated batch 148 batch loss 1.06036878
Validated batch 149 batch loss 1.19705415
Validated batch 150 batch loss 1.10372186
Validated batch 151 batch loss 0.969842911
Validated batch 152 batch loss 1.27610612
Validated batch 153 batch loss 1.05841923
Validated batch 154 batch loss 1.20677924
Validated batch 155 batch loss 1.24405897
Validated batch 156 batch loss 1.22837806
Validated batch 157 batch loss 1.38412881
Validated batch 158 batch loss 1.27268267
Validated batch 159 batch loss 1.09151268
Validated batch 160 batch loss 0.943143249
Validated batch 161 batch loss 1.2516526
Validated batch 162 batch loss 0.898437262
Validated batch 163 batch loss 1.03748906
Validated batch 164 batch loss 0.995752
Validated batch 165 batch loss 1.40989912
Validated batch 166 batch loss 1.17171502
Validated batch 167 batch loss 1.16268146
Validated batch 168 batch loss 1.13644838
Validated batch 169 batch loss 1.41778064
Validated batch 170 batch loss 1.43161714
Validated batch 171 batch loss 1.24742091
Validated batch 172 batch loss 1.12559605
Validated batch 173 batch loss 1.26143312
Validated batch 174 batch loss 1.22170055
Validated batch 175 batch loss 1.23777652
Validated batch 176 batch loss 1.23036087
Validated batch 177 batch loss 1.18369508
Validated batch 178 batch loss 1.29545546
Validated batch 179 batch loss 1.09720969
Validated batch 180 batch loss 1.07228565
Validated batch 181 batch loss 0.998452783
Validated batch 182 batch loss 1.13298273
Validated batch 183 batch loss 1.00418043
Validated batch 184 batch loss 1.28970957
Validated batch 185 batch loss 1.09275198
Validated batch 186 batch loss 1.15473151
Validated batch 187 batch loss 1.15139842
Validated batch 188 batch loss 1.21095026
Validated batch 189 batch loss 1.25021803
Validated batch 190 batch loss 1.19060528
Validated batch 191 batch loss 1.07416177
Validated batch 192 batch loss 1.30237401
Validated batch 193 batch loss 1.2101804
Validated batch 194 batch loss 1.13719642
Validated batch 195 batch loss 1.16859162
Validated batch 196 batch loss 1.18219209
Validated batch 197 batch loss 1.2649343
Validated batch 198 batch loss 0.860395133
Validated batch 199 batch loss 1.33044577
Validated batch 200 batch loss 1.13991594
Validated batch 201 batch loss 1.07766771
Validated batch 202 batch loss 1.26507139
Validated batch 203 batch loss 1.37284422
Validated batch 204 batch loss 1.12824893
Validated batch 205 batch loss 1.48187172
Validated batch 206 batch loss 1.4496237
Validated batch 207 batch loss 1.29675221
Validated batch 208 batch loss 1.1433686
Validated batch 209 batch loss 1.15447831
Validated batch 210 batch loss 1.06375837
Validated batch 211 batch loss 1.12414169
Validated batch 212 batch loss 1.15788281
Validated batch 213 batch loss 1.10902369
Validated batch 214 batch loss 1.31411982
Validated batch 215 batch loss 1.34248042
Validated batch 216 batch loss 1.22097456
Validated batch 217 batch loss 1.06779075
Validated batch 218 batch loss 1.03133917
Validated batch 219 batch loss 0.983860314
Validated batch 220 batch loss 1.39656615
Validated batch 221 batch loss 1.20047832
Validated batch 222 batch loss 1.21577239
Validated batch 223 batch loss 1.22717333
Validated batch 224 batch loss 1.22476125
Validated batch 225 batch loss 1.1499567
Validated batch 226 batch loss 1.23487949
Validated batch 227 batch loss 1.2090919
Validated batch 228 batch loss 1.29997873
Validated batch 229 batch loss 1.06965351
Validated batch 230 batch loss 1.19572282
Validated batch 231 batch loss 1.01329136
Validated batch 232 batch loss 1.00165641
Validated batch 233 batch loss 1.3615613
Validated batch 234 batch loss 1.0354985
Validated batch 235 batch loss 1.44117808
Validated batch 236 batch loss 1.49051118
Validated batch 237 batch loss 1.35643482
Validated batch 238 batch loss 1.12616658
Validated batch 239 batch loss 0.831395864
Validated batch 240 batch loss 1.18910527
Validated batch 241 batch loss 1.15409207
Validated batch 242 batch loss 1.32877147
Validated batch 243 batch loss 1.36304593
Validated batch 244 batch loss 1.3068893
Validated batch 245 batch loss 1.08815622
Validated batch 246 batch loss 1.21482074
Validated batch 247 batch loss 1.24134088
Validated batch 248 batch loss 1.00033069
Validated batch 249 batch loss 1.34331489
Validated batch 250 batch loss 1.23775256
Validated batch 251 batch loss 1.15958357
Validated batch 252 batch loss 1.29889047
Validated batch 253 batch loss 1.34829056
Validated batch 254 batch loss 1.04927874
Validated batch 255 batch loss 0.856781065
Validated batch 256 batch loss 0.959211349
Validated batch 257 batch loss 1.07690048
Validated batch 258 batch loss 1.38971567
Validated batch 259 batch loss 1.14369011
Validated batch 260 batch loss 1.30335057
Validated batch 261 batch loss 1.17427969
Validated batch 262 batch loss 1.14988673
Validated batch 263 batch loss 1.18652844
Validated batch 264 batch loss 1.02947772
Validated batch 265 batch loss 1.21030259
Validated batch 266 batch loss 1.26612067
Validated batch 267 batch loss 1.13495922
Validated batch 268 batch loss 1.11619473
Validated batch 269 batch loss 1.40777564
Validated batch 270 batch loss 1.10288262
Validated batch 271 batch loss 1.0996424
Validated batch 272 batch loss 1.2711513
Validated batch 273 batch loss 1.20391464
Validated batch 274 batch loss 0.990083098
Validated batch 275 batch loss 1.2372843
Validated batch 276 batch loss 1.2540344
Validated batch 277 batch loss 1.4715507
Validated batch 278 batch loss 1.04035711
Validated batch 279 batch loss 1.20556664
Validated batch 280 batch loss 1.11327052
Validated batch 281 batch loss 1.11255908
Validated batch 282 batch loss 1.14399028
Validated batch 283 batch loss 0.955369771
Validated batch 284 batch loss 1.12144113
Validated batch 285 batch loss 1.10753202
Validated batch 286 batch loss 1.1832304
Validated batch 287 batch loss 1.10545707
Validated batch 288 batch loss 1.05651116
Validated batch 289 batch loss 1.04031348
Validated batch 290 batch loss 1.27715862
Validated batch 291 batch loss 0.954708457
Validated batch 292 batch loss 0.954403341
Validated batch 293 batch loss 1.07164752
Validated batch 294 batch loss 1.2363404
Validated batch 295 batch loss 0.931802
Validated batch 296 batch loss 1.25415206
Validated batch 297 batch loss 1.20963097
Validated batch 298 batch loss 1.23868442
Validated batch 299 batch loss 1.25955868
Validated batch 300 batch loss 1.14684391
Validated batch 301 batch loss 1.24500775
Validated batch 302 batch loss 1.0928278
Validated batch 303 batch loss 0.97391814
Validated batch 304 batch loss 1.49508
Validated batch 305 batch loss 1.03297591
Validated batch 306 batch loss 1.1727376
Validated batch 307 batch loss 1.18015552
Validated batch 308 batch loss 1.22251415
Validated batch 309 batch loss 1.32661903
Validated batch 310 batch loss 1.11198
Validated batch 311 batch loss 1.26969337
Validated batch 312 batch loss 0.885391235
Validated batch 313 batch loss 1.19142532
Validated batch 314 batch loss 1.02558696
Validated batch 315 batch loss 1.06779456
Validated batch 316 batch loss 1.26605225
Validated batch 317 batch loss 1.30690956
Validated batch 318 batch loss 1.23189759
Validated batch 319 batch loss 1.05946636
Validated batch 320 batch loss 1.03105128
Validated batch 321 batch loss 1.27928257
Validated batch 322 batch loss 1.46490073
Validated batch 323 batch loss 1.01163149
Validated batch 324 batch loss 1.0525986
Validated batch 325 batch loss 0.913152695
Validated batch 326 batch loss 0.956020117
Validated batch 327 batch loss 1.14847994
Validated batch 328 batch loss 1.2999382
Validated batch 329 batch loss 1.28974724
Validated batch 330 batch loss 1.07675982
Validated batch 331 batch loss 1.10665965
Validated batch 332 batch loss 1.08893263
Validated batch 333 batch loss 1.36357069
Validated batch 334 batch loss 1.06368494
Validated batch 335 batch loss 1.18690491
Validated batch 336 batch loss 1.08344924
Validated batch 337 batch loss 1.20770192
Validated batch 338 batch loss 0.937214375
Validated batch 339 batch loss 1.08490205
Validated batch 340 batch loss 1.14181387
Validated batch 341 batch loss 1.30986953
Validated batch 342 batch loss 1.34213233
Validated batch 343 batch loss 1.2338829
Validated batch 344 batch loss 1.29783249
Validated batch 345 batch loss 1.12235475
Validated batch 346 batch loss 0.944171309
Validated batch 347 batch loss 1.19130218
Validated batch 348 batch loss 1.35864246
Validated batch 349 batch loss 1.30566883
Validated batch 350 batch loss 1.15105581
Validated batch 351 batch loss 1.136603
Validated batch 352 batch loss 0.737910509
Validated batch 353 batch loss 0.987890482
Validated batch 354 batch loss 1.27590621
Validated batch 355 batch loss 1.02410674
Validated batch 356 batch loss 1.32458973
Validated batch 357 batch loss 1.20857096
Validated batch 358 batch loss 1.12377977
Validated batch 359 batch loss 1.20253301
Validated batch 360 batch loss 1.12734461
Validated batch 361 batch loss 1.16394842
Validated batch 362 batch loss 1.28139019
Validated batch 363 batch loss 0.997165561
Validated batch 364 batch loss 0.880672455
Validated batch 365 batch loss 1.08222938
Validated batch 366 batch loss 1.27391553
Validated batch 367 batch loss 1.03626609
Validated batch 368 batch loss 1.25567341
Validated batch 369 batch loss 1.14679885
Validated batch 370 batch loss 0.949866176
Validated batch 371 batch loss 1.1661098
Validated batch 372 batch loss 1.04737
Validated batch 373 batch loss 1.15548718
Validated batch 374 batch loss 1.1257081
Validated batch 375 batch loss 1.20479119
Validated batch 376 batch loss 0.878807664
Validated batch 377 batch loss 1.06035352
Validated batch 378 batch loss 1.21744514
Validated batch 379 batch loss 1.15857601
Validated batch 380 batch loss 1.02352059
Validated batch 381 batch loss 0.876579046
Validated batch 382 batch loss 1.06038141
Validated batch 383 batch loss 1.04839993
Validated batch 384 batch loss 1.13707
Validated batch 385 batch loss 1.1817081
Validated batch 386 batch loss 1.19855201
Validated batch 387 batch loss 1.10476136
Validated batch 388 batch loss 0.944921851
Validated batch 389 batch loss 1.19809806
Validated batch 390 batch loss 1.37686884
Validated batch 391 batch loss 1.48908353
Validated batch 392 batch loss 1.06155825
Validated batch 393 batch loss 0.966775775
Validated batch 394 batch loss 1.16477203
Validated batch 395 batch loss 0.869202375
Validated batch 396 batch loss 1.12403202
Validated batch 397 batch loss 1.37875009
Validated batch 398 batch loss 0.964188874
Validated batch 399 batch loss 0.766251147
Validated batch 400 batch loss 1.00493121
Validated batch 401 batch loss 0.951756775
Validated batch 402 batch loss 1.03525782
Validated batch 403 batch loss 1.01023471
Validated batch 404 batch loss 1.10208511
Validated batch 405 batch loss 0.990602
Validated batch 406 batch loss 1.22021747
Validated batch 407 batch loss 1.25829053
Validated batch 408 batch loss 0.918506145
Validated batch 409 batch loss 1.01379108
Validated batch 410 batch loss 1.21680927
Validated batch 411 batch loss 0.945731521
Validated batch 412 batch loss 1.05192018
Validated batch 413 batch loss 1.13313532
Validated batch 414 batch loss 1.32409215
Validated batch 415 batch loss 1.11558867
Validated batch 416 batch loss 0.9858706
Validated batch 417 batch loss 1.03726
Validated batch 418 batch loss 1.14437473
Validated batch 419 batch loss 0.836499751
Validated batch 420 batch loss 1.48890257
Validated batch 421 batch loss 1.04114461
Validated batch 422 batch loss 1.02299452
Validated batch 423 batch loss 1.06253839
Validated batch 424 batch loss 1.23690867
Validated batch 425 batch loss 1.1578238
Validated batch 426 batch loss 1.15608561
Validated batch 427 batch loss 1.27543938
Validated batch 428 batch loss 1.07172167
Validated batch 429 batch loss 1.24413061
Validated batch 430 batch loss 1.23336184
Validated batch 431 batch loss 1.20152664
Validated batch 432 batch loss 1.35708737
Validated batch 433 batch loss 0.985599756
Validated batch 434 batch loss 1.1424042
Validated batch 435 batch loss 0.977144897
Validated batch 436 batch loss 0.988780916
Validated batch 437 batch loss 1.30366683
Validated batch 438 batch loss 1.2253828
Validated batch 439 batch loss 1.42441773
Validated batch 440 batch loss 0.936160624
Validated batch 441 batch loss 1.25398397
Validated batch 442 batch loss 0.814069331
Validated batch 443 batch loss 1.01827931
Validated batch 444 batch loss 0.848433852
Validated batch 445 batch loss 1.33772254
Validated batch 446 batch loss 0.916153848
Validated batch 447 batch loss 0.941845596
Validated batch 448 batch loss 1.27931213
Validated batch 449 batch loss 1.22522938
Validated batch 450 batch loss 1.04087257
Validated batch 451 batch loss 0.975210428
Validated batch 452 batch loss 0.951671302
Validated batch 453 batch loss 0.897919655
Validated batch 454 batch loss 1.13535
Validated batch 455 batch loss 1.23947382
Validated batch 456 batch loss 1.1135273
Validated batch 457 batch loss 1.27364349
Validated batch 458 batch loss 1.38482523
Validated batch 459 batch loss 1.27159333
Validated batch 460 batch loss 1.26105618
Validated batch 461 batch loss 1.16252959
Validated batch 462 batch loss 1.30880618
Validated batch 463 batch loss 1.27935505
Validated batch 464 batch loss 1.37133431
Validated batch 465 batch loss 1.1516062
Validated batch 466 batch loss 1.1091156
Validated batch 467 batch loss 1.08472455
Validated batch 468 batch loss 1.28640199
Validated batch 469 batch loss 1.405882
Validated batch 470 batch loss 1.12983894
Validated batch 471 batch loss 1.15296268
Validated batch 472 batch loss 0.840670884
Validated batch 473 batch loss 1.23728681
Validated batch 474 batch loss 1.10944676
Validated batch 475 batch loss 1.14267492
Validated batch 476 batch loss 1.28936934
Validated batch 477 batch loss 1.15676332
Validated batch 478 batch loss 1.12152469
Validated batch 479 batch loss 0.95558548
Validated batch 480 batch loss 1.11086082
Validated batch 481 batch loss 1.14397502
Validated batch 482 batch loss 1.26752448
Validated batch 483 batch loss 1.27584887
Validated batch 484 batch loss 1.11269808
Validated batch 485 batch loss 1.24957407
Validated batch 486 batch loss 1.24755049
Validated batch 487 batch loss 1.2432673
Validated batch 488 batch loss 1.08199084
Validated batch 489 batch loss 1.38309383
Validated batch 490 batch loss 0.992881477
Validated batch 491 batch loss 1.10426235
Validated batch 492 batch loss 1.07620335
Validated batch 493 batch loss 1.02989352
Validated batch 494 batch loss 1.14050615
Validated batch 495 batch loss 1.11420155
Validated batch 496 batch loss 1.29449511
Validated batch 497 batch loss 1.36876249
Validated batch 498 batch loss 1.16899633
Validated batch 499 batch loss 1.43568087
Validated batch 500 batch loss 0.932038426
Validated batch 501 batch loss 1.2902528
Validated batch 502 batch loss 1.234303
Validated batch 503 batch loss 1.13364553
Validated batch 504 batch loss 1.20258975
Validated batch 505 batch loss 1.35180318
Validated batch 506 batch loss 1.33617353
Validated batch 507 batch loss 1.20010257
Validated batch 508 batch loss 1.26317406
Validated batch 509 batch loss 1.02846897
Validated batch 510 batch loss 1.32244146
Validated batch 511 batch loss 1.37740231
Validated batch 512 batch loss 1.13680553
Validated batch 513 batch loss 0.959823251
Validated batch 514 batch loss 1.00185072
Validated batch 515 batch loss 1.21783853
Validated batch 516 batch loss 1.10597873
Validated batch 517 batch loss 1.14617538
Validated batch 518 batch loss 1.33566761
Validated batch 519 batch loss 1.10587895
Validated batch 520 batch loss 0.961782336
Validated batch 521 batch loss 1.19808447
Validated batch 522 batch loss 1.2468096
Validated batch 523 batch loss 1.10855675
Validated batch 524 batch loss 1.07097375
Validated batch 525 batch loss 1.1664083
Validated batch 526 batch loss 0.947363
Validated batch 527 batch loss 1.45469809
Validated batch 528 batch loss 1.01812792
Validated batch 529 batch loss 1.1133498
Validated batch 530 batch loss 1.15441346
Validated batch 531 batch loss 1.23903465
Validated batch 532 batch loss 1.18753386
Validated batch 533 batch loss 1.14861953
Validated batch 534 batch loss 1.2603817
Validated batch 535 batch loss 1.24084163
Validated batch 536 batch loss 1.2286098
Validated batch 537 batch loss 1.23005438
Validated batch 538 batch loss 1.3947767
Validated batch 539 batch loss 1.35489321
Validated batch 540 batch loss 1.50318551
Validated batch 541 batch loss 1.45631385
Validated batch 542 batch loss 1.3791374
Validated batch 543 batch loss 1.25621068
Validated batch 544 batch loss 1.18008113
Validated batch 545 batch loss 1.2057271
Validated batch 546 batch loss 1.01618195
Validated batch 547 batch loss 1.29667056
Validated batch 548 batch loss 1.21411395
Validated batch 549 batch loss 1.12846899
Validated batch 550 batch loss 1.06977892
Validated batch 551 batch loss 1.01913977
Validated batch 552 batch loss 1.10913777
Validated batch 553 batch loss 1.04264665
Validated batch 554 batch loss 1.00478101
Validated batch 555 batch loss 1.09897757
Validated batch 556 batch loss 1.2612021
Validated batch 557 batch loss 1.20126355
Validated batch 558 batch loss 1.31280804
Validated batch 559 batch loss 1.24877882
Validated batch 560 batch loss 0.889624357
Validated batch 561 batch loss 1.16542339
Validated batch 562 batch loss 0.916448116
Validated batch 563 batch loss 0.966164708
Validated batch 564 batch loss 1.42115879
Validated batch 565 batch loss 1.19308984
Validated batch 566 batch loss 1.26754427
Validated batch 567 batch loss 1.05353904
Validated batch 568 batch loss 0.974493206
Validated batch 569 batch loss 1.10217547
Validated batch 570 batch loss 1.10343337
Validated batch 571 batch loss 1.17039204
Validated batch 572 batch loss 1.14079702
Validated batch 573 batch loss 1.11729074
Validated batch 574 batch loss 1.00307822
Validated batch 575 batch loss 1.41894662
Validated batch 576 batch loss 1.22373915
Validated batch 577 batch loss 1.13415527
Validated batch 578 batch loss 1.16031516
Validated batch 579 batch loss 1.39551091
Validated batch 580 batch loss 1.04594052
Validated batch 581 batch loss 1.06030488
Validated batch 582 batch loss 1.10612941
Validated batch 583 batch loss 1.08848834
Validated batch 584 batch loss 1.39519238
Validated batch 585 batch loss 1.01512921
Validated batch 586 batch loss 0.846949697
Validated batch 587 batch loss 1.09036195
Validated batch 588 batch loss 1.37712729
Validated batch 589 batch loss 1.4065752
Validated batch 590 batch loss 1.43323731
Validated batch 591 batch loss 1.15272152
Validated batch 592 batch loss 1.16193354
Validated batch 593 batch loss 1.17692327
Validated batch 594 batch loss 1.2212193
Validated batch 595 batch loss 1.0380131
Validated batch 596 batch loss 1.03892303
Validated batch 597 batch loss 1.06798387
Validated batch 598 batch loss 1.00539052
Validated batch 599 batch loss 1.07015014
Validated batch 600 batch loss 0.969504535
Validated batch 601 batch loss 1.06615067
Validated batch 602 batch loss 1.15662313
Validated batch 603 batch loss 1.16737282
Validated batch 604 batch loss 0.993140638
Validated batch 605 batch loss 1.42274904
Validated batch 606 batch loss 1.25430179
Validated batch 607 batch loss 1.30567944
Validated batch 608 batch loss 1.40622509
Validated batch 609 batch loss 1.14961886
Validated batch 610 batch loss 1.09091067
Validated batch 611 batch loss 1.45439494
Validated batch 612 batch loss 1.39100873
Validated batch 613 batch loss 1.36301112
Validated batch 614 batch loss 1.31494236
Validated batch 615 batch loss 1.23552144
Validated batch 616 batch loss 1.26101089
Validated batch 617 batch loss 1.23105705
Validated batch 618 batch loss 1.12852979
Validated batch 619 batch loss 1.06643891
Validated batch 620 batch loss 1.09950423
Validated batch 621 batch loss 1.31097507
Validated batch 622 batch loss 1.42456007
Validated batch 623 batch loss 1.37148297
Validated batch 624 batch loss 1.21180367
Validated batch 625 batch loss 1.32904029
Validated batch 626 batch loss 1.08448136
Validated batch 627 batch loss 1.08075452
Validated batch 628 batch loss 1.19114625
Validated batch 629 batch loss 1.28144574
Validated batch 630 batch loss 1.57506609
Validated batch 631 batch loss 1.24390924
Validated batch 632 batch loss 0.930121303
Validated batch 633 batch loss 1.10096681
Validated batch 634 batch loss 1.20371056
Validated batch 635 batch loss 1.16220105
Validated batch 636 batch loss 1.2984134
Validated batch 637 batch loss 0.998850942
Validated batch 638 batch loss 0.920218587
Validated batch 639 batch loss 0.953248739
Validated batch 640 batch loss 0.76988852
Validated batch 641 batch loss 0.993738651
Validated batch 642 batch loss 1.08215117
Validated batch 643 batch loss 1.05795908
Validated batch 644 batch loss 1.23674631
Validated batch 645 batch loss 1.20040083
Validated batch 646 batch loss 1.03314638
Validated batch 647 batch loss 1.16609216
Validated batch 648 batch loss 1.12308657
Validated batch 649 batch loss 1.21986485
Validated batch 650 batch loss 1.2523613
Validated batch 651 batch loss 1.10687089
Validated batch 652 batch loss 1.12278497
Validated batch 653 batch loss 1.23275888
Validated batch 654 batch loss 0.929914713
Validated batch 655 batch loss 1.28578615
Validated batch 656 batch loss 1.26223123
Validated batch 657 batch loss 1.01308811
Validated batch 658 batch loss 0.851122797
Validated batch 659 batch loss 1.28898215
Validated batch 660 batch loss 1.136163
Validated batch 661 batch loss 1.21147788
Validated batch 662 batch loss 1.38127112
Validated batch 663 batch loss 1.00181246
Validated batch 664 batch loss 1.2812078
Validated batch 665 batch loss 1.13684392
Validated batch 666 batch loss 1.20854759
Validated batch 667 batch loss 1.14361453
Validated batch 668 batch loss 1.27201533
Validated batch 669 batch loss 1.29670882
Validated batch 670 batch loss 1.2743001
Validated batch 671 batch loss 1.19795871
Validated batch 672 batch loss 1.22681963
Validated batch 673 batch loss 1.27436721
Validated batch 674 batch loss 1.3495239
Validated batch 675 batch loss 1.11760557
Validated batch 676 batch loss 1.51680183
Validated batch 677 batch loss 1.0950737
Validated batch 678 batch loss 1.1224339
Validated batch 679 batch loss 1.30247021
Validated batch 680 batch loss 1.26658034
Validated batch 681 batch loss 1.13489628
Validated batch 682 batch loss 1.18224132
Validated batch 683 batch loss 1.08353937
Validated batch 684 batch loss 1.13440156
Validated batch 685 batch loss 1.06544709
Validated batch 686 batch loss 1.23956418
Validated batch 687 batch loss 1.2614888
Validated batch 688 batch loss 1.10087848
Validated batch 689 batch loss 1.24999011
Validated batch 690 batch loss 1.08108282
Validated batch 691 batch loss 1.34834492
Validated batch 692 batch loss 0.992016435
Validated batch 693 batch loss 1.07522941
Validated batch 694 batch loss 1.18801641
Validated batch 695 batch loss 1.0225749
Validated batch 696 batch loss 1.28335845
Validated batch 697 batch loss 1.23691988
Validated batch 698 batch loss 1.29053664
Validated batch 699 batch loss 1.4131577
Validated batch 700 batch loss 1.10768127
Validated batch 701 batch loss 1.43177903
Validated batch 702 batch loss 1.37169409
Validated batch 703 batch loss 1.22933769
Validated batch 704 batch loss 1.33001769
Validated batch 705 batch loss 1.09445572
Validated batch 706 batch loss 1.29645801
Validated batch 707 batch loss 1.03475773
Validated batch 708 batch loss 1.24568987
Validated batch 709 batch loss 1.28308368
Validated batch 710 batch loss 1.08500898
Validated batch 711 batch loss 1.25288558
Validated batch 712 batch loss 1.35734463
Validated batch 713 batch loss 1.5557276
Validated batch 714 batch loss 1.05658174
Validated batch 715 batch loss 1.03257942
Validated batch 716 batch loss 1.15380144
Validated batch 717 batch loss 1.11899662
Validated batch 718 batch loss 1.11258841
Validated batch 719 batch loss 1.09441042
Validated batch 720 batch loss 1.14357054
Validated batch 721 batch loss 1.48646986
Validated batch 722 batch loss 1.22634757
Validated batch 723 batch loss 0.985254884
Validated batch 724 batch loss 0.969531536
Validated batch 725 batch loss 1.01878572
Validated batch 726 batch loss 1.03976965
Validated batch 727 batch loss 0.893419
Validated batch 728 batch loss 1.22429967
Validated batch 729 batch loss 1.26751447
Validated batch 730 batch loss 1.36531758
Validated batch 731 batch loss 1.1534543
Validated batch 732 batch loss 1.23200822
Validated batch 733 batch loss 1.34029412
Validated batch 734 batch loss 1.09706986
Validated batch 735 batch loss 1.04284322
Validated batch 736 batch loss 0.940776885
Validated batch 737 batch loss 1.14945
Validated batch 738 batch loss 1.0635668
Epoch 4 val loss 1.168715000152588
Start epoch 5 with learning rate 0.0003
Start distributed traininng...
Trained batch 1 batch loss 1.21737075 epoch total loss 1.21737075
Trained batch 2 batch loss 1.30405128 epoch total loss 1.26071095
Trained batch 3 batch loss 1.55655217 epoch total loss 1.35932481
Trained batch 4 batch loss 1.22538316 epoch total loss 1.3258394
Trained batch 5 batch loss 1.15881586 epoch total loss 1.29243469
Trained batch 6 batch loss 1.08832407 epoch total loss 1.2584163
Trained batch 7 batch loss 0.984693229 epoch total loss 1.21931291
Trained batch 8 batch loss 0.930372357 epoch total loss 1.18319535
Trained batch 9 batch loss 0.888062656 epoch total loss 1.15040278
Trained batch 10 batch loss 1.37975252 epoch total loss 1.1733377
Trained batch 11 batch loss 1.3429656 epoch total loss 1.18875849
Trained batch 12 batch loss 1.05645168 epoch total loss 1.17773294
Trained batch 13 batch loss 0.995839 epoch total loss 1.16374111
Trained batch 14 batch loss 1.13052034 epoch total loss 1.16136825
Trained batch 15 batch loss 1.35092962 epoch total loss 1.17400563
Trained batch 16 batch loss 1.48892903 epoch total loss 1.19368839
Trained batch 17 batch loss 1.26903987 epoch total loss 1.19812083
Trained batch 18 batch loss 1.04321313 epoch total loss 1.18951476
Trained batch 19 batch loss 1.22610831 epoch total loss 1.19144082
Trained batch 20 batch loss 1.04550338 epoch total loss 1.1841439
Trained batch 21 batch loss 1.25060964 epoch total loss 1.18730903
Trained batch 22 batch loss 1.08974433 epoch total loss 1.1828742
Trained batch 23 batch loss 1.27709317 epoch total loss 1.18697071
Trained batch 24 batch loss 1.1500361 epoch total loss 1.18543184
Trained batch 25 batch loss 1.10148108 epoch total loss 1.18207371
Trained batch 26 batch loss 0.958898962 epoch total loss 1.17349
Trained batch 27 batch loss 0.880162597 epoch total loss 1.16262615
Trained batch 28 batch loss 0.966928542 epoch total loss 1.15563691
Trained batch 29 batch loss 0.967830718 epoch total loss 1.14916086
Trained batch 30 batch loss 0.776233137 epoch total loss 1.13673
Trained batch 31 batch loss 1.07333279 epoch total loss 1.13468492
Trained batch 32 batch loss 1.07979298 epoch total loss 1.1329695
Trained batch 33 batch loss 0.950569928 epoch total loss 1.12744224
Trained batch 34 batch loss 1.1790843 epoch total loss 1.12896109
Trained batch 35 batch loss 0.994174242 epoch total loss 1.12511
Trained batch 36 batch loss 1.1475842 epoch total loss 1.12573433
Trained batch 37 batch loss 0.809524119 epoch total loss 1.1171881
Trained batch 38 batch loss 1.06874347 epoch total loss 1.11591327
Trained batch 39 batch loss 0.835718513 epoch total loss 1.10872889
Trained batch 40 batch loss 1.14623892 epoch total loss 1.10966659
Trained batch 41 batch loss 1.1571914 epoch total loss 1.11082578
Trained batch 42 batch loss 1.29898918 epoch total loss 1.1153059
Trained batch 43 batch loss 1.0869472 epoch total loss 1.11464643
Trained batch 44 batch loss 1.02605 epoch total loss 1.11263287
Trained batch 45 batch loss 1.02861166 epoch total loss 1.1107657
Trained batch 46 batch loss 0.965159178 epoch total loss 1.10760033
Trained batch 47 batch loss 1.10042596 epoch total loss 1.10744774
Trained batch 48 batch loss 1.18613696 epoch total loss 1.10908711
Trained batch 49 batch loss 1.17470765 epoch total loss 1.11042631
Trained batch 50 batch loss 1.15579629 epoch total loss 1.11133373
Trained batch 51 batch loss 1.17650402 epoch total loss 1.11261153
Trained batch 52 batch loss 1.19694722 epoch total loss 1.11423337
Trained batch 53 batch loss 1.10115993 epoch total loss 1.11398673
Trained batch 54 batch loss 1.13141394 epoch total loss 1.11430943
Trained batch 55 batch loss 0.992607772 epoch total loss 1.11209667
Trained batch 56 batch loss 1.14979231 epoch total loss 1.11276972
Trained batch 57 batch loss 0.999274075 epoch total loss 1.11077857
Trained batch 58 batch loss 1.0950743 epoch total loss 1.11050785
Trained batch 59 batch loss 0.998062313 epoch total loss 1.10860193
Trained batch 60 batch loss 1.23545885 epoch total loss 1.11071622
Trained batch 61 batch loss 1.20134664 epoch total loss 1.11220205
Trained batch 62 batch loss 1.22897673 epoch total loss 1.11408544
Trained batch 63 batch loss 1.27782941 epoch total loss 1.11668456
Trained batch 64 batch loss 0.934875071 epoch total loss 1.1138438
Trained batch 65 batch loss 0.935281038 epoch total loss 1.11109662
Trained batch 66 batch loss 0.687714756 epoch total loss 1.10468173
Trained batch 67 batch loss 0.782994747 epoch total loss 1.09988046
Trained batch 68 batch loss 0.819030523 epoch total loss 1.09575033
Trained batch 69 batch loss 0.850483298 epoch total loss 1.09219587
Trained batch 70 batch loss 0.838430464 epoch total loss 1.08857059
Trained batch 71 batch loss 0.89313513 epoch total loss 1.08581805
Trained batch 72 batch loss 0.976556599 epoch total loss 1.08430052
Trained batch 73 batch loss 0.852223217 epoch total loss 1.08112133
Trained batch 74 batch loss 0.946294546 epoch total loss 1.07929945
Trained batch 75 batch loss 0.916402102 epoch total loss 1.07712746
Trained batch 76 batch loss 1.19156694 epoch total loss 1.07863331
Trained batch 77 batch loss 1.12304556 epoch total loss 1.07921
Trained batch 78 batch loss 1.11058879 epoch total loss 1.07961237
Trained batch 79 batch loss 1.13951635 epoch total loss 1.08037066
Trained batch 80 batch loss 1.21275532 epoch total loss 1.08202541
Trained batch 81 batch loss 1.04672813 epoch total loss 1.0815897
Trained batch 82 batch loss 1.02012992 epoch total loss 1.08084011
Trained batch 83 batch loss 1.2726953 epoch total loss 1.0831517
Trained batch 84 batch loss 0.945493877 epoch total loss 1.08151293
Trained batch 85 batch loss 0.92203033 epoch total loss 1.07963657
Trained batch 86 batch loss 0.939175904 epoch total loss 1.07800341
Trained batch 87 batch loss 1.25000167 epoch total loss 1.07998037
Trained batch 88 batch loss 1.08703732 epoch total loss 1.08006048
Trained batch 89 batch loss 1.3419373 epoch total loss 1.08300292
Trained batch 90 batch loss 1.06400836 epoch total loss 1.08279192
Trained batch 91 batch loss 1.02507269 epoch total loss 1.08215761
Trained batch 92 batch loss 1.14943337 epoch total loss 1.08288884
Trained batch 93 batch loss 1.33882833 epoch total loss 1.08564091
Trained batch 94 batch loss 1.15797603 epoch total loss 1.0864104
Trained batch 95 batch loss 0.93899411 epoch total loss 1.08485866
Trained batch 96 batch loss 1.22685814 epoch total loss 1.08633792
Trained batch 97 batch loss 1.11184537 epoch total loss 1.0866009
Trained batch 98 batch loss 0.935248256 epoch total loss 1.08505642
Trained batch 99 batch loss 0.988961875 epoch total loss 1.08408582
Trained batch 100 batch loss 1.01787901 epoch total loss 1.08342373
Trained batch 101 batch loss 1.25001812 epoch total loss 1.08507311
Trained batch 102 batch loss 1.13754475 epoch total loss 1.0855875
Trained batch 103 batch loss 0.819790423 epoch total loss 1.08300698
Trained batch 104 batch loss 1.22059894 epoch total loss 1.08433
Trained batch 105 batch loss 1.06920934 epoch total loss 1.08418596
Trained batch 106 batch loss 0.936130941 epoch total loss 1.08278918
Trained batch 107 batch loss 0.994903207 epoch total loss 1.08196783
Trained batch 108 batch loss 0.985164 epoch total loss 1.0810715
Trained batch 109 batch loss 0.867269278 epoch total loss 1.07911
Trained batch 110 batch loss 0.81839788 epoch total loss 1.07673991
Trained batch 111 batch loss 0.949034572 epoch total loss 1.07558942
Trained batch 112 batch loss 0.954781234 epoch total loss 1.07451081
Trained batch 113 batch loss 0.957717061 epoch total loss 1.07347727
Trained batch 114 batch loss 1.10846472 epoch total loss 1.07378411
Trained batch 115 batch loss 1.02316749 epoch total loss 1.07334399
Trained batch 116 batch loss 1.20266199 epoch total loss 1.07445884
Trained batch 117 batch loss 1.00051737 epoch total loss 1.07382679
Trained batch 118 batch loss 0.979889035 epoch total loss 1.07303071
Trained batch 119 batch loss 0.916071534 epoch total loss 1.07171178
Trained batch 120 batch loss 1.03006279 epoch total loss 1.07136476
Trained batch 121 batch loss 0.899801493 epoch total loss 1.06994677
Trained batch 122 batch loss 0.83324194 epoch total loss 1.06800652
Trained batch 123 batch loss 1.09715819 epoch total loss 1.0682435
Trained batch 124 batch loss 1.05696607 epoch total loss 1.06815255
Trained batch 125 batch loss 1.01016176 epoch total loss 1.06768858
Trained batch 126 batch loss 0.969010711 epoch total loss 1.06690538
Trained batch 127 batch loss 1.02140212 epoch total loss 1.06654716
Trained batch 128 batch loss 0.976522923 epoch total loss 1.06584382
Trained batch 129 batch loss 0.742599666 epoch total loss 1.06333804
Trained batch 130 batch loss 1.00998521 epoch total loss 1.0629276
Trained batch 131 batch loss 1.02315867 epoch total loss 1.0626241
Trained batch 132 batch loss 1.16328382 epoch total loss 1.06338668
Trained batch 133 batch loss 0.915052772 epoch total loss 1.06227136
Trained batch 134 batch loss 0.906831145 epoch total loss 1.06111133
Trained batch 135 batch loss 0.879373968 epoch total loss 1.05976522
Trained batch 136 batch loss 0.924214482 epoch total loss 1.05876839
Trained batch 137 batch loss 1.09135175 epoch total loss 1.05900633
Trained batch 138 batch loss 1.15188146 epoch total loss 1.05967939
Trained batch 139 batch loss 1.01797628 epoch total loss 1.05937934
Trained batch 140 batch loss 1.29151833 epoch total loss 1.06103742
Trained batch 141 batch loss 1.11466479 epoch total loss 1.06141782
Trained batch 142 batch loss 1.16734982 epoch total loss 1.06216371
Trained batch 143 batch loss 1.17847753 epoch total loss 1.06297719
Trained batch 144 batch loss 1.24048471 epoch total loss 1.06420982
Trained batch 145 batch loss 1.2977941 epoch total loss 1.06582069
Trained batch 146 batch loss 1.2292304 epoch total loss 1.06694
Trained batch 147 batch loss 0.848165095 epoch total loss 1.06545174
Trained batch 148 batch loss 1.03183961 epoch total loss 1.06522465
Trained batch 149 batch loss 0.94158721 epoch total loss 1.06439483
Trained batch 150 batch loss 1.15431154 epoch total loss 1.06499434
Trained batch 151 batch loss 1.02418625 epoch total loss 1.06472409
Trained batch 152 batch loss 0.955022633 epoch total loss 1.06400228
Trained batch 153 batch loss 1.2383945 epoch total loss 1.06514204
Trained batch 154 batch loss 1.23747385 epoch total loss 1.06626105
Trained batch 155 batch loss 0.96466279 epoch total loss 1.06560564
Trained batch 156 batch loss 1.00681198 epoch total loss 1.0652287
Trained batch 157 batch loss 1.21052289 epoch total loss 1.06615412
Trained batch 158 batch loss 1.16861916 epoch total loss 1.06680274
Trained batch 159 batch loss 1.15065348 epoch total loss 1.06733
Trained batch 160 batch loss 0.917160153 epoch total loss 1.06639147
Trained batch 161 batch loss 0.93377459 epoch total loss 1.06556773
Trained batch 162 batch loss 0.819322228 epoch total loss 1.06404769
Trained batch 163 batch loss 1.0421114 epoch total loss 1.06391323
Trained batch 164 batch loss 0.997766554 epoch total loss 1.06350982
Trained batch 165 batch loss 0.937423587 epoch total loss 1.06274569
Trained batch 166 batch loss 1.05557561 epoch total loss 1.06270254
Trained batch 167 batch loss 1.03098631 epoch total loss 1.06251264
Trained batch 168 batch loss 1.28484559 epoch total loss 1.0638361
Trained batch 169 batch loss 0.916210353 epoch total loss 1.06296253
Trained batch 170 batch loss 1.43404043 epoch total loss 1.06514537
Trained batch 171 batch loss 1.16395426 epoch total loss 1.06572318
Trained batch 172 batch loss 0.989876866 epoch total loss 1.06528223
Trained batch 173 batch loss 1.31709027 epoch total loss 1.06673777
Trained batch 174 batch loss 1.03581619 epoch total loss 1.06656
Trained batch 175 batch loss 1.20099497 epoch total loss 1.06732821
Trained batch 176 batch loss 1.31944907 epoch total loss 1.06876075
Trained batch 177 batch loss 1.33494735 epoch total loss 1.07026458
Trained batch 178 batch loss 1.1993413 epoch total loss 1.07098973
Trained batch 179 batch loss 1.55405939 epoch total loss 1.07368839
Trained batch 180 batch loss 1.0943594 epoch total loss 1.07380331
Trained batch 181 batch loss 1.00206017 epoch total loss 1.07340693
Trained batch 182 batch loss 0.931123376 epoch total loss 1.07262516
Trained batch 183 batch loss 1.33997512 epoch total loss 1.07408607
Trained batch 184 batch loss 1.27616715 epoch total loss 1.07518435
Trained batch 185 batch loss 1.29943526 epoch total loss 1.07639658
Trained batch 186 batch loss 1.15034652 epoch total loss 1.07679415
Trained batch 187 batch loss 1.26000094 epoch total loss 1.07777381
Trained batch 188 batch loss 0.801065743 epoch total loss 1.07630193
Trained batch 189 batch loss 1.03952885 epoch total loss 1.0761075
Trained batch 190 batch loss 0.999734342 epoch total loss 1.07570553
Trained batch 191 batch loss 0.89733237 epoch total loss 1.07477164
Trained batch 192 batch loss 1.00848985 epoch total loss 1.07442641
Trained batch 193 batch loss 1.04469728 epoch total loss 1.07427239
Trained batch 194 batch loss 0.92883718 epoch total loss 1.07352269
Trained batch 195 batch loss 1.05750835 epoch total loss 1.07344055
Trained batch 196 batch loss 0.989676952 epoch total loss 1.07301319
Trained batch 197 batch loss 1.082443 epoch total loss 1.07306099
Trained batch 198 batch loss 1.15813518 epoch total loss 1.07349074
Trained batch 199 batch loss 1.15759599 epoch total loss 1.07391334
Trained batch 200 batch loss 1.03449416 epoch total loss 1.07371628
Trained batch 201 batch loss 0.717371881 epoch total loss 1.0719434
Trained batch 202 batch loss 1.17095268 epoch total loss 1.07243359
Trained batch 203 batch loss 1.14404547 epoch total loss 1.07278633
Trained batch 204 batch loss 1.14473867 epoch total loss 1.07313907
Trained batch 205 batch loss 1.17892 epoch total loss 1.07365513
Trained batch 206 batch loss 1.22258353 epoch total loss 1.07437813
Trained batch 207 batch loss 1.09236979 epoch total loss 1.07446504
Trained batch 208 batch loss 1.06139779 epoch total loss 1.07440221
Trained batch 209 batch loss 1.23044181 epoch total loss 1.07514882
Trained batch 210 batch loss 1.06921923 epoch total loss 1.07512057
Trained batch 211 batch loss 1.04373431 epoch total loss 1.0749718
Trained batch 212 batch loss 1.16951931 epoch total loss 1.07541776
Trained batch 213 batch loss 1.1523447 epoch total loss 1.07577896
Trained batch 214 batch loss 1.04878235 epoch total loss 1.07565284
Trained batch 215 batch loss 1.11128807 epoch total loss 1.07581854
Trained batch 216 batch loss 1.12173867 epoch total loss 1.07603109
Trained batch 217 batch loss 1.10168958 epoch total loss 1.07614934
Trained batch 218 batch loss 1.27041626 epoch total loss 1.07704043
Trained batch 219 batch loss 1.01801991 epoch total loss 1.0767709
Trained batch 220 batch loss 1.12010586 epoch total loss 1.07696795
Trained batch 221 batch loss 1.08989727 epoch total loss 1.07702649
Trained batch 222 batch loss 0.870736718 epoch total loss 1.07609725
Trained batch 223 batch loss 0.935792685 epoch total loss 1.07546806
Trained batch 224 batch loss 1.15280652 epoch total loss 1.07581329
Trained batch 225 batch loss 1.02160358 epoch total loss 1.07557237
Trained batch 226 batch loss 1.00401223 epoch total loss 1.07525575
Trained batch 227 batch loss 1.10832334 epoch total loss 1.07540143
Trained batch 228 batch loss 1.23820794 epoch total loss 1.07611549
Trained batch 229 batch loss 1.09561229 epoch total loss 1.0762006
Trained batch 230 batch loss 0.987841785 epoch total loss 1.07581639
Trained batch 231 batch loss 1.08254743 epoch total loss 1.0758456
Trained batch 232 batch loss 1.14699364 epoch total loss 1.07615221
Trained batch 233 batch loss 1.02023435 epoch total loss 1.07591224
Trained batch 234 batch loss 0.988912582 epoch total loss 1.07554042
Trained batch 235 batch loss 0.788982093 epoch total loss 1.07432103
Trained batch 236 batch loss 0.81210506 epoch total loss 1.07320988
Trained batch 237 batch loss 0.991596639 epoch total loss 1.07286561
Trained batch 238 batch loss 1.21214235 epoch total loss 1.0734508
Trained batch 239 batch loss 1.26295698 epoch total loss 1.07424366
Trained batch 240 batch loss 1.40863144 epoch total loss 1.07563698
Trained batch 241 batch loss 1.04490852 epoch total loss 1.07550943
Trained batch 242 batch loss 1.1803031 epoch total loss 1.07594252
Trained batch 243 batch loss 1.06979537 epoch total loss 1.07591724
Trained batch 244 batch loss 0.949658036 epoch total loss 1.07539964
Trained batch 245 batch loss 1.0098871 epoch total loss 1.07513225
Trained batch 246 batch loss 1.08781362 epoch total loss 1.07518375
Trained batch 247 batch loss 1.03875804 epoch total loss 1.07503629
Trained batch 248 batch loss 1.27321935 epoch total loss 1.07583547
Trained batch 249 batch loss 0.936097383 epoch total loss 1.07527423
Trained batch 250 batch loss 1.05744076 epoch total loss 1.07520282
Trained batch 251 batch loss 1.07808185 epoch total loss 1.07521439
Trained batch 252 batch loss 1.22151184 epoch total loss 1.07579505
Trained batch 253 batch loss 1.0682503 epoch total loss 1.07576513
Trained batch 254 batch loss 1.01094759 epoch total loss 1.07551
Trained batch 255 batch loss 1.02413666 epoch total loss 1.07530856
Trained batch 256 batch loss 0.965121567 epoch total loss 1.0748781
Trained batch 257 batch loss 1.03226948 epoch total loss 1.07471228
Trained batch 258 batch loss 1.04384136 epoch total loss 1.07459259
Trained batch 259 batch loss 0.8110888 epoch total loss 1.07357526
Trained batch 260 batch loss 1.05463338 epoch total loss 1.07350242
Trained batch 261 batch loss 1.1318723 epoch total loss 1.07372606
Trained batch 262 batch loss 1.39462709 epoch total loss 1.07495081
Trained batch 263 batch loss 1.32648158 epoch total loss 1.07590723
Trained batch 264 batch loss 1.40641713 epoch total loss 1.07715905
Trained batch 265 batch loss 1.31331468 epoch total loss 1.07805026
Trained batch 266 batch loss 1.37635326 epoch total loss 1.07917166
Trained batch 267 batch loss 1.23903 epoch total loss 1.07977045
Trained batch 268 batch loss 1.14282954 epoch total loss 1.08000565
Trained batch 269 batch loss 1.22061622 epoch total loss 1.08052838
Trained batch 270 batch loss 0.944945574 epoch total loss 1.08002627
Trained batch 271 batch loss 1.34333169 epoch total loss 1.08099782
Trained batch 272 batch loss 1.20003629 epoch total loss 1.08143544
Trained batch 273 batch loss 1.13547778 epoch total loss 1.08163345
Trained batch 274 batch loss 0.906432331 epoch total loss 1.08099401
Trained batch 275 batch loss 1.06628156 epoch total loss 1.08094049
Trained batch 276 batch loss 0.777256846 epoch total loss 1.07984018
Trained batch 277 batch loss 0.879369497 epoch total loss 1.07911646
Trained batch 278 batch loss 0.896277308 epoch total loss 1.07845867
Trained batch 279 batch loss 1.14555514 epoch total loss 1.07869923
Trained batch 280 batch loss 1.21249104 epoch total loss 1.07917714
Trained batch 281 batch loss 1.13931954 epoch total loss 1.07939112
Trained batch 282 batch loss 1.16292858 epoch total loss 1.07968736
Trained batch 283 batch loss 1.26452208 epoch total loss 1.0803405
Trained batch 284 batch loss 1.18721676 epoch total loss 1.08071685
Trained batch 285 batch loss 1.27829754 epoch total loss 1.08141
Trained batch 286 batch loss 1.12643635 epoch total loss 1.08156753
Trained batch 287 batch loss 1.2056905 epoch total loss 1.082
Trained batch 288 batch loss 1.02722609 epoch total loss 1.08180976
Trained batch 289 batch loss 0.864750445 epoch total loss 1.08105874
Trained batch 290 batch loss 0.904032707 epoch total loss 1.08044827
Trained batch 291 batch loss 0.911782622 epoch total loss 1.07986856
Trained batch 292 batch loss 1.03459835 epoch total loss 1.07971358
Trained batch 293 batch loss 0.918058634 epoch total loss 1.07916188
Trained batch 294 batch loss 0.887043655 epoch total loss 1.0785085
Trained batch 295 batch loss 0.892274559 epoch total loss 1.07787716
Trained batch 296 batch loss 0.767389715 epoch total loss 1.07682824
Trained batch 297 batch loss 0.872561693 epoch total loss 1.0761404
Trained batch 298 batch loss 0.855319 epoch total loss 1.0753994
Trained batch 299 batch loss 0.919178247 epoch total loss 1.07487702
Trained batch 300 batch loss 1.22369409 epoch total loss 1.07537305
Trained batch 301 batch loss 1.08854651 epoch total loss 1.07541668
Trained batch 302 batch loss 0.866940856 epoch total loss 1.07472646
Trained batch 303 batch loss 1.05421662 epoch total loss 1.07465875
Trained batch 304 batch loss 1.14549589 epoch total loss 1.07489181
Trained batch 305 batch loss 1.32575035 epoch total loss 1.07571435
Trained batch 306 batch loss 1.10876155 epoch total loss 1.07582235
Trained batch 307 batch loss 0.932262182 epoch total loss 1.0753547
Trained batch 308 batch loss 0.901574314 epoch total loss 1.07479048
Trained batch 309 batch loss 0.791292429 epoch total loss 1.07387292
Trained batch 310 batch loss 1.04179716 epoch total loss 1.07376957
Trained batch 311 batch loss 0.85686481 epoch total loss 1.07307208
Trained batch 312 batch loss 0.838857651 epoch total loss 1.07232153
Trained batch 313 batch loss 1.08447731 epoch total loss 1.07236028
Trained batch 314 batch loss 1.00435507 epoch total loss 1.07214379
Trained batch 315 batch loss 1.20874667 epoch total loss 1.07257736
Trained batch 316 batch loss 1.13813138 epoch total loss 1.07278478
Trained batch 317 batch loss 1.00729847 epoch total loss 1.07257819
Trained batch 318 batch loss 0.987723827 epoch total loss 1.0723114
Trained batch 319 batch loss 1.06268227 epoch total loss 1.07228124
Trained batch 320 batch loss 1.1219424 epoch total loss 1.07243645
Trained batch 321 batch loss 1.042068 epoch total loss 1.0723418
Trained batch 322 batch loss 1.2926923 epoch total loss 1.07302606
Trained batch 323 batch loss 1.16139698 epoch total loss 1.07329977
Trained batch 324 batch loss 1.29502892 epoch total loss 1.07398415
Trained batch 325 batch loss 1.0642966 epoch total loss 1.07395434
Trained batch 326 batch loss 1.0485847 epoch total loss 1.0738765
Trained batch 327 batch loss 0.828209639 epoch total loss 1.07312524
Trained batch 328 batch loss 0.890785515 epoch total loss 1.07256937
Trained batch 329 batch loss 1.00455642 epoch total loss 1.07236254
Trained batch 330 batch loss 1.04044032 epoch total loss 1.07226586
Trained batch 331 batch loss 1.02389944 epoch total loss 1.07211971
Trained batch 332 batch loss 0.909336627 epoch total loss 1.07162941
Trained batch 333 batch loss 1.11140287 epoch total loss 1.07174873
Trained batch 334 batch loss 1.16415262 epoch total loss 1.07202542
Trained batch 335 batch loss 1.30452371 epoch total loss 1.07271945
Trained batch 336 batch loss 1.2347343 epoch total loss 1.07320166
Trained batch 337 batch loss 1.16754162 epoch total loss 1.07348156
Trained batch 338 batch loss 1.25163651 epoch total loss 1.0740087
Trained batch 339 batch loss 1.12505269 epoch total loss 1.07415938
Trained batch 340 batch loss 1.29077148 epoch total loss 1.07479644
Trained batch 341 batch loss 1.16276383 epoch total loss 1.07505441
Trained batch 342 batch loss 1.19140482 epoch total loss 1.07539451
Trained batch 343 batch loss 1.1050334 epoch total loss 1.07548106
Trained batch 344 batch loss 1.07668531 epoch total loss 1.07548451
Trained batch 345 batch loss 1.15855622 epoch total loss 1.07572532
Trained batch 346 batch loss 1.05723929 epoch total loss 1.07567191
Trained batch 347 batch loss 1.05607629 epoch total loss 1.07561553
Trained batch 348 batch loss 1.15883231 epoch total loss 1.07585466
Trained batch 349 batch loss 1.22103405 epoch total loss 1.0762707
Trained batch 350 batch loss 1.25832748 epoch total loss 1.07679081
Trained batch 351 batch loss 1.38157439 epoch total loss 1.07765913
Trained batch 352 batch loss 1.17913687 epoch total loss 1.0779475
Trained batch 353 batch loss 1.25956154 epoch total loss 1.07846189
Trained batch 354 batch loss 1.27147102 epoch total loss 1.07900715
Trained batch 355 batch loss 1.04110229 epoch total loss 1.07890046
Trained batch 356 batch loss 1.13055897 epoch total loss 1.07904553
Trained batch 357 batch loss 1.13666809 epoch total loss 1.07920682
Trained batch 358 batch loss 1.12178612 epoch total loss 1.0793258
Trained batch 359 batch loss 0.842826426 epoch total loss 1.07866704
Trained batch 360 batch loss 0.806814075 epoch total loss 1.07791197
Trained batch 361 batch loss 1.10046923 epoch total loss 1.07797444
Trained batch 362 batch loss 0.806365371 epoch total loss 1.07722414
Trained batch 363 batch loss 0.772647679 epoch total loss 1.07638502
Trained batch 364 batch loss 0.853292763 epoch total loss 1.07577217
Trained batch 365 batch loss 1.16584086 epoch total loss 1.07601893
Trained batch 366 batch loss 1.24184465 epoch total loss 1.07647204
Trained batch 367 batch loss 1.15827227 epoch total loss 1.07669497
Trained batch 368 batch loss 1.06208062 epoch total loss 1.07665515
Trained batch 369 batch loss 1.065099 epoch total loss 1.0766238
Trained batch 370 batch loss 0.968591452 epoch total loss 1.07633185
Trained batch 371 batch loss 0.818068743 epoch total loss 1.07563567
Trained batch 372 batch loss 1.06259799 epoch total loss 1.07560062
Trained batch 373 batch loss 0.977820218 epoch total loss 1.07533848
Trained batch 374 batch loss 0.890074134 epoch total loss 1.07484317
Trained batch 375 batch loss 1.011724 epoch total loss 1.07467484
Trained batch 376 batch loss 1.19817853 epoch total loss 1.07500327
Trained batch 377 batch loss 1.01258957 epoch total loss 1.0748378
Trained batch 378 batch loss 1.03310251 epoch total loss 1.07472742
Trained batch 379 batch loss 1.03263545 epoch total loss 1.07461631
Trained batch 380 batch loss 1.03723216 epoch total loss 1.07451785
Trained batch 381 batch loss 1.20437717 epoch total loss 1.07485878
Trained batch 382 batch loss 1.36111236 epoch total loss 1.07560813
Trained batch 383 batch loss 1.11010516 epoch total loss 1.07569814
Trained batch 384 batch loss 1.15037429 epoch total loss 1.07589257
Trained batch 385 batch loss 1.19922447 epoch total loss 1.07621288
Trained batch 386 batch loss 0.716591358 epoch total loss 1.07528126
Trained batch 387 batch loss 1.2351172 epoch total loss 1.0756942
Trained batch 388 batch loss 0.91910696 epoch total loss 1.07529068
Trained batch 389 batch loss 0.891706228 epoch total loss 1.07481861
Trained batch 390 batch loss 1.13191533 epoch total loss 1.07496512
Trained batch 391 batch loss 1.08669591 epoch total loss 1.07499516
Trained batch 392 batch loss 1.19331145 epoch total loss 1.07529688
Trained batch 393 batch loss 1.19984567 epoch total loss 1.07561386
Trained batch 394 batch loss 1.25996459 epoch total loss 1.07608175
Trained batch 395 batch loss 1.35368812 epoch total loss 1.07678461
Trained batch 396 batch loss 1.02929068 epoch total loss 1.07666469
Trained batch 397 batch loss 1.09110546 epoch total loss 1.07670105
Trained batch 398 batch loss 1.02007437 epoch total loss 1.07655883
Trained batch 399 batch loss 1.25097978 epoch total loss 1.07699597
Trained batch 400 batch loss 1.30242181 epoch total loss 1.07755947
Trained batch 401 batch loss 1.48141909 epoch total loss 1.07856667
Trained batch 402 batch loss 1.24387121 epoch total loss 1.07897782
Trained batch 403 batch loss 1.38347661 epoch total loss 1.07973337
Trained batch 404 batch loss 1.60954952 epoch total loss 1.08104491
Trained batch 405 batch loss 1.41644764 epoch total loss 1.08187306
Trained batch 406 batch loss 1.19766474 epoch total loss 1.08215821
Trained batch 407 batch loss 1.26696193 epoch total loss 1.08261228
Trained batch 408 batch loss 1.49216163 epoch total loss 1.08361602
Trained batch 409 batch loss 1.44848228 epoch total loss 1.08450818
Trained batch 410 batch loss 1.27104568 epoch total loss 1.0849632
Trained batch 411 batch loss 1.34730315 epoch total loss 1.08560145
Trained batch 412 batch loss 1.07036722 epoch total loss 1.08556449
Trained batch 413 batch loss 1.06701994 epoch total loss 1.08551955
Trained batch 414 batch loss 0.952130616 epoch total loss 1.08519733
Trained batch 415 batch loss 0.826729536 epoch total loss 1.08457446
Trained batch 416 batch loss 0.959668756 epoch total loss 1.08427417
Trained batch 417 batch loss 1.00039291 epoch total loss 1.08407307
Trained batch 418 batch loss 0.918358386 epoch total loss 1.0836767
Trained batch 419 batch loss 0.993989706 epoch total loss 1.0834626
Trained batch 420 batch loss 1.03078163 epoch total loss 1.08333719
Trained batch 421 batch loss 1.08198905 epoch total loss 1.08333397
Trained batch 422 batch loss 1.202986 epoch total loss 1.08361757
Trained batch 423 batch loss 1.32014835 epoch total loss 1.08417666
Trained batch 424 batch loss 1.31661129 epoch total loss 1.0847249
Trained batch 425 batch loss 1.41189015 epoch total loss 1.08549476
Trained batch 426 batch loss 1.39749479 epoch total loss 1.08622718
Trained batch 427 batch loss 1.28244591 epoch total loss 1.08668661
Trained batch 428 batch loss 1.35695279 epoch total loss 1.08731818
Trained batch 429 batch loss 1.23720717 epoch total loss 1.08766758
Trained batch 430 batch loss 1.11018586 epoch total loss 1.08771992
Trained batch 431 batch loss 1.27389967 epoch total loss 1.08815193
Trained batch 432 batch loss 1.12541628 epoch total loss 1.08823824
Trained batch 433 batch loss 1.1627996 epoch total loss 1.08841038
Trained batch 434 batch loss 1.08786285 epoch total loss 1.08840919
Trained batch 435 batch loss 1.05330706 epoch total loss 1.08832848
Trained batch 436 batch loss 0.985884905 epoch total loss 1.08809352
Trained batch 437 batch loss 1.14116335 epoch total loss 1.08821499
Trained batch 438 batch loss 0.85448885 epoch total loss 1.08768129
Trained batch 439 batch loss 1.0617342 epoch total loss 1.08762217
Trained batch 440 batch loss 1.14504743 epoch total loss 1.0877527
Trained batch 441 batch loss 1.22360659 epoch total loss 1.08806074
Trained batch 442 batch loss 1.20409119 epoch total loss 1.08832335
Trained batch 443 batch loss 1.44744086 epoch total loss 1.08913398
Trained batch 444 batch loss 1.44184101 epoch total loss 1.08992839
Trained batch 445 batch loss 1.49609363 epoch total loss 1.09084105
Trained batch 446 batch loss 1.29983747 epoch total loss 1.09130967
Trained batch 447 batch loss 1.20165408 epoch total loss 1.09155655
Trained batch 448 batch loss 0.90619576 epoch total loss 1.09114277
Trained batch 449 batch loss 0.818373561 epoch total loss 1.09053528
Trained batch 450 batch loss 0.90711 epoch total loss 1.09012759
Trained batch 451 batch loss 1.23072052 epoch total loss 1.09043932
Trained batch 452 batch loss 1.00614262 epoch total loss 1.09025288
Trained batch 453 batch loss 1.1033839 epoch total loss 1.09028184
Trained batch 454 batch loss 0.956285357 epoch total loss 1.08998668
Trained batch 455 batch loss 0.683278203 epoch total loss 1.08909285
Trained batch 456 batch loss 0.668006301 epoch total loss 1.08816946
Trained batch 457 batch loss 0.875197768 epoch total loss 1.08770335
Trained batch 458 batch loss 0.895382524 epoch total loss 1.08728349
Trained batch 459 batch loss 1.11472714 epoch total loss 1.08734322
Trained batch 460 batch loss 0.927972436 epoch total loss 1.08699679
Trained batch 461 batch loss 0.899675369 epoch total loss 1.08659053
Trained batch 462 batch loss 1.35702634 epoch total loss 1.08717585
Trained batch 463 batch loss 1.03055501 epoch total loss 1.08705354
Trained batch 464 batch loss 0.979551554 epoch total loss 1.08682179
Trained batch 465 batch loss 1.09136593 epoch total loss 1.08683169
Trained batch 466 batch loss 0.994154692 epoch total loss 1.08663273
Trained batch 467 batch loss 1.17774963 epoch total loss 1.08682775
Trained batch 468 batch loss 1.35059953 epoch total loss 1.08739138
Trained batch 469 batch loss 1.54898787 epoch total loss 1.08837557
Trained batch 470 batch loss 1.23132539 epoch total loss 1.08867979
Trained batch 471 batch loss 1.19810081 epoch total loss 1.08891201
Trained batch 472 batch loss 0.98273468 epoch total loss 1.08868706
Trained batch 473 batch loss 1.18347788 epoch total loss 1.08888745
Trained batch 474 batch loss 1.04351795 epoch total loss 1.08879173
Trained batch 475 batch loss 1.15268755 epoch total loss 1.08892632
Trained batch 476 batch loss 1.02132261 epoch total loss 1.08878422
Trained batch 477 batch loss 1.10332823 epoch total loss 1.08881474
Trained batch 478 batch loss 0.873344123 epoch total loss 1.08836401
Trained batch 479 batch loss 1.20207644 epoch total loss 1.08860135
Trained batch 480 batch loss 1.17202 epoch total loss 1.08877516
Trained batch 481 batch loss 1.18539333 epoch total loss 1.08897591
Trained batch 482 batch loss 0.859547853 epoch total loss 1.0885
Trained batch 483 batch loss 1.10808647 epoch total loss 1.08854055
Trained batch 484 batch loss 1.0746417 epoch total loss 1.08851182
Trained batch 485 batch loss 0.946493506 epoch total loss 1.08821893
Trained batch 486 batch loss 1.02509809 epoch total loss 1.08808911
Trained batch 487 batch loss 1.13542295 epoch total loss 1.08818626
Trained batch 488 batch loss 1.021788 epoch total loss 1.08805025
Trained batch 489 batch loss 1.03538203 epoch total loss 1.0879426
Trained batch 490 batch loss 1.01140952 epoch total loss 1.08778632
Trained batch 491 batch loss 1.17325556 epoch total loss 1.08796048
Trained batch 492 batch loss 1.16456795 epoch total loss 1.08811617
Trained batch 493 batch loss 1.10965908 epoch total loss 1.08815992
Trained batch 494 batch loss 0.970096946 epoch total loss 1.0879209
Trained batch 495 batch loss 1.26357841 epoch total loss 1.08827567
Trained batch 496 batch loss 1.0860424 epoch total loss 1.08827126
Trained batch 497 batch loss 1.29463673 epoch total loss 1.08868647
Trained batch 498 batch loss 1.04214466 epoch total loss 1.08859289
Trained batch 499 batch loss 1.55182946 epoch total loss 1.08952117
Trained batch 500 batch loss 1.22501016 epoch total loss 1.08979225
Trained batch 501 batch loss 1.24983847 epoch total loss 1.09011161
Trained batch 502 batch loss 1.1539979 epoch total loss 1.09023893
Trained batch 503 batch loss 1.05170643 epoch total loss 1.09016228
Trained batch 504 batch loss 1.22650743 epoch total loss 1.09043276
Trained batch 505 batch loss 0.990412891 epoch total loss 1.09023476
Trained batch 506 batch loss 0.856587768 epoch total loss 1.08977294
Trained batch 507 batch loss 0.784054935 epoch total loss 1.08917
Trained batch 508 batch loss 0.874267578 epoch total loss 1.08874691
Trained batch 509 batch loss 0.905243397 epoch total loss 1.08838642
Trained batch 510 batch loss 1.11813688 epoch total loss 1.08844483
Trained batch 511 batch loss 0.948665261 epoch total loss 1.08817136
Trained batch 512 batch loss 0.990726948 epoch total loss 1.08798099
Trained batch 513 batch loss 0.844578624 epoch total loss 1.08750653
Trained batch 514 batch loss 0.912764668 epoch total loss 1.08716667
Trained batch 515 batch loss 0.943600178 epoch total loss 1.08688784
Trained batch 516 batch loss 1.01554251 epoch total loss 1.08674967
Trained batch 517 batch loss 1.01978421 epoch total loss 1.08662009
Trained batch 518 batch loss 1.02798235 epoch total loss 1.08650684
Trained batch 519 batch loss 1.29510927 epoch total loss 1.08690882
Trained batch 520 batch loss 1.41588783 epoch total loss 1.08754146
Trained batch 521 batch loss 1.49820542 epoch total loss 1.08832967
Trained batch 522 batch loss 1.00327456 epoch total loss 1.08816683
Trained batch 523 batch loss 0.969811082 epoch total loss 1.08794045
Trained batch 524 batch loss 0.982655525 epoch total loss 1.08773959
Trained batch 525 batch loss 0.971152782 epoch total loss 1.08751738
Trained batch 526 batch loss 0.983843327 epoch total loss 1.08732033
Trained batch 527 batch loss 1.07981968 epoch total loss 1.08730614
Trained batch 528 batch loss 0.943628788 epoch total loss 1.08703399
Trained batch 529 batch loss 1.01111531 epoch total loss 1.08689046
Trained batch 530 batch loss 1.19433701 epoch total loss 1.08709311
Trained batch 531 batch loss 0.951887667 epoch total loss 1.0868386
Trained batch 532 batch loss 1.14552593 epoch total loss 1.08694887
Trained batch 533 batch loss 1.01189435 epoch total loss 1.08680797
Trained batch 534 batch loss 1.30764198 epoch total loss 1.0872215
Trained batch 535 batch loss 0.994693398 epoch total loss 1.08704853
Trained batch 536 batch loss 0.956893444 epoch total loss 1.08680582
Trained batch 537 batch loss 1.11706257 epoch total loss 1.08686209
Trained batch 538 batch loss 0.851515174 epoch total loss 1.08642459
Trained batch 539 batch loss 0.805289268 epoch total loss 1.08590305
Trained batch 540 batch loss 0.872193694 epoch total loss 1.08550727
Trained batch 541 batch loss 1.1508925 epoch total loss 1.08562815
Trained batch 542 batch loss 1.06818533 epoch total loss 1.08559597
Trained batch 543 batch loss 1.09498584 epoch total loss 1.08561325
Trained batch 544 batch loss 0.965926051 epoch total loss 1.08539319
Trained batch 545 batch loss 0.918828785 epoch total loss 1.08508766
Trained batch 546 batch loss 1.03773558 epoch total loss 1.08500087
Trained batch 547 batch loss 1.0029068 epoch total loss 1.08485079
Trained batch 548 batch loss 1.01389647 epoch total loss 1.08472133
Trained batch 549 batch loss 0.769516349 epoch total loss 1.08414721
Trained batch 550 batch loss 1.00285757 epoch total loss 1.08399951
Trained batch 551 batch loss 1.01300621 epoch total loss 1.08387065
Trained batch 552 batch loss 1.11891901 epoch total loss 1.08393407
Trained batch 553 batch loss 1.1043601 epoch total loss 1.08397102
Trained batch 554 batch loss 0.902499437 epoch total loss 1.08364356
Trained batch 555 batch loss 1.00383663 epoch total loss 1.08349967
Trained batch 556 batch loss 0.994288445 epoch total loss 1.08333921
Trained batch 557 batch loss 1.21639657 epoch total loss 1.08357811
Trained batch 558 batch loss 0.873942137 epoch total loss 1.08320236
Trained batch 559 batch loss 1.01837969 epoch total loss 1.08308637
Trained batch 560 batch loss 1.09095359 epoch total loss 1.08310044
Trained batch 561 batch loss 0.943638623 epoch total loss 1.08285189
Trained batch 562 batch loss 1.21524167 epoch total loss 1.08308756
Trained batch 563 batch loss 0.921049118 epoch total loss 1.08279967
Trained batch 564 batch loss 1.06051528 epoch total loss 1.0827601
Trained batch 565 batch loss 1.53780031 epoch total loss 1.08356547
Trained batch 566 batch loss 1.00189662 epoch total loss 1.08342111
Trained batch 567 batch loss 1.00466871 epoch total loss 1.08328223
Trained batch 568 batch loss 1.05167007 epoch total loss 1.08322656
Trained batch 569 batch loss 0.714033127 epoch total loss 1.08257782
Trained batch 570 batch loss 1.01721048 epoch total loss 1.08246315
Trained batch 571 batch loss 1.19686472 epoch total loss 1.08266342
Trained batch 572 batch loss 1.23518538 epoch total loss 1.08293
Trained batch 573 batch loss 1.13259792 epoch total loss 1.08301663
Trained batch 574 batch loss 0.951345205 epoch total loss 1.08278728
Trained batch 575 batch loss 1.16759968 epoch total loss 1.08293474
Trained batch 576 batch loss 1.08277726 epoch total loss 1.0829345
Trained batch 577 batch loss 1.07520771 epoch total loss 1.08292103
Trained batch 578 batch loss 1.03093147 epoch total loss 1.08283114
Trained batch 579 batch loss 0.872770369 epoch total loss 1.08246827
Trained batch 580 batch loss 1.02031851 epoch total loss 1.0823611
Trained batch 581 batch loss 1.11783922 epoch total loss 1.08242226
Trained batch 582 batch loss 1.05497277 epoch total loss 1.08237517
Trained batch 583 batch loss 0.910880148 epoch total loss 1.08208096
Trained batch 584 batch loss 1.16952515 epoch total loss 1.08223069
Trained batch 585 batch loss 1.22751021 epoch total loss 1.082479
Trained batch 586 batch loss 1.24159169 epoch total loss 1.08275056
Trained batch 587 batch loss 1.33330715 epoch total loss 1.08317745
Trained batch 588 batch loss 1.03312778 epoch total loss 1.08309233
Trained batch 589 batch loss 1.24616361 epoch total loss 1.08336914
Trained batch 590 batch loss 1.0485816 epoch total loss 1.08331025
Trained batch 591 batch loss 0.78841269 epoch total loss 1.08281124
Trained batch 592 batch loss 0.80372715 epoch total loss 1.08233976
Trained batch 593 batch loss 0.898800731 epoch total loss 1.08203018
Trained batch 594 batch loss 1.20735192 epoch total loss 1.08224118
Trained batch 595 batch loss 1.14153242 epoch total loss 1.08234084
Trained batch 596 batch loss 1.22055316 epoch total loss 1.08257282
Trained batch 597 batch loss 1.12962246 epoch total loss 1.08265162
Trained batch 598 batch loss 1.05343556 epoch total loss 1.08260274
Trained batch 599 batch loss 0.768378615 epoch total loss 1.0820781
Trained batch 600 batch loss 1.01159811 epoch total loss 1.08196068
Trained batch 601 batch loss 0.842887461 epoch total loss 1.08156288
Trained batch 602 batch loss 0.955754399 epoch total loss 1.0813539
Trained batch 603 batch loss 1.05401 epoch total loss 1.0813086
Trained batch 604 batch loss 1.04771614 epoch total loss 1.08125293
Trained batch 605 batch loss 1.24797082 epoch total loss 1.08152854
Trained batch 606 batch loss 1.18385744 epoch total loss 1.08169734
Trained batch 607 batch loss 1.20153713 epoch total loss 1.08189476
Trained batch 608 batch loss 0.988112211 epoch total loss 1.0817405
Trained batch 609 batch loss 0.828032255 epoch total loss 1.08132386
Trained batch 610 batch loss 1.28767872 epoch total loss 1.08166218
Trained batch 611 batch loss 1.0630188 epoch total loss 1.08163166
Trained batch 612 batch loss 1.17782724 epoch total loss 1.0817889
Trained batch 613 batch loss 1.10994911 epoch total loss 1.08183479
Trained batch 614 batch loss 1.1083616 epoch total loss 1.08187795
Trained batch 615 batch loss 1.1130234 epoch total loss 1.08192861
Trained batch 616 batch loss 0.78240335 epoch total loss 1.08144236
Trained batch 617 batch loss 0.874244809 epoch total loss 1.08110666
Trained batch 618 batch loss 0.870673537 epoch total loss 1.08076608
Trained batch 619 batch loss 0.901258647 epoch total loss 1.08047605
Trained batch 620 batch loss 0.92244947 epoch total loss 1.08022118
Trained batch 621 batch loss 0.910787582 epoch total loss 1.07994831
Trained batch 622 batch loss 0.847430587 epoch total loss 1.07957447
Trained batch 623 batch loss 0.922750354 epoch total loss 1.0793227
Trained batch 624 batch loss 0.801014 epoch total loss 1.07887673
Trained batch 625 batch loss 1.27148974 epoch total loss 1.07918489
Trained batch 626 batch loss 0.897894382 epoch total loss 1.07889521
Trained batch 627 batch loss 1.07483912 epoch total loss 1.07888877
Trained batch 628 batch loss 1.21536887 epoch total loss 1.07910609
Trained batch 629 batch loss 1.29161584 epoch total loss 1.07944405
Trained batch 630 batch loss 1.09330535 epoch total loss 1.07946599
Trained batch 631 batch loss 1.16073751 epoch total loss 1.07959485
Trained batch 632 batch loss 1.01473725 epoch total loss 1.07949221
Trained batch 633 batch loss 1.07994032 epoch total loss 1.07949293
Trained batch 634 batch loss 1.10173833 epoch total loss 1.07952809
Trained batch 635 batch loss 1.26431966 epoch total loss 1.07981908
Trained batch 636 batch loss 1.22651982 epoch total loss 1.08004975
Trained batch 637 batch loss 1.13520265 epoch total loss 1.0801363
Trained batch 638 batch loss 1.14620018 epoch total loss 1.08023977
Trained batch 639 batch loss 1.18696332 epoch total loss 1.08040679
Trained batch 640 batch loss 1.08715761 epoch total loss 1.08041739
Trained batch 641 batch loss 1.13235164 epoch total loss 1.08049834
Trained batch 642 batch loss 1.36727357 epoch total loss 1.08094501
Trained batch 643 batch loss 1.24154568 epoch total loss 1.08119464
Trained batch 644 batch loss 1.42111313 epoch total loss 1.08172262
Trained batch 645 batch loss 1.33281136 epoch total loss 1.08211184
Trained batch 646 batch loss 1.213871 epoch total loss 1.0823158
Trained batch 647 batch loss 0.994817913 epoch total loss 1.08218062
Trained batch 648 batch loss 1.07922375 epoch total loss 1.08217597
Trained batch 649 batch loss 1.14797831 epoch total loss 1.08227742
Trained batch 650 batch loss 1.02836919 epoch total loss 1.08219445
Trained batch 651 batch loss 1.1443553 epoch total loss 1.08228993
Trained batch 652 batch loss 1.26018548 epoch total loss 1.0825628
Trained batch 653 batch loss 1.10252011 epoch total loss 1.08259332
Trained batch 654 batch loss 0.889326155 epoch total loss 1.08229792
Trained batch 655 batch loss 1.05245709 epoch total loss 1.08225226
Trained batch 656 batch loss 1.19506168 epoch total loss 1.08242428
Trained batch 657 batch loss 1.1638428 epoch total loss 1.08254814
Trained batch 658 batch loss 1.03967023 epoch total loss 1.08248293
Trained batch 659 batch loss 1.06664574 epoch total loss 1.08245897
Trained batch 660 batch loss 1.23263216 epoch total loss 1.08268642
Trained batch 661 batch loss 1.10202789 epoch total loss 1.08271575
Trained batch 662 batch loss 1.17447937 epoch total loss 1.08285439
Trained batch 663 batch loss 1.05584061 epoch total loss 1.08281362
Trained batch 664 batch loss 1.21547556 epoch total loss 1.08301342
Trained batch 665 batch loss 1.2360847 epoch total loss 1.08324361
Trained batch 666 batch loss 1.01392055 epoch total loss 1.08313954
Trained batch 667 batch loss 0.833517373 epoch total loss 1.08276522
Trained batch 668 batch loss 0.973615527 epoch total loss 1.0826019
Trained batch 669 batch loss 0.799885631 epoch total loss 1.08217919
Trained batch 670 batch loss 0.663416922 epoch total loss 1.08155417
Trained batch 671 batch loss 0.796564 epoch total loss 1.08112943
Trained batch 672 batch loss 0.775833964 epoch total loss 1.08067513
Trained batch 673 batch loss 0.830797851 epoch total loss 1.08030391
Trained batch 674 batch loss 0.675380468 epoch total loss 1.07970309
Trained batch 675 batch loss 0.749553084 epoch total loss 1.07921398
Trained batch 676 batch loss 0.898391604 epoch total loss 1.07894647
Trained batch 677 batch loss 1.15703297 epoch total loss 1.07906175
Trained batch 678 batch loss 1.16030788 epoch total loss 1.07918155
Trained batch 679 batch loss 1.17252314 epoch total loss 1.07931912
Trained batch 680 batch loss 1.10622311 epoch total loss 1.07935858
Trained batch 681 batch loss 1.16908455 epoch total loss 1.0794903
Trained batch 682 batch loss 1.18125486 epoch total loss 1.07963955
Trained batch 683 batch loss 1.34327364 epoch total loss 1.08002555
Trained batch 684 batch loss 1.27160394 epoch total loss 1.0803057
Trained batch 685 batch loss 1.21556711 epoch total loss 1.08050311
Trained batch 686 batch loss 1.22835362 epoch total loss 1.08071864
Trained batch 687 batch loss 1.26272845 epoch total loss 1.08098364
Trained batch 688 batch loss 1.27113736 epoch total loss 1.08126
Trained batch 689 batch loss 1.22378445 epoch total loss 1.08146679
Trained batch 690 batch loss 1.29448724 epoch total loss 1.08177555
Trained batch 691 batch loss 1.29468977 epoch total loss 1.08208358
Trained batch 692 batch loss 1.24786568 epoch total loss 1.08232319
Trained batch 693 batch loss 1.18989635 epoch total loss 1.0824784
Trained batch 694 batch loss 1.2829721 epoch total loss 1.08276725
Trained batch 695 batch loss 1.2685647 epoch total loss 1.08303463
Trained batch 696 batch loss 1.03479469 epoch total loss 1.08296525
Trained batch 697 batch loss 1.0549376 epoch total loss 1.08292508
Trained batch 698 batch loss 1.01224589 epoch total loss 1.08282387
Trained batch 699 batch loss 1.11023724 epoch total loss 1.08286309
Trained batch 700 batch loss 1.07311773 epoch total loss 1.08284914
Trained batch 701 batch loss 0.920322359 epoch total loss 1.08261728
Trained batch 702 batch loss 1.16569221 epoch total loss 1.08273566
Trained batch 703 batch loss 1.20719707 epoch total loss 1.0829128
Trained batch 704 batch loss 1.11016369 epoch total loss 1.08295143
Trained batch 705 batch loss 1.25138068 epoch total loss 1.08319044
Trained batch 706 batch loss 1.107373 epoch total loss 1.08322465
Trained batch 707 batch loss 1.28746271 epoch total loss 1.0835135
Trained batch 708 batch loss 0.927198231 epoch total loss 1.08329272
Trained batch 709 batch loss 1.18129408 epoch total loss 1.08343089
Trained batch 710 batch loss 1.11350322 epoch total loss 1.08347332
Trained batch 711 batch loss 0.974643707 epoch total loss 1.08332026
Trained batch 712 batch loss 1.12295294 epoch total loss 1.08337593
Trained batch 713 batch loss 1.13648462 epoch total loss 1.08345044
Trained batch 714 batch loss 1.20368814 epoch total loss 1.08361876
Trained batch 715 batch loss 1.02412629 epoch total loss 1.08353555
Trained batch 716 batch loss 1.06231713 epoch total loss 1.08350587
Trained batch 717 batch loss 1.12000084 epoch total loss 1.08355677
Trained batch 718 batch loss 1.16054034 epoch total loss 1.08366394
Trained batch 719 batch loss 1.09200656 epoch total loss 1.0836755
Trained batch 720 batch loss 0.963365912 epoch total loss 1.08350849
Trained batch 721 batch loss 0.918845654 epoch total loss 1.08328009
Trained batch 722 batch loss 0.914831579 epoch total loss 1.08304679
Trained batch 723 batch loss 1.13527012 epoch total loss 1.08311903
Trained batch 724 batch loss 1.26174784 epoch total loss 1.08336568
Trained batch 725 batch loss 1.2992444 epoch total loss 1.08366346
Trained batch 726 batch loss 1.09817624 epoch total loss 1.08368349
Trained batch 727 batch loss 1.35567772 epoch total loss 1.08405757
Trained batch 728 batch loss 1.02619517 epoch total loss 1.08397806
Trained batch 729 batch loss 1.21173382 epoch total loss 1.08415329
Trained batch 730 batch loss 0.935726404 epoch total loss 1.08395
Trained batch 731 batch loss 1.1146785 epoch total loss 1.083992
Trained batch 732 batch loss 1.28520882 epoch total loss 1.0842669
Trained batch 733 batch loss 1.0802573 epoch total loss 1.08426154
Trained batch 734 batch loss 1.14248419 epoch total loss 1.08434081
Trained batch 735 batch loss 1.33337891 epoch total loss 1.0846796
Trained batch 736 batch loss 1.32980609 epoch total loss 1.08501267
Trained batch 737 batch loss 1.01521933 epoch total loss 1.0849179
Trained batch 738 batch loss 1.10524452 epoch total loss 1.08494544
Trained batch 739 batch loss 0.82027626 epoch total loss 1.08458734
Trained batch 740 batch loss 1.14960265 epoch total loss 1.08467519
Trained batch 741 batch loss 1.04188919 epoch total loss 1.08461738
Trained batch 742 batch loss 0.885701 epoch total loss 1.08434927
Trained batch 743 batch loss 1.20925784 epoch total loss 1.08451736
Trained batch 744 batch loss 1.06630397 epoch total loss 1.0844928
Trained batch 745 batch loss 1.05899239 epoch total loss 1.08445859
Trained batch 746 batch loss 0.960449338 epoch total loss 1.08429241
Trained batch 747 batch loss 1.06758416 epoch total loss 1.08427
Trained batch 748 batch loss 1.06773937 epoch total loss 1.08424795
Trained batch 749 batch loss 1.04386234 epoch total loss 1.08419406
Trained batch 750 batch loss 1.22938228 epoch total loss 1.08438766
Trained batch 751 batch loss 1.08797145 epoch total loss 1.08439231
Trained batch 752 batch loss 1.07831061 epoch total loss 1.08438432
Trained batch 753 batch loss 1.0720017 epoch total loss 1.08436787
Trained batch 754 batch loss 1.05163622 epoch total loss 1.08432448
Trained batch 755 batch loss 1.32106876 epoch total loss 1.084638
Trained batch 756 batch loss 1.21402788 epoch total loss 1.08480918
Trained batch 757 batch loss 1.13512993 epoch total loss 1.08487558
Trained batch 758 batch loss 1.15848458 epoch total loss 1.08497274
Trained batch 759 batch loss 1.18991208 epoch total loss 1.08511102
Trained batch 760 batch loss 1.15983725 epoch total loss 1.08520937
Trained batch 761 batch loss 1.28194225 epoch total loss 1.08546793
Trained batch 762 batch loss 1.27079821 epoch total loss 1.08571112
Trained batch 763 batch loss 1.00987697 epoch total loss 1.08561182
Trained batch 764 batch loss 1.4330349 epoch total loss 1.08606648
Trained batch 765 batch loss 1.28173971 epoch total loss 1.08632231
Trained batch 766 batch loss 1.18221974 epoch total loss 1.08644748
Trained batch 767 batch loss 1.2080276 epoch total loss 1.08660591
Trained batch 768 batch loss 1.3840034 epoch total loss 1.08699322
Trained batch 769 batch loss 1.16473031 epoch total loss 1.08709431
Trained batch 770 batch loss 1.09595215 epoch total loss 1.08710575
Trained batch 771 batch loss 0.997105896 epoch total loss 1.08698916
Trained batch 772 batch loss 1.37236202 epoch total loss 1.08735883
Trained batch 773 batch loss 1.19674253 epoch total loss 1.08750021
Trained batch 774 batch loss 1.47993827 epoch total loss 1.08800721
Trained batch 775 batch loss 1.19515014 epoch total loss 1.08814549
Trained batch 776 batch loss 1.05240345 epoch total loss 1.08809948
Trained batch 777 batch loss 1.02611494 epoch total loss 1.08801973
Trained batch 778 batch loss 1.00769746 epoch total loss 1.08791649
Trained batch 779 batch loss 0.924925864 epoch total loss 1.08770716
Trained batch 780 batch loss 0.952067673 epoch total loss 1.08753335
Trained batch 781 batch loss 1.1928401 epoch total loss 1.08766818
Trained batch 782 batch loss 1.09937978 epoch total loss 1.08768308
Trained batch 783 batch loss 1.06697559 epoch total loss 1.08765662
Trained batch 784 batch loss 1.15249825 epoch total loss 1.08773935
Trained batch 785 batch loss 0.964797795 epoch total loss 1.08758271
Trained batch 786 batch loss 0.993854 epoch total loss 1.0874635
Trained batch 787 batch loss 1.14237034 epoch total loss 1.08753324
Trained batch 788 batch loss 0.887053609 epoch total loss 1.08727884
Trained batch 789 batch loss 1.14724183 epoch total loss 1.08735478
Trained batch 790 batch loss 1.34939766 epoch total loss 1.08768654
Trained batch 791 batch loss 1.08670831 epoch total loss 1.08768535
Trained batch 792 batch loss 1.32762766 epoch total loss 1.08798826
Trained batch 793 batch loss 1.03397524 epoch total loss 1.08792019
Trained batch 794 batch loss 1.31677985 epoch total loss 1.08820844
Trained batch 795 batch loss 1.12423968 epoch total loss 1.08825374
Trained batch 796 batch loss 1.25800776 epoch total loss 1.088467
Trained batch 797 batch loss 1.17807961 epoch total loss 1.08857942
Trained batch 798 batch loss 1.25371 epoch total loss 1.08878636
Trained batch 799 batch loss 1.06043518 epoch total loss 1.08875096
Trained batch 800 batch loss 1.17768455 epoch total loss 1.08886206
Trained batch 801 batch loss 1.17223203 epoch total loss 1.08896613
Trained batch 802 batch loss 1.09350693 epoch total loss 1.08897185
Trained batch 803 batch loss 0.98580265 epoch total loss 1.08884335
Trained batch 804 batch loss 0.992444515 epoch total loss 1.08872342
Trained batch 805 batch loss 1.13451576 epoch total loss 1.08878028
Trained batch 806 batch loss 1.08640468 epoch total loss 1.08877742
Trained batch 807 batch loss 0.999083757 epoch total loss 1.0886662
Trained batch 808 batch loss 0.899616241 epoch total loss 1.08843219
Trained batch 809 batch loss 0.954588532 epoch total loss 1.08826685
Trained batch 810 batch loss 0.950345039 epoch total loss 1.0880965
Trained batch 811 batch loss 1.10477281 epoch total loss 1.08811712
Trained batch 812 batch loss 0.925640941 epoch total loss 1.08791697
Trained batch 813 batch loss 0.95251596 epoch total loss 1.08775043
Trained batch 814 batch loss 0.862394392 epoch total loss 1.08747363
Trained batch 815 batch loss 0.902714372 epoch total loss 1.08724689
Trained batch 816 batch loss 1.00807905 epoch total loss 1.08714986
Trained batch 817 batch loss 1.22797418 epoch total loss 1.08732224
Trained batch 818 batch loss 1.03269625 epoch total loss 1.08725548
Trained batch 819 batch loss 1.14405298 epoch total loss 1.08732474
Trained batch 820 batch loss 1.14540601 epoch total loss 1.08739555
Trained batch 821 batch loss 1.16453433 epoch total loss 1.0874896
Trained batch 822 batch loss 1.0684092 epoch total loss 1.08746636
Trained batch 823 batch loss 1.1637125 epoch total loss 1.08755898
Trained batch 824 batch loss 1.26036823 epoch total loss 1.08776867
Trained batch 825 batch loss 1.02740812 epoch total loss 1.08769548
Trained batch 826 batch loss 1.17084885 epoch total loss 1.08779621
Trained batch 827 batch loss 1.14547813 epoch total loss 1.08786595
Trained batch 828 batch loss 0.880307913 epoch total loss 1.08761525
Trained batch 829 batch loss 0.739412665 epoch total loss 1.08719528
Trained batch 830 batch loss 0.877447486 epoch total loss 1.08694255
Trained batch 831 batch loss 0.777919292 epoch total loss 1.08657074
Trained batch 832 batch loss 0.942944288 epoch total loss 1.08639801
Trained batch 833 batch loss 0.94131434 epoch total loss 1.08622384
Trained batch 834 batch loss 0.969197154 epoch total loss 1.08608353
Trained batch 835 batch loss 1.00364482 epoch total loss 1.08598483
Trained batch 836 batch loss 0.794942796 epoch total loss 1.08563662
Trained batch 837 batch loss 0.92059207 epoch total loss 1.08543944
Trained batch 838 batch loss 1.16361868 epoch total loss 1.08553278
Trained batch 839 batch loss 1.05422544 epoch total loss 1.08549547
Trained batch 840 batch loss 1.08039951 epoch total loss 1.08548927
Trained batch 841 batch loss 1.42996168 epoch total loss 1.08589888
Trained batch 842 batch loss 1.54658842 epoch total loss 1.08644605
Trained batch 843 batch loss 1.28293216 epoch total loss 1.0866791
Trained batch 844 batch loss 1.17510605 epoch total loss 1.08678389
Trained batch 845 batch loss 1.1540277 epoch total loss 1.08686352
Trained batch 846 batch loss 1.03333926 epoch total loss 1.08680022
Trained batch 847 batch loss 0.950255036 epoch total loss 1.08663905
Trained batch 848 batch loss 0.994865477 epoch total loss 1.0865308
Trained batch 849 batch loss 0.937761068 epoch total loss 1.08635557
Trained batch 850 batch loss 1.11197042 epoch total loss 1.08638573
Trained batch 851 batch loss 1.23664498 epoch total loss 1.08656228
Trained batch 852 batch loss 1.11922681 epoch total loss 1.08660054
Trained batch 853 batch loss 1.08759809 epoch total loss 1.08660173
Trained batch 854 batch loss 0.886450171 epoch total loss 1.08636737
Trained batch 855 batch loss 0.75202 epoch total loss 1.08597636
Trained batch 856 batch loss 0.630779624 epoch total loss 1.08544457
Trained batch 857 batch loss 0.753811479 epoch total loss 1.08505762
Trained batch 858 batch loss 0.748294055 epoch total loss 1.08466506
Trained batch 859 batch loss 0.593811035 epoch total loss 1.08409369
Trained batch 860 batch loss 0.7030797 epoch total loss 1.08365059
Trained batch 861 batch loss 0.541977346 epoch total loss 1.08302152
Trained batch 862 batch loss 0.724510074 epoch total loss 1.0826056
Trained batch 863 batch loss 0.564415216 epoch total loss 1.08200502
Trained batch 864 batch loss 1.03254354 epoch total loss 1.0819478
Trained batch 865 batch loss 0.745961308 epoch total loss 1.08155942
Trained batch 866 batch loss 0.824718475 epoch total loss 1.08126283
Trained batch 867 batch loss 0.794368744 epoch total loss 1.0809319
Trained batch 868 batch loss 1.13492012 epoch total loss 1.08099413
Trained batch 869 batch loss 0.947790861 epoch total loss 1.08084095
Trained batch 870 batch loss 1.19706678 epoch total loss 1.08097446
Trained batch 871 batch loss 1.10154581 epoch total loss 1.08099818
Trained batch 872 batch loss 1.22754812 epoch total loss 1.08116615
Trained batch 873 batch loss 1.25720084 epoch total loss 1.08136785
Trained batch 874 batch loss 1.00335145 epoch total loss 1.08127856
Trained batch 875 batch loss 1.02100062 epoch total loss 1.08120966
Trained batch 876 batch loss 0.982930779 epoch total loss 1.08109748
Trained batch 877 batch loss 0.909901619 epoch total loss 1.08090222
Trained batch 878 batch loss 1.31125569 epoch total loss 1.08116472
Trained batch 879 batch loss 0.901896119 epoch total loss 1.08096075
Trained batch 880 batch loss 1.0953486 epoch total loss 1.08097708
Trained batch 881 batch loss 1.29572654 epoch total loss 1.08122087
Trained batch 882 batch loss 1.21933222 epoch total loss 1.08137739
Trained batch 883 batch loss 1.18337464 epoch total loss 1.0814929
Trained batch 884 batch loss 1.12773108 epoch total loss 1.08154523
Trained batch 885 batch loss 1.17575908 epoch total loss 1.08165169
Trained batch 886 batch loss 1.19537735 epoch total loss 1.08178008
Trained batch 887 batch loss 0.930092 epoch total loss 1.08160913
Trained batch 888 batch loss 1.31563592 epoch total loss 1.08187258
Trained batch 889 batch loss 1.11632967 epoch total loss 1.08191133
Trained batch 890 batch loss 1.05183649 epoch total loss 1.08187759
Trained batch 891 batch loss 1.15353918 epoch total loss 1.08195806
Trained batch 892 batch loss 0.921874166 epoch total loss 1.08177853
Trained batch 893 batch loss 1.02660596 epoch total loss 1.08171678
Trained batch 894 batch loss 0.831213772 epoch total loss 1.08143663
Trained batch 895 batch loss 1.12470508 epoch total loss 1.08148491
Trained batch 896 batch loss 0.967404962 epoch total loss 1.0813576
Trained batch 897 batch loss 1.04822111 epoch total loss 1.08132064
Trained batch 898 batch loss 1.21448863 epoch total loss 1.08146894
Trained batch 899 batch loss 1.1388371 epoch total loss 1.08153284
Trained batch 900 batch loss 1.00716579 epoch total loss 1.0814501
Trained batch 901 batch loss 0.9221946 epoch total loss 1.08127332
Trained batch 902 batch loss 0.940753102 epoch total loss 1.08111751
Trained batch 903 batch loss 1.01785541 epoch total loss 1.08104753
Trained batch 904 batch loss 0.951594949 epoch total loss 1.08090436
Trained batch 905 batch loss 0.977373838 epoch total loss 1.08078992
Trained batch 906 batch loss 1.10876071 epoch total loss 1.0808208
Trained batch 907 batch loss 1.06325245 epoch total loss 1.08080137
Trained batch 908 batch loss 1.06068945 epoch total loss 1.08077919
Trained batch 909 batch loss 1.066414 epoch total loss 1.08076346
Trained batch 910 batch loss 1.05998921 epoch total loss 1.08074057
Trained batch 911 batch loss 1.16797328 epoch total loss 1.0808363
Trained batch 912 batch loss 1.31994295 epoch total loss 1.08109856
Trained batch 913 batch loss 1.18596101 epoch total loss 1.08121336
Trained batch 914 batch loss 1.14106989 epoch total loss 1.08127892
Trained batch 915 batch loss 1.16064835 epoch total loss 1.08136559
Trained batch 916 batch loss 1.06296945 epoch total loss 1.08134556
Trained batch 917 batch loss 1.3031826 epoch total loss 1.08158743
Trained batch 918 batch loss 1.14086103 epoch total loss 1.08165205
Trained batch 919 batch loss 1.04960465 epoch total loss 1.08161712
Trained batch 920 batch loss 1.30655289 epoch total loss 1.08186173
Trained batch 921 batch loss 1.1073339 epoch total loss 1.08188939
Trained batch 922 batch loss 1.05223393 epoch total loss 1.0818572
Trained batch 923 batch loss 0.937178731 epoch total loss 1.08170044
Trained batch 924 batch loss 1.14293587 epoch total loss 1.08176672
Trained batch 925 batch loss 1.1985774 epoch total loss 1.08189297
Trained batch 926 batch loss 1.09329033 epoch total loss 1.08190525
Trained batch 927 batch loss 1.21971893 epoch total loss 1.08205402
Trained batch 928 batch loss 1.08296525 epoch total loss 1.08205497
Trained batch 929 batch loss 1.12814486 epoch total loss 1.08210456
Trained batch 930 batch loss 1.19049275 epoch total loss 1.08222115
Trained batch 931 batch loss 1.10108328 epoch total loss 1.08224142
Trained batch 932 batch loss 1.07317138 epoch total loss 1.08223164
Trained batch 933 batch loss 1.10848713 epoch total loss 1.08225977
Trained batch 934 batch loss 1.21706045 epoch total loss 1.08240402
Trained batch 935 batch loss 1.02565777 epoch total loss 1.08234334
Trained batch 936 batch loss 0.925246477 epoch total loss 1.08217549
Trained batch 937 batch loss 0.931769907 epoch total loss 1.08201492
Trained batch 938 batch loss 1.20486951 epoch total loss 1.08214593
Trained batch 939 batch loss 1.011657 epoch total loss 1.08207095
Trained batch 940 batch loss 1.13406754 epoch total loss 1.08212626
Trained batch 941 batch loss 0.958313823 epoch total loss 1.08199465
Trained batch 942 batch loss 1.10676599 epoch total loss 1.082021
Trained batch 943 batch loss 0.964506745 epoch total loss 1.08189631
Trained batch 944 batch loss 1.10157704 epoch total loss 1.08191717
Trained batch 945 batch loss 1.14881182 epoch total loss 1.08198786
Trained batch 946 batch loss 1.08508551 epoch total loss 1.0819912
Trained batch 947 batch loss 1.19812536 epoch total loss 1.08211386
Trained batch 948 batch loss 1.03634202 epoch total loss 1.08206558
Trained batch 949 batch loss 0.736871541 epoch total loss 1.08170187
Trained batch 950 batch loss 0.893935144 epoch total loss 1.08150411
Trained batch 951 batch loss 0.928715467 epoch total loss 1.08134353
Trained batch 952 batch loss 1.0992285 epoch total loss 1.08136225
Trained batch 953 batch loss 1.09318542 epoch total loss 1.08137465
Trained batch 954 batch loss 1.13757324 epoch total loss 1.08143353
Trained batch 955 batch loss 1.20819652 epoch total loss 1.08156633
Trained batch 956 batch loss 1.32623231 epoch total loss 1.08182228
Trained batch 957 batch loss 1.31987333 epoch total loss 1.08207095
Trained batch 958 batch loss 1.25641334 epoch total loss 1.08225298
Trained batch 959 batch loss 1.23246849 epoch total loss 1.0824095
Trained batch 960 batch loss 0.97868 epoch total loss 1.0823015
Trained batch 961 batch loss 1.23788929 epoch total loss 1.08246338
Trained batch 962 batch loss 0.995941758 epoch total loss 1.0823735
Trained batch 963 batch loss 1.19634652 epoch total loss 1.08249176
Trained batch 964 batch loss 1.22075844 epoch total loss 1.08263516
Trained batch 965 batch loss 1.01477098 epoch total loss 1.08256483
Trained batch 966 batch loss 0.881374359 epoch total loss 1.08235657
Trained batch 967 batch loss 1.21772492 epoch total loss 1.08249652
Trained batch 968 batch loss 1.10849941 epoch total loss 1.08252347
Trained batch 969 batch loss 1.17601395 epoch total loss 1.08261991
Trained batch 970 batch loss 1.29104185 epoch total loss 1.08283472
Trained batch 971 batch loss 1.07279658 epoch total loss 1.08282435
Trained batch 972 batch loss 0.863866925 epoch total loss 1.08259916
Trained batch 973 batch loss 1.09394193 epoch total loss 1.08261085
Trained batch 974 batch loss 1.06606579 epoch total loss 1.0825938
Trained batch 975 batch loss 1.24271083 epoch total loss 1.08275807
Trained batch 976 batch loss 1.14940298 epoch total loss 1.08282638
Trained batch 977 batch loss 1.14086759 epoch total loss 1.08288574
Trained batch 978 batch loss 1.42838323 epoch total loss 1.08323896
Trained batch 979 batch loss 1.31474447 epoch total loss 1.08347535
Trained batch 980 batch loss 1.31814909 epoch total loss 1.08371484
Trained batch 981 batch loss 1.08312738 epoch total loss 1.08371425
Trained batch 982 batch loss 1.30564356 epoch total loss 1.08394027
Trained batch 983 batch loss 1.25627184 epoch total loss 1.08411551
Trained batch 984 batch loss 1.2882669 epoch total loss 1.08432293
Trained batch 985 batch loss 1.43791032 epoch total loss 1.08468187
Trained batch 986 batch loss 0.950070441 epoch total loss 1.08454537
Trained batch 987 batch loss 0.818146706 epoch total loss 1.08427536
Trained batch 988 batch loss 0.989207149 epoch total loss 1.08417916
Trained batch 989 batch loss 1.19391787 epoch total loss 1.08429027
Trained batch 990 batch loss 1.09425378 epoch total loss 1.08430028
Trained batch 991 batch loss 1.11155915 epoch total loss 1.08432782
Trained batch 992 batch loss 1.05979848 epoch total loss 1.08430314
Trained batch 993 batch loss 1.25351787 epoch total loss 1.08447349
Trained batch 994 batch loss 1.12822676 epoch total loss 1.08451748
Trained batch 995 batch loss 1.05219674 epoch total loss 1.08448505
Trained batch 996 batch loss 1.11658525 epoch total loss 1.08451724
Trained batch 997 batch loss 1.28049231 epoch total loss 1.08471382
Trained batch 998 batch loss 1.03766751 epoch total loss 1.08466673
Trained batch 999 batch loss 1.13321626 epoch total loss 1.08471537
Trained batch 1000 batch loss 1.23828173 epoch total loss 1.08486891
Trained batch 1001 batch loss 1.0300684 epoch total loss 1.08481407
Trained batch 1002 batch loss 1.12097216 epoch total loss 1.08485019
Trained batch 1003 batch loss 1.19212043 epoch total loss 1.08495712
Trained batch 1004 batch loss 1.37409329 epoch total loss 1.08524525
Trained batch 1005 batch loss 1.19606566 epoch total loss 1.0853554
Trained batch 1006 batch loss 0.994617 epoch total loss 1.08526528
Trained batch 1007 batch loss 1.04748726 epoch total loss 1.08522773
Trained batch 1008 batch loss 1.22276545 epoch total loss 1.08536422
Trained batch 1009 batch loss 0.909096718 epoch total loss 1.08518946
Trained batch 1010 batch loss 1.09757733 epoch total loss 1.08520174
Trained batch 1011 batch loss 1.13140321 epoch total loss 1.0852474
Trained batch 1012 batch loss 1.10638046 epoch total loss 1.08526814
Trained batch 1013 batch loss 1.14141512 epoch total loss 1.08532357
Trained batch 1014 batch loss 1.10162663 epoch total loss 1.08533967
Trained batch 1015 batch loss 1.12833357 epoch total loss 1.08538198
Trained batch 1016 batch loss 1.06551671 epoch total loss 1.08536243
Trained batch 1017 batch loss 1.45692873 epoch total loss 1.08572781
Trained batch 1018 batch loss 1.17432404 epoch total loss 1.08581483
Trained batch 1019 batch loss 1.02087843 epoch total loss 1.08575106
Trained batch 1020 batch loss 1.39546561 epoch total loss 1.0860548
Trained batch 1021 batch loss 1.18467522 epoch total loss 1.08615136
Trained batch 1022 batch loss 1.33135295 epoch total loss 1.08639121
Trained batch 1023 batch loss 1.2213248 epoch total loss 1.08652318
Trained batch 1024 batch loss 1.10413945 epoch total loss 1.08654034
Trained batch 1025 batch loss 1.15419865 epoch total loss 1.08660638
Trained batch 1026 batch loss 1.19480407 epoch total loss 1.08671176
Trained batch 1027 batch loss 1.01804733 epoch total loss 1.08664501
Trained batch 1028 batch loss 0.940434933 epoch total loss 1.08650267
Trained batch 1029 batch loss 1.35773206 epoch total loss 1.08676636
Trained batch 1030 batch loss 1.30556631 epoch total loss 1.08697879
Trained batch 1031 batch loss 1.42876244 epoch total loss 1.08731019
Trained batch 1032 batch loss 0.989509284 epoch total loss 1.08721542
Trained batch 1033 batch loss 1.36939287 epoch total loss 1.08748865
Trained batch 1034 batch loss 0.87650013 epoch total loss 1.08728456
Trained batch 1035 batch loss 1.22244835 epoch total loss 1.0874151
Trained batch 1036 batch loss 1.11446023 epoch total loss 1.08744121
Trained batch 1037 batch loss 1.32305264 epoch total loss 1.08766842
Trained batch 1038 batch loss 1.14387071 epoch total loss 1.08772254
Trained batch 1039 batch loss 1.03584123 epoch total loss 1.08767271
Trained batch 1040 batch loss 0.948111892 epoch total loss 1.08753848
Trained batch 1041 batch loss 1.0342555 epoch total loss 1.08748734
Trained batch 1042 batch loss 1.05771339 epoch total loss 1.08745885
Trained batch 1043 batch loss 1.06003141 epoch total loss 1.0874325
Trained batch 1044 batch loss 1.12021124 epoch total loss 1.08746397
Trained batch 1045 batch loss 1.12294269 epoch total loss 1.08749795
Trained batch 1046 batch loss 1.19443822 epoch total loss 1.08760011
Trained batch 1047 batch loss 1.23710275 epoch total loss 1.08774292
Trained batch 1048 batch loss 1.03852487 epoch total loss 1.08769596
Trained batch 1049 batch loss 1.1859889 epoch total loss 1.08778977
Trained batch 1050 batch loss 0.984466076 epoch total loss 1.08769131
Trained batch 1051 batch loss 1.09855866 epoch total loss 1.08770168
Trained batch 1052 batch loss 1.10278583 epoch total loss 1.08771598
Trained batch 1053 batch loss 1.03760529 epoch total loss 1.08766842
Trained batch 1054 batch loss 0.804917693 epoch total loss 1.0874002
Trained batch 1055 batch loss 0.914903581 epoch total loss 1.08723664
Trained batch 1056 batch loss 1.01046085 epoch total loss 1.08716393
Trained batch 1057 batch loss 0.917987525 epoch total loss 1.08700395
Trained batch 1058 batch loss 0.972287238 epoch total loss 1.08689547
Trained batch 1059 batch loss 0.898699164 epoch total loss 1.08671772
Trained batch 1060 batch loss 0.878537536 epoch total loss 1.08652139
Trained batch 1061 batch loss 0.89279443 epoch total loss 1.08633876
Trained batch 1062 batch loss 0.698853374 epoch total loss 1.08597398
Trained batch 1063 batch loss 0.926075161 epoch total loss 1.08582342
Trained batch 1064 batch loss 0.83724916 epoch total loss 1.08558989
Trained batch 1065 batch loss 0.852547407 epoch total loss 1.08537102
Trained batch 1066 batch loss 0.776221633 epoch total loss 1.0850811
Trained batch 1067 batch loss 1.25356233 epoch total loss 1.08523893
Trained batch 1068 batch loss 1.19175601 epoch total loss 1.08533871
Trained batch 1069 batch loss 1.29283869 epoch total loss 1.08553278
Trained batch 1070 batch loss 1.19548845 epoch total loss 1.08563554
Trained batch 1071 batch loss 1.31862009 epoch total loss 1.0858531
Trained batch 1072 batch loss 1.1527648 epoch total loss 1.08591545
Trained batch 1073 batch loss 1.24877095 epoch total loss 1.0860672
Trained batch 1074 batch loss 1.04546928 epoch total loss 1.08602929
Trained batch 1075 batch loss 1.05098224 epoch total loss 1.08599675
Trained batch 1076 batch loss 1.24468613 epoch total loss 1.08614421
Trained batch 1077 batch loss 1.28035259 epoch total loss 1.08632457
Trained batch 1078 batch loss 1.43724763 epoch total loss 1.08665013
Trained batch 1079 batch loss 1.40282416 epoch total loss 1.08694315
Trained batch 1080 batch loss 1.21649992 epoch total loss 1.08706319
Trained batch 1081 batch loss 1.2102102 epoch total loss 1.08717704
Trained batch 1082 batch loss 1.32126868 epoch total loss 1.0873934
Trained batch 1083 batch loss 1.15167403 epoch total loss 1.08745289
Trained batch 1084 batch loss 1.14996624 epoch total loss 1.08751059
Trained batch 1085 batch loss 1.11626828 epoch total loss 1.08753705
Trained batch 1086 batch loss 1.27402294 epoch total loss 1.08770871
Trained batch 1087 batch loss 1.18662715 epoch total loss 1.08779979
Trained batch 1088 batch loss 1.09947598 epoch total loss 1.08781052
Trained batch 1089 batch loss 1.29026604 epoch total loss 1.08799648
Trained batch 1090 batch loss 1.04864204 epoch total loss 1.08796024
Trained batch 1091 batch loss 1.20252609 epoch total loss 1.08806527
Trained batch 1092 batch loss 1.27222574 epoch total loss 1.08823395
Trained batch 1093 batch loss 1.17255712 epoch total loss 1.08831108
Trained batch 1094 batch loss 1.1023612 epoch total loss 1.08832395
Trained batch 1095 batch loss 0.804534 epoch total loss 1.08806491
Trained batch 1096 batch loss 0.983311772 epoch total loss 1.0879693
Trained batch 1097 batch loss 0.956804037 epoch total loss 1.08784962
Trained batch 1098 batch loss 0.990525723 epoch total loss 1.08776104
Trained batch 1099 batch loss 0.949096203 epoch total loss 1.0876348
Trained batch 1100 batch loss 0.888102412 epoch total loss 1.08745337
Trained batch 1101 batch loss 1.11502075 epoch total loss 1.0874784
Trained batch 1102 batch loss 1.09349513 epoch total loss 1.08748388
Trained batch 1103 batch loss 1.22173524 epoch total loss 1.0876056
Trained batch 1104 batch loss 0.935599744 epoch total loss 1.08746779
Trained batch 1105 batch loss 1.20057845 epoch total loss 1.08757019
Trained batch 1106 batch loss 1.12723124 epoch total loss 1.08760595
Trained batch 1107 batch loss 1.08900344 epoch total loss 1.08760726
Trained batch 1108 batch loss 1.19145727 epoch total loss 1.08770096
Trained batch 1109 batch loss 1.08133399 epoch total loss 1.08769512
Trained batch 1110 batch loss 1.01691401 epoch total loss 1.08763146
Trained batch 1111 batch loss 0.961987555 epoch total loss 1.08751833
Trained batch 1112 batch loss 1.21968794 epoch total loss 1.08763731
Trained batch 1113 batch loss 1.00449133 epoch total loss 1.08756256
Trained batch 1114 batch loss 1.1143446 epoch total loss 1.08758664
Trained batch 1115 batch loss 1.06588173 epoch total loss 1.08756721
Trained batch 1116 batch loss 1.23186135 epoch total loss 1.08769643
Trained batch 1117 batch loss 1.25841141 epoch total loss 1.08784926
Trained batch 1118 batch loss 1.12445092 epoch total loss 1.08788216
Trained batch 1119 batch loss 1.05321264 epoch total loss 1.08785117
Trained batch 1120 batch loss 1.0883019 epoch total loss 1.08785152
Trained batch 1121 batch loss 1.04406643 epoch total loss 1.08781242
Trained batch 1122 batch loss 1.25446308 epoch total loss 1.08796096
Trained batch 1123 batch loss 1.18463159 epoch total loss 1.08804715
Trained batch 1124 batch loss 1.13548613 epoch total loss 1.08808935
Trained batch 1125 batch loss 1.16130614 epoch total loss 1.08815444
Trained batch 1126 batch loss 1.22757959 epoch total loss 1.08827817
Trained batch 1127 batch loss 1.06578064 epoch total loss 1.08825827
Trained batch 1128 batch loss 1.14087415 epoch total loss 1.08830488
Trained batch 1129 batch loss 1.08611178 epoch total loss 1.08830285
Trained batch 1130 batch loss 1.10276556 epoch total loss 1.08831573
Trained batch 1131 batch loss 1.23440659 epoch total loss 1.08844483
Trained batch 1132 batch loss 1.21591914 epoch total loss 1.08855748
Trained batch 1133 batch loss 1.12455821 epoch total loss 1.08858919
Trained batch 1134 batch loss 1.2289927 epoch total loss 1.08871305
Trained batch 1135 batch loss 1.25191903 epoch total loss 1.08885682
Trained batch 1136 batch loss 1.08083344 epoch total loss 1.08884978
Trained batch 1137 batch loss 1.10245776 epoch total loss 1.0888617
Trained batch 1138 batch loss 1.26017594 epoch total loss 1.08901227
Trained batch 1139 batch loss 1.0335629 epoch total loss 1.08896351
Trained batch 1140 batch loss 1.15670133 epoch total loss 1.08902299
Trained batch 1141 batch loss 0.936470747 epoch total loss 1.08888936
Trained batch 1142 batch loss 1.07009649 epoch total loss 1.08887291
Trained batch 1143 batch loss 0.994660497 epoch total loss 1.08879042
Trained batch 1144 batch loss 1.11594748 epoch total loss 1.08881414
Trained batch 1145 batch loss 1.35546494 epoch total loss 1.08904707
Trained batch 1146 batch loss 1.25069594 epoch total loss 1.0891881
Trained batch 1147 batch loss 1.45910525 epoch total loss 1.08951068
Trained batch 1148 batch loss 1.41799033 epoch total loss 1.08979678
Trained batch 1149 batch loss 1.23168159 epoch total loss 1.08992028
Trained batch 1150 batch loss 1.21410322 epoch total loss 1.09002829
Trained batch 1151 batch loss 1.2900573 epoch total loss 1.09020197
Trained batch 1152 batch loss 1.17671025 epoch total loss 1.09027719
Trained batch 1153 batch loss 1.26334071 epoch total loss 1.09042716
Trained batch 1154 batch loss 1.18133163 epoch total loss 1.09050596
Trained batch 1155 batch loss 1.15916383 epoch total loss 1.09056544
Trained batch 1156 batch loss 1.2706356 epoch total loss 1.09072113
Trained batch 1157 batch loss 1.09871256 epoch total loss 1.09072804
Trained batch 1158 batch loss 0.947405219 epoch total loss 1.09060431
Trained batch 1159 batch loss 1.16868865 epoch total loss 1.09067166
Trained batch 1160 batch loss 0.99610132 epoch total loss 1.09059012
Trained batch 1161 batch loss 1.06930149 epoch total loss 1.09057188
Trained batch 1162 batch loss 1.19018745 epoch total loss 1.09065759
Trained batch 1163 batch loss 0.963151634 epoch total loss 1.09054792
Trained batch 1164 batch loss 1.11431694 epoch total loss 1.0905683
Trained batch 1165 batch loss 1.07901359 epoch total loss 1.09055841
Trained batch 1166 batch loss 1.03913355 epoch total loss 1.0905143
Trained batch 1167 batch loss 0.990757465 epoch total loss 1.09042883
Trained batch 1168 batch loss 1.10018611 epoch total loss 1.09043717
Trained batch 1169 batch loss 1.10303319 epoch total loss 1.0904479
Trained batch 1170 batch loss 0.977794886 epoch total loss 1.0903517
Trained batch 1171 batch loss 1.19906 epoch total loss 1.09044456
Trained batch 1172 batch loss 1.19135976 epoch total loss 1.09053063
Trained batch 1173 batch loss 1.48698306 epoch total loss 1.09086859
Trained batch 1174 batch loss 1.29408073 epoch total loss 1.09104168
Trained batch 1175 batch loss 1.17124557 epoch total loss 1.09111
Trained batch 1176 batch loss 1.18905962 epoch total loss 1.09119332
Trained batch 1177 batch loss 1.24803388 epoch total loss 1.09132659
Trained batch 1178 batch loss 1.35271287 epoch total loss 1.09154832
Trained batch 1179 batch loss 1.09015715 epoch total loss 1.09154725
Trained batch 1180 batch loss 1.43160009 epoch total loss 1.0918355
Trained batch 1181 batch loss 1.33788157 epoch total loss 1.09204376
Trained batch 1182 batch loss 1.46094453 epoch total loss 1.09235585
Trained batch 1183 batch loss 1.41110229 epoch total loss 1.09262538
Trained batch 1184 batch loss 1.46545553 epoch total loss 1.09294021
Trained batch 1185 batch loss 1.29202378 epoch total loss 1.09310818
Trained batch 1186 batch loss 0.819370627 epoch total loss 1.09287739
Trained batch 1187 batch loss 1.17045128 epoch total loss 1.09294271
Trained batch 1188 batch loss 0.860643268 epoch total loss 1.09274709
Trained batch 1189 batch loss 1.13390541 epoch total loss 1.09278178
Trained batch 1190 batch loss 1.22496259 epoch total loss 1.09289289
Trained batch 1191 batch loss 1.00692666 epoch total loss 1.09282064
Trained batch 1192 batch loss 1.10881555 epoch total loss 1.09283412
Trained batch 1193 batch loss 1.18581653 epoch total loss 1.09291196
Trained batch 1194 batch loss 1.45849705 epoch total loss 1.09321821
Trained batch 1195 batch loss 1.17211974 epoch total loss 1.09328425
Trained batch 1196 batch loss 1.13719392 epoch total loss 1.09332097
Trained batch 1197 batch loss 1.11116838 epoch total loss 1.09333587
Trained batch 1198 batch loss 1.03302634 epoch total loss 1.09328556
Trained batch 1199 batch loss 1.05890656 epoch total loss 1.09325695
Trained batch 1200 batch loss 1.12259412 epoch total loss 1.09328139
Trained batch 1201 batch loss 1.26739764 epoch total loss 1.09342635
Trained batch 1202 batch loss 1.40269136 epoch total loss 1.09368372
Trained batch 1203 batch loss 1.2266531 epoch total loss 1.09379423
Trained batch 1204 batch loss 1.45648706 epoch total loss 1.09409547
Trained batch 1205 batch loss 1.22604537 epoch total loss 1.09420502
Trained batch 1206 batch loss 1.14200866 epoch total loss 1.0942446
Trained batch 1207 batch loss 1.28685069 epoch total loss 1.09440422
Trained batch 1208 batch loss 1.14277029 epoch total loss 1.09444427
Trained batch 1209 batch loss 1.07562399 epoch total loss 1.09442878
Trained batch 1210 batch loss 1.19612551 epoch total loss 1.09451294
Trained batch 1211 batch loss 0.916259825 epoch total loss 1.09436572
Trained batch 1212 batch loss 0.817632 epoch total loss 1.09413731
Trained batch 1213 batch loss 0.759572 epoch total loss 1.09386146
Trained batch 1214 batch loss 0.902935624 epoch total loss 1.09370422
Trained batch 1215 batch loss 1.34095 epoch total loss 1.09390771
Trained batch 1216 batch loss 1.40676332 epoch total loss 1.09416497
Trained batch 1217 batch loss 1.29233956 epoch total loss 1.09432781
Trained batch 1218 batch loss 1.330158 epoch total loss 1.09452152
Trained batch 1219 batch loss 1.44218493 epoch total loss 1.09480667
Trained batch 1220 batch loss 1.31893539 epoch total loss 1.09499037
Trained batch 1221 batch loss 1.39158511 epoch total loss 1.09523332
Trained batch 1222 batch loss 1.24355888 epoch total loss 1.09535468
Trained batch 1223 batch loss 1.50170243 epoch total loss 1.09568691
Trained batch 1224 batch loss 1.33784437 epoch total loss 1.0958848
Trained batch 1225 batch loss 1.26783872 epoch total loss 1.09602523
Trained batch 1226 batch loss 1.05916166 epoch total loss 1.09599519
Trained batch 1227 batch loss 0.979282379 epoch total loss 1.0959
Trained batch 1228 batch loss 0.781636834 epoch total loss 1.09564412
Trained batch 1229 batch loss 1.12717938 epoch total loss 1.09566975
Trained batch 1230 batch loss 0.961101294 epoch total loss 1.09556031
Trained batch 1231 batch loss 1.11782169 epoch total loss 1.09557843
Trained batch 1232 batch loss 1.02485371 epoch total loss 1.09552097
Trained batch 1233 batch loss 1.05289686 epoch total loss 1.0954864
Trained batch 1234 batch loss 1.16457617 epoch total loss 1.09554243
Trained batch 1235 batch loss 0.899106622 epoch total loss 1.09538329
Trained batch 1236 batch loss 0.683464527 epoch total loss 1.09505
Trained batch 1237 batch loss 1.22117949 epoch total loss 1.09515202
Trained batch 1238 batch loss 1.35350287 epoch total loss 1.09536064
Trained batch 1239 batch loss 1.1372962 epoch total loss 1.09539449
Trained batch 1240 batch loss 1.07072496 epoch total loss 1.09537458
Trained batch 1241 batch loss 1.11179197 epoch total loss 1.09538782
Trained batch 1242 batch loss 1.14800251 epoch total loss 1.09543014
Trained batch 1243 batch loss 1.19554698 epoch total loss 1.09551072
Trained batch 1244 batch loss 1.22276723 epoch total loss 1.095613
Trained batch 1245 batch loss 1.11154056 epoch total loss 1.09562588
Trained batch 1246 batch loss 1.18297362 epoch total loss 1.09569597
Trained batch 1247 batch loss 0.950341284 epoch total loss 1.09557939
Trained batch 1248 batch loss 1.32547235 epoch total loss 1.09576356
Trained batch 1249 batch loss 1.11954355 epoch total loss 1.09578264
Trained batch 1250 batch loss 1.14546633 epoch total loss 1.09582233
Trained batch 1251 batch loss 1.24479043 epoch total loss 1.09594142
Trained batch 1252 batch loss 1.05932665 epoch total loss 1.09591222
Trained batch 1253 batch loss 1.34165478 epoch total loss 1.09610832
Trained batch 1254 batch loss 1.24770141 epoch total loss 1.0962292
Trained batch 1255 batch loss 1.36449051 epoch total loss 1.09644294
Trained batch 1256 batch loss 1.27884316 epoch total loss 1.09658813
Trained batch 1257 batch loss 1.3063035 epoch total loss 1.09675491
Trained batch 1258 batch loss 1.30235362 epoch total loss 1.09691834
Trained batch 1259 batch loss 1.32937884 epoch total loss 1.097103
Trained batch 1260 batch loss 1.38587606 epoch total loss 1.09733224
Trained batch 1261 batch loss 1.4051038 epoch total loss 1.09757626
Trained batch 1262 batch loss 1.16962242 epoch total loss 1.09763348
Trained batch 1263 batch loss 1.60922408 epoch total loss 1.09803855
Trained batch 1264 batch loss 1.14163077 epoch total loss 1.09807301
Trained batch 1265 batch loss 1.15568161 epoch total loss 1.09811842
Trained batch 1266 batch loss 1.02347445 epoch total loss 1.09805954
Trained batch 1267 batch loss 1.12507975 epoch total loss 1.09808087
Trained batch 1268 batch loss 1.08314419 epoch total loss 1.09806907
Trained batch 1269 batch loss 1.12875628 epoch total loss 1.09809327
Trained batch 1270 batch loss 1.11418748 epoch total loss 1.09810591
Trained batch 1271 batch loss 1.21640825 epoch total loss 1.09819901
Trained batch 1272 batch loss 1.21287394 epoch total loss 1.09828913
Trained batch 1273 batch loss 0.841042876 epoch total loss 1.09808707
Trained batch 1274 batch loss 0.964880049 epoch total loss 1.09798253
Trained batch 1275 batch loss 1.00476456 epoch total loss 1.09790933
Trained batch 1276 batch loss 0.937433362 epoch total loss 1.09778357
Trained batch 1277 batch loss 1.3372947 epoch total loss 1.09797108
Trained batch 1278 batch loss 1.11734009 epoch total loss 1.09798622
Trained batch 1279 batch loss 1.23453403 epoch total loss 1.09809303
Trained batch 1280 batch loss 1.28570533 epoch total loss 1.09823954
Trained batch 1281 batch loss 1.35778 epoch total loss 1.09844208
Trained batch 1282 batch loss 1.06982183 epoch total loss 1.09841979
Trained batch 1283 batch loss 1.1689682 epoch total loss 1.09847474
Trained batch 1284 batch loss 0.976872 epoch total loss 1.09838009
Trained batch 1285 batch loss 1.09456742 epoch total loss 1.09837723
Trained batch 1286 batch loss 1.04137564 epoch total loss 1.09833288
Trained batch 1287 batch loss 1.12199283 epoch total loss 1.09835124
Trained batch 1288 batch loss 1.06653535 epoch total loss 1.09832644
Trained batch 1289 batch loss 1.12042403 epoch total loss 1.09834373
Trained batch 1290 batch loss 1.08560359 epoch total loss 1.09833384
Trained batch 1291 batch loss 1.09595644 epoch total loss 1.09833193
Trained batch 1292 batch loss 1.10085797 epoch total loss 1.09833384
Trained batch 1293 batch loss 1.01478 epoch total loss 1.09826922
Trained batch 1294 batch loss 1.06090796 epoch total loss 1.09824038
Trained batch 1295 batch loss 1.29357958 epoch total loss 1.09839118
Trained batch 1296 batch loss 0.915264 epoch total loss 1.09824991
Trained batch 1297 batch loss 1.02950168 epoch total loss 1.09819698
Trained batch 1298 batch loss 1.10332727 epoch total loss 1.09820092
Trained batch 1299 batch loss 1.32520747 epoch total loss 1.09837556
Trained batch 1300 batch loss 0.962928474 epoch total loss 1.09827137
Trained batch 1301 batch loss 1.02051401 epoch total loss 1.09821165
Trained batch 1302 batch loss 1.1476959 epoch total loss 1.09824967
Trained batch 1303 batch loss 1.03827596 epoch total loss 1.09820366
Trained batch 1304 batch loss 1.01468253 epoch total loss 1.09813952
Trained batch 1305 batch loss 1.16394186 epoch total loss 1.09819
Trained batch 1306 batch loss 0.901997328 epoch total loss 1.09803975
Trained batch 1307 batch loss 1.27119422 epoch total loss 1.09817231
Trained batch 1308 batch loss 0.965897322 epoch total loss 1.09807122
Trained batch 1309 batch loss 1.1817106 epoch total loss 1.09813511
Trained batch 1310 batch loss 1.17100203 epoch total loss 1.09819078
Trained batch 1311 batch loss 1.1976105 epoch total loss 1.0982666
Trained batch 1312 batch loss 0.936714172 epoch total loss 1.09814346
Trained batch 1313 batch loss 0.855899572 epoch total loss 1.09795904
Trained batch 1314 batch loss 0.930946946 epoch total loss 1.09783196
Trained batch 1315 batch loss 0.749258935 epoch total loss 1.09756684
Trained batch 1316 batch loss 0.763485789 epoch total loss 1.09731293
Trained batch 1317 batch loss 0.852971852 epoch total loss 1.09712744
Trained batch 1318 batch loss 0.967299 epoch total loss 1.09702897
Trained batch 1319 batch loss 1.02770519 epoch total loss 1.0969764
Trained batch 1320 batch loss 0.910161257 epoch total loss 1.0968349
Trained batch 1321 batch loss 0.945238829 epoch total loss 1.0967201
Trained batch 1322 batch loss 1.03742325 epoch total loss 1.09667528
Trained batch 1323 batch loss 0.845855236 epoch total loss 1.09648561
Trained batch 1324 batch loss 1.10853505 epoch total loss 1.09649479
Trained batch 1325 batch loss 0.989253521 epoch total loss 1.09641385
Trained batch 1326 batch loss 1.06070924 epoch total loss 1.09638679
Trained batch 1327 batch loss 0.977848947 epoch total loss 1.09629762
Trained batch 1328 batch loss 0.982053459 epoch total loss 1.09621155
Trained batch 1329 batch loss 1.11219668 epoch total loss 1.09622359
Trained batch 1330 batch loss 1.11805379 epoch total loss 1.09623992
Trained batch 1331 batch loss 0.880181313 epoch total loss 1.09607756
Trained batch 1332 batch loss 1.06642818 epoch total loss 1.09605527
Trained batch 1333 batch loss 1.10901451 epoch total loss 1.09606504
Trained batch 1334 batch loss 1.23458743 epoch total loss 1.09616888
Trained batch 1335 batch loss 0.96874845 epoch total loss 1.09607351
Trained batch 1336 batch loss 0.884915948 epoch total loss 1.09591544
Trained batch 1337 batch loss 0.938544929 epoch total loss 1.09579766
Trained batch 1338 batch loss 0.980477691 epoch total loss 1.09571147
Trained batch 1339 batch loss 1.07612622 epoch total loss 1.09569693
Trained batch 1340 batch loss 1.1681509 epoch total loss 1.09575093
Trained batch 1341 batch loss 1.24796844 epoch total loss 1.09586442
Trained batch 1342 batch loss 1.13425398 epoch total loss 1.09589303
Trained batch 1343 batch loss 1.32508934 epoch total loss 1.09606373
Trained batch 1344 batch loss 1.33364165 epoch total loss 1.0962404
Trained batch 1345 batch loss 1.11824584 epoch total loss 1.09625685
Trained batch 1346 batch loss 1.35257447 epoch total loss 1.09644723
Trained batch 1347 batch loss 1.25769043 epoch total loss 1.09656692
Trained batch 1348 batch loss 1.08981705 epoch total loss 1.09656191
Trained batch 1349 batch loss 1.22961164 epoch total loss 1.09666061
Trained batch 1350 batch loss 1.22205949 epoch total loss 1.09675348
Trained batch 1351 batch loss 1.14430451 epoch total loss 1.09678864
Trained batch 1352 batch loss 1.31089902 epoch total loss 1.09694707
Trained batch 1353 batch loss 1.23629868 epoch total loss 1.09705007
Trained batch 1354 batch loss 1.05928683 epoch total loss 1.09702218
Trained batch 1355 batch loss 0.978496075 epoch total loss 1.09693468
Trained batch 1356 batch loss 0.868765473 epoch total loss 1.09676647
Trained batch 1357 batch loss 0.917554677 epoch total loss 1.09663439
Trained batch 1358 batch loss 0.948741794 epoch total loss 1.09652555
Trained batch 1359 batch loss 0.928420842 epoch total loss 1.09640181
Trained batch 1360 batch loss 1.01498628 epoch total loss 1.09634197
Trained batch 1361 batch loss 1.00643992 epoch total loss 1.09627604
Trained batch 1362 batch loss 1.06211305 epoch total loss 1.09625089
Trained batch 1363 batch loss 1.05429482 epoch total loss 1.09622014
Trained batch 1364 batch loss 1.00706387 epoch total loss 1.09615481
Trained batch 1365 batch loss 1.08842671 epoch total loss 1.09614909
Trained batch 1366 batch loss 1.06900263 epoch total loss 1.09612918
Trained batch 1367 batch loss 1.12287104 epoch total loss 1.09614885
Trained batch 1368 batch loss 1.21917224 epoch total loss 1.09623873
Trained batch 1369 batch loss 1.14816141 epoch total loss 1.09627664
Trained batch 1370 batch loss 1.19954 epoch total loss 1.0963521
Trained batch 1371 batch loss 1.25112343 epoch total loss 1.09646487
Trained batch 1372 batch loss 1.13574147 epoch total loss 1.0964936
Trained batch 1373 batch loss 1.33261859 epoch total loss 1.0966655
Trained batch 1374 batch loss 1.24424446 epoch total loss 1.09677303
Trained batch 1375 batch loss 1.34689116 epoch total loss 1.09695494
Trained batch 1376 batch loss 1.1012466 epoch total loss 1.09695804
Trained batch 1377 batch loss 1.10415876 epoch total loss 1.09696317
Trained batch 1378 batch loss 1.1673224 epoch total loss 1.09701431
Trained batch 1379 batch loss 1.15654564 epoch total loss 1.09705746
Trained batch 1380 batch loss 1.23768592 epoch total loss 1.09715927
Trained batch 1381 batch loss 1.20906305 epoch total loss 1.09724033
Trained batch 1382 batch loss 1.27756429 epoch total loss 1.09737086
Trained batch 1383 batch loss 0.968623519 epoch total loss 1.09727776
Trained batch 1384 batch loss 0.908688188 epoch total loss 1.0971415
Trained batch 1385 batch loss 1.04148316 epoch total loss 1.09710133
Trained batch 1386 batch loss 1.22932947 epoch total loss 1.09719682
Trained batch 1387 batch loss 0.876020253 epoch total loss 1.09703732
Trained batch 1388 batch loss 1.01836228 epoch total loss 1.09698057
Trained batch 1389 batch loss 1.33272886 epoch total loss 1.09715033
Trained batch 1390 batch loss 1.00676692 epoch total loss 1.09708524
Trained batch 1391 batch loss 0.985917509 epoch total loss 1.09700537
Trained batch 1392 batch loss 1.07431269 epoch total loss 1.09698904
Trained batch 1393 batch loss 1.2971406 epoch total loss 1.09713268
Trained batch 1394 batch loss 1.15347743 epoch total loss 1.09717309
Trained batch 1395 batch loss 1.12043548 epoch total loss 1.0971899
Trained batch 1396 batch loss 1.14500344 epoch total loss 1.09722412
Trained batch 1397 batch loss 0.982459545 epoch total loss 1.09714198
Trained batch 1398 batch loss 1.16825497 epoch total loss 1.09719276
Trained batch 1399 batch loss 1.34236717 epoch total loss 1.097368
Trained batch 1400 batch loss 1.11729598 epoch total loss 1.09738231
Trained batch 1401 batch loss 1.08663249 epoch total loss 1.09737468
Trained batch 1402 batch loss 1.25351512 epoch total loss 1.09748602
Trained batch 1403 batch loss 0.945041835 epoch total loss 1.09737742
Trained batch 1404 batch loss 1.01624346 epoch total loss 1.0973196
Trained batch 1405 batch loss 1.08613658 epoch total loss 1.09731162
Trained batch 1406 batch loss 1.14946103 epoch total loss 1.09734869
Trained batch 1407 batch loss 1.38978374 epoch total loss 1.09755659
Trained batch 1408 batch loss 1.59504509 epoch total loss 1.09790993
Trained batch 1409 batch loss 1.36183894 epoch total loss 1.09809721
Trained batch 1410 batch loss 1.27506328 epoch total loss 1.09822273
Trained batch 1411 batch loss 1.42025805 epoch total loss 1.09845102
Trained batch 1412 batch loss 1.13448882 epoch total loss 1.09847653
Trained batch 1413 batch loss 1.22469759 epoch total loss 1.09856582
Trained batch 1414 batch loss 0.950533748 epoch total loss 1.09846115
Trained batch 1415 batch loss 0.86143136 epoch total loss 1.09829366
Trained batch 1416 batch loss 1.089028 epoch total loss 1.09828711
Trained batch 1417 batch loss 1.15129 epoch total loss 1.09832454
Trained batch 1418 batch loss 1.03193831 epoch total loss 1.09827769
Trained batch 1419 batch loss 1.14115644 epoch total loss 1.09830785
Trained batch 1420 batch loss 1.38176656 epoch total loss 1.09850752
Trained batch 1421 batch loss 1.23120427 epoch total loss 1.09860086
Trained batch 1422 batch loss 1.24115968 epoch total loss 1.09870112
Trained batch 1423 batch loss 1.23405671 epoch total loss 1.09879625
Trained batch 1424 batch loss 1.34608531 epoch total loss 1.09896994
Trained batch 1425 batch loss 1.15358949 epoch total loss 1.0990082
Trained batch 1426 batch loss 1.16851139 epoch total loss 1.09905684
Trained batch 1427 batch loss 1.04680824 epoch total loss 1.09902024
Trained batch 1428 batch loss 1.05712295 epoch total loss 1.09899092
Trained batch 1429 batch loss 1.22367823 epoch total loss 1.09907818
Trained batch 1430 batch loss 1.02374816 epoch total loss 1.09902549
Trained batch 1431 batch loss 0.825171828 epoch total loss 1.09883416
Trained batch 1432 batch loss 1.12187886 epoch total loss 1.09885013
Trained batch 1433 batch loss 1.15076947 epoch total loss 1.09888637
Trained batch 1434 batch loss 1.29942274 epoch total loss 1.09902632
Trained batch 1435 batch loss 1.1062808 epoch total loss 1.09903133
Trained batch 1436 batch loss 0.86790359 epoch total loss 1.0988704
Trained batch 1437 batch loss 1.00812185 epoch total loss 1.09880733
Trained batch 1438 batch loss 1.01694441 epoch total loss 1.09875035
Trained batch 1439 batch loss 0.85348475 epoch total loss 1.09858
Trained batch 1440 batch loss 1.08789074 epoch total loss 1.09857249
Trained batch 1441 batch loss 0.892034769 epoch total loss 1.0984292
Trained batch 1442 batch loss 1.00333691 epoch total loss 1.09836328
Trained batch 1443 batch loss 1.02781057 epoch total loss 1.0983144
Trained batch 1444 batch loss 1.14020681 epoch total loss 1.09834349
Trained batch 1445 batch loss 1.26271367 epoch total loss 1.09845722
Trained batch 1446 batch loss 1.07985032 epoch total loss 1.09844434
Trained batch 1447 batch loss 1.02982569 epoch total loss 1.0983969
Trained batch 1448 batch loss 1.13371444 epoch total loss 1.09842122
Trained batch 1449 batch loss 1.12611198 epoch total loss 1.09844029
Trained batch 1450 batch loss 1.01326299 epoch total loss 1.09838164
Trained batch 1451 batch loss 0.963525891 epoch total loss 1.09828866
Trained batch 1452 batch loss 1.21089435 epoch total loss 1.09836626
Trained batch 1453 batch loss 1.2074976 epoch total loss 1.09844136
Trained batch 1454 batch loss 1.20902658 epoch total loss 1.09851742
Trained batch 1455 batch loss 1.23346281 epoch total loss 1.09861016
Trained batch 1456 batch loss 1.10311663 epoch total loss 1.09861326
Trained batch 1457 batch loss 1.13171685 epoch total loss 1.09863603
Trained batch 1458 batch loss 1.06351733 epoch total loss 1.09861183
Trained batch 1459 batch loss 0.964034319 epoch total loss 1.09851956
Trained batch 1460 batch loss 0.89255929 epoch total loss 1.09837854
Trained batch 1461 batch loss 1.01551199 epoch total loss 1.0983218
Trained batch 1462 batch loss 1.14891768 epoch total loss 1.09835649
Trained batch 1463 batch loss 0.967856 epoch total loss 1.09826732
Trained batch 1464 batch loss 1.27809 epoch total loss 1.0983901
Trained batch 1465 batch loss 1.28649449 epoch total loss 1.09851849
Trained batch 1466 batch loss 1.12561524 epoch total loss 1.09853697
Trained batch 1467 batch loss 0.939888239 epoch total loss 1.09842885
Trained batch 1468 batch loss 0.998651743 epoch total loss 1.0983609
Trained batch 1469 batch loss 1.20903158 epoch total loss 1.09843624
Trained batch 1470 batch loss 1.04921103 epoch total loss 1.09840274
Trained batch 1471 batch loss 1.13030231 epoch total loss 1.09842432
Trained batch 1472 batch loss 1.20294821 epoch total loss 1.09849536
Trained batch 1473 batch loss 0.967257 epoch total loss 1.09840631
Trained batch 1474 batch loss 1.26175332 epoch total loss 1.09851706
Trained batch 1475 batch loss 1.13558936 epoch total loss 1.09854233
Trained batch 1476 batch loss 0.98234731 epoch total loss 1.09846354
Trained batch 1477 batch loss 1.20190239 epoch total loss 1.09853351
Trained batch 1478 batch loss 1.0781641 epoch total loss 1.0985198
Trained batch 1479 batch loss 1.01672328 epoch total loss 1.09846449
Trained batch 1480 batch loss 1.06553125 epoch total loss 1.0984422
Trained batch 1481 batch loss 1.24373472 epoch total loss 1.09854031
Trained batch 1482 batch loss 1.05432153 epoch total loss 1.0985105
Trained batch 1483 batch loss 0.949189186 epoch total loss 1.09840977
Trained batch 1484 batch loss 0.809894 epoch total loss 1.09821546
Trained batch 1485 batch loss 0.978111744 epoch total loss 1.09813464
Trained batch 1486 batch loss 0.994475961 epoch total loss 1.0980649
Trained batch 1487 batch loss 1.14299822 epoch total loss 1.09809506
Trained batch 1488 batch loss 1.31594396 epoch total loss 1.09824145
Trained batch 1489 batch loss 1.0553906 epoch total loss 1.0982126
Trained batch 1490 batch loss 1.21714139 epoch total loss 1.09829247
Trained batch 1491 batch loss 1.14614201 epoch total loss 1.09832454
Trained batch 1492 batch loss 1.21298838 epoch total loss 1.09840143
Trained batch 1493 batch loss 1.1895963 epoch total loss 1.09846246
Trained batch 1494 batch loss 1.23323369 epoch total loss 1.0985527
Trained batch 1495 batch loss 1.11437345 epoch total loss 1.09856331
Trained batch 1496 batch loss 1.09715807 epoch total loss 1.09856236
Trained batch 1497 batch loss 1.01239109 epoch total loss 1.0985049
Trained batch 1498 batch loss 1.10974407 epoch total loss 1.09851241
Trained batch 1499 batch loss 1.13587677 epoch total loss 1.09853733
Trained batch 1500 batch loss 0.970397353 epoch total loss 1.09845185
Trained batch 1501 batch loss 1.05174732 epoch total loss 1.09842074
Trained batch 1502 batch loss 0.858895659 epoch total loss 1.09826124
Trained batch 1503 batch loss 0.993620157 epoch total loss 1.09819162
Trained batch 1504 batch loss 1.09414601 epoch total loss 1.09818888
Trained batch 1505 batch loss 1.08156025 epoch total loss 1.09817791
Trained batch 1506 batch loss 1.23087692 epoch total loss 1.09826601
Trained batch 1507 batch loss 1.03727603 epoch total loss 1.09822547
Trained batch 1508 batch loss 1.1459744 epoch total loss 1.09825718
Trained batch 1509 batch loss 1.26732206 epoch total loss 1.09836912
Trained batch 1510 batch loss 1.04378057 epoch total loss 1.098333
Trained batch 1511 batch loss 0.944514155 epoch total loss 1.0982312
Trained batch 1512 batch loss 0.994220734 epoch total loss 1.09816241
Trained batch 1513 batch loss 1.06110191 epoch total loss 1.09813797
Trained batch 1514 batch loss 1.25847745 epoch total loss 1.09824383
Trained batch 1515 batch loss 1.36291122 epoch total loss 1.09841859
Trained batch 1516 batch loss 1.29775548 epoch total loss 1.09855008
Trained batch 1517 batch loss 1.23424876 epoch total loss 1.09863949
Trained batch 1518 batch loss 1.03542936 epoch total loss 1.09859788
Trained batch 1519 batch loss 1.08140063 epoch total loss 1.09858656
Trained batch 1520 batch loss 1.11919582 epoch total loss 1.0986
Trained batch 1521 batch loss 0.943739533 epoch total loss 1.09849823
Trained batch 1522 batch loss 1.00327969 epoch total loss 1.09843564
Trained batch 1523 batch loss 0.914990127 epoch total loss 1.09831524
Trained batch 1524 batch loss 1.00167811 epoch total loss 1.09825182
Trained batch 1525 batch loss 0.8283813 epoch total loss 1.09807491
Trained batch 1526 batch loss 1.05890775 epoch total loss 1.09804928
Trained batch 1527 batch loss 1.12288356 epoch total loss 1.0980655
Trained batch 1528 batch loss 1.04692495 epoch total loss 1.098032
Trained batch 1529 batch loss 1.11892688 epoch total loss 1.09804571
Trained batch 1530 batch loss 1.11503088 epoch total loss 1.09805679
Trained batch 1531 batch loss 1.06331956 epoch total loss 1.09803414
Trained batch 1532 batch loss 1.13520384 epoch total loss 1.09805834
Trained batch 1533 batch loss 1.10393357 epoch total loss 1.09806216
Trained batch 1534 batch loss 1.11517167 epoch total loss 1.09807336
Trained batch 1535 batch loss 1.19574475 epoch total loss 1.09813702
Trained batch 1536 batch loss 0.971550226 epoch total loss 1.09805453
Trained batch 1537 batch loss 1.11965561 epoch total loss 1.09806859
Trained batch 1538 batch loss 0.975879252 epoch total loss 1.09798908
Trained batch 1539 batch loss 1.24066639 epoch total loss 1.09808183
Trained batch 1540 batch loss 1.13213515 epoch total loss 1.098104
Trained batch 1541 batch loss 1.24643803 epoch total loss 1.0982002
Trained batch 1542 batch loss 1.13463044 epoch total loss 1.09822381
Trained batch 1543 batch loss 1.10994971 epoch total loss 1.09823143
Trained batch 1544 batch loss 1.2990011 epoch total loss 1.09836149
Trained batch 1545 batch loss 0.992293298 epoch total loss 1.09829283
Trained batch 1546 batch loss 1.09352851 epoch total loss 1.09828973
Trained batch 1547 batch loss 0.891298771 epoch total loss 1.09815598
Trained batch 1548 batch loss 0.978198111 epoch total loss 1.09807849
Trained batch 1549 batch loss 0.911238194 epoch total loss 1.09795785
Trained batch 1550 batch loss 1.07469344 epoch total loss 1.09794283
Trained batch 1551 batch loss 0.9192729 epoch total loss 1.09782767
Trained batch 1552 batch loss 0.918516338 epoch total loss 1.09771204
Trained batch 1553 batch loss 0.869974375 epoch total loss 1.09756541
Trained batch 1554 batch loss 0.905755 epoch total loss 1.09744203
Trained batch 1555 batch loss 1.15156674 epoch total loss 1.09747684
Trained batch 1556 batch loss 1.11487126 epoch total loss 1.09748805
Trained batch 1557 batch loss 1.29073501 epoch total loss 1.09761214
Trained batch 1558 batch loss 1.13968587 epoch total loss 1.0976392
Trained batch 1559 batch loss 0.972356796 epoch total loss 1.09755886
Trained batch 1560 batch loss 0.900839508 epoch total loss 1.09743273
Trained batch 1561 batch loss 0.891825438 epoch total loss 1.09730101
Trained batch 1562 batch loss 0.954430103 epoch total loss 1.09720957
Trained batch 1563 batch loss 1.17422938 epoch total loss 1.09725893
Trained batch 1564 batch loss 1.43598986 epoch total loss 1.09747553
Trained batch 1565 batch loss 1.19255948 epoch total loss 1.09753621
Trained batch 1566 batch loss 0.902410269 epoch total loss 1.09741163
Trained batch 1567 batch loss 0.988017678 epoch total loss 1.0973419
Trained batch 1568 batch loss 1.13818514 epoch total loss 1.09736788
Trained batch 1569 batch loss 1.28066778 epoch total loss 1.09748471
Trained batch 1570 batch loss 1.11047602 epoch total loss 1.09749293
Trained batch 1571 batch loss 1.25832939 epoch total loss 1.09759533
Trained batch 1572 batch loss 1.19405615 epoch total loss 1.09765673
Trained batch 1573 batch loss 1.20066893 epoch total loss 1.09772217
Trained batch 1574 batch loss 1.22830367 epoch total loss 1.09780514
Trained batch 1575 batch loss 1.31001425 epoch total loss 1.09794
Trained batch 1576 batch loss 1.21139812 epoch total loss 1.09801197
Trained batch 1577 batch loss 0.881097794 epoch total loss 1.0978744
Trained batch 1578 batch loss 0.959326327 epoch total loss 1.09778655
Trained batch 1579 batch loss 1.00368714 epoch total loss 1.09772694
Trained batch 1580 batch loss 1.08507252 epoch total loss 1.09771895
Trained batch 1581 batch loss 1.06642783 epoch total loss 1.09769917
Trained batch 1582 batch loss 1.19442272 epoch total loss 1.09776032
Trained batch 1583 batch loss 1.23179078 epoch total loss 1.09784508
Trained batch 1584 batch loss 1.31277823 epoch total loss 1.09798074
Trained batch 1585 batch loss 1.36321592 epoch total loss 1.09814799
Trained batch 1586 batch loss 1.22758341 epoch total loss 1.09822953
Trained batch 1587 batch loss 1.15204537 epoch total loss 1.0982635
Trained batch 1588 batch loss 0.9387393 epoch total loss 1.09816301
Trained batch 1589 batch loss 1.06192541 epoch total loss 1.09814024
Trained batch 1590 batch loss 1.09090614 epoch total loss 1.09813571
Trained batch 1591 batch loss 1.09591639 epoch total loss 1.09813428
Trained batch 1592 batch loss 1.10515988 epoch total loss 1.09813869
Trained batch 1593 batch loss 0.934134662 epoch total loss 1.09803569
Trained batch 1594 batch loss 0.921954751 epoch total loss 1.09792531
Trained batch 1595 batch loss 0.904734 epoch total loss 1.09780419
Trained batch 1596 batch loss 1.12091327 epoch total loss 1.09781873
Trained batch 1597 batch loss 0.926885843 epoch total loss 1.09771168
Trained batch 1598 batch loss 1.10769987 epoch total loss 1.09771788
Trained batch 1599 batch loss 1.19209981 epoch total loss 1.09777689
Trained batch 1600 batch loss 1.26781428 epoch total loss 1.09788322
Trained batch 1601 batch loss 1.20614171 epoch total loss 1.09795082
Trained batch 1602 batch loss 1.54065335 epoch total loss 1.09822726
Trained batch 1603 batch loss 1.18642545 epoch total loss 1.09828222
Trained batch 1604 batch loss 1.37293339 epoch total loss 1.0984534
Trained batch 1605 batch loss 1.3191539 epoch total loss 1.09859097
Trained batch 1606 batch loss 1.23189092 epoch total loss 1.09867406
Trained batch 1607 batch loss 1.18838525 epoch total loss 1.09872985
Trained batch 1608 batch loss 1.05505371 epoch total loss 1.09870267
Trained batch 1609 batch loss 1.01998496 epoch total loss 1.09865379
Trained batch 1610 batch loss 0.962965965 epoch total loss 1.09856951
Trained batch 1611 batch loss 1.12527955 epoch total loss 1.09858608
Trained batch 1612 batch loss 0.91388154 epoch total loss 1.09847152
Trained batch 1613 batch loss 1.19506073 epoch total loss 1.09853137
Trained batch 1614 batch loss 1.1082828 epoch total loss 1.09853745
Trained batch 1615 batch loss 0.816736698 epoch total loss 1.09836292
Trained batch 1616 batch loss 1.12413383 epoch total loss 1.0983789
Trained batch 1617 batch loss 1.26345682 epoch total loss 1.09848094
Trained batch 1618 batch loss 1.22102118 epoch total loss 1.09855676
Trained batch 1619 batch loss 1.03449166 epoch total loss 1.09851718
Trained batch 1620 batch loss 1.36827254 epoch total loss 1.09868371
Trained batch 1621 batch loss 1.28059042 epoch total loss 1.09879601
Trained batch 1622 batch loss 1.02493596 epoch total loss 1.09875047
Trained batch 1623 batch loss 0.941976428 epoch total loss 1.09865391
Trained batch 1624 batch loss 0.900364161 epoch total loss 1.09853184
Trained batch 1625 batch loss 1.1804781 epoch total loss 1.09858215
Trained batch 1626 batch loss 1.20619369 epoch total loss 1.09864831
Trained batch 1627 batch loss 1.2912513 epoch total loss 1.09876668
Trained batch 1628 batch loss 1.19758987 epoch total loss 1.09882748
Trained batch 1629 batch loss 1.37650478 epoch total loss 1.09899795
Trained batch 1630 batch loss 1.35551023 epoch total loss 1.09915519
Trained batch 1631 batch loss 1.25107777 epoch total loss 1.09924841
Trained batch 1632 batch loss 1.00060511 epoch total loss 1.09918797
Trained batch 1633 batch loss 1.28821552 epoch total loss 1.09930372
Trained batch 1634 batch loss 1.37401938 epoch total loss 1.09947181
Trained batch 1635 batch loss 1.27869749 epoch total loss 1.09958148
Trained batch 1636 batch loss 1.2749958 epoch total loss 1.09968865
Trained batch 1637 batch loss 0.960201859 epoch total loss 1.09960353
Trained batch 1638 batch loss 1.23940825 epoch total loss 1.09968877
Trained batch 1639 batch loss 1.15402329 epoch total loss 1.09972203
Trained batch 1640 batch loss 0.871692181 epoch total loss 1.09958291
Trained batch 1641 batch loss 0.818113089 epoch total loss 1.09941149
Trained batch 1642 batch loss 0.994151652 epoch total loss 1.09934735
Trained batch 1643 batch loss 0.859651923 epoch total loss 1.09920144
Trained batch 1644 batch loss 0.954185247 epoch total loss 1.09911323
Trained batch 1645 batch loss 0.907577634 epoch total loss 1.09899676
Trained batch 1646 batch loss 0.952310383 epoch total loss 1.09890771
Trained batch 1647 batch loss 0.832060158 epoch total loss 1.09874558
Trained batch 1648 batch loss 0.891527832 epoch total loss 1.09861982
Trained batch 1649 batch loss 1.01522374 epoch total loss 1.09856927
Trained batch 1650 batch loss 1.00424314 epoch total loss 1.09851217
Trained batch 1651 batch loss 1.17192864 epoch total loss 1.09855664
Trained batch 1652 batch loss 1.12470961 epoch total loss 1.09857249
Trained batch 1653 batch loss 0.786986768 epoch total loss 1.0983839
Trained batch 1654 batch loss 1.11412358 epoch total loss 1.09839344
Trained batch 1655 batch loss 0.960883319 epoch total loss 1.09831047
Trained batch 1656 batch loss 1.02295315 epoch total loss 1.09826493
Trained batch 1657 batch loss 0.979321301 epoch total loss 1.09819317
Trained batch 1658 batch loss 0.998641849 epoch total loss 1.09813309
Trained batch 1659 batch loss 0.98371911 epoch total loss 1.09806418
Trained batch 1660 batch loss 1.09577084 epoch total loss 1.09806287
Trained batch 1661 batch loss 1.0831902 epoch total loss 1.09805381
Trained batch 1662 batch loss 1.03784382 epoch total loss 1.09801757
Trained batch 1663 batch loss 1.20191014 epoch total loss 1.09808
Trained batch 1664 batch loss 0.989329696 epoch total loss 1.09801471
Trained batch 1665 batch loss 1.23800242 epoch total loss 1.09809887
Trained batch 1666 batch loss 1.11887169 epoch total loss 1.09811139
Trained batch 1667 batch loss 1.07296681 epoch total loss 1.09809625
Trained batch 1668 batch loss 1.04076958 epoch total loss 1.09806192
Trained batch 1669 batch loss 1.01048422 epoch total loss 1.09800947
Trained batch 1670 batch loss 1.18385398 epoch total loss 1.09806085
Trained batch 1671 batch loss 1.09024262 epoch total loss 1.0980562
Trained batch 1672 batch loss 1.04241443 epoch total loss 1.09802282
Trained batch 1673 batch loss 1.19580817 epoch total loss 1.09808123
Trained batch 1674 batch loss 1.2719065 epoch total loss 1.09818506
Trained batch 1675 batch loss 1.21249962 epoch total loss 1.09825337
Trained batch 1676 batch loss 1.19525552 epoch total loss 1.09831131
Trained batch 1677 batch loss 1.24681175 epoch total loss 1.09839976
Trained batch 1678 batch loss 1.23375785 epoch total loss 1.09848046
Trained batch 1679 batch loss 1.03607273 epoch total loss 1.09844339
Trained batch 1680 batch loss 1.15209913 epoch total loss 1.09847534
Trained batch 1681 batch loss 1.1239934 epoch total loss 1.09849048
Trained batch 1682 batch loss 1.17152214 epoch total loss 1.09853387
Trained batch 1683 batch loss 1.22516704 epoch total loss 1.09860921
Trained batch 1684 batch loss 1.3706373 epoch total loss 1.09877074
Trained batch 1685 batch loss 1.18592536 epoch total loss 1.09882236
Trained batch 1686 batch loss 1.16042852 epoch total loss 1.09885895
Trained batch 1687 batch loss 1.07044733 epoch total loss 1.09884202
Trained batch 1688 batch loss 1.10860062 epoch total loss 1.09884787
Trained batch 1689 batch loss 1.1924262 epoch total loss 1.0989033
Trained batch 1690 batch loss 1.1981492 epoch total loss 1.09896195
Trained batch 1691 batch loss 0.996145844 epoch total loss 1.09890115
Trained batch 1692 batch loss 0.957472563 epoch total loss 1.09881759
Trained batch 1693 batch loss 1.1121875 epoch total loss 1.09882545
Trained batch 1694 batch loss 1.06202197 epoch total loss 1.09880376
Trained batch 1695 batch loss 1.25646913 epoch total loss 1.09889674
Trained batch 1696 batch loss 0.954531193 epoch total loss 1.09881163
Trained batch 1697 batch loss 0.81217283 epoch total loss 1.09864271
Trained batch 1698 batch loss 0.83314538 epoch total loss 1.09848642
Trained batch 1699 batch loss 0.842409134 epoch total loss 1.09833562
Trained batch 1700 batch loss 1.03572595 epoch total loss 1.09829879
Trained batch 1701 batch loss 0.906628847 epoch total loss 1.09818614
Trained batch 1702 batch loss 1.01908493 epoch total loss 1.09813964
Trained batch 1703 batch loss 0.910003304 epoch total loss 1.09802926
Trained batch 1704 batch loss 1.05241144 epoch total loss 1.09800243
Trained batch 1705 batch loss 1.12867785 epoch total loss 1.09802043
Trained batch 1706 batch loss 1.07767725 epoch total loss 1.09800839
Trained batch 1707 batch loss 1.12360597 epoch total loss 1.09802341
Trained batch 1708 batch loss 1.10273695 epoch total loss 1.09802628
Trained batch 1709 batch loss 1.27808976 epoch total loss 1.09813166
Trained batch 1710 batch loss 1.23858 epoch total loss 1.09821367
Trained batch 1711 batch loss 1.29051113 epoch total loss 1.09832609
Trained batch 1712 batch loss 1.20807886 epoch total loss 1.09839022
Trained batch 1713 batch loss 1.28266 epoch total loss 1.09849787
Trained batch 1714 batch loss 1.12240779 epoch total loss 1.09851182
Trained batch 1715 batch loss 1.12647092 epoch total loss 1.09852815
Trained batch 1716 batch loss 1.01642895 epoch total loss 1.09848034
Trained batch 1717 batch loss 1.09340894 epoch total loss 1.09847736
Trained batch 1718 batch loss 1.08689964 epoch total loss 1.09847057
Trained batch 1719 batch loss 1.18221283 epoch total loss 1.09851933
Trained batch 1720 batch loss 1.00585866 epoch total loss 1.09846544
Trained batch 1721 batch loss 1.08611894 epoch total loss 1.09845829
Trained batch 1722 batch loss 1.00427318 epoch total loss 1.09840357
Trained batch 1723 batch loss 1.22344553 epoch total loss 1.09847605
Trained batch 1724 batch loss 0.963089705 epoch total loss 1.09839761
Trained batch 1725 batch loss 1.02684283 epoch total loss 1.09835613
Trained batch 1726 batch loss 1.0845865 epoch total loss 1.09834814
Trained batch 1727 batch loss 1.096452 epoch total loss 1.09834707
Trained batch 1728 batch loss 1.08122587 epoch total loss 1.09833705
Trained batch 1729 batch loss 1.1317935 epoch total loss 1.09835649
Trained batch 1730 batch loss 1.08466959 epoch total loss 1.09834862
Trained batch 1731 batch loss 1.00040829 epoch total loss 1.09829199
Trained batch 1732 batch loss 0.726748586 epoch total loss 1.09807754
Trained batch 1733 batch loss 1.13902688 epoch total loss 1.09810114
Trained batch 1734 batch loss 0.719215691 epoch total loss 1.09788263
Trained batch 1735 batch loss 0.812887669 epoch total loss 1.09771836
Trained batch 1736 batch loss 0.994789958 epoch total loss 1.09765911
Trained batch 1737 batch loss 1.11319816 epoch total loss 1.09766793
Trained batch 1738 batch loss 1.06335771 epoch total loss 1.09764826
Trained batch 1739 batch loss 0.99872762 epoch total loss 1.0975914
Trained batch 1740 batch loss 0.921982884 epoch total loss 1.09749043
Trained batch 1741 batch loss 0.901254058 epoch total loss 1.09737778
Trained batch 1742 batch loss 0.987244129 epoch total loss 1.0973146
Trained batch 1743 batch loss 0.899385929 epoch total loss 1.09720099
Trained batch 1744 batch loss 1.1274 epoch total loss 1.09721839
Trained batch 1745 batch loss 1.02779698 epoch total loss 1.09717858
Trained batch 1746 batch loss 0.889897585 epoch total loss 1.09705985
Trained batch 1747 batch loss 1.22168374 epoch total loss 1.09713125
Trained batch 1748 batch loss 1.26058674 epoch total loss 1.09722471
Trained batch 1749 batch loss 1.19942904 epoch total loss 1.09728324
Trained batch 1750 batch loss 1.16781306 epoch total loss 1.09732354
Trained batch 1751 batch loss 1.05735338 epoch total loss 1.09730065
Trained batch 1752 batch loss 1.13087559 epoch total loss 1.09731984
Trained batch 1753 batch loss 1.17372179 epoch total loss 1.09736347
Trained batch 1754 batch loss 1.14865339 epoch total loss 1.09739268
Trained batch 1755 batch loss 1.05031669 epoch total loss 1.09736586
Trained batch 1756 batch loss 1.05796957 epoch total loss 1.09734344
Trained batch 1757 batch loss 1.11903358 epoch total loss 1.09735572
Trained batch 1758 batch loss 1.14548182 epoch total loss 1.09738314
Trained batch 1759 batch loss 1.2652185 epoch total loss 1.09747863
Trained batch 1760 batch loss 1.03917861 epoch total loss 1.09744549
Trained batch 1761 batch loss 1.21860969 epoch total loss 1.09751427
Trained batch 1762 batch loss 1.09442234 epoch total loss 1.0975126
Trained batch 1763 batch loss 1.31747818 epoch total loss 1.0976373
Trained batch 1764 batch loss 1.26134813 epoch total loss 1.09773016
Trained batch 1765 batch loss 1.27641129 epoch total loss 1.09783137
Trained batch 1766 batch loss 1.23164725 epoch total loss 1.09790719
Trained batch 1767 batch loss 1.1913178 epoch total loss 1.09796
Trained batch 1768 batch loss 1.33628869 epoch total loss 1.09809482
Trained batch 1769 batch loss 1.26448154 epoch total loss 1.09818888
Trained batch 1770 batch loss 1.32941437 epoch total loss 1.09831953
Trained batch 1771 batch loss 1.35364699 epoch total loss 1.09846377
Trained batch 1772 batch loss 1.23100376 epoch total loss 1.09853852
Trained batch 1773 batch loss 1.27813947 epoch total loss 1.09863985
Trained batch 1774 batch loss 1.26762 epoch total loss 1.09873509
Trained batch 1775 batch loss 1.36480141 epoch total loss 1.09888494
Trained batch 1776 batch loss 1.29121149 epoch total loss 1.0989933
Trained batch 1777 batch loss 1.31098557 epoch total loss 1.09911263
Trained batch 1778 batch loss 1.07321537 epoch total loss 1.09909797
Trained batch 1779 batch loss 0.919557214 epoch total loss 1.09899712
Trained batch 1780 batch loss 1.0446353 epoch total loss 1.0989666
Trained batch 1781 batch loss 1.12225485 epoch total loss 1.09897971
Trained batch 1782 batch loss 1.10129213 epoch total loss 1.09898102
Trained batch 1783 batch loss 0.881805182 epoch total loss 1.09885919
Trained batch 1784 batch loss 0.996290624 epoch total loss 1.09880173
Trained batch 1785 batch loss 0.991006494 epoch total loss 1.09874129
Trained batch 1786 batch loss 1.22024846 epoch total loss 1.09880936
Trained batch 1787 batch loss 1.20034933 epoch total loss 1.09886611
Trained batch 1788 batch loss 1.32894421 epoch total loss 1.09899485
Trained batch 1789 batch loss 1.27143621 epoch total loss 1.09909129
Trained batch 1790 batch loss 1.02442837 epoch total loss 1.09904957
Trained batch 1791 batch loss 1.46776724 epoch total loss 1.09925544
Trained batch 1792 batch loss 1.44215751 epoch total loss 1.09944677
Trained batch 1793 batch loss 1.13335514 epoch total loss 1.09946561
Trained batch 1794 batch loss 0.919737399 epoch total loss 1.09936547
Trained batch 1795 batch loss 1.07230783 epoch total loss 1.09935033
Trained batch 1796 batch loss 0.974324405 epoch total loss 1.09928071
Trained batch 1797 batch loss 0.957424164 epoch total loss 1.0992018
Trained batch 1798 batch loss 1.05215025 epoch total loss 1.09917557
Trained batch 1799 batch loss 1.2157228 epoch total loss 1.09924042
Trained batch 1800 batch loss 1.04512429 epoch total loss 1.09921038
Trained batch 1801 batch loss 0.952457905 epoch total loss 1.09912884
Trained batch 1802 batch loss 0.987214684 epoch total loss 1.09906673
Trained batch 1803 batch loss 1.02397418 epoch total loss 1.09902513
Trained batch 1804 batch loss 0.986106 epoch total loss 1.09896243
Trained batch 1805 batch loss 1.10165048 epoch total loss 1.09896398
Trained batch 1806 batch loss 1.11813164 epoch total loss 1.09897459
Trained batch 1807 batch loss 1.05187833 epoch total loss 1.0989486
Trained batch 1808 batch loss 1.03576374 epoch total loss 1.09891367
Trained batch 1809 batch loss 0.953581 epoch total loss 1.09883332
Trained batch 1810 batch loss 0.95845139 epoch total loss 1.09875572
Trained batch 1811 batch loss 0.832042873 epoch total loss 1.09860849
Trained batch 1812 batch loss 0.975771904 epoch total loss 1.09854066
Trained batch 1813 batch loss 1.22296965 epoch total loss 1.09860933
Trained batch 1814 batch loss 0.982453823 epoch total loss 1.09854531
Trained batch 1815 batch loss 0.96996206 epoch total loss 1.0984745
Trained batch 1816 batch loss 1.18820608 epoch total loss 1.09852397
Trained batch 1817 batch loss 1.10358047 epoch total loss 1.09852672
Trained batch 1818 batch loss 1.06497884 epoch total loss 1.09850824
Trained batch 1819 batch loss 0.971779168 epoch total loss 1.09843862
Trained batch 1820 batch loss 1.17778277 epoch total loss 1.09848213
Trained batch 1821 batch loss 1.05068111 epoch total loss 1.09845591
Trained batch 1822 batch loss 1.15696192 epoch total loss 1.09848797
Trained batch 1823 batch loss 1.12333155 epoch total loss 1.09850168
Trained batch 1824 batch loss 0.880128264 epoch total loss 1.09838188
Trained batch 1825 batch loss 1.16112566 epoch total loss 1.09841633
Trained batch 1826 batch loss 0.940988898 epoch total loss 1.09833014
Trained batch 1827 batch loss 0.87822336 epoch total loss 1.09820962
Trained batch 1828 batch loss 0.983105659 epoch total loss 1.09814668
Trained batch 1829 batch loss 1.27583718 epoch total loss 1.09824383
Trained batch 1830 batch loss 1.16030538 epoch total loss 1.09827769
Trained batch 1831 batch loss 1.23750806 epoch total loss 1.09835386
Trained batch 1832 batch loss 1.16781664 epoch total loss 1.09839177
Trained batch 1833 batch loss 1.00064397 epoch total loss 1.09833837
Trained batch 1834 batch loss 1.21178579 epoch total loss 1.09840024
Trained batch 1835 batch loss 1.2236352 epoch total loss 1.09846854
Trained batch 1836 batch loss 1.15724206 epoch total loss 1.09850049
Trained batch 1837 batch loss 1.28318167 epoch total loss 1.0986011
Trained batch 1838 batch loss 1.17415571 epoch total loss 1.09864223
Trained batch 1839 batch loss 1.17086756 epoch total loss 1.09868145
Trained batch 1840 batch loss 1.18175828 epoch total loss 1.09872663
Trained batch 1841 batch loss 1.26373565 epoch total loss 1.09881628
Trained batch 1842 batch loss 1.26767898 epoch total loss 1.09890795
Trained batch 1843 batch loss 1.09000587 epoch total loss 1.09890306
Trained batch 1844 batch loss 1.06691241 epoch total loss 1.09888577
Trained batch 1845 batch loss 1.04165769 epoch total loss 1.09885478
Trained batch 1846 batch loss 1.2200979 epoch total loss 1.09892035
Trained batch 1847 batch loss 1.21942842 epoch total loss 1.09898567
Trained batch 1848 batch loss 1.09928846 epoch total loss 1.09898579
Trained batch 1849 batch loss 1.26490092 epoch total loss 1.09907556
Trained batch 1850 batch loss 0.963685036 epoch total loss 1.09900236
Trained batch 1851 batch loss 1.05440068 epoch total loss 1.09897828
Trained batch 1852 batch loss 1.26770699 epoch total loss 1.09906948
Trained batch 1853 batch loss 1.33115065 epoch total loss 1.09919465
Trained batch 1854 batch loss 1.41756904 epoch total loss 1.09936643
Trained batch 1855 batch loss 1.23080325 epoch total loss 1.09943724
Trained batch 1856 batch loss 1.16973913 epoch total loss 1.09947515
Trained batch 1857 batch loss 1.17642546 epoch total loss 1.09951663
Trained batch 1858 batch loss 0.913290143 epoch total loss 1.09941638
Trained batch 1859 batch loss 1.00753164 epoch total loss 1.09936702
Trained batch 1860 batch loss 1.23958063 epoch total loss 1.09944236
Trained batch 1861 batch loss 1.22826028 epoch total loss 1.09951162
Trained batch 1862 batch loss 1.22939837 epoch total loss 1.09958136
Trained batch 1863 batch loss 1.24032605 epoch total loss 1.09965694
Trained batch 1864 batch loss 1.16451287 epoch total loss 1.09969175
Trained batch 1865 batch loss 1.23628271 epoch total loss 1.09976506
Trained batch 1866 batch loss 1.18326211 epoch total loss 1.09980977
Trained batch 1867 batch loss 1.27543461 epoch total loss 1.09990382
Trained batch 1868 batch loss 1.24309039 epoch total loss 1.09998059
Trained batch 1869 batch loss 1.00607419 epoch total loss 1.09993029
Trained batch 1870 batch loss 1.12099075 epoch total loss 1.09994161
Trained batch 1871 batch loss 1.37376165 epoch total loss 1.100088
Trained batch 1872 batch loss 1.09944034 epoch total loss 1.10008764
Trained batch 1873 batch loss 1.12723875 epoch total loss 1.10010207
Trained batch 1874 batch loss 1.03419328 epoch total loss 1.1000669
Trained batch 1875 batch loss 1.1727221 epoch total loss 1.10010564
Trained batch 1876 batch loss 1.32905328 epoch total loss 1.10022771
Trained batch 1877 batch loss 1.10123026 epoch total loss 1.10022819
Trained batch 1878 batch loss 1.25374746 epoch total loss 1.10031
Trained batch 1879 batch loss 0.922606349 epoch total loss 1.10021532
Trained batch 1880 batch loss 1.06708491 epoch total loss 1.10019779
Trained batch 1881 batch loss 1.10478377 epoch total loss 1.10020018
Trained batch 1882 batch loss 1.06699502 epoch total loss 1.10018253
Trained batch 1883 batch loss 1.06477833 epoch total loss 1.1001637
Trained batch 1884 batch loss 0.998717248 epoch total loss 1.10010982
Trained batch 1885 batch loss 0.982271314 epoch total loss 1.10004723
Trained batch 1886 batch loss 1.1171664 epoch total loss 1.10005641
Trained batch 1887 batch loss 1.2438122 epoch total loss 1.10013258
Trained batch 1888 batch loss 0.862437 epoch total loss 1.1000067
Trained batch 1889 batch loss 1.31128752 epoch total loss 1.10011864
Trained batch 1890 batch loss 1.27907717 epoch total loss 1.10021329
Trained batch 1891 batch loss 1.14347529 epoch total loss 1.10023618
Trained batch 1892 batch loss 1.19814885 epoch total loss 1.10028803
Trained batch 1893 batch loss 1.19674599 epoch total loss 1.10033894
Trained batch 1894 batch loss 1.35670722 epoch total loss 1.10047436
Trained batch 1895 batch loss 1.05449748 epoch total loss 1.10045
Trained batch 1896 batch loss 1.05360329 epoch total loss 1.10042536
Trained batch 1897 batch loss 1.17550492 epoch total loss 1.10046494
Trained batch 1898 batch loss 1.10265529 epoch total loss 1.10046601
Trained batch 1899 batch loss 1.31726313 epoch total loss 1.10058033
Trained batch 1900 batch loss 1.17682266 epoch total loss 1.10062039
Trained batch 1901 batch loss 1.03285825 epoch total loss 1.10058475
Trained batch 1902 batch loss 0.945560396 epoch total loss 1.10050333
Trained batch 1903 batch loss 0.993155599 epoch total loss 1.10044682
Trained batch 1904 batch loss 1.08296835 epoch total loss 1.10043776
Trained batch 1905 batch loss 0.974407792 epoch total loss 1.10037148
Trained batch 1906 batch loss 0.942743778 epoch total loss 1.10028875
Trained batch 1907 batch loss 0.936635733 epoch total loss 1.10020292
Trained batch 1908 batch loss 0.983096 epoch total loss 1.10014153
Trained batch 1909 batch loss 0.981303573 epoch total loss 1.1000793
Trained batch 1910 batch loss 1.09973645 epoch total loss 1.10007918
Trained batch 1911 batch loss 1.08701587 epoch total loss 1.10007226
Trained batch 1912 batch loss 1.10736227 epoch total loss 1.10007608
Trained batch 1913 batch loss 1.23739362 epoch total loss 1.10014784
Trained batch 1914 batch loss 1.10311174 epoch total loss 1.10014927
Trained batch 1915 batch loss 1.0827024 epoch total loss 1.10014021
Trained batch 1916 batch loss 1.11573315 epoch total loss 1.10014832
Trained batch 1917 batch loss 1.00416231 epoch total loss 1.10009825
Trained batch 1918 batch loss 1.06033897 epoch total loss 1.10007751
Trained batch 1919 batch loss 0.953421354 epoch total loss 1.1000011
Trained batch 1920 batch loss 0.842707932 epoch total loss 1.09986711
Trained batch 1921 batch loss 0.950709343 epoch total loss 1.0997895
Trained batch 1922 batch loss 1.2161032 epoch total loss 1.09984994
Trained batch 1923 batch loss 1.06131792 epoch total loss 1.09982991
Trained batch 1924 batch loss 1.04398346 epoch total loss 1.09980083
Trained batch 1925 batch loss 0.97974205 epoch total loss 1.09973848
Trained batch 1926 batch loss 0.878513813 epoch total loss 1.09962356
Trained batch 1927 batch loss 1.14689422 epoch total loss 1.09964812
Trained batch 1928 batch loss 1.23231101 epoch total loss 1.09971702
Trained batch 1929 batch loss 1.2530371 epoch total loss 1.09979641
Trained batch 1930 batch loss 1.19837201 epoch total loss 1.09984756
Trained batch 1931 batch loss 1.29347706 epoch total loss 1.09994781
Trained batch 1932 batch loss 1.081653 epoch total loss 1.09993827
Trained batch 1933 batch loss 1.10919321 epoch total loss 1.09994304
Trained batch 1934 batch loss 1.24655271 epoch total loss 1.10001886
Trained batch 1935 batch loss 1.30224955 epoch total loss 1.10012341
Trained batch 1936 batch loss 1.21233404 epoch total loss 1.10018134
Trained batch 1937 batch loss 1.52910602 epoch total loss 1.10040283
Trained batch 1938 batch loss 1.05392933 epoch total loss 1.10037887
Trained batch 1939 batch loss 1.08806288 epoch total loss 1.10037255
Trained batch 1940 batch loss 1.29931521 epoch total loss 1.10047507
Trained batch 1941 batch loss 1.10024381 epoch total loss 1.10047495
Trained batch 1942 batch loss 1.24476492 epoch total loss 1.10054934
Trained batch 1943 batch loss 1.16562891 epoch total loss 1.10058284
Trained batch 1944 batch loss 1.06706381 epoch total loss 1.10056555
Trained batch 1945 batch loss 1.15094399 epoch total loss 1.10059142
Trained batch 1946 batch loss 1.15710223 epoch total loss 1.10062039
Trained batch 1947 batch loss 1.098876 epoch total loss 1.10061955
Trained batch 1948 batch loss 1.23287237 epoch total loss 1.1006875
Trained batch 1949 batch loss 1.01396298 epoch total loss 1.10064292
Trained batch 1950 batch loss 1.13802218 epoch total loss 1.10066211
Trained batch 1951 batch loss 1.30577517 epoch total loss 1.10076714
Trained batch 1952 batch loss 1.2920841 epoch total loss 1.10086513
Trained batch 1953 batch loss 1.27847922 epoch total loss 1.10095608
Trained batch 1954 batch loss 1.16950691 epoch total loss 1.10099113
Trained batch 1955 batch loss 0.935266554 epoch total loss 1.10090637
Trained batch 1956 batch loss 1.1299696 epoch total loss 1.10092115
Trained batch 1957 batch loss 1.00700915 epoch total loss 1.10087323
Trained batch 1958 batch loss 1.22212875 epoch total loss 1.10093522
Trained batch 1959 batch loss 1.06300902 epoch total loss 1.10091579
Trained batch 1960 batch loss 1.07363951 epoch total loss 1.10090196
Trained batch 1961 batch loss 0.909148335 epoch total loss 1.10080421
Trained batch 1962 batch loss 1.22958946 epoch total loss 1.10086977
Trained batch 1963 batch loss 1.23576808 epoch total loss 1.10093856
Trained batch 1964 batch loss 1.2283392 epoch total loss 1.10100341
Trained batch 1965 batch loss 0.959465086 epoch total loss 1.10093129
Trained batch 1966 batch loss 1.04642117 epoch total loss 1.10090363
Trained batch 1967 batch loss 0.991139412 epoch total loss 1.10084784
Trained batch 1968 batch loss 0.934603214 epoch total loss 1.10076332
Trained batch 1969 batch loss 0.996245623 epoch total loss 1.10071027
Trained batch 1970 batch loss 0.974759579 epoch total loss 1.10064638
Trained batch 1971 batch loss 0.895635962 epoch total loss 1.10054243
Trained batch 1972 batch loss 0.955028832 epoch total loss 1.10046875
Trained batch 1973 batch loss 1.11309767 epoch total loss 1.10047507
Trained batch 1974 batch loss 1.17229962 epoch total loss 1.10051143
Trained batch 1975 batch loss 1.43150759 epoch total loss 1.10067904
Trained batch 1976 batch loss 0.980625689 epoch total loss 1.10061836
Trained batch 1977 batch loss 1.24731183 epoch total loss 1.10069251
Trained batch 1978 batch loss 1.18801546 epoch total loss 1.10073662
Trained batch 1979 batch loss 0.947834432 epoch total loss 1.10065937
Trained batch 1980 batch loss 0.941841841 epoch total loss 1.10057914
Trained batch 1981 batch loss 0.949399948 epoch total loss 1.10050285
Trained batch 1982 batch loss 1.035905 epoch total loss 1.1004703
Trained batch 1983 batch loss 1.17672253 epoch total loss 1.10050869
Trained batch 1984 batch loss 0.952895224 epoch total loss 1.1004343
Trained batch 1985 batch loss 1.04129088 epoch total loss 1.1004045
Trained batch 1986 batch loss 1.07604337 epoch total loss 1.10039222
Trained batch 1987 batch loss 0.989627182 epoch total loss 1.10033655
Trained batch 1988 batch loss 0.864870548 epoch total loss 1.10021818
Trained batch 1989 batch loss 1.02092218 epoch total loss 1.10017824
Trained batch 1990 batch loss 1.06282949 epoch total loss 1.10015953
Trained batch 1991 batch loss 1.23490334 epoch total loss 1.10022712
Trained batch 1992 batch loss 1.01483238 epoch total loss 1.10018432
Trained batch 1993 batch loss 1.12161708 epoch total loss 1.10019505
Trained batch 1994 batch loss 0.940717816 epoch total loss 1.10011506
Trained batch 1995 batch loss 0.881206512 epoch total loss 1.10000527
Trained batch 1996 batch loss 1.08004332 epoch total loss 1.09999526
Trained batch 1997 batch loss 0.795960784 epoch total loss 1.09984303
Trained batch 1998 batch loss 1.07410431 epoch total loss 1.09983015
Trained batch 1999 batch loss 0.983496904 epoch total loss 1.09977198
Trained batch 2000 batch loss 0.879461646 epoch total loss 1.09966171
Trained batch 2001 batch loss 1.03019691 epoch total loss 1.09962702
Trained batch 2002 batch loss 0.920148075 epoch total loss 1.09953737
Trained batch 2003 batch loss 1.14361417 epoch total loss 1.09955943
Trained batch 2004 batch loss 1.06017303 epoch total loss 1.09953964
Trained batch 2005 batch loss 1.17523026 epoch total loss 1.09957743
Trained batch 2006 batch loss 1.14742327 epoch total loss 1.09960139
Trained batch 2007 batch loss 1.08925962 epoch total loss 1.09959626
Trained batch 2008 batch loss 1.05649447 epoch total loss 1.09957469
Trained batch 2009 batch loss 0.885590076 epoch total loss 1.09946811
Trained batch 2010 batch loss 0.817747116 epoch total loss 1.09932792
Trained batch 2011 batch loss 1.18832552 epoch total loss 1.09937215
Trained batch 2012 batch loss 1.04191327 epoch total loss 1.09934366
Trained batch 2013 batch loss 1.27164769 epoch total loss 1.09942925
Trained batch 2014 batch loss 1.09508753 epoch total loss 1.0994271
Trained batch 2015 batch loss 1.1247716 epoch total loss 1.09943962
Trained batch 2016 batch loss 1.15395617 epoch total loss 1.09946668
Trained batch 2017 batch loss 1.10805559 epoch total loss 1.09947097
Trained batch 2018 batch loss 1.11617219 epoch total loss 1.09947932
Trained batch 2019 batch loss 1.18691635 epoch total loss 1.09952271
Trained batch 2020 batch loss 1.20896769 epoch total loss 1.09957683
Trained batch 2021 batch loss 1.08577859 epoch total loss 1.09957
Trained batch 2022 batch loss 1.12942243 epoch total loss 1.0995847
Trained batch 2023 batch loss 1.01308727 epoch total loss 1.09954202
Trained batch 2024 batch loss 1.15626049 epoch total loss 1.09957
Trained batch 2025 batch loss 1.03320754 epoch total loss 1.09953725
Trained batch 2026 batch loss 1.08590913 epoch total loss 1.09953058
Trained batch 2027 batch loss 1.17382514 epoch total loss 1.09956717
Trained batch 2028 batch loss 0.993443549 epoch total loss 1.09951484
Trained batch 2029 batch loss 1.29509616 epoch total loss 1.09961128
Trained batch 2030 batch loss 1.45178509 epoch total loss 1.09978485
Trained batch 2031 batch loss 1.23859322 epoch total loss 1.09985316
Trained batch 2032 batch loss 1.19946849 epoch total loss 1.09990215
Trained batch 2033 batch loss 1.14256263 epoch total loss 1.09992313
Trained batch 2034 batch loss 1.15795231 epoch total loss 1.09995174
Trained batch 2035 batch loss 1.27586508 epoch total loss 1.10003817
Trained batch 2036 batch loss 1.05285287 epoch total loss 1.10001493
Trained batch 2037 batch loss 1.20232201 epoch total loss 1.10006523
Trained batch 2038 batch loss 1.30366349 epoch total loss 1.10016513
Trained batch 2039 batch loss 1.26808786 epoch total loss 1.1002475
Trained batch 2040 batch loss 1.22098804 epoch total loss 1.10030663
Trained batch 2041 batch loss 1.24593389 epoch total loss 1.10037792
Trained batch 2042 batch loss 1.00725031 epoch total loss 1.10033238
Trained batch 2043 batch loss 0.991963 epoch total loss 1.10027933
Trained batch 2044 batch loss 1.02216375 epoch total loss 1.10024107
Trained batch 2045 batch loss 1.13047862 epoch total loss 1.10025585
Trained batch 2046 batch loss 1.12734938 epoch total loss 1.10026908
Trained batch 2047 batch loss 0.897537589 epoch total loss 1.10017
Trained batch 2048 batch loss 0.908049881 epoch total loss 1.1000762
Trained batch 2049 batch loss 1.16802669 epoch total loss 1.10010934
Trained batch 2050 batch loss 0.969332159 epoch total loss 1.10004544
Trained batch 2051 batch loss 0.877040267 epoch total loss 1.09993672
Trained batch 2052 batch loss 0.847512126 epoch total loss 1.0998137
Trained batch 2053 batch loss 0.935413837 epoch total loss 1.09973347
Trained batch 2054 batch loss 1.38511348 epoch total loss 1.09987247
Trained batch 2055 batch loss 1.26473069 epoch total loss 1.09995258
Trained batch 2056 batch loss 0.959457755 epoch total loss 1.09988427
Trained batch 2057 batch loss 1.28273 epoch total loss 1.0999732
Trained batch 2058 batch loss 1.20569372 epoch total loss 1.10002458
Trained batch 2059 batch loss 1.07837701 epoch total loss 1.10001409
Trained batch 2060 batch loss 0.958432436 epoch total loss 1.09994531
Trained batch 2061 batch loss 1.12839103 epoch total loss 1.09995914
Trained batch 2062 batch loss 1.39783454 epoch total loss 1.10010374
Trained batch 2063 batch loss 1.52647328 epoch total loss 1.10031033
Trained batch 2064 batch loss 1.35870242 epoch total loss 1.1004355
Trained batch 2065 batch loss 1.25910449 epoch total loss 1.10051227
Trained batch 2066 batch loss 0.981749296 epoch total loss 1.10045481
Trained batch 2067 batch loss 1.26791644 epoch total loss 1.10053575
Trained batch 2068 batch loss 1.1984 epoch total loss 1.10058308
Trained batch 2069 batch loss 1.31402051 epoch total loss 1.10068619
Trained batch 2070 batch loss 1.24695075 epoch total loss 1.100757
Trained batch 2071 batch loss 1.20278525 epoch total loss 1.10080624
Trained batch 2072 batch loss 1.28981328 epoch total loss 1.10089743
Trained batch 2073 batch loss 0.841155112 epoch total loss 1.10077214
Trained batch 2074 batch loss 0.814151227 epoch total loss 1.10063398
Trained batch 2075 batch loss 0.961033523 epoch total loss 1.10056663
Trained batch 2076 batch loss 0.887234807 epoch total loss 1.10046387
Trained batch 2077 batch loss 0.985557079 epoch total loss 1.10040855
Trained batch 2078 batch loss 1.03240919 epoch total loss 1.10037589
Trained batch 2079 batch loss 1.08883417 epoch total loss 1.10037029
Trained batch 2080 batch loss 1.29285657 epoch total loss 1.10046291
Trained batch 2081 batch loss 1.17029953 epoch total loss 1.10049653
Trained batch 2082 batch loss 1.09393 epoch total loss 1.10049343
Trained batch 2083 batch loss 1.05025589 epoch total loss 1.10046935
Trained batch 2084 batch loss 1.10034513 epoch total loss 1.10046923
Trained batch 2085 batch loss 0.998451829 epoch total loss 1.10042036
Trained batch 2086 batch loss 1.17335403 epoch total loss 1.10045528
Trained batch 2087 batch loss 1.34705138 epoch total loss 1.10057354
Trained batch 2088 batch loss 1.05148721 epoch total loss 1.10055
Trained batch 2089 batch loss 1.16655695 epoch total loss 1.10058165
Trained batch 2090 batch loss 1.12144244 epoch total loss 1.10059154
Trained batch 2091 batch loss 1.01832938 epoch total loss 1.1005522
Trained batch 2092 batch loss 1.18616664 epoch total loss 1.10059321
Trained batch 2093 batch loss 1.26855206 epoch total loss 1.10067344
Trained batch 2094 batch loss 1.14291978 epoch total loss 1.10069358
Trained batch 2095 batch loss 1.1886692 epoch total loss 1.10073555
Trained batch 2096 batch loss 1.12417364 epoch total loss 1.10074675
Trained batch 2097 batch loss 1.00513077 epoch total loss 1.10070121
Trained batch 2098 batch loss 1.01308799 epoch total loss 1.10065949
Trained batch 2099 batch loss 1.15475368 epoch total loss 1.10068524
Trained batch 2100 batch loss 1.13002801 epoch total loss 1.10069931
Trained batch 2101 batch loss 1.54024553 epoch total loss 1.10090852
Trained batch 2102 batch loss 1.50796437 epoch total loss 1.10110223
Trained batch 2103 batch loss 1.60897982 epoch total loss 1.10134363
Trained batch 2104 batch loss 1.41143274 epoch total loss 1.10149097
Trained batch 2105 batch loss 1.21540093 epoch total loss 1.1015451
Trained batch 2106 batch loss 1.2692914 epoch total loss 1.10162473
Trained batch 2107 batch loss 1.50917888 epoch total loss 1.1018182
Trained batch 2108 batch loss 1.32772732 epoch total loss 1.10192537
Trained batch 2109 batch loss 1.09478 epoch total loss 1.10192192
Trained batch 2110 batch loss 0.956601739 epoch total loss 1.10185301
Trained batch 2111 batch loss 1.01284504 epoch total loss 1.10181093
Trained batch 2112 batch loss 1.13124084 epoch total loss 1.10182488
Trained batch 2113 batch loss 0.960802794 epoch total loss 1.10175812
Trained batch 2114 batch loss 1.14426386 epoch total loss 1.10177827
Trained batch 2115 batch loss 1.19602728 epoch total loss 1.10182285
Trained batch 2116 batch loss 0.895637155 epoch total loss 1.10172546
Trained batch 2117 batch loss 0.972368896 epoch total loss 1.1016643
Trained batch 2118 batch loss 0.94798255 epoch total loss 1.10159183
Trained batch 2119 batch loss 0.682852864 epoch total loss 1.10139418
Trained batch 2120 batch loss 0.798352599 epoch total loss 1.10125124
Trained batch 2121 batch loss 0.745149791 epoch total loss 1.10108328
Trained batch 2122 batch loss 0.717199922 epoch total loss 1.10090244
Trained batch 2123 batch loss 0.781250119 epoch total loss 1.10075188
Trained batch 2124 batch loss 0.787543178 epoch total loss 1.10060441
Trained batch 2125 batch loss 1.05341196 epoch total loss 1.10058224
Trained batch 2126 batch loss 1.1959517 epoch total loss 1.10062718
Trained batch 2127 batch loss 1.01457214 epoch total loss 1.10058677
Trained batch 2128 batch loss 1.17470801 epoch total loss 1.10062158
Trained batch 2129 batch loss 1.22502089 epoch total loss 1.10068011
Trained batch 2130 batch loss 0.833594918 epoch total loss 1.1005547
Trained batch 2131 batch loss 1.07090259 epoch total loss 1.10054064
Trained batch 2132 batch loss 0.909105539 epoch total loss 1.10045087
Trained batch 2133 batch loss 0.690395474 epoch total loss 1.10025871
Trained batch 2134 batch loss 0.69101572 epoch total loss 1.1000669
Trained batch 2135 batch loss 0.766022325 epoch total loss 1.0999105
Trained batch 2136 batch loss 0.673136 epoch total loss 1.09971058
Trained batch 2137 batch loss 0.727309942 epoch total loss 1.09953642
Trained batch 2138 batch loss 0.822903156 epoch total loss 1.09940708
Trained batch 2139 batch loss 0.859429777 epoch total loss 1.09929478
Trained batch 2140 batch loss 0.79908812 epoch total loss 1.09915447
Trained batch 2141 batch loss 0.848109603 epoch total loss 1.09903729
Trained batch 2142 batch loss 0.968033791 epoch total loss 1.09897614
Trained batch 2143 batch loss 0.719124496 epoch total loss 1.09879887
Trained batch 2144 batch loss 0.929855347 epoch total loss 1.09872019
Trained batch 2145 batch loss 1.01463604 epoch total loss 1.09868097
Trained batch 2146 batch loss 1.07720888 epoch total loss 1.09867096
Trained batch 2147 batch loss 0.944657743 epoch total loss 1.0985992
Trained batch 2148 batch loss 0.947876334 epoch total loss 1.0985291
Trained batch 2149 batch loss 1.11417222 epoch total loss 1.09853637
Trained batch 2150 batch loss 1.18607473 epoch total loss 1.09857702
Trained batch 2151 batch loss 1.0325017 epoch total loss 1.09854627
Trained batch 2152 batch loss 0.845288038 epoch total loss 1.09842861
Trained batch 2153 batch loss 0.819126546 epoch total loss 1.09829891
Trained batch 2154 batch loss 1.02394319 epoch total loss 1.09826434
Trained batch 2155 batch loss 1.18372774 epoch total loss 1.09830403
Trained batch 2156 batch loss 1.34819365 epoch total loss 1.0984199
Trained batch 2157 batch loss 1.07047057 epoch total loss 1.09840703
Trained batch 2158 batch loss 1.05786633 epoch total loss 1.0983882
Trained batch 2159 batch loss 1.0435034 epoch total loss 1.0983628
Trained batch 2160 batch loss 0.882444 epoch total loss 1.09826279
Trained batch 2161 batch loss 1.26287961 epoch total loss 1.09833896
Trained batch 2162 batch loss 1.16612577 epoch total loss 1.09837031
Trained batch 2163 batch loss 1.07481492 epoch total loss 1.09835935
Trained batch 2164 batch loss 1.20929778 epoch total loss 1.09841061
Trained batch 2165 batch loss 0.947201967 epoch total loss 1.09834075
Trained batch 2166 batch loss 1.22898185 epoch total loss 1.09840107
Trained batch 2167 batch loss 1.19969296 epoch total loss 1.0984478
Trained batch 2168 batch loss 1.03332317 epoch total loss 1.09841776
Trained batch 2169 batch loss 1.2954669 epoch total loss 1.0985086
Trained batch 2170 batch loss 1.17515731 epoch total loss 1.09854376
Trained batch 2171 batch loss 1.19628382 epoch total loss 1.09858882
Trained batch 2172 batch loss 0.866257489 epoch total loss 1.09848189
Trained batch 2173 batch loss 1.1187458 epoch total loss 1.09849119
Trained batch 2174 batch loss 1.14559376 epoch total loss 1.09851277
Trained batch 2175 batch loss 1.06480598 epoch total loss 1.09849727
Trained batch 2176 batch loss 1.05483675 epoch total loss 1.09847724
Trained batch 2177 batch loss 1.07950008 epoch total loss 1.09846854
Trained batch 2178 batch loss 0.983635426 epoch total loss 1.09841585
Trained batch 2179 batch loss 1.25661075 epoch total loss 1.09848833
Trained batch 2180 batch loss 1.25589728 epoch total loss 1.09856057
Trained batch 2181 batch loss 1.16420746 epoch total loss 1.09859073
Trained batch 2182 batch loss 0.886193812 epoch total loss 1.09849346
Trained batch 2183 batch loss 1.13740945 epoch total loss 1.09851122
Trained batch 2184 batch loss 0.916752458 epoch total loss 1.09842801
Trained batch 2185 batch loss 1.06118178 epoch total loss 1.09841096
Trained batch 2186 batch loss 1.02772093 epoch total loss 1.09837878
Trained batch 2187 batch loss 1.10697126 epoch total loss 1.09838259
Trained batch 2188 batch loss 1.1368916 epoch total loss 1.09840024
Trained batch 2189 batch loss 0.842634201 epoch total loss 1.09828341
Trained batch 2190 batch loss 1.07588506 epoch total loss 1.09827316
Trained batch 2191 batch loss 0.962016165 epoch total loss 1.09821093
Trained batch 2192 batch loss 1.28952932 epoch total loss 1.09829819
Trained batch 2193 batch loss 1.24076748 epoch total loss 1.09836316
Trained batch 2194 batch loss 1.17313719 epoch total loss 1.09839725
Trained batch 2195 batch loss 1.00212216 epoch total loss 1.09835339
Trained batch 2196 batch loss 0.916935086 epoch total loss 1.09827077
Trained batch 2197 batch loss 1.13650513 epoch total loss 1.09828818
Trained batch 2198 batch loss 0.950873315 epoch total loss 1.09822118
Trained batch 2199 batch loss 0.854394078 epoch total loss 1.09811032
Trained batch 2200 batch loss 0.816759288 epoch total loss 1.09798241
Trained batch 2201 batch loss 1.00675261 epoch total loss 1.09794104
Trained batch 2202 batch loss 1.1847955 epoch total loss 1.0979805
Trained batch 2203 batch loss 1.07943952 epoch total loss 1.09797204
Trained batch 2204 batch loss 1.02685416 epoch total loss 1.09793973
Trained batch 2205 batch loss 1.18149686 epoch total loss 1.09797752
Trained batch 2206 batch loss 1.01437724 epoch total loss 1.09793973
Trained batch 2207 batch loss 0.991327405 epoch total loss 1.09789133
Trained batch 2208 batch loss 0.964928627 epoch total loss 1.09783101
Trained batch 2209 batch loss 1.03077948 epoch total loss 1.09780073
Trained batch 2210 batch loss 1.29351962 epoch total loss 1.09788918
Trained batch 2211 batch loss 0.877398372 epoch total loss 1.09778953
Trained batch 2212 batch loss 0.888515949 epoch total loss 1.09769487
Trained batch 2213 batch loss 0.876334548 epoch total loss 1.09759486
Trained batch 2214 batch loss 1.10926366 epoch total loss 1.0976001
Trained batch 2215 batch loss 1.07000101 epoch total loss 1.0975877
Trained batch 2216 batch loss 1.00200224 epoch total loss 1.09754455
Trained batch 2217 batch loss 1.080755 epoch total loss 1.09753704
Trained batch 2218 batch loss 0.946039796 epoch total loss 1.09746873
Trained batch 2219 batch loss 0.976968408 epoch total loss 1.09741437
Trained batch 2220 batch loss 0.828921676 epoch total loss 1.0972935
Trained batch 2221 batch loss 1.26874018 epoch total loss 1.09737062
Trained batch 2222 batch loss 0.883817315 epoch total loss 1.09727454
Trained batch 2223 batch loss 1.20780909 epoch total loss 1.09732425
Trained batch 2224 batch loss 0.988753319 epoch total loss 1.0972755
Trained batch 2225 batch loss 1.24901009 epoch total loss 1.09734368
Trained batch 2226 batch loss 1.22365689 epoch total loss 1.09740043
Trained batch 2227 batch loss 1.11421716 epoch total loss 1.09740794
Trained batch 2228 batch loss 1.15320563 epoch total loss 1.09743309
Trained batch 2229 batch loss 1.06564665 epoch total loss 1.09741879
Trained batch 2230 batch loss 1.20165396 epoch total loss 1.09746552
Trained batch 2231 batch loss 1.08986568 epoch total loss 1.09746218
Trained batch 2232 batch loss 1.02282834 epoch total loss 1.09742868
Trained batch 2233 batch loss 1.14544964 epoch total loss 1.09745026
Trained batch 2234 batch loss 1.07335794 epoch total loss 1.09743941
Trained batch 2235 batch loss 1.10743737 epoch total loss 1.09744394
Trained batch 2236 batch loss 1.08330393 epoch total loss 1.0974375
Trained batch 2237 batch loss 1.17550695 epoch total loss 1.09747243
Trained batch 2238 batch loss 1.12773299 epoch total loss 1.09748602
Trained batch 2239 batch loss 1.33858192 epoch total loss 1.09759367
Trained batch 2240 batch loss 1.23200178 epoch total loss 1.09765363
Trained batch 2241 batch loss 1.16679716 epoch total loss 1.0976845
Trained batch 2242 batch loss 1.11472654 epoch total loss 1.09769213
Trained batch 2243 batch loss 1.1684581 epoch total loss 1.0977236
Trained batch 2244 batch loss 1.27699447 epoch total loss 1.09780359
Trained batch 2245 batch loss 1.13903606 epoch total loss 1.09782183
Trained batch 2246 batch loss 1.20389497 epoch total loss 1.09786904
Trained batch 2247 batch loss 1.22360611 epoch total loss 1.09792507
Trained batch 2248 batch loss 1.13159108 epoch total loss 1.09794009
Trained batch 2249 batch loss 1.29468751 epoch total loss 1.09802747
Trained batch 2250 batch loss 1.1127317 epoch total loss 1.09803402
Trained batch 2251 batch loss 1.18670678 epoch total loss 1.09807348
Trained batch 2252 batch loss 1.12629473 epoch total loss 1.098086
Trained batch 2253 batch loss 1.23666251 epoch total loss 1.09814751
Trained batch 2254 batch loss 1.11730433 epoch total loss 1.09815586
Trained batch 2255 batch loss 1.06030941 epoch total loss 1.09813917
Trained batch 2256 batch loss 0.833083808 epoch total loss 1.09802163
Trained batch 2257 batch loss 0.987933218 epoch total loss 1.09797287
Trained batch 2258 batch loss 1.17326307 epoch total loss 1.09800625
Trained batch 2259 batch loss 1.10281527 epoch total loss 1.09800839
Trained batch 2260 batch loss 1.0648942 epoch total loss 1.09799373
Trained batch 2261 batch loss 1.04748774 epoch total loss 1.09797144
Trained batch 2262 batch loss 1.07885742 epoch total loss 1.09796298
Trained batch 2263 batch loss 1.02123868 epoch total loss 1.09792912
Trained batch 2264 batch loss 0.993511558 epoch total loss 1.09788287
Trained batch 2265 batch loss 0.905239 epoch total loss 1.09779787
Trained batch 2266 batch loss 1.05158973 epoch total loss 1.09777749
Trained batch 2267 batch loss 0.975615263 epoch total loss 1.0977236
Trained batch 2268 batch loss 0.739976764 epoch total loss 1.09756577
Trained batch 2269 batch loss 1.08934283 epoch total loss 1.09756219
Trained batch 2270 batch loss 1.05564547 epoch total loss 1.09754372
Trained batch 2271 batch loss 0.971740484 epoch total loss 1.09748828
Trained batch 2272 batch loss 0.968943834 epoch total loss 1.09743178
Trained batch 2273 batch loss 1.02167916 epoch total loss 1.09739852
Trained batch 2274 batch loss 0.941347361 epoch total loss 1.09732985
Trained batch 2275 batch loss 0.86894536 epoch total loss 1.09722948
Trained batch 2276 batch loss 1.04096651 epoch total loss 1.0972048
Trained batch 2277 batch loss 1.08522534 epoch total loss 1.09719944
Trained batch 2278 batch loss 0.91714114 epoch total loss 1.09712052
Trained batch 2279 batch loss 0.788582683 epoch total loss 1.0969851
Trained batch 2280 batch loss 0.981400073 epoch total loss 1.09693444
Trained batch 2281 batch loss 0.843386769 epoch total loss 1.09682333
Trained batch 2282 batch loss 0.771101177 epoch total loss 1.09668052
Trained batch 2283 batch loss 0.942175031 epoch total loss 1.09661281
Trained batch 2284 batch loss 1.19081211 epoch total loss 1.09665418
Trained batch 2285 batch loss 1.03174496 epoch total loss 1.09662569
Trained batch 2286 batch loss 0.959267 epoch total loss 1.0965656
Trained batch 2287 batch loss 0.85430038 epoch total loss 1.09645963
Trained batch 2288 batch loss 1.07324278 epoch total loss 1.09644949
Trained batch 2289 batch loss 1.08254421 epoch total loss 1.09644341
Trained batch 2290 batch loss 1.11147869 epoch total loss 1.09645009
Trained batch 2291 batch loss 0.946532369 epoch total loss 1.09638464
Trained batch 2292 batch loss 1.06345272 epoch total loss 1.09637022
Trained batch 2293 batch loss 0.82057035 epoch total loss 1.09624994
Trained batch 2294 batch loss 0.784609258 epoch total loss 1.09611416
Trained batch 2295 batch loss 1.23084307 epoch total loss 1.09617293
Trained batch 2296 batch loss 0.818518698 epoch total loss 1.09605205
Trained batch 2297 batch loss 0.94249928 epoch total loss 1.09598505
Trained batch 2298 batch loss 0.972558141 epoch total loss 1.09593141
Trained batch 2299 batch loss 0.886920571 epoch total loss 1.09584057
Trained batch 2300 batch loss 0.863859415 epoch total loss 1.0957396
Trained batch 2301 batch loss 1.12574923 epoch total loss 1.09575272
Trained batch 2302 batch loss 0.986183047 epoch total loss 1.09570503
Trained batch 2303 batch loss 1.01176953 epoch total loss 1.09566855
Trained batch 2304 batch loss 0.844230533 epoch total loss 1.09555948
Trained batch 2305 batch loss 1.08974886 epoch total loss 1.09555697
Trained batch 2306 batch loss 0.819181144 epoch total loss 1.09543705
Trained batch 2307 batch loss 0.82088995 epoch total loss 1.09531808
Trained batch 2308 batch loss 1.22419167 epoch total loss 1.09537387
Trained batch 2309 batch loss 1.36271977 epoch total loss 1.09548962
Trained batch 2310 batch loss 1.23000145 epoch total loss 1.09554791
Trained batch 2311 batch loss 1.5019753 epoch total loss 1.09572375
Trained batch 2312 batch loss 1.16211653 epoch total loss 1.09575248
Trained batch 2313 batch loss 1.5721792 epoch total loss 1.09595847
Trained batch 2314 batch loss 1.5223341 epoch total loss 1.09614265
Trained batch 2315 batch loss 1.19017351 epoch total loss 1.0961833
Trained batch 2316 batch loss 1.11349297 epoch total loss 1.09619081
Trained batch 2317 batch loss 1.05981064 epoch total loss 1.09617507
Trained batch 2318 batch loss 1.0284642 epoch total loss 1.09614587
Trained batch 2319 batch loss 0.951816797 epoch total loss 1.09608376
Trained batch 2320 batch loss 1.1181488 epoch total loss 1.09609318
Trained batch 2321 batch loss 1.05214965 epoch total loss 1.09607434
Trained batch 2322 batch loss 1.12723219 epoch total loss 1.09608769
Trained batch 2323 batch loss 1.32993591 epoch total loss 1.09618831
Trained batch 2324 batch loss 1.06181538 epoch total loss 1.09617352
Trained batch 2325 batch loss 1.30198526 epoch total loss 1.0962621
Trained batch 2326 batch loss 1.27669764 epoch total loss 1.09633958
Trained batch 2327 batch loss 1.19661164 epoch total loss 1.09638262
Trained batch 2328 batch loss 1.08486128 epoch total loss 1.09637773
Trained batch 2329 batch loss 1.19934785 epoch total loss 1.09642208
Trained batch 2330 batch loss 1.09866786 epoch total loss 1.09642303
Trained batch 2331 batch loss 1.02823651 epoch total loss 1.0963937
Trained batch 2332 batch loss 1.05635595 epoch total loss 1.09637666
Trained batch 2333 batch loss 1.11021066 epoch total loss 1.0963825
Trained batch 2334 batch loss 1.12840211 epoch total loss 1.09639621
Trained batch 2335 batch loss 1.25553751 epoch total loss 1.0964644
Trained batch 2336 batch loss 1.01487625 epoch total loss 1.09642947
Trained batch 2337 batch loss 1.21874332 epoch total loss 1.0964818
Trained batch 2338 batch loss 1.11187673 epoch total loss 1.09648836
Trained batch 2339 batch loss 0.880122125 epoch total loss 1.09639585
Trained batch 2340 batch loss 0.948557734 epoch total loss 1.09633267
Trained batch 2341 batch loss 0.851912379 epoch total loss 1.09622824
Trained batch 2342 batch loss 1.18360782 epoch total loss 1.09626555
Trained batch 2343 batch loss 0.936950266 epoch total loss 1.09619761
Trained batch 2344 batch loss 0.981558621 epoch total loss 1.09614861
Trained batch 2345 batch loss 1.19165874 epoch total loss 1.09618938
Trained batch 2346 batch loss 1.07080722 epoch total loss 1.09617853
Trained batch 2347 batch loss 1.14342785 epoch total loss 1.09619856
Trained batch 2348 batch loss 1.27586985 epoch total loss 1.09627509
Trained batch 2349 batch loss 1.05338013 epoch total loss 1.09625685
Trained batch 2350 batch loss 1.11228812 epoch total loss 1.09626377
Trained batch 2351 batch loss 1.17543936 epoch total loss 1.09629738
Trained batch 2352 batch loss 1.08551109 epoch total loss 1.09629285
Trained batch 2353 batch loss 1.11588025 epoch total loss 1.0963012
Trained batch 2354 batch loss 0.654759526 epoch total loss 1.09611356
Trained batch 2355 batch loss 0.885086894 epoch total loss 1.09602404
Trained batch 2356 batch loss 0.893314958 epoch total loss 1.09593797
Trained batch 2357 batch loss 0.887439 epoch total loss 1.09584951
Trained batch 2358 batch loss 0.893102884 epoch total loss 1.09576344
Trained batch 2359 batch loss 0.917218089 epoch total loss 1.09568787
Trained batch 2360 batch loss 1.0418036 epoch total loss 1.09566498
Trained batch 2361 batch loss 1.05189824 epoch total loss 1.0956465
Trained batch 2362 batch loss 0.950580776 epoch total loss 1.09558511
Trained batch 2363 batch loss 0.960813284 epoch total loss 1.09552801
Trained batch 2364 batch loss 1.0769974 epoch total loss 1.09552014
Trained batch 2365 batch loss 0.883123517 epoch total loss 1.09543025
Trained batch 2366 batch loss 0.922989786 epoch total loss 1.09535742
Trained batch 2367 batch loss 1.00049043 epoch total loss 1.09531736
Trained batch 2368 batch loss 0.921302199 epoch total loss 1.09524393
Trained batch 2369 batch loss 1.07474768 epoch total loss 1.09523523
Trained batch 2370 batch loss 1.10631323 epoch total loss 1.09523988
Trained batch 2371 batch loss 0.758645058 epoch total loss 1.0950979
Trained batch 2372 batch loss 0.819494247 epoch total loss 1.09498167
Trained batch 2373 batch loss 1.0269134 epoch total loss 1.09495306
Trained batch 2374 batch loss 1.14268732 epoch total loss 1.09497309
Trained batch 2375 batch loss 0.7856251 epoch total loss 1.09484279
Trained batch 2376 batch loss 1.10286736 epoch total loss 1.09484613
Trained batch 2377 batch loss 0.867544 epoch total loss 1.09475052
Trained batch 2378 batch loss 1.1236428 epoch total loss 1.09476256
Trained batch 2379 batch loss 0.95774579 epoch total loss 1.09470499
Trained batch 2380 batch loss 0.915177286 epoch total loss 1.09462965
Trained batch 2381 batch loss 1.13193655 epoch total loss 1.09464526
Trained batch 2382 batch loss 1.19361305 epoch total loss 1.09468675
Trained batch 2383 batch loss 1.04483676 epoch total loss 1.09466588
Trained batch 2384 batch loss 1.06445575 epoch total loss 1.09465325
Trained batch 2385 batch loss 1.08283114 epoch total loss 1.09464824
Trained batch 2386 batch loss 1.04402852 epoch total loss 1.09462702
Trained batch 2387 batch loss 0.918564081 epoch total loss 1.09455323
Trained batch 2388 batch loss 0.896769524 epoch total loss 1.09447038
Trained batch 2389 batch loss 1.09142041 epoch total loss 1.09446907
Trained batch 2390 batch loss 0.731779039 epoch total loss 1.0943172
Trained batch 2391 batch loss 0.876725078 epoch total loss 1.09422624
Trained batch 2392 batch loss 1.05570412 epoch total loss 1.09421015
Trained batch 2393 batch loss 1.13447285 epoch total loss 1.09422696
Trained batch 2394 batch loss 1.22732139 epoch total loss 1.09428251
Trained batch 2395 batch loss 1.03798831 epoch total loss 1.09425902
Trained batch 2396 batch loss 1.11755395 epoch total loss 1.0942688
Trained batch 2397 batch loss 1.06404817 epoch total loss 1.09425616
Trained batch 2398 batch loss 1.0396229 epoch total loss 1.09423339
Trained batch 2399 batch loss 1.2205596 epoch total loss 1.09428596
Trained batch 2400 batch loss 1.37267363 epoch total loss 1.09440196
Trained batch 2401 batch loss 0.915047824 epoch total loss 1.09432721
Trained batch 2402 batch loss 1.28864646 epoch total loss 1.09440815
Trained batch 2403 batch loss 1.00601745 epoch total loss 1.09437132
Trained batch 2404 batch loss 0.99933207 epoch total loss 1.09433186
Trained batch 2405 batch loss 1.22821665 epoch total loss 1.09438753
Trained batch 2406 batch loss 1.21913481 epoch total loss 1.09443939
Trained batch 2407 batch loss 1.0937773 epoch total loss 1.09443915
Trained batch 2408 batch loss 1.2578609 epoch total loss 1.09450698
Trained batch 2409 batch loss 1.26225638 epoch total loss 1.0945766
Trained batch 2410 batch loss 1.06506562 epoch total loss 1.09456432
Trained batch 2411 batch loss 1.13678849 epoch total loss 1.09458184
Trained batch 2412 batch loss 0.957239628 epoch total loss 1.09452498
Trained batch 2413 batch loss 0.847457826 epoch total loss 1.09442258
Trained batch 2414 batch loss 0.889621854 epoch total loss 1.0943377
Trained batch 2415 batch loss 1.07074964 epoch total loss 1.09432793
Trained batch 2416 batch loss 1.21381593 epoch total loss 1.0943774
Trained batch 2417 batch loss 1.13139153 epoch total loss 1.09439278
Trained batch 2418 batch loss 1.08515549 epoch total loss 1.09438896
Trained batch 2419 batch loss 0.989348769 epoch total loss 1.09434545
Trained batch 2420 batch loss 0.860946298 epoch total loss 1.09424901
Trained batch 2421 batch loss 1.05544555 epoch total loss 1.09423292
Trained batch 2422 batch loss 1.10319817 epoch total loss 1.09423661
Trained batch 2423 batch loss 1.24122834 epoch total loss 1.09429729
Trained batch 2424 batch loss 1.1008724 epoch total loss 1.0943
Trained batch 2425 batch loss 0.871692777 epoch total loss 1.09420812
Trained batch 2426 batch loss 1.17372918 epoch total loss 1.09424102
Trained batch 2427 batch loss 0.992052257 epoch total loss 1.09419882
Trained batch 2428 batch loss 0.917820275 epoch total loss 1.09412622
Trained batch 2429 batch loss 0.906528413 epoch total loss 1.09404898
Trained batch 2430 batch loss 0.820229292 epoch total loss 1.09393632
Trained batch 2431 batch loss 0.934661627 epoch total loss 1.09387076
Trained batch 2432 batch loss 0.920539081 epoch total loss 1.09379947
Trained batch 2433 batch loss 0.904553771 epoch total loss 1.09372175
Trained batch 2434 batch loss 0.732383549 epoch total loss 1.09357321
Trained batch 2435 batch loss 0.862209439 epoch total loss 1.09347832
Trained batch 2436 batch loss 0.997523546 epoch total loss 1.09343886
Trained batch 2437 batch loss 1.14511847 epoch total loss 1.09346008
Trained batch 2438 batch loss 1.2046591 epoch total loss 1.09350562
Trained batch 2439 batch loss 1.0619427 epoch total loss 1.09349275
Trained batch 2440 batch loss 1.19807971 epoch total loss 1.09353554
Trained batch 2441 batch loss 1.34842384 epoch total loss 1.09364
Trained batch 2442 batch loss 1.25851858 epoch total loss 1.09370756
Trained batch 2443 batch loss 1.28343248 epoch total loss 1.09378517
Trained batch 2444 batch loss 1.19465864 epoch total loss 1.09382641
Trained batch 2445 batch loss 1.3236326 epoch total loss 1.09392047
Trained batch 2446 batch loss 1.0290004 epoch total loss 1.09389389
Trained batch 2447 batch loss 1.05926323 epoch total loss 1.09387982
Trained batch 2448 batch loss 1.33197355 epoch total loss 1.09397709
Trained batch 2449 batch loss 1.06711864 epoch total loss 1.09396613
Trained batch 2450 batch loss 1.45132852 epoch total loss 1.09411204
Trained batch 2451 batch loss 1.03103209 epoch total loss 1.09408629
Trained batch 2452 batch loss 1.19308257 epoch total loss 1.0941267
Trained batch 2453 batch loss 1.1701349 epoch total loss 1.0941577
Trained batch 2454 batch loss 1.2370671 epoch total loss 1.09421587
Trained batch 2455 batch loss 0.973253727 epoch total loss 1.09416664
Trained batch 2456 batch loss 1.37027049 epoch total loss 1.09427905
Trained batch 2457 batch loss 1.4279654 epoch total loss 1.09441483
Trained batch 2458 batch loss 1.1793623 epoch total loss 1.0944494
Trained batch 2459 batch loss 1.27407265 epoch total loss 1.09452248
Trained batch 2460 batch loss 1.15871775 epoch total loss 1.09454858
Trained batch 2461 batch loss 1.14561129 epoch total loss 1.09456933
Trained batch 2462 batch loss 1.17279482 epoch total loss 1.09460115
Trained batch 2463 batch loss 1.22485447 epoch total loss 1.09465396
Trained batch 2464 batch loss 1.07756901 epoch total loss 1.09464705
Trained batch 2465 batch loss 0.900005698 epoch total loss 1.09456813
Trained batch 2466 batch loss 1.19348288 epoch total loss 1.09460831
Trained batch 2467 batch loss 1.17841733 epoch total loss 1.09464228
Trained batch 2468 batch loss 1.35552013 epoch total loss 1.0947479
Trained batch 2469 batch loss 1.37770176 epoch total loss 1.09486258
Trained batch 2470 batch loss 1.07587481 epoch total loss 1.09485483
Trained batch 2471 batch loss 1.16616309 epoch total loss 1.0948838
Trained batch 2472 batch loss 1.22879422 epoch total loss 1.09493792
Trained batch 2473 batch loss 1.29221082 epoch total loss 1.09501767
Trained batch 2474 batch loss 1.10912824 epoch total loss 1.09502339
Trained batch 2475 batch loss 0.888287902 epoch total loss 1.09493983
Trained batch 2476 batch loss 1.25439787 epoch total loss 1.0950042
Trained batch 2477 batch loss 1.05573905 epoch total loss 1.09498835
Trained batch 2478 batch loss 1.10855603 epoch total loss 1.09499383
Trained batch 2479 batch loss 0.863579154 epoch total loss 1.09490049
Trained batch 2480 batch loss 1.0404309 epoch total loss 1.09487855
Trained batch 2481 batch loss 0.936798811 epoch total loss 1.09481478
Trained batch 2482 batch loss 0.820850253 epoch total loss 1.09470439
Trained batch 2483 batch loss 1.04887319 epoch total loss 1.09468591
Trained batch 2484 batch loss 1.11707711 epoch total loss 1.09469497
Trained batch 2485 batch loss 0.937905133 epoch total loss 1.09463191
Trained batch 2486 batch loss 0.764136553 epoch total loss 1.09449899
Trained batch 2487 batch loss 0.730068445 epoch total loss 1.09435248
Trained batch 2488 batch loss 0.733613253 epoch total loss 1.09420753
Trained batch 2489 batch loss 0.976823211 epoch total loss 1.09416032
Trained batch 2490 batch loss 0.86866796 epoch total loss 1.09406972
Trained batch 2491 batch loss 0.966460586 epoch total loss 1.09401858
Trained batch 2492 batch loss 0.855266452 epoch total loss 1.09392273
Trained batch 2493 batch loss 1.11768103 epoch total loss 1.09393227
Trained batch 2494 batch loss 0.944229305 epoch total loss 1.09387231
Trained batch 2495 batch loss 1.06832385 epoch total loss 1.09386206
Trained batch 2496 batch loss 1.03666008 epoch total loss 1.09383905
Trained batch 2497 batch loss 1.01906371 epoch total loss 1.09380913
Trained batch 2498 batch loss 1.29635787 epoch total loss 1.09389019
Trained batch 2499 batch loss 1.24816871 epoch total loss 1.09395194
Trained batch 2500 batch loss 1.27058554 epoch total loss 1.09402251
Trained batch 2501 batch loss 1.12043023 epoch total loss 1.09403312
Trained batch 2502 batch loss 1.17379737 epoch total loss 1.09406495
Trained batch 2503 batch loss 1.03164542 epoch total loss 1.09404
Trained batch 2504 batch loss 1.08809328 epoch total loss 1.09403777
Trained batch 2505 batch loss 1.32771826 epoch total loss 1.09413099
Trained batch 2506 batch loss 0.977181494 epoch total loss 1.09408438
Trained batch 2507 batch loss 1.21796775 epoch total loss 1.09413373
Trained batch 2508 batch loss 1.2490555 epoch total loss 1.0941956
Trained batch 2509 batch loss 1.15837717 epoch total loss 1.09422112
Trained batch 2510 batch loss 1.21306539 epoch total loss 1.09426856
Trained batch 2511 batch loss 1.24839818 epoch total loss 1.09432983
Trained batch 2512 batch loss 1.25390863 epoch total loss 1.09439337
Trained batch 2513 batch loss 1.17583728 epoch total loss 1.0944258
Trained batch 2514 batch loss 1.00167823 epoch total loss 1.09438896
Trained batch 2515 batch loss 1.17345703 epoch total loss 1.09442031
Trained batch 2516 batch loss 0.901771426 epoch total loss 1.09434378
Trained batch 2517 batch loss 1.02275956 epoch total loss 1.09431529
Trained batch 2518 batch loss 1.29697704 epoch total loss 1.09439576
Trained batch 2519 batch loss 1.15025342 epoch total loss 1.09441793
Trained batch 2520 batch loss 1.33535624 epoch total loss 1.09451354
Trained batch 2521 batch loss 0.93093884 epoch total loss 1.09444857
Trained batch 2522 batch loss 1.03227282 epoch total loss 1.09442401
Trained batch 2523 batch loss 1.15914428 epoch total loss 1.09444964
Trained batch 2524 batch loss 1.19582963 epoch total loss 1.09448981
Trained batch 2525 batch loss 1.21867752 epoch total loss 1.09453893
Trained batch 2526 batch loss 1.09977317 epoch total loss 1.09454107
Trained batch 2527 batch loss 1.34686017 epoch total loss 1.09464097
Trained batch 2528 batch loss 1.24347544 epoch total loss 1.09469986
Trained batch 2529 batch loss 1.28361082 epoch total loss 1.09477448
Trained batch 2530 batch loss 1.38251 epoch total loss 1.09488833
Trained batch 2531 batch loss 1.17053878 epoch total loss 1.09491825
Trained batch 2532 batch loss 1.13637519 epoch total loss 1.09493458
Trained batch 2533 batch loss 0.978329 epoch total loss 1.09488857
Trained batch 2534 batch loss 0.967321634 epoch total loss 1.09483826
Trained batch 2535 batch loss 1.06568885 epoch total loss 1.0948267
Trained batch 2536 batch loss 1.15137982 epoch total loss 1.09484899
Trained batch 2537 batch loss 1.22119248 epoch total loss 1.09489882
Trained batch 2538 batch loss 1.05544329 epoch total loss 1.0948832
Trained batch 2539 batch loss 1.15726924 epoch total loss 1.09490776
Trained batch 2540 batch loss 1.32440948 epoch total loss 1.09499824
Trained batch 2541 batch loss 1.15356994 epoch total loss 1.09502125
Trained batch 2542 batch loss 1.28899693 epoch total loss 1.09509754
Trained batch 2543 batch loss 1.2761718 epoch total loss 1.09516871
Trained batch 2544 batch loss 1.14221108 epoch total loss 1.09518719
Trained batch 2545 batch loss 1.23645473 epoch total loss 1.09524274
Trained batch 2546 batch loss 1.14789224 epoch total loss 1.09526348
Trained batch 2547 batch loss 1.2160871 epoch total loss 1.09531093
Trained batch 2548 batch loss 1.21014869 epoch total loss 1.09535599
Trained batch 2549 batch loss 1.12763357 epoch total loss 1.09536862
Trained batch 2550 batch loss 1.10209799 epoch total loss 1.09537125
Trained batch 2551 batch loss 1.23534119 epoch total loss 1.0954262
Trained batch 2552 batch loss 1.20396471 epoch total loss 1.09546864
Trained batch 2553 batch loss 1.0222435 epoch total loss 1.09543991
Trained batch 2554 batch loss 1.06147885 epoch total loss 1.09542668
Trained batch 2555 batch loss 1.17416036 epoch total loss 1.09545743
Trained batch 2556 batch loss 1.15945518 epoch total loss 1.09548247
Trained batch 2557 batch loss 1.0378933 epoch total loss 1.09545994
Trained batch 2558 batch loss 1.2760849 epoch total loss 1.09553051
Trained batch 2559 batch loss 1.10371852 epoch total loss 1.09553373
Trained batch 2560 batch loss 1.22084117 epoch total loss 1.09558272
Trained batch 2561 batch loss 1.17566538 epoch total loss 1.09561408
Trained batch 2562 batch loss 1.25630021 epoch total loss 1.09567678
Trained batch 2563 batch loss 1.32582712 epoch total loss 1.09576666
Trained batch 2564 batch loss 1.13970721 epoch total loss 1.09578383
Trained batch 2565 batch loss 1.36180258 epoch total loss 1.09588754
Trained batch 2566 batch loss 1.31427062 epoch total loss 1.09597254
Trained batch 2567 batch loss 1.21365428 epoch total loss 1.09601843
Trained batch 2568 batch loss 1.13656735 epoch total loss 1.09603417
Trained batch 2569 batch loss 1.24249268 epoch total loss 1.09609115
Trained batch 2570 batch loss 1.15568304 epoch total loss 1.0961144
Trained batch 2571 batch loss 0.957412839 epoch total loss 1.09606051
Trained batch 2572 batch loss 1.03814387 epoch total loss 1.09603786
Trained batch 2573 batch loss 1.394418 epoch total loss 1.09615397
Trained batch 2574 batch loss 1.06660223 epoch total loss 1.09614241
Trained batch 2575 batch loss 1.17401958 epoch total loss 1.09617269
Trained batch 2576 batch loss 1.18144798 epoch total loss 1.09620583
Trained batch 2577 batch loss 1.10575354 epoch total loss 1.09620953
Trained batch 2578 batch loss 0.848078072 epoch total loss 1.09611332
Trained batch 2579 batch loss 0.990832686 epoch total loss 1.09607244
Trained batch 2580 batch loss 0.868576169 epoch total loss 1.09598422
Trained batch 2581 batch loss 0.872591197 epoch total loss 1.09589767
Trained batch 2582 batch loss 0.84000653 epoch total loss 1.09579861
Trained batch 2583 batch loss 0.798912168 epoch total loss 1.09568369
Trained batch 2584 batch loss 0.885786414 epoch total loss 1.09560239
Trained batch 2585 batch loss 0.948725581 epoch total loss 1.09554565
Trained batch 2586 batch loss 1.2031939 epoch total loss 1.09558713
Trained batch 2587 batch loss 1.15108061 epoch total loss 1.09560871
Trained batch 2588 batch loss 0.971118331 epoch total loss 1.09556055
Trained batch 2589 batch loss 0.830296397 epoch total loss 1.09545815
Trained batch 2590 batch loss 1.23641062 epoch total loss 1.09551251
Trained batch 2591 batch loss 1.1393317 epoch total loss 1.09552944
Trained batch 2592 batch loss 1.00261176 epoch total loss 1.09549367
Trained batch 2593 batch loss 1.13008046 epoch total loss 1.09550703
Trained batch 2594 batch loss 1.01942635 epoch total loss 1.0954777
Trained batch 2595 batch loss 1.04048657 epoch total loss 1.09545648
Trained batch 2596 batch loss 1.42186451 epoch total loss 1.09558225
Trained batch 2597 batch loss 1.3464278 epoch total loss 1.09567893
Trained batch 2598 batch loss 1.31562459 epoch total loss 1.09576356
Trained batch 2599 batch loss 1.09723592 epoch total loss 1.09576404
Trained batch 2600 batch loss 0.859217107 epoch total loss 1.09567308
Trained batch 2601 batch loss 1.20850241 epoch total loss 1.09571648
Trained batch 2602 batch loss 1.28170633 epoch total loss 1.095788
Trained batch 2603 batch loss 1.07751989 epoch total loss 1.09578097
Trained batch 2604 batch loss 0.884832442 epoch total loss 1.09569991
Trained batch 2605 batch loss 0.834793448 epoch total loss 1.09559977
Trained batch 2606 batch loss 0.80646 epoch total loss 1.09548879
Trained batch 2607 batch loss 0.848074794 epoch total loss 1.0953939
Trained batch 2608 batch loss 1.13447869 epoch total loss 1.09540892
Trained batch 2609 batch loss 0.852310598 epoch total loss 1.09531569
Trained batch 2610 batch loss 0.820862174 epoch total loss 1.09521055
Trained batch 2611 batch loss 0.830975294 epoch total loss 1.09510934
Trained batch 2612 batch loss 1.30003619 epoch total loss 1.09518778
Trained batch 2613 batch loss 1.18723273 epoch total loss 1.09522307
Trained batch 2614 batch loss 0.906544089 epoch total loss 1.09515083
Trained batch 2615 batch loss 1.20523632 epoch total loss 1.09519303
Trained batch 2616 batch loss 1.00574827 epoch total loss 1.09515882
Trained batch 2617 batch loss 1.08755505 epoch total loss 1.09515595
Trained batch 2618 batch loss 0.887324691 epoch total loss 1.09507656
Trained batch 2619 batch loss 1.01551938 epoch total loss 1.09504616
Trained batch 2620 batch loss 0.991975904 epoch total loss 1.09500682
Trained batch 2621 batch loss 1.168648 epoch total loss 1.09503496
Trained batch 2622 batch loss 1.04978442 epoch total loss 1.09501767
Trained batch 2623 batch loss 1.06466031 epoch total loss 1.09500611
Trained batch 2624 batch loss 1.15524769 epoch total loss 1.09502912
Trained batch 2625 batch loss 0.993608117 epoch total loss 1.09499049
Trained batch 2626 batch loss 0.97399652 epoch total loss 1.09494436
Trained batch 2627 batch loss 1.05854619 epoch total loss 1.09493053
Trained batch 2628 batch loss 0.994793534 epoch total loss 1.0948925
Trained batch 2629 batch loss 0.825364 epoch total loss 1.09479
Trained batch 2630 batch loss 0.821276665 epoch total loss 1.09468603
Trained batch 2631 batch loss 0.869795084 epoch total loss 1.09460056
Trained batch 2632 batch loss 1.07202542 epoch total loss 1.09459198
Trained batch 2633 batch loss 1.33107817 epoch total loss 1.09468174
Trained batch 2634 batch loss 0.937060773 epoch total loss 1.0946219
Trained batch 2635 batch loss 1.10741496 epoch total loss 1.09462678
Trained batch 2636 batch loss 1.22830272 epoch total loss 1.09467745
Trained batch 2637 batch loss 1.19971514 epoch total loss 1.09471726
Trained batch 2638 batch loss 0.995442 epoch total loss 1.09467959
Trained batch 2639 batch loss 1.2755208 epoch total loss 1.09474826
Trained batch 2640 batch loss 1.04832911 epoch total loss 1.09473062
Trained batch 2641 batch loss 1.01665604 epoch total loss 1.09470105
Trained batch 2642 batch loss 0.941638 epoch total loss 1.09464312
Trained batch 2643 batch loss 1.42532909 epoch total loss 1.09476817
Trained batch 2644 batch loss 1.07968819 epoch total loss 1.09476244
Trained batch 2645 batch loss 1.17936373 epoch total loss 1.09479451
Trained batch 2646 batch loss 1.13390446 epoch total loss 1.09480929
Trained batch 2647 batch loss 0.791339 epoch total loss 1.09469461
Trained batch 2648 batch loss 0.987780511 epoch total loss 1.0946542
Trained batch 2649 batch loss 0.82385993 epoch total loss 1.09455204
Trained batch 2650 batch loss 1.03751075 epoch total loss 1.09453046
Trained batch 2651 batch loss 0.795473039 epoch total loss 1.09441769
Trained batch 2652 batch loss 1.175318 epoch total loss 1.09444821
Trained batch 2653 batch loss 0.874696136 epoch total loss 1.09436536
Trained batch 2654 batch loss 0.996491432 epoch total loss 1.09432852
Trained batch 2655 batch loss 1.01880538 epoch total loss 1.0943
Trained batch 2656 batch loss 0.969846904 epoch total loss 1.09425318
Trained batch 2657 batch loss 1.09125257 epoch total loss 1.09425211
Trained batch 2658 batch loss 1.11897779 epoch total loss 1.09426129
Trained batch 2659 batch loss 0.953696728 epoch total loss 1.09420848
Trained batch 2660 batch loss 0.964832425 epoch total loss 1.09415984
Trained batch 2661 batch loss 0.95028758 epoch total loss 1.09410572
Trained batch 2662 batch loss 1.14515471 epoch total loss 1.09412491
Trained batch 2663 batch loss 1.18157959 epoch total loss 1.09415781
Trained batch 2664 batch loss 1.45473301 epoch total loss 1.09429312
Trained batch 2665 batch loss 0.870635629 epoch total loss 1.09420919
Trained batch 2666 batch loss 1.17765093 epoch total loss 1.09424055
Trained batch 2667 batch loss 1.03226566 epoch total loss 1.0942173
Trained batch 2668 batch loss 1.31272745 epoch total loss 1.0942992
Trained batch 2669 batch loss 1.32972753 epoch total loss 1.09438753
Trained batch 2670 batch loss 1.39227605 epoch total loss 1.09449911
Trained batch 2671 batch loss 1.44268894 epoch total loss 1.09462941
Trained batch 2672 batch loss 1.39139748 epoch total loss 1.09474051
Trained batch 2673 batch loss 1.12722695 epoch total loss 1.09475255
Trained batch 2674 batch loss 1.25821102 epoch total loss 1.0948137
Trained batch 2675 batch loss 1.12907076 epoch total loss 1.09482658
Trained batch 2676 batch loss 1.33295655 epoch total loss 1.09491563
Trained batch 2677 batch loss 1.12484193 epoch total loss 1.09492671
Trained batch 2678 batch loss 0.903149486 epoch total loss 1.09485507
Trained batch 2679 batch loss 1.16714168 epoch total loss 1.09488213
Trained batch 2680 batch loss 0.924736 epoch total loss 1.09481871
Trained batch 2681 batch loss 0.930179477 epoch total loss 1.0947572
Trained batch 2682 batch loss 0.950837851 epoch total loss 1.09470367
Trained batch 2683 batch loss 1.07998109 epoch total loss 1.09469819
Trained batch 2684 batch loss 1.22803211 epoch total loss 1.0947479
Trained batch 2685 batch loss 1.00807202 epoch total loss 1.0947156
Trained batch 2686 batch loss 0.863342285 epoch total loss 1.09462941
Trained batch 2687 batch loss 1.01218033 epoch total loss 1.09459877
Trained batch 2688 batch loss 0.93660897 epoch total loss 1.09453988
Trained batch 2689 batch loss 1.18292713 epoch total loss 1.09457278
Trained batch 2690 batch loss 1.25826859 epoch total loss 1.09463358
Trained batch 2691 batch loss 1.19926894 epoch total loss 1.09467244
Trained batch 2692 batch loss 1.26409769 epoch total loss 1.0947355
Trained batch 2693 batch loss 1.27266741 epoch total loss 1.09480155
Trained batch 2694 batch loss 0.958412766 epoch total loss 1.09475088
Trained batch 2695 batch loss 1.0989033 epoch total loss 1.09475243
Trained batch 2696 batch loss 0.762764335 epoch total loss 1.09462929
Trained batch 2697 batch loss 1.2026217 epoch total loss 1.09466934
Trained batch 2698 batch loss 1.08150971 epoch total loss 1.09466445
Trained batch 2699 batch loss 1.2381289 epoch total loss 1.09471762
Trained batch 2700 batch loss 1.17717218 epoch total loss 1.09474814
Trained batch 2701 batch loss 1.42352247 epoch total loss 1.09487
Trained batch 2702 batch loss 1.23026156 epoch total loss 1.09492
Trained batch 2703 batch loss 1.26013422 epoch total loss 1.09498119
Trained batch 2704 batch loss 1.22845626 epoch total loss 1.09503055
Trained batch 2705 batch loss 1.14435768 epoch total loss 1.09504879
Trained batch 2706 batch loss 0.941971421 epoch total loss 1.09499216
Trained batch 2707 batch loss 0.899828553 epoch total loss 1.09492016
Trained batch 2708 batch loss 1.22763276 epoch total loss 1.09496903
Trained batch 2709 batch loss 1.11115384 epoch total loss 1.09497499
Trained batch 2710 batch loss 1.22750223 epoch total loss 1.09502399
Trained batch 2711 batch loss 0.989444792 epoch total loss 1.09498501
Trained batch 2712 batch loss 1.19108438 epoch total loss 1.09502053
Trained batch 2713 batch loss 1.07045221 epoch total loss 1.09501147
Trained batch 2714 batch loss 1.22996426 epoch total loss 1.09506118
Trained batch 2715 batch loss 1.20218968 epoch total loss 1.09510064
Trained batch 2716 batch loss 1.12722683 epoch total loss 1.09511244
Trained batch 2717 batch loss 1.2153275 epoch total loss 1.09515667
Trained batch 2718 batch loss 0.970621228 epoch total loss 1.09511089
Trained batch 2719 batch loss 1.09955895 epoch total loss 1.09511256
Trained batch 2720 batch loss 1.43301833 epoch total loss 1.09523678
Trained batch 2721 batch loss 1.14392376 epoch total loss 1.09525478
Trained batch 2722 batch loss 1.42415452 epoch total loss 1.09537554
Trained batch 2723 batch loss 1.4792043 epoch total loss 1.09551656
Trained batch 2724 batch loss 1.14454532 epoch total loss 1.09553456
Trained batch 2725 batch loss 1.09488308 epoch total loss 1.09553432
Trained batch 2726 batch loss 1.10024905 epoch total loss 1.09553611
Trained batch 2727 batch loss 0.917287052 epoch total loss 1.09547067
Trained batch 2728 batch loss 0.786196053 epoch total loss 1.0953573
Trained batch 2729 batch loss 0.840881884 epoch total loss 1.09526408
Trained batch 2730 batch loss 0.993725777 epoch total loss 1.09522688
Trained batch 2731 batch loss 0.780359 epoch total loss 1.09511149
Trained batch 2732 batch loss 0.811616302 epoch total loss 1.09500766
Trained batch 2733 batch loss 0.940990448 epoch total loss 1.09495127
Trained batch 2734 batch loss 1.07749748 epoch total loss 1.09494495
Trained batch 2735 batch loss 0.843418062 epoch total loss 1.09485292
Trained batch 2736 batch loss 1.49966395 epoch total loss 1.09500098
Trained batch 2737 batch loss 0.901107252 epoch total loss 1.09493017
Trained batch 2738 batch loss 1.05527043 epoch total loss 1.09491563
Trained batch 2739 batch loss 0.921221495 epoch total loss 1.09485221
Trained batch 2740 batch loss 1.28747964 epoch total loss 1.09492254
Trained batch 2741 batch loss 1.14797115 epoch total loss 1.09494185
Trained batch 2742 batch loss 1.18443584 epoch total loss 1.0949744
Trained batch 2743 batch loss 0.937103093 epoch total loss 1.09491682
Trained batch 2744 batch loss 1.03350925 epoch total loss 1.09489441
Trained batch 2745 batch loss 1.07238221 epoch total loss 1.09488618
Trained batch 2746 batch loss 1.10244358 epoch total loss 1.09488904
Trained batch 2747 batch loss 0.99254787 epoch total loss 1.09485173
Trained batch 2748 batch loss 1.26297462 epoch total loss 1.09491289
Trained batch 2749 batch loss 0.998474956 epoch total loss 1.09487784
Trained batch 2750 batch loss 1.05154037 epoch total loss 1.09486198
Trained batch 2751 batch loss 1.36996698 epoch total loss 1.094962
Trained batch 2752 batch loss 1.04240012 epoch total loss 1.09494293
Trained batch 2753 batch loss 1.27865231 epoch total loss 1.09500968
Trained batch 2754 batch loss 1.01068282 epoch total loss 1.09497905
Trained batch 2755 batch loss 1.04686558 epoch total loss 1.09496152
Trained batch 2756 batch loss 1.311064 epoch total loss 1.09504
Trained batch 2757 batch loss 1.070732 epoch total loss 1.09503114
Trained batch 2758 batch loss 1.18352711 epoch total loss 1.09506333
Trained batch 2759 batch loss 1.31548 epoch total loss 1.0951432
Trained batch 2760 batch loss 1.23177385 epoch total loss 1.09519267
Trained batch 2761 batch loss 1.23370612 epoch total loss 1.09524274
Trained batch 2762 batch loss 1.15115654 epoch total loss 1.095263
Trained batch 2763 batch loss 1.11863732 epoch total loss 1.09527147
Trained batch 2764 batch loss 1.0323807 epoch total loss 1.09524882
Trained batch 2765 batch loss 1.16235089 epoch total loss 1.09527302
Trained batch 2766 batch loss 0.993806124 epoch total loss 1.09523642
Trained batch 2767 batch loss 1.07990527 epoch total loss 1.09523082
Trained batch 2768 batch loss 1.36809361 epoch total loss 1.0953294
Trained batch 2769 batch loss 1.3501581 epoch total loss 1.09542143
Trained batch 2770 batch loss 1.2514956 epoch total loss 1.0954777
Trained batch 2771 batch loss 1.36699939 epoch total loss 1.09557569
Trained batch 2772 batch loss 1.30684388 epoch total loss 1.09565198
Trained batch 2773 batch loss 1.24170268 epoch total loss 1.09570467
Trained batch 2774 batch loss 1.32425 epoch total loss 1.09578705
Trained batch 2775 batch loss 1.42354929 epoch total loss 1.09590507
Trained batch 2776 batch loss 1.27818441 epoch total loss 1.09597075
Trained batch 2777 batch loss 1.28074586 epoch total loss 1.09603727
Trained batch 2778 batch loss 0.969093919 epoch total loss 1.09599161
Trained batch 2779 batch loss 0.899006128 epoch total loss 1.09592068
Trained batch 2780 batch loss 0.94930625 epoch total loss 1.09586787
Trained batch 2781 batch loss 1.00175762 epoch total loss 1.09583402
Trained batch 2782 batch loss 1.09128392 epoch total loss 1.09583235
Trained batch 2783 batch loss 1.12563825 epoch total loss 1.09584308
Trained batch 2784 batch loss 1.22852492 epoch total loss 1.09589076
Trained batch 2785 batch loss 1.29250109 epoch total loss 1.09596133
Trained batch 2786 batch loss 1.33286691 epoch total loss 1.09604633
Trained batch 2787 batch loss 1.19091582 epoch total loss 1.09608042
Trained batch 2788 batch loss 0.894879401 epoch total loss 1.09600818
Trained batch 2789 batch loss 1.0830344 epoch total loss 1.09600353
Trained batch 2790 batch loss 1.14803827 epoch total loss 1.09602213
Trained batch 2791 batch loss 0.960286856 epoch total loss 1.09597349
Trained batch 2792 batch loss 1.15067136 epoch total loss 1.09599304
Trained batch 2793 batch loss 1.27882886 epoch total loss 1.09605849
Trained batch 2794 batch loss 1.52570164 epoch total loss 1.09621227
Trained batch 2795 batch loss 1.28898501 epoch total loss 1.09628129
Trained batch 2796 batch loss 1.2807138 epoch total loss 1.09634721
Trained batch 2797 batch loss 1.46877432 epoch total loss 1.09648037
Trained batch 2798 batch loss 1.19208229 epoch total loss 1.09651458
Trained batch 2799 batch loss 1.15527475 epoch total loss 1.09653556
Trained batch 2800 batch loss 1.2427851 epoch total loss 1.09658778
Trained batch 2801 batch loss 1.41949475 epoch total loss 1.09670305
Trained batch 2802 batch loss 1.52089453 epoch total loss 1.09685445
Trained batch 2803 batch loss 1.43982196 epoch total loss 1.09697688
Trained batch 2804 batch loss 1.34178948 epoch total loss 1.09706414
Trained batch 2805 batch loss 1.33776164 epoch total loss 1.09715
Trained batch 2806 batch loss 1.26420498 epoch total loss 1.09720945
Trained batch 2807 batch loss 0.973989606 epoch total loss 1.09716558
Trained batch 2808 batch loss 0.993983924 epoch total loss 1.09712875
Trained batch 2809 batch loss 0.946522474 epoch total loss 1.0970751
Trained batch 2810 batch loss 0.980057657 epoch total loss 1.0970335
Trained batch 2811 batch loss 0.863372266 epoch total loss 1.09695029
Trained batch 2812 batch loss 0.961123884 epoch total loss 1.09690201
Trained batch 2813 batch loss 0.860034466 epoch total loss 1.09681785
Trained batch 2814 batch loss 1.01259589 epoch total loss 1.09678793
Trained batch 2815 batch loss 1.24648011 epoch total loss 1.09684122
Trained batch 2816 batch loss 1.27465272 epoch total loss 1.09690428
Trained batch 2817 batch loss 1.16718554 epoch total loss 1.09692931
Trained batch 2818 batch loss 1.08491969 epoch total loss 1.09692502
Trained batch 2819 batch loss 0.99632 epoch total loss 1.09688938
Trained batch 2820 batch loss 1.09143305 epoch total loss 1.09688747
Trained batch 2821 batch loss 0.978654683 epoch total loss 1.09684563
Trained batch 2822 batch loss 0.977725863 epoch total loss 1.09680343
Trained batch 2823 batch loss 0.855359674 epoch total loss 1.09671795
Trained batch 2824 batch loss 1.14434123 epoch total loss 1.09673476
Trained batch 2825 batch loss 0.924984515 epoch total loss 1.09667397
Trained batch 2826 batch loss 0.762866855 epoch total loss 1.09655595
Trained batch 2827 batch loss 0.945610046 epoch total loss 1.09650242
Trained batch 2828 batch loss 0.984112799 epoch total loss 1.09646273
Trained batch 2829 batch loss 0.836659849 epoch total loss 1.09637094
Trained batch 2830 batch loss 0.944672823 epoch total loss 1.09631729
Trained batch 2831 batch loss 1.06155419 epoch total loss 1.09630501
Trained batch 2832 batch loss 0.905683517 epoch total loss 1.09623766
Trained batch 2833 batch loss 0.958192468 epoch total loss 1.09618902
Trained batch 2834 batch loss 0.907010555 epoch total loss 1.09612226
Trained batch 2835 batch loss 1.16675091 epoch total loss 1.09614718
Trained batch 2836 batch loss 1.00165379 epoch total loss 1.0961138
Trained batch 2837 batch loss 0.793887 epoch total loss 1.09600735
Trained batch 2838 batch loss 0.952216268 epoch total loss 1.09595668
Trained batch 2839 batch loss 0.77972436 epoch total loss 1.09584522
Trained batch 2840 batch loss 0.827875495 epoch total loss 1.09575093
Trained batch 2841 batch loss 0.844469666 epoch total loss 1.09566247
Trained batch 2842 batch loss 0.869068861 epoch total loss 1.09558272
Trained batch 2843 batch loss 0.744536579 epoch total loss 1.09545934
Trained batch 2844 batch loss 0.904750645 epoch total loss 1.09539223
Trained batch 2845 batch loss 0.918448746 epoch total loss 1.09533012
Trained batch 2846 batch loss 0.843655467 epoch total loss 1.09524167
Trained batch 2847 batch loss 0.826871455 epoch total loss 1.09514749
Trained batch 2848 batch loss 1.03212047 epoch total loss 1.09512532
Trained batch 2849 batch loss 1.0796479 epoch total loss 1.09512
Trained batch 2850 batch loss 1.03222322 epoch total loss 1.09509778
Trained batch 2851 batch loss 1.13894081 epoch total loss 1.09511316
Trained batch 2852 batch loss 1.33626032 epoch total loss 1.09519768
Trained batch 2853 batch loss 1.11521387 epoch total loss 1.09520471
Trained batch 2854 batch loss 0.981301486 epoch total loss 1.09516478
Trained batch 2855 batch loss 1.10302973 epoch total loss 1.09516752
Trained batch 2856 batch loss 0.706007957 epoch total loss 1.09503126
Trained batch 2857 batch loss 0.734501779 epoch total loss 1.09490514
Trained batch 2858 batch loss 0.818876088 epoch total loss 1.09480858
Trained batch 2859 batch loss 0.902106047 epoch total loss 1.09474111
Trained batch 2860 batch loss 0.893950284 epoch total loss 1.09467101
Trained batch 2861 batch loss 1.06269073 epoch total loss 1.09465981
Trained batch 2862 batch loss 0.884070635 epoch total loss 1.09458625
Trained batch 2863 batch loss 1.04270935 epoch total loss 1.09456813
Trained batch 2864 batch loss 1.02617133 epoch total loss 1.09454417
Trained batch 2865 batch loss 1.1514411 epoch total loss 1.09456408
Trained batch 2866 batch loss 1.30132389 epoch total loss 1.0946362
Trained batch 2867 batch loss 1.0767529 epoch total loss 1.09462988
Trained batch 2868 batch loss 1.16092837 epoch total loss 1.09465301
Trained batch 2869 batch loss 1.27577329 epoch total loss 1.09471619
Trained batch 2870 batch loss 0.859416 epoch total loss 1.09463418
Trained batch 2871 batch loss 1.01180565 epoch total loss 1.09460533
Trained batch 2872 batch loss 0.85867238 epoch total loss 1.09452319
Trained batch 2873 batch loss 0.812506795 epoch total loss 1.09442496
Trained batch 2874 batch loss 0.801811218 epoch total loss 1.09432316
Trained batch 2875 batch loss 0.940482497 epoch total loss 1.09426963
Trained batch 2876 batch loss 0.72506 epoch total loss 1.09414124
Trained batch 2877 batch loss 0.860309482 epoch total loss 1.09406
Trained batch 2878 batch loss 0.991073549 epoch total loss 1.09402418
Trained batch 2879 batch loss 0.802559495 epoch total loss 1.09392285
Trained batch 2880 batch loss 1.03370047 epoch total loss 1.09390199
Trained batch 2881 batch loss 0.74634093 epoch total loss 1.09378135
Trained batch 2882 batch loss 0.806690097 epoch total loss 1.09368169
Trained batch 2883 batch loss 0.865219 epoch total loss 1.09360254
Trained batch 2884 batch loss 1.01059818 epoch total loss 1.09357369
Trained batch 2885 batch loss 1.05375886 epoch total loss 1.09355986
Trained batch 2886 batch loss 1.47716212 epoch total loss 1.09369278
Trained batch 2887 batch loss 1.26039696 epoch total loss 1.09375048
Trained batch 2888 batch loss 1.10042918 epoch total loss 1.09375274
Trained batch 2889 batch loss 1.15361297 epoch total loss 1.09377348
Trained batch 2890 batch loss 1.32386184 epoch total loss 1.09385312
Trained batch 2891 batch loss 1.19351971 epoch total loss 1.09388769
Trained batch 2892 batch loss 1.14758646 epoch total loss 1.09390628
Trained batch 2893 batch loss 1.23863 epoch total loss 1.09395623
Trained batch 2894 batch loss 1.24508047 epoch total loss 1.09400845
Trained batch 2895 batch loss 1.14993274 epoch total loss 1.09402776
Trained batch 2896 batch loss 1.40943944 epoch total loss 1.09413671
Trained batch 2897 batch loss 1.19472897 epoch total loss 1.0941714
Trained batch 2898 batch loss 1.17448473 epoch total loss 1.09419918
Trained batch 2899 batch loss 1.08375823 epoch total loss 1.0941956
Trained batch 2900 batch loss 1.18046331 epoch total loss 1.09422529
Trained batch 2901 batch loss 0.931138 epoch total loss 1.09416914
Trained batch 2902 batch loss 0.886437535 epoch total loss 1.0940975
Trained batch 2903 batch loss 0.862985313 epoch total loss 1.09401798
Trained batch 2904 batch loss 1.1572485 epoch total loss 1.09403968
Trained batch 2905 batch loss 0.873571157 epoch total loss 1.09396374
Trained batch 2906 batch loss 1.01810932 epoch total loss 1.09393764
Trained batch 2907 batch loss 0.94415307 epoch total loss 1.09388614
Trained batch 2908 batch loss 0.729205847 epoch total loss 1.09376073
Trained batch 2909 batch loss 1.04720092 epoch total loss 1.09374475
Trained batch 2910 batch loss 0.993316293 epoch total loss 1.09371018
Trained batch 2911 batch loss 1.34547472 epoch total loss 1.09379673
Trained batch 2912 batch loss 1.31732082 epoch total loss 1.0938735
Trained batch 2913 batch loss 1.0561198 epoch total loss 1.09386051
Trained batch 2914 batch loss 1.27359843 epoch total loss 1.09392226
Trained batch 2915 batch loss 0.883630157 epoch total loss 1.09385014
Trained batch 2916 batch loss 1.04095042 epoch total loss 1.09383202
Trained batch 2917 batch loss 0.970475078 epoch total loss 1.0937897
Trained batch 2918 batch loss 1.18117309 epoch total loss 1.09381962
Trained batch 2919 batch loss 1.24324965 epoch total loss 1.09387076
Trained batch 2920 batch loss 1.12919796 epoch total loss 1.0938828
Trained batch 2921 batch loss 1.11400247 epoch total loss 1.09388971
Trained batch 2922 batch loss 1.22117293 epoch total loss 1.09393334
Trained batch 2923 batch loss 0.776757717 epoch total loss 1.09382486
Trained batch 2924 batch loss 1.16508722 epoch total loss 1.09384918
Trained batch 2925 batch loss 1.02384257 epoch total loss 1.09382534
Trained batch 2926 batch loss 1.17467308 epoch total loss 1.09385288
Trained batch 2927 batch loss 1.10458219 epoch total loss 1.09385657
Trained batch 2928 batch loss 1.194489 epoch total loss 1.09389091
Trained batch 2929 batch loss 1.47507906 epoch total loss 1.09402108
Trained batch 2930 batch loss 1.34590459 epoch total loss 1.09410703
Trained batch 2931 batch loss 1.32823133 epoch total loss 1.0941869
Trained batch 2932 batch loss 1.23803902 epoch total loss 1.0942359
Trained batch 2933 batch loss 1.17072105 epoch total loss 1.094262
Trained batch 2934 batch loss 1.03745604 epoch total loss 1.09424257
Trained batch 2935 batch loss 0.883637965 epoch total loss 1.09417081
Trained batch 2936 batch loss 1.20421386 epoch total loss 1.09420824
Trained batch 2937 batch loss 1.1580081 epoch total loss 1.09422994
Trained batch 2938 batch loss 1.01997161 epoch total loss 1.09420466
Trained batch 2939 batch loss 1.22597671 epoch total loss 1.09424961
Trained batch 2940 batch loss 1.24695444 epoch total loss 1.09430158
Trained batch 2941 batch loss 0.983714 epoch total loss 1.09426391
Trained batch 2942 batch loss 1.24390972 epoch total loss 1.09431481
Trained batch 2943 batch loss 1.12100744 epoch total loss 1.09432387
Trained batch 2944 batch loss 0.955988646 epoch total loss 1.09427691
Trained batch 2945 batch loss 0.911245465 epoch total loss 1.0942148
Trained batch 2946 batch loss 0.824793458 epoch total loss 1.09412324
Trained batch 2947 batch loss 0.965543509 epoch total loss 1.09407961
Trained batch 2948 batch loss 0.871685147 epoch total loss 1.09400415
Trained batch 2949 batch loss 1.04355 epoch total loss 1.09398699
Trained batch 2950 batch loss 1.06835675 epoch total loss 1.09397829
Trained batch 2951 batch loss 1.06607461 epoch total loss 1.09396887
Trained batch 2952 batch loss 1.15805697 epoch total loss 1.09399056
Trained batch 2953 batch loss 1.29284668 epoch total loss 1.09405792
Trained batch 2954 batch loss 0.994345188 epoch total loss 1.09402418
Trained batch 2955 batch loss 1.15311313 epoch total loss 1.09404409
Trained batch 2956 batch loss 1.26728976 epoch total loss 1.09410274
Trained batch 2957 batch loss 1.14727306 epoch total loss 1.09412074
Trained batch 2958 batch loss 1.10335255 epoch total loss 1.09412384
Trained batch 2959 batch loss 1.00084019 epoch total loss 1.09409225
Trained batch 2960 batch loss 1.02454901 epoch total loss 1.09406877
Trained batch 2961 batch loss 0.982818544 epoch total loss 1.09403121
Trained batch 2962 batch loss 1.20430207 epoch total loss 1.09406853
Trained batch 2963 batch loss 1.0252043 epoch total loss 1.09404528
Trained batch 2964 batch loss 1.40698385 epoch total loss 1.09415078
Trained batch 2965 batch loss 1.21978307 epoch total loss 1.0941931
Trained batch 2966 batch loss 1.29191625 epoch total loss 1.09425986
Trained batch 2967 batch loss 1.03274632 epoch total loss 1.09423912
Trained batch 2968 batch loss 1.03943968 epoch total loss 1.09422064
Trained batch 2969 batch loss 0.883865893 epoch total loss 1.09414983
Trained batch 2970 batch loss 0.862478733 epoch total loss 1.09407187
Trained batch 2971 batch loss 0.880762339 epoch total loss 1.0940001
Trained batch 2972 batch loss 0.956180573 epoch total loss 1.09395373
Trained batch 2973 batch loss 1.03011322 epoch total loss 1.09393227
Trained batch 2974 batch loss 0.840677679 epoch total loss 1.09384704
Trained batch 2975 batch loss 0.797100425 epoch total loss 1.09374726
Trained batch 2976 batch loss 0.969164729 epoch total loss 1.09370542
Trained batch 2977 batch loss 0.775758266 epoch total loss 1.09359872
Trained batch 2978 batch loss 0.972745776 epoch total loss 1.09355807
Trained batch 2979 batch loss 1.10064411 epoch total loss 1.09356046
Trained batch 2980 batch loss 1.26619768 epoch total loss 1.09361839
Trained batch 2981 batch loss 1.27798593 epoch total loss 1.09368026
Trained batch 2982 batch loss 1.24148905 epoch total loss 1.09372973
Trained batch 2983 batch loss 1.28885674 epoch total loss 1.09379518
Trained batch 2984 batch loss 1.25131047 epoch total loss 1.09384799
Trained batch 2985 batch loss 1.01205564 epoch total loss 1.09382045
Trained batch 2986 batch loss 1.19562149 epoch total loss 1.09385455
Trained batch 2987 batch loss 1.47138286 epoch total loss 1.09398103
Trained batch 2988 batch loss 1.38465369 epoch total loss 1.0940783
Trained batch 2989 batch loss 1.27919912 epoch total loss 1.09414029
Trained batch 2990 batch loss 1.21895242 epoch total loss 1.09418201
Trained batch 2991 batch loss 1.04866791 epoch total loss 1.09416676
Trained batch 2992 batch loss 1.07275963 epoch total loss 1.0941596
Trained batch 2993 batch loss 1.11774731 epoch total loss 1.09416747
Trained batch 2994 batch loss 1.25060582 epoch total loss 1.09421968
Trained batch 2995 batch loss 1.46487379 epoch total loss 1.09434342
Trained batch 2996 batch loss 1.27936578 epoch total loss 1.09440517
Trained batch 2997 batch loss 1.23905241 epoch total loss 1.09445345
Trained batch 2998 batch loss 1.36121821 epoch total loss 1.09454238
Trained batch 2999 batch loss 1.08053935 epoch total loss 1.09453773
Trained batch 3000 batch loss 1.06196642 epoch total loss 1.09452689
Trained batch 3001 batch loss 1.20716298 epoch total loss 1.09456456
Trained batch 3002 batch loss 1.25483966 epoch total loss 1.09461796
Trained batch 3003 batch loss 1.14153409 epoch total loss 1.09463358
Trained batch 3004 batch loss 1.20949984 epoch total loss 1.09467173
Trained batch 3005 batch loss 1.19195533 epoch total loss 1.09470415
Trained batch 3006 batch loss 1.12612748 epoch total loss 1.09471464
Trained batch 3007 batch loss 1.18835223 epoch total loss 1.09474576
Trained batch 3008 batch loss 1.20005655 epoch total loss 1.09478068
Trained batch 3009 batch loss 1.09661174 epoch total loss 1.09478128
Trained batch 3010 batch loss 1.10750961 epoch total loss 1.09478557
Trained batch 3011 batch loss 1.05904365 epoch total loss 1.09477365
Trained batch 3012 batch loss 1.11848903 epoch total loss 1.09478152
Trained batch 3013 batch loss 0.98559761 epoch total loss 1.09474528
Trained batch 3014 batch loss 1.09605193 epoch total loss 1.09474564
Trained batch 3015 batch loss 1.23517728 epoch total loss 1.09479225
Trained batch 3016 batch loss 1.31848335 epoch total loss 1.09486639
Trained batch 3017 batch loss 1.25255251 epoch total loss 1.09491873
Trained batch 3018 batch loss 1.14650202 epoch total loss 1.09493577
Trained batch 3019 batch loss 1.23405218 epoch total loss 1.09498191
Trained batch 3020 batch loss 1.03283215 epoch total loss 1.09496129
Trained batch 3021 batch loss 1.11700583 epoch total loss 1.09496856
Trained batch 3022 batch loss 1.391644 epoch total loss 1.09506667
Trained batch 3023 batch loss 1.25808513 epoch total loss 1.09512055
Trained batch 3024 batch loss 1.00971305 epoch total loss 1.09509242
Trained batch 3025 batch loss 1.18761563 epoch total loss 1.09512293
Trained batch 3026 batch loss 1.33634734 epoch total loss 1.09520268
Trained batch 3027 batch loss 1.3261981 epoch total loss 1.09527898
Trained batch 3028 batch loss 1.27364326 epoch total loss 1.09533787
Trained batch 3029 batch loss 1.17630243 epoch total loss 1.09536457
Trained batch 3030 batch loss 1.1371963 epoch total loss 1.0953784
Trained batch 3031 batch loss 1.14294982 epoch total loss 1.09539413
Trained batch 3032 batch loss 1.03600574 epoch total loss 1.09537446
Trained batch 3033 batch loss 1.09543347 epoch total loss 1.09537458
Trained batch 3034 batch loss 1.18525589 epoch total loss 1.09540415
Trained batch 3035 batch loss 1.09072781 epoch total loss 1.09540272
Trained batch 3036 batch loss 1.11605847 epoch total loss 1.09540939
Trained batch 3037 batch loss 1.08243132 epoch total loss 1.09540522
Trained batch 3038 batch loss 1.18461537 epoch total loss 1.09543455
Trained batch 3039 batch loss 1.28288293 epoch total loss 1.0954963
Trained batch 3040 batch loss 0.777195811 epoch total loss 1.09539151
Trained batch 3041 batch loss 1.16311944 epoch total loss 1.0954138
Trained batch 3042 batch loss 0.972468853 epoch total loss 1.09537339
Trained batch 3043 batch loss 1.08946347 epoch total loss 1.09537137
Trained batch 3044 batch loss 0.851653934 epoch total loss 1.09529126
Trained batch 3045 batch loss 0.878566563 epoch total loss 1.09522009
Trained batch 3046 batch loss 0.950895965 epoch total loss 1.09517276
Trained batch 3047 batch loss 0.824172318 epoch total loss 1.09508383
Trained batch 3048 batch loss 0.786878347 epoch total loss 1.09498274
Trained batch 3049 batch loss 0.953843951 epoch total loss 1.09493649
Trained batch 3050 batch loss 1.0974493 epoch total loss 1.09493721
Trained batch 3051 batch loss 1.2027328 epoch total loss 1.09497249
Trained batch 3052 batch loss 1.18555486 epoch total loss 1.09500217
Trained batch 3053 batch loss 1.23038948 epoch total loss 1.09504664
Trained batch 3054 batch loss 1.27534938 epoch total loss 1.09510565
Trained batch 3055 batch loss 1.20927644 epoch total loss 1.09514296
Trained batch 3056 batch loss 1.08933353 epoch total loss 1.09514105
Trained batch 3057 batch loss 1.0539391 epoch total loss 1.09512758
Trained batch 3058 batch loss 1.07652402 epoch total loss 1.0951215
Trained batch 3059 batch loss 1.30274439 epoch total loss 1.09518933
Trained batch 3060 batch loss 1.15153527 epoch total loss 1.09520781
Trained batch 3061 batch loss 1.26752663 epoch total loss 1.09526408
Trained batch 3062 batch loss 1.33754098 epoch total loss 1.09534335
Trained batch 3063 batch loss 1.06624389 epoch total loss 1.09533381
Trained batch 3064 batch loss 1.05649567 epoch total loss 1.09532106
Trained batch 3065 batch loss 1.04403353 epoch total loss 1.09530425
Trained batch 3066 batch loss 1.07244515 epoch total loss 1.09529686
Trained batch 3067 batch loss 1.16003871 epoch total loss 1.09531796
Trained batch 3068 batch loss 1.11718822 epoch total loss 1.09532511
Trained batch 3069 batch loss 1.16419733 epoch total loss 1.09534764
Trained batch 3070 batch loss 1.0236547 epoch total loss 1.09532428
Trained batch 3071 batch loss 1.06773818 epoch total loss 1.09531522
Trained batch 3072 batch loss 1.14874816 epoch total loss 1.09533262
Trained batch 3073 batch loss 1.27434814 epoch total loss 1.09539092
Trained batch 3074 batch loss 1.32829 epoch total loss 1.09546673
Trained batch 3075 batch loss 1.05467272 epoch total loss 1.09545338
Trained batch 3076 batch loss 1.36943877 epoch total loss 1.09554243
Trained batch 3077 batch loss 1.27380276 epoch total loss 1.09560037
Trained batch 3078 batch loss 1.15826821 epoch total loss 1.09562075
Trained batch 3079 batch loss 1.30965662 epoch total loss 1.09569025
Trained batch 3080 batch loss 1.00784206 epoch total loss 1.09566164
Trained batch 3081 batch loss 1.08693171 epoch total loss 1.09565878
Trained batch 3082 batch loss 0.924808919 epoch total loss 1.09560335
Trained batch 3083 batch loss 0.975261331 epoch total loss 1.09556437
Trained batch 3084 batch loss 1.09004 epoch total loss 1.09556258
Trained batch 3085 batch loss 1.04759264 epoch total loss 1.09554708
Trained batch 3086 batch loss 1.20739985 epoch total loss 1.09558332
Trained batch 3087 batch loss 0.922017872 epoch total loss 1.09552717
Trained batch 3088 batch loss 0.972768426 epoch total loss 1.09548736
Trained batch 3089 batch loss 1.04585242 epoch total loss 1.09547126
Trained batch 3090 batch loss 1.15479791 epoch total loss 1.09549046
Trained batch 3091 batch loss 0.907988787 epoch total loss 1.0954299
Trained batch 3092 batch loss 1.00920796 epoch total loss 1.095402
Trained batch 3093 batch loss 1.1315639 epoch total loss 1.09541368
Trained batch 3094 batch loss 1.06611705 epoch total loss 1.09540427
Trained batch 3095 batch loss 1.39995301 epoch total loss 1.09550261
Trained batch 3096 batch loss 0.799450338 epoch total loss 1.09540701
Trained batch 3097 batch loss 0.760187745 epoch total loss 1.09529877
Trained batch 3098 batch loss 0.896865308 epoch total loss 1.09523475
Trained batch 3099 batch loss 0.966297865 epoch total loss 1.09519315
Trained batch 3100 batch loss 0.849185169 epoch total loss 1.09511375
Trained batch 3101 batch loss 0.834546447 epoch total loss 1.09502971
Trained batch 3102 batch loss 1.15810156 epoch total loss 1.0950501
Trained batch 3103 batch loss 1.30663645 epoch total loss 1.09511828
Trained batch 3104 batch loss 0.929225087 epoch total loss 1.09506488
Trained batch 3105 batch loss 1.15663862 epoch total loss 1.09508467
Trained batch 3106 batch loss 1.21354055 epoch total loss 1.09512293
Trained batch 3107 batch loss 1.12595332 epoch total loss 1.09513283
Trained batch 3108 batch loss 0.765509725 epoch total loss 1.09502673
Trained batch 3109 batch loss 0.630600274 epoch total loss 1.09487736
Trained batch 3110 batch loss 1.04945517 epoch total loss 1.09486282
Trained batch 3111 batch loss 1.1264298 epoch total loss 1.09487295
Trained batch 3112 batch loss 1.10336173 epoch total loss 1.09487569
Trained batch 3113 batch loss 1.06303227 epoch total loss 1.09486544
Trained batch 3114 batch loss 0.903408289 epoch total loss 1.09480393
Trained batch 3115 batch loss 1.01902461 epoch total loss 1.09477961
Trained batch 3116 batch loss 0.855598092 epoch total loss 1.09470296
Trained batch 3117 batch loss 0.843111038 epoch total loss 1.09462214
Trained batch 3118 batch loss 0.948187947 epoch total loss 1.09457517
Trained batch 3119 batch loss 0.865115762 epoch total loss 1.09450173
Trained batch 3120 batch loss 1.13230801 epoch total loss 1.09451377
Trained batch 3121 batch loss 0.942671895 epoch total loss 1.09446514
Trained batch 3122 batch loss 0.931524456 epoch total loss 1.09441292
Trained batch 3123 batch loss 1.18972301 epoch total loss 1.09444344
Trained batch 3124 batch loss 0.992331505 epoch total loss 1.09441078
Trained batch 3125 batch loss 1.0054307 epoch total loss 1.09438229
Trained batch 3126 batch loss 1.13566589 epoch total loss 1.09439552
Trained batch 3127 batch loss 0.968784809 epoch total loss 1.09435534
Trained batch 3128 batch loss 1.3731153 epoch total loss 1.09444451
Trained batch 3129 batch loss 1.08589745 epoch total loss 1.09444177
Trained batch 3130 batch loss 1.52363598 epoch total loss 1.09457886
Trained batch 3131 batch loss 1.44014049 epoch total loss 1.09468925
Trained batch 3132 batch loss 1.49087894 epoch total loss 1.09481585
Trained batch 3133 batch loss 1.16051841 epoch total loss 1.09483671
Trained batch 3134 batch loss 1.56468725 epoch total loss 1.09498668
Trained batch 3135 batch loss 1.30672216 epoch total loss 1.09505415
Trained batch 3136 batch loss 1.33109331 epoch total loss 1.09512949
Trained batch 3137 batch loss 1.27726674 epoch total loss 1.09518754
Trained batch 3138 batch loss 1.24139452 epoch total loss 1.09523416
Trained batch 3139 batch loss 1.24675632 epoch total loss 1.09528244
Trained batch 3140 batch loss 1.29755116 epoch total loss 1.09534681
Trained batch 3141 batch loss 1.38960481 epoch total loss 1.09544051
Trained batch 3142 batch loss 1.25189495 epoch total loss 1.09549034
Trained batch 3143 batch loss 1.323421 epoch total loss 1.09556293
Trained batch 3144 batch loss 1.30864739 epoch total loss 1.09563065
Trained batch 3145 batch loss 1.12964511 epoch total loss 1.09564149
Trained batch 3146 batch loss 1.19083357 epoch total loss 1.09567177
Trained batch 3147 batch loss 1.15310156 epoch total loss 1.09569
Trained batch 3148 batch loss 1.22952545 epoch total loss 1.09573257
Trained batch 3149 batch loss 1.20553088 epoch total loss 1.09576738
Trained batch 3150 batch loss 1.1473968 epoch total loss 1.09578383
Trained batch 3151 batch loss 1.01974654 epoch total loss 1.09575963
Trained batch 3152 batch loss 1.20866883 epoch total loss 1.09579551
Trained batch 3153 batch loss 1.27488184 epoch total loss 1.09585238
Trained batch 3154 batch loss 1.144768 epoch total loss 1.09586787
Trained batch 3155 batch loss 1.10309136 epoch total loss 1.09587014
Trained batch 3156 batch loss 1.21268845 epoch total loss 1.09590709
Trained batch 3157 batch loss 1.10078645 epoch total loss 1.09590864
Trained batch 3158 batch loss 1.25865531 epoch total loss 1.09596014
Trained batch 3159 batch loss 0.968374074 epoch total loss 1.09591973
Trained batch 3160 batch loss 1.37884831 epoch total loss 1.09600925
Trained batch 3161 batch loss 1.10589433 epoch total loss 1.09601247
Trained batch 3162 batch loss 1.1397438 epoch total loss 1.0960263
Trained batch 3163 batch loss 1.22325945 epoch total loss 1.09606647
Trained batch 3164 batch loss 1.19130576 epoch total loss 1.09609652
Trained batch 3165 batch loss 1.05189133 epoch total loss 1.09608269
Trained batch 3166 batch loss 1.0285356 epoch total loss 1.09606135
Trained batch 3167 batch loss 1.17839563 epoch total loss 1.09608734
Trained batch 3168 batch loss 1.07875347 epoch total loss 1.09608185
Trained batch 3169 batch loss 1.23413467 epoch total loss 1.09612548
Trained batch 3170 batch loss 1.14825797 epoch total loss 1.09614193
Trained batch 3171 batch loss 1.19004083 epoch total loss 1.0961715
Trained batch 3172 batch loss 1.04066801 epoch total loss 1.09615397
Trained batch 3173 batch loss 1.08811855 epoch total loss 1.09615147
Trained batch 3174 batch loss 1.19254 epoch total loss 1.09618187
Trained batch 3175 batch loss 1.2043196 epoch total loss 1.09621596
Trained batch 3176 batch loss 1.012133 epoch total loss 1.0961895
Trained batch 3177 batch loss 1.11910462 epoch total loss 1.09619665
Trained batch 3178 batch loss 0.982049644 epoch total loss 1.09616077
Trained batch 3179 batch loss 1.09885907 epoch total loss 1.0961616
Trained batch 3180 batch loss 0.945333242 epoch total loss 1.09611416
Trained batch 3181 batch loss 1.13609934 epoch total loss 1.09612668
Trained batch 3182 batch loss 1.14945984 epoch total loss 1.09614348
Trained batch 3183 batch loss 0.943571687 epoch total loss 1.09609556
Trained batch 3184 batch loss 1.01506913 epoch total loss 1.09607
Trained batch 3185 batch loss 0.804512858 epoch total loss 1.0959785
Trained batch 3186 batch loss 0.949435472 epoch total loss 1.0959326
Trained batch 3187 batch loss 0.842497945 epoch total loss 1.09585309
Trained batch 3188 batch loss 0.77340436 epoch total loss 1.09575188
Trained batch 3189 batch loss 0.867855549 epoch total loss 1.09568048
Trained batch 3190 batch loss 0.829254508 epoch total loss 1.09559703
Trained batch 3191 batch loss 0.937982917 epoch total loss 1.09554756
Trained batch 3192 batch loss 0.864130676 epoch total loss 1.09547508
Trained batch 3193 batch loss 0.960204899 epoch total loss 1.09543264
Trained batch 3194 batch loss 1.13082147 epoch total loss 1.09544373
Trained batch 3195 batch loss 1.21539 epoch total loss 1.09548128
Trained batch 3196 batch loss 1.31755018 epoch total loss 1.09555078
Trained batch 3197 batch loss 1.3204875 epoch total loss 1.09562123
Trained batch 3198 batch loss 1.27321148 epoch total loss 1.09567666
Trained batch 3199 batch loss 1.12147284 epoch total loss 1.09568477
Trained batch 3200 batch loss 1.09279752 epoch total loss 1.09568393
Trained batch 3201 batch loss 1.11565351 epoch total loss 1.09569013
Trained batch 3202 batch loss 1.0541482 epoch total loss 1.09567726
Trained batch 3203 batch loss 1.28563809 epoch total loss 1.0957365
Trained batch 3204 batch loss 1.38481331 epoch total loss 1.09582675
Trained batch 3205 batch loss 1.27817988 epoch total loss 1.09588361
Trained batch 3206 batch loss 1.34678483 epoch total loss 1.09596181
Trained batch 3207 batch loss 1.05403733 epoch total loss 1.0959487
Trained batch 3208 batch loss 1.06620646 epoch total loss 1.0959394
Trained batch 3209 batch loss 1.189803 epoch total loss 1.0959686
Trained batch 3210 batch loss 1.25804257 epoch total loss 1.09601915
Trained batch 3211 batch loss 1.09769249 epoch total loss 1.09601963
Trained batch 3212 batch loss 1.24019027 epoch total loss 1.09606457
Trained batch 3213 batch loss 1.42353272 epoch total loss 1.09616649
Trained batch 3214 batch loss 1.04593134 epoch total loss 1.09615088
Trained batch 3215 batch loss 1.25552773 epoch total loss 1.09620047
Trained batch 3216 batch loss 1.12398648 epoch total loss 1.09620905
Trained batch 3217 batch loss 1.16242909 epoch total loss 1.09622967
Trained batch 3218 batch loss 1.10902059 epoch total loss 1.09623361
Trained batch 3219 batch loss 0.876235604 epoch total loss 1.0961653
Trained batch 3220 batch loss 1.0238657 epoch total loss 1.09614289
Trained batch 3221 batch loss 1.1514 epoch total loss 1.09616
Trained batch 3222 batch loss 1.28133512 epoch total loss 1.09621751
Trained batch 3223 batch loss 1.10905874 epoch total loss 1.09622145
Trained batch 3224 batch loss 1.1990397 epoch total loss 1.0962534
Trained batch 3225 batch loss 0.965435684 epoch total loss 1.09621274
Trained batch 3226 batch loss 1.10417414 epoch total loss 1.09621525
Trained batch 3227 batch loss 1.15139413 epoch total loss 1.0962323
Trained batch 3228 batch loss 1.14290428 epoch total loss 1.09624672
Trained batch 3229 batch loss 1.00314713 epoch total loss 1.09621799
Trained batch 3230 batch loss 1.19952846 epoch total loss 1.09624994
Trained batch 3231 batch loss 1.26638246 epoch total loss 1.09630251
Trained batch 3232 batch loss 1.24984169 epoch total loss 1.09635007
Trained batch 3233 batch loss 1.1644311 epoch total loss 1.09637117
Trained batch 3234 batch loss 1.01726937 epoch total loss 1.09634674
Trained batch 3235 batch loss 1.05878246 epoch total loss 1.09633505
Trained batch 3236 batch loss 1.08366871 epoch total loss 1.09633124
Trained batch 3237 batch loss 0.933962166 epoch total loss 1.09628105
Trained batch 3238 batch loss 0.988055408 epoch total loss 1.09624767
Trained batch 3239 batch loss 0.988793731 epoch total loss 1.09621441
Trained batch 3240 batch loss 1.11547089 epoch total loss 1.09622037
Trained batch 3241 batch loss 1.24015009 epoch total loss 1.09626484
Trained batch 3242 batch loss 1.01727939 epoch total loss 1.09624052
Trained batch 3243 batch loss 0.848369718 epoch total loss 1.09616411
Trained batch 3244 batch loss 0.983748198 epoch total loss 1.09612942
Trained batch 3245 batch loss 0.870588541 epoch total loss 1.09605992
Trained batch 3246 batch loss 0.946513951 epoch total loss 1.09601378
Trained batch 3247 batch loss 0.983141065 epoch total loss 1.09597909
Trained batch 3248 batch loss 0.888404965 epoch total loss 1.0959152
Trained batch 3249 batch loss 0.984165668 epoch total loss 1.09588075
Trained batch 3250 batch loss 1.05345976 epoch total loss 1.09586775
Trained batch 3251 batch loss 1.18156886 epoch total loss 1.0958941
Trained batch 3252 batch loss 1.25030875 epoch total loss 1.09594154
Trained batch 3253 batch loss 1.17807698 epoch total loss 1.09596682
Trained batch 3254 batch loss 1.13825715 epoch total loss 1.09597981
Trained batch 3255 batch loss 1.00708866 epoch total loss 1.09595239
Trained batch 3256 batch loss 1.05528319 epoch total loss 1.09593987
Trained batch 3257 batch loss 1.35316908 epoch total loss 1.09601891
Trained batch 3258 batch loss 1.34701419 epoch total loss 1.09609592
Trained batch 3259 batch loss 1.24617791 epoch total loss 1.09614193
Trained batch 3260 batch loss 1.14865136 epoch total loss 1.09615803
Trained batch 3261 batch loss 0.990781069 epoch total loss 1.09612572
Trained batch 3262 batch loss 1.07676601 epoch total loss 1.09611976
Trained batch 3263 batch loss 1.23376179 epoch total loss 1.09616196
Trained batch 3264 batch loss 1.19388413 epoch total loss 1.09619188
Trained batch 3265 batch loss 1.03481102 epoch total loss 1.09617305
Trained batch 3266 batch loss 1.16298699 epoch total loss 1.09619355
Trained batch 3267 batch loss 1.0256654 epoch total loss 1.09617198
Trained batch 3268 batch loss 1.09406471 epoch total loss 1.09617126
Trained batch 3269 batch loss 1.00128829 epoch total loss 1.09614229
Trained batch 3270 batch loss 1.25416708 epoch total loss 1.09619057
Trained batch 3271 batch loss 1.28160381 epoch total loss 1.0962472
Trained batch 3272 batch loss 0.898498297 epoch total loss 1.09618676
Trained batch 3273 batch loss 1.08262181 epoch total loss 1.09618258
Trained batch 3274 batch loss 1.00916326 epoch total loss 1.096156
Trained batch 3275 batch loss 1.23165202 epoch total loss 1.09619749
Trained batch 3276 batch loss 1.27773631 epoch total loss 1.09625292
Trained batch 3277 batch loss 0.940537751 epoch total loss 1.09620535
Trained batch 3278 batch loss 1.02480721 epoch total loss 1.09618354
Trained batch 3279 batch loss 0.833011866 epoch total loss 1.09610331
Trained batch 3280 batch loss 0.895753324 epoch total loss 1.09604228
Trained batch 3281 batch loss 0.696195245 epoch total loss 1.09592044
Trained batch 3282 batch loss 0.998178303 epoch total loss 1.09589064
Trained batch 3283 batch loss 1.0195868 epoch total loss 1.0958674
Trained batch 3284 batch loss 1.13264656 epoch total loss 1.0958786
Trained batch 3285 batch loss 1.18665242 epoch total loss 1.09590626
Trained batch 3286 batch loss 1.2018615 epoch total loss 1.09593844
Trained batch 3287 batch loss 1.19823456 epoch total loss 1.09596968
Trained batch 3288 batch loss 1.08967948 epoch total loss 1.09596765
Trained batch 3289 batch loss 1.2004056 epoch total loss 1.09599948
Trained batch 3290 batch loss 1.17398572 epoch total loss 1.0960232
Trained batch 3291 batch loss 1.34871101 epoch total loss 1.0961
Trained batch 3292 batch loss 1.08741665 epoch total loss 1.09609735
Trained batch 3293 batch loss 1.07152557 epoch total loss 1.09608984
Trained batch 3294 batch loss 1.10930848 epoch total loss 1.09609389
Trained batch 3295 batch loss 1.25724626 epoch total loss 1.09614277
Trained batch 3296 batch loss 1.10616302 epoch total loss 1.09614587
Trained batch 3297 batch loss 0.99455595 epoch total loss 1.09611511
Trained batch 3298 batch loss 1.15914059 epoch total loss 1.09613419
Trained batch 3299 batch loss 0.987213671 epoch total loss 1.09610116
Trained batch 3300 batch loss 1.14057994 epoch total loss 1.09611464
Trained batch 3301 batch loss 0.894995332 epoch total loss 1.09605372
Trained batch 3302 batch loss 1.02921224 epoch total loss 1.09603357
Trained batch 3303 batch loss 1.04125798 epoch total loss 1.096017
Trained batch 3304 batch loss 1.17924166 epoch total loss 1.09604216
Trained batch 3305 batch loss 1.34814763 epoch total loss 1.09611845
Trained batch 3306 batch loss 1.2817204 epoch total loss 1.0961746
Trained batch 3307 batch loss 1.39976835 epoch total loss 1.09626639
Trained batch 3308 batch loss 1.32445955 epoch total loss 1.09633529
Trained batch 3309 batch loss 1.28010416 epoch total loss 1.09639084
Trained batch 3310 batch loss 1.36078179 epoch total loss 1.09647071
Trained batch 3311 batch loss 1.17184675 epoch total loss 1.09649348
Trained batch 3312 batch loss 1.03341591 epoch total loss 1.09647441
Trained batch 3313 batch loss 1.10844314 epoch total loss 1.0964781
Trained batch 3314 batch loss 1.00024605 epoch total loss 1.09644902
Trained batch 3315 batch loss 1.21155024 epoch total loss 1.09648383
Trained batch 3316 batch loss 1.35498548 epoch total loss 1.09656179
Trained batch 3317 batch loss 1.16092086 epoch total loss 1.0965811
Trained batch 3318 batch loss 1.09428287 epoch total loss 1.09658039
Trained batch 3319 batch loss 1.12582815 epoch total loss 1.09658921
Trained batch 3320 batch loss 1.23093712 epoch total loss 1.09662974
Trained batch 3321 batch loss 1.08618069 epoch total loss 1.09662652
Trained batch 3322 batch loss 0.957350612 epoch total loss 1.09658456
Trained batch 3323 batch loss 0.917962968 epoch total loss 1.0965308
Trained batch 3324 batch loss 0.869780064 epoch total loss 1.09646261
Trained batch 3325 batch loss 1.28354943 epoch total loss 1.09651887
Trained batch 3326 batch loss 1.1958729 epoch total loss 1.09654868
Trained batch 3327 batch loss 1.09371352 epoch total loss 1.09654784
Trained batch 3328 batch loss 1.026739 epoch total loss 1.09652698
Trained batch 3329 batch loss 0.906826138 epoch total loss 1.09647
Trained batch 3330 batch loss 1.00226879 epoch total loss 1.09644163
Trained batch 3331 batch loss 0.783925712 epoch total loss 1.09634781
Trained batch 3332 batch loss 1.10406566 epoch total loss 1.09635007
Trained batch 3333 batch loss 1.13421428 epoch total loss 1.09636152
Trained batch 3334 batch loss 1.33396411 epoch total loss 1.09643281
Trained batch 3335 batch loss 1.0947758 epoch total loss 1.09643221
Trained batch 3336 batch loss 1.28692055 epoch total loss 1.09648931
Trained batch 3337 batch loss 0.983682 epoch total loss 1.09645557
Trained batch 3338 batch loss 1.15876913 epoch total loss 1.09647417
Trained batch 3339 batch loss 1.01730609 epoch total loss 1.09645045
Trained batch 3340 batch loss 1.15524411 epoch total loss 1.09646809
Trained batch 3341 batch loss 1.01921284 epoch total loss 1.09644496
Trained batch 3342 batch loss 0.995787919 epoch total loss 1.09641492
Trained batch 3343 batch loss 0.82916832 epoch total loss 1.09633493
Trained batch 3344 batch loss 0.767058849 epoch total loss 1.09623647
Trained batch 3345 batch loss 0.998040497 epoch total loss 1.09620714
Trained batch 3346 batch loss 1.0435338 epoch total loss 1.09619129
Trained batch 3347 batch loss 1.0951463 epoch total loss 1.09619105
Trained batch 3348 batch loss 0.790354 epoch total loss 1.09609962
Trained batch 3349 batch loss 0.860035956 epoch total loss 1.09602916
Trained batch 3350 batch loss 0.651646912 epoch total loss 1.0958966
Trained batch 3351 batch loss 1.1611414 epoch total loss 1.09591603
Trained batch 3352 batch loss 1.03072786 epoch total loss 1.0958966
Trained batch 3353 batch loss 0.818430185 epoch total loss 1.09581375
Trained batch 3354 batch loss 0.854048908 epoch total loss 1.09574175
Trained batch 3355 batch loss 0.87707305 epoch total loss 1.09567654
Trained batch 3356 batch loss 0.806607246 epoch total loss 1.09559035
Trained batch 3357 batch loss 1.04561579 epoch total loss 1.09557545
Trained batch 3358 batch loss 1.146209 epoch total loss 1.09559059
Trained batch 3359 batch loss 1.30576146 epoch total loss 1.09565318
Trained batch 3360 batch loss 1.19360101 epoch total loss 1.09568226
Trained batch 3361 batch loss 1.25369596 epoch total loss 1.09572923
Trained batch 3362 batch loss 1.40759301 epoch total loss 1.0958221
Trained batch 3363 batch loss 1.42620814 epoch total loss 1.09592032
Trained batch 3364 batch loss 1.3711859 epoch total loss 1.0960021
Trained batch 3365 batch loss 1.22948682 epoch total loss 1.0960418
Trained batch 3366 batch loss 1.3534013 epoch total loss 1.09611833
Trained batch 3367 batch loss 1.2982173 epoch total loss 1.09617829
Trained batch 3368 batch loss 1.13088 epoch total loss 1.09618855
Trained batch 3369 batch loss 1.30065084 epoch total loss 1.09624922
Trained batch 3370 batch loss 1.42279088 epoch total loss 1.09634614
Trained batch 3371 batch loss 1.26028919 epoch total loss 1.09639478
Trained batch 3372 batch loss 1.18966794 epoch total loss 1.09642243
Trained batch 3373 batch loss 1.0169282 epoch total loss 1.09639883
Trained batch 3374 batch loss 0.971768439 epoch total loss 1.09636188
Trained batch 3375 batch loss 1.04735088 epoch total loss 1.09634733
Trained batch 3376 batch loss 1.39582324 epoch total loss 1.09643602
Trained batch 3377 batch loss 1.33451641 epoch total loss 1.0965066
Trained batch 3378 batch loss 1.3343749 epoch total loss 1.09657693
Trained batch 3379 batch loss 1.27419591 epoch total loss 1.0966295
Trained batch 3380 batch loss 1.36530662 epoch total loss 1.09670901
Trained batch 3381 batch loss 1.3718493 epoch total loss 1.09679043
Trained batch 3382 batch loss 1.36784482 epoch total loss 1.09687054
Trained batch 3383 batch loss 1.13004279 epoch total loss 1.09688044
Trained batch 3384 batch loss 1.43496525 epoch total loss 1.09698033
Trained batch 3385 batch loss 1.29945135 epoch total loss 1.09704018
Trained batch 3386 batch loss 1.26541948 epoch total loss 1.09708989
Trained batch 3387 batch loss 0.991876543 epoch total loss 1.09705889
Trained batch 3388 batch loss 1.02608275 epoch total loss 1.09703791
Trained batch 3389 batch loss 1.2813592 epoch total loss 1.09709227
Trained batch 3390 batch loss 1.22334456 epoch total loss 1.09712946
Trained batch 3391 batch loss 1.2514714 epoch total loss 1.097175
Trained batch 3392 batch loss 1.00605011 epoch total loss 1.09714818
Trained batch 3393 batch loss 0.91524744 epoch total loss 1.09709454
Trained batch 3394 batch loss 1.09474313 epoch total loss 1.09709382
Trained batch 3395 batch loss 0.9813236 epoch total loss 1.09705985
Trained batch 3396 batch loss 0.889282823 epoch total loss 1.09699869
Trained batch 3397 batch loss 1.00442755 epoch total loss 1.09697139
Trained batch 3398 batch loss 0.968825698 epoch total loss 1.09693372
Trained batch 3399 batch loss 0.924142718 epoch total loss 1.09688282
Trained batch 3400 batch loss 0.896548271 epoch total loss 1.09682393
Trained batch 3401 batch loss 0.919700623 epoch total loss 1.09677184
Trained batch 3402 batch loss 0.850231409 epoch total loss 1.09669936
Trained batch 3403 batch loss 0.885827065 epoch total loss 1.09663737
Trained batch 3404 batch loss 1.07238078 epoch total loss 1.09663022
Trained batch 3405 batch loss 1.0719583 epoch total loss 1.09662294
Trained batch 3406 batch loss 0.860774398 epoch total loss 1.0965538
Trained batch 3407 batch loss 1.21930766 epoch total loss 1.0965898
Trained batch 3408 batch loss 1.46091151 epoch total loss 1.09669662
Trained batch 3409 batch loss 1.47638249 epoch total loss 1.09680808
Trained batch 3410 batch loss 1.47368252 epoch total loss 1.09691858
Trained batch 3411 batch loss 1.55452251 epoch total loss 1.09705269
Trained batch 3412 batch loss 1.18966579 epoch total loss 1.09707987
Trained batch 3413 batch loss 1.00632739 epoch total loss 1.09705329
Trained batch 3414 batch loss 1.10324728 epoch total loss 1.09705508
Trained batch 3415 batch loss 1.07066023 epoch total loss 1.09704733
Trained batch 3416 batch loss 1.02025676 epoch total loss 1.0970248
Trained batch 3417 batch loss 1.19288564 epoch total loss 1.09705281
Trained batch 3418 batch loss 1.12622809 epoch total loss 1.0970614
Trained batch 3419 batch loss 0.977094233 epoch total loss 1.09702635
Trained batch 3420 batch loss 1.10149503 epoch total loss 1.09702766
Trained batch 3421 batch loss 0.927988529 epoch total loss 1.09697819
Trained batch 3422 batch loss 0.867454 epoch total loss 1.09691107
Trained batch 3423 batch loss 0.99043417 epoch total loss 1.09688008
Trained batch 3424 batch loss 0.99459517 epoch total loss 1.09685016
Trained batch 3425 batch loss 1.0642451 epoch total loss 1.09684062
Trained batch 3426 batch loss 1.11188793 epoch total loss 1.09684503
Trained batch 3427 batch loss 1.26024723 epoch total loss 1.09689271
Trained batch 3428 batch loss 0.904384255 epoch total loss 1.09683657
Trained batch 3429 batch loss 1.13156772 epoch total loss 1.0968467
Trained batch 3430 batch loss 0.870252609 epoch total loss 1.09678066
Trained batch 3431 batch loss 1.0391314 epoch total loss 1.09676385
Trained batch 3432 batch loss 1.0359962 epoch total loss 1.09674609
Trained batch 3433 batch loss 1.01764369 epoch total loss 1.09672296
Trained batch 3434 batch loss 0.680914938 epoch total loss 1.09660196
Trained batch 3435 batch loss 0.907882094 epoch total loss 1.09654701
Trained batch 3436 batch loss 1.08079576 epoch total loss 1.09654236
Trained batch 3437 batch loss 0.965234041 epoch total loss 1.09650421
Trained batch 3438 batch loss 1.09660721 epoch total loss 1.09650433
Trained batch 3439 batch loss 1.17773426 epoch total loss 1.09652793
Trained batch 3440 batch loss 1.23276448 epoch total loss 1.09656751
Trained batch 3441 batch loss 1.12423992 epoch total loss 1.0965755
Trained batch 3442 batch loss 1.04830849 epoch total loss 1.09656155
Trained batch 3443 batch loss 1.3055886 epoch total loss 1.09662223
Trained batch 3444 batch loss 0.891364872 epoch total loss 1.09656262
Trained batch 3445 batch loss 0.985573471 epoch total loss 1.09653044
Trained batch 3446 batch loss 1.04880095 epoch total loss 1.09651661
Trained batch 3447 batch loss 1.24578261 epoch total loss 1.09655988
Trained batch 3448 batch loss 1.20000625 epoch total loss 1.09658992
Trained batch 3449 batch loss 1.00840652 epoch total loss 1.09656429
Trained batch 3450 batch loss 1.15168905 epoch total loss 1.09658027
Trained batch 3451 batch loss 1.18442702 epoch total loss 1.09660566
Trained batch 3452 batch loss 1.08145142 epoch total loss 1.09660137
Trained batch 3453 batch loss 1.15883064 epoch total loss 1.09661937
Trained batch 3454 batch loss 1.27031112 epoch total loss 1.09666967
Trained batch 3455 batch loss 1.20971155 epoch total loss 1.09670234
Trained batch 3456 batch loss 1.02367473 epoch total loss 1.09668124
Trained batch 3457 batch loss 1.14461863 epoch total loss 1.09669507
Trained batch 3458 batch loss 0.890751719 epoch total loss 1.09663558
Trained batch 3459 batch loss 1.09043741 epoch total loss 1.09663379
Trained batch 3460 batch loss 1.08940697 epoch total loss 1.09663165
Trained batch 3461 batch loss 0.903346658 epoch total loss 1.09657574
Trained batch 3462 batch loss 0.988902926 epoch total loss 1.09654474
Trained batch 3463 batch loss 1.08904219 epoch total loss 1.0965426
Trained batch 3464 batch loss 1.08335733 epoch total loss 1.09653878
Trained batch 3465 batch loss 1.09062409 epoch total loss 1.09653699
Trained batch 3466 batch loss 1.02361345 epoch total loss 1.09651601
Trained batch 3467 batch loss 0.900051236 epoch total loss 1.09645939
Trained batch 3468 batch loss 0.973542809 epoch total loss 1.09642398
Trained batch 3469 batch loss 1.20121801 epoch total loss 1.09645414
Trained batch 3470 batch loss 1.22147131 epoch total loss 1.09649014
Trained batch 3471 batch loss 1.17378139 epoch total loss 1.09651244
Trained batch 3472 batch loss 1.30368233 epoch total loss 1.09657216
Trained batch 3473 batch loss 1.33095479 epoch total loss 1.09663963
Trained batch 3474 batch loss 1.24242544 epoch total loss 1.09668159
Trained batch 3475 batch loss 1.12039208 epoch total loss 1.09668839
Trained batch 3476 batch loss 1.03721869 epoch total loss 1.09667122
Trained batch 3477 batch loss 0.993750691 epoch total loss 1.09664166
Trained batch 3478 batch loss 1.12453604 epoch total loss 1.09664965
Trained batch 3479 batch loss 1.07611227 epoch total loss 1.09664381
Trained batch 3480 batch loss 1.28186345 epoch total loss 1.09669697
Trained batch 3481 batch loss 0.946588278 epoch total loss 1.09665382
Trained batch 3482 batch loss 1.1586237 epoch total loss 1.0966717
Trained batch 3483 batch loss 1.24605954 epoch total loss 1.09671462
Trained batch 3484 batch loss 1.05579495 epoch total loss 1.09670293
Trained batch 3485 batch loss 1.39940238 epoch total loss 1.09678972
Trained batch 3486 batch loss 0.89996171 epoch total loss 1.09673321
Trained batch 3487 batch loss 1.19095349 epoch total loss 1.09676027
Trained batch 3488 batch loss 1.04452491 epoch total loss 1.09674525
Trained batch 3489 batch loss 1.02285647 epoch total loss 1.09672415
Trained batch 3490 batch loss 1.05142212 epoch total loss 1.09671116
Trained batch 3491 batch loss 0.912017584 epoch total loss 1.09665823
Trained batch 3492 batch loss 1.02631712 epoch total loss 1.0966382
Trained batch 3493 batch loss 0.976759195 epoch total loss 1.09660387
Trained batch 3494 batch loss 0.91050595 epoch total loss 1.09655058
Trained batch 3495 batch loss 0.980636239 epoch total loss 1.09651744
Trained batch 3496 batch loss 0.90494442 epoch total loss 1.09646261
Trained batch 3497 batch loss 1.20928526 epoch total loss 1.09649491
Trained batch 3498 batch loss 1.14193654 epoch total loss 1.09650791
Trained batch 3499 batch loss 1.11027312 epoch total loss 1.09651184
Trained batch 3500 batch loss 1.12376904 epoch total loss 1.09651959
Trained batch 3501 batch loss 1.18954372 epoch total loss 1.09654617
Trained batch 3502 batch loss 1.13241386 epoch total loss 1.09655631
Trained batch 3503 batch loss 1.34425247 epoch total loss 1.09662712
Trained batch 3504 batch loss 1.29796576 epoch total loss 1.09668446
Trained batch 3505 batch loss 1.05854666 epoch total loss 1.09667361
Trained batch 3506 batch loss 1.10630763 epoch total loss 1.09667635
Trained batch 3507 batch loss 0.970330298 epoch total loss 1.09664023
Trained batch 3508 batch loss 0.988223195 epoch total loss 1.09660935
Trained batch 3509 batch loss 1.01438856 epoch total loss 1.09658599
Trained batch 3510 batch loss 0.972568274 epoch total loss 1.0965507
Trained batch 3511 batch loss 1.00442541 epoch total loss 1.09652436
Trained batch 3512 batch loss 1.04884219 epoch total loss 1.09651089
Trained batch 3513 batch loss 1.08082438 epoch total loss 1.09650636
Trained batch 3514 batch loss 1.22508144 epoch total loss 1.09654295
Trained batch 3515 batch loss 1.20880437 epoch total loss 1.0965749
Trained batch 3516 batch loss 1.23791289 epoch total loss 1.09661508
Trained batch 3517 batch loss 1.19231164 epoch total loss 1.09664226
Trained batch 3518 batch loss 1.25630534 epoch total loss 1.09668767
Trained batch 3519 batch loss 1.1493175 epoch total loss 1.09670269
Trained batch 3520 batch loss 1.21182394 epoch total loss 1.09673536
Trained batch 3521 batch loss 0.886424839 epoch total loss 1.09667563
Trained batch 3522 batch loss 0.877418399 epoch total loss 1.09661341
Trained batch 3523 batch loss 0.943910718 epoch total loss 1.09657
Trained batch 3524 batch loss 0.909955621 epoch total loss 1.09651709
Trained batch 3525 batch loss 0.928930461 epoch total loss 1.09646952
Trained batch 3526 batch loss 1.21805286 epoch total loss 1.09650397
Trained batch 3527 batch loss 0.998688161 epoch total loss 1.09647632
Trained batch 3528 batch loss 1.15854573 epoch total loss 1.09649384
Trained batch 3529 batch loss 1.15988445 epoch total loss 1.09651184
Trained batch 3530 batch loss 1.14287329 epoch total loss 1.09652495
Trained batch 3531 batch loss 1.26626551 epoch total loss 1.09657311
Trained batch 3532 batch loss 1.14540267 epoch total loss 1.09658694
Trained batch 3533 batch loss 0.959860742 epoch total loss 1.0965482
Trained batch 3534 batch loss 0.986115217 epoch total loss 1.09651697
Trained batch 3535 batch loss 1.03515291 epoch total loss 1.09649968
Trained batch 3536 batch loss 1.22830427 epoch total loss 1.09653687
Trained batch 3537 batch loss 1.1687541 epoch total loss 1.09655726
Trained batch 3538 batch loss 1.18926895 epoch total loss 1.09658349
Trained batch 3539 batch loss 1.28539538 epoch total loss 1.09663689
Trained batch 3540 batch loss 0.96890521 epoch total loss 1.09660077
Trained batch 3541 batch loss 1.09654093 epoch total loss 1.09660077
Trained batch 3542 batch loss 1.26088333 epoch total loss 1.09664714
Trained batch 3543 batch loss 0.951693356 epoch total loss 1.09660625
Trained batch 3544 batch loss 1.1557591 epoch total loss 1.09662294
Trained batch 3545 batch loss 0.893535554 epoch total loss 1.0965656
Trained batch 3546 batch loss 1.00360286 epoch total loss 1.0965395
Trained batch 3547 batch loss 0.829083681 epoch total loss 1.09646404
Trained batch 3548 batch loss 0.854366779 epoch total loss 1.09639573
Trained batch 3549 batch loss 0.842175305 epoch total loss 1.09632421
Trained batch 3550 batch loss 1.02858591 epoch total loss 1.09630513
Trained batch 3551 batch loss 1.02319777 epoch total loss 1.09628451
Trained batch 3552 batch loss 1.45983577 epoch total loss 1.09638679
Trained batch 3553 batch loss 0.967843354 epoch total loss 1.09635067
Trained batch 3554 batch loss 1.0588361 epoch total loss 1.09634006
Trained batch 3555 batch loss 1.24322462 epoch total loss 1.09638131
Trained batch 3556 batch loss 1.2222687 epoch total loss 1.09641671
Trained batch 3557 batch loss 0.972193718 epoch total loss 1.09638178
Trained batch 3558 batch loss 1.23945475 epoch total loss 1.09642208
Trained batch 3559 batch loss 1.10808039 epoch total loss 1.09642529
Trained batch 3560 batch loss 1.22122622 epoch total loss 1.09646034
Trained batch 3561 batch loss 1.32251108 epoch total loss 1.09652388
Trained batch 3562 batch loss 1.01671159 epoch total loss 1.09650147
Trained batch 3563 batch loss 1.21077085 epoch total loss 1.09653342
Trained batch 3564 batch loss 0.9582932 epoch total loss 1.09649467
Trained batch 3565 batch loss 1.15757537 epoch total loss 1.09651172
Trained batch 3566 batch loss 0.988860607 epoch total loss 1.09648156
Trained batch 3567 batch loss 1.2937696 epoch total loss 1.09653687
Trained batch 3568 batch loss 1.23782408 epoch total loss 1.09657645
Trained batch 3569 batch loss 1.17023945 epoch total loss 1.09659708
Trained batch 3570 batch loss 1.27016902 epoch total loss 1.09664571
Trained batch 3571 batch loss 1.05538893 epoch total loss 1.09663415
Trained batch 3572 batch loss 0.968147695 epoch total loss 1.09659827
Trained batch 3573 batch loss 0.783898 epoch total loss 1.09651077
Trained batch 3574 batch loss 1.07780552 epoch total loss 1.09650552
Trained batch 3575 batch loss 1.03315783 epoch total loss 1.09648776
Trained batch 3576 batch loss 1.11789727 epoch total loss 1.09649384
Trained batch 3577 batch loss 1.2714541 epoch total loss 1.09654272
Trained batch 3578 batch loss 1.0367794 epoch total loss 1.09652603
Trained batch 3579 batch loss 1.23463213 epoch total loss 1.09656465
Trained batch 3580 batch loss 1.03741598 epoch total loss 1.09654808
Trained batch 3581 batch loss 1.14195776 epoch total loss 1.09656072
Trained batch 3582 batch loss 1.04976404 epoch total loss 1.09654772
Trained batch 3583 batch loss 0.955597878 epoch total loss 1.09650826
Trained batch 3584 batch loss 1.11199033 epoch total loss 1.09651268
Trained batch 3585 batch loss 0.967316628 epoch total loss 1.09647655
Trained batch 3586 batch loss 0.984446 epoch total loss 1.09644532
Trained batch 3587 batch loss 1.06987941 epoch total loss 1.09643793
Trained batch 3588 batch loss 1.12227464 epoch total loss 1.09644508
Trained batch 3589 batch loss 1.0647769 epoch total loss 1.09643626
Trained batch 3590 batch loss 0.949358582 epoch total loss 1.09639537
Trained batch 3591 batch loss 1.06040144 epoch total loss 1.09638536
Trained batch 3592 batch loss 1.15791476 epoch total loss 1.09640241
Trained batch 3593 batch loss 1.17771816 epoch total loss 1.09642506
Trained batch 3594 batch loss 1.3492626 epoch total loss 1.09649551
Trained batch 3595 batch loss 1.259987 epoch total loss 1.09654093
Trained batch 3596 batch loss 1.34011531 epoch total loss 1.09660864
Trained batch 3597 batch loss 1.09772348 epoch total loss 1.096609
Trained batch 3598 batch loss 1.03455949 epoch total loss 1.09659171
Trained batch 3599 batch loss 1.13975 epoch total loss 1.09660375
Trained batch 3600 batch loss 1.24757743 epoch total loss 1.09664559
Trained batch 3601 batch loss 1.24778247 epoch total loss 1.09668767
Trained batch 3602 batch loss 1.26241684 epoch total loss 1.09673369
Trained batch 3603 batch loss 1.1526885 epoch total loss 1.09674919
Trained batch 3604 batch loss 1.04390073 epoch total loss 1.09673452
Trained batch 3605 batch loss 1.3614372 epoch total loss 1.09680784
Trained batch 3606 batch loss 1.2265234 epoch total loss 1.09684384
Trained batch 3607 batch loss 1.23020601 epoch total loss 1.09688079
Trained batch 3608 batch loss 1.10574579 epoch total loss 1.0968833
Trained batch 3609 batch loss 1.19680583 epoch total loss 1.09691095
Trained batch 3610 batch loss 1.09982717 epoch total loss 1.09691179
Trained batch 3611 batch loss 0.98303628 epoch total loss 1.09688032
Trained batch 3612 batch loss 1.16708851 epoch total loss 1.09689975
Trained batch 3613 batch loss 1.278584 epoch total loss 1.09694993
Trained batch 3614 batch loss 1.17496085 epoch total loss 1.09697163
Trained batch 3615 batch loss 1.277197 epoch total loss 1.09702146
Trained batch 3616 batch loss 1.22054458 epoch total loss 1.09705555
Trained batch 3617 batch loss 1.06965673 epoch total loss 1.09704792
Trained batch 3618 batch loss 1.30751944 epoch total loss 1.0971061
Trained batch 3619 batch loss 1.16776943 epoch total loss 1.09712565
Trained batch 3620 batch loss 0.981236 epoch total loss 1.0970937
Trained batch 3621 batch loss 1.33824921 epoch total loss 1.09716022
Trained batch 3622 batch loss 0.990360498 epoch total loss 1.09713078
Trained batch 3623 batch loss 0.916249096 epoch total loss 1.09708083
Trained batch 3624 batch loss 1.37043285 epoch total loss 1.09715629
Trained batch 3625 batch loss 1.3603375 epoch total loss 1.09722888
Trained batch 3626 batch loss 1.01595438 epoch total loss 1.09720647
Trained batch 3627 batch loss 1.1212126 epoch total loss 1.09721303
Trained batch 3628 batch loss 1.14469218 epoch total loss 1.09722614
Trained batch 3629 batch loss 0.893766403 epoch total loss 1.09717
Trained batch 3630 batch loss 1.17128682 epoch total loss 1.0971905
Trained batch 3631 batch loss 1.19532132 epoch total loss 1.09721756
Trained batch 3632 batch loss 1.09374213 epoch total loss 1.09721661
Trained batch 3633 batch loss 1.04768467 epoch total loss 1.0972029
Trained batch 3634 batch loss 1.04684246 epoch total loss 1.09718907
Trained batch 3635 batch loss 0.899169326 epoch total loss 1.09713459
Trained batch 3636 batch loss 0.837806702 epoch total loss 1.0970633
Trained batch 3637 batch loss 1.0687921 epoch total loss 1.09705555
Trained batch 3638 batch loss 0.842875779 epoch total loss 1.09698558
Trained batch 3639 batch loss 0.796413302 epoch total loss 1.09690309
Trained batch 3640 batch loss 0.874185324 epoch total loss 1.09684181
Trained batch 3641 batch loss 0.813704073 epoch total loss 1.09676409
Trained batch 3642 batch loss 1.24552894 epoch total loss 1.09680498
Trained batch 3643 batch loss 1.18456662 epoch total loss 1.09682906
Trained batch 3644 batch loss 0.876186907 epoch total loss 1.0967685
Trained batch 3645 batch loss 1.09840488 epoch total loss 1.09676898
Trained batch 3646 batch loss 1.04408681 epoch total loss 1.09675455
Trained batch 3647 batch loss 0.986080289 epoch total loss 1.09672415
Trained batch 3648 batch loss 0.893415451 epoch total loss 1.09666848
Trained batch 3649 batch loss 0.992655933 epoch total loss 1.09664
Trained batch 3650 batch loss 0.879623592 epoch total loss 1.09658051
Trained batch 3651 batch loss 0.914904356 epoch total loss 1.09653068
Trained batch 3652 batch loss 0.988845706 epoch total loss 1.09650123
Trained batch 3653 batch loss 0.726933956 epoch total loss 1.0964
Trained batch 3654 batch loss 1.03247869 epoch total loss 1.09638262
Trained batch 3655 batch loss 1.05804968 epoch total loss 1.09637213
Trained batch 3656 batch loss 1.02314842 epoch total loss 1.0963521
Trained batch 3657 batch loss 0.913763 epoch total loss 1.09630215
Trained batch 3658 batch loss 0.881656051 epoch total loss 1.0962435
Trained batch 3659 batch loss 1.12084424 epoch total loss 1.09625018
Trained batch 3660 batch loss 1.11868072 epoch total loss 1.09625626
Trained batch 3661 batch loss 1.11271143 epoch total loss 1.09626079
Trained batch 3662 batch loss 1.32023025 epoch total loss 1.09632206
Trained batch 3663 batch loss 1.16856015 epoch total loss 1.09634173
Trained batch 3664 batch loss 1.02745903 epoch total loss 1.09632289
Trained batch 3665 batch loss 1.18471742 epoch total loss 1.09634697
Trained batch 3666 batch loss 1.0312345 epoch total loss 1.09632921
Trained batch 3667 batch loss 1.07363725 epoch total loss 1.09632313
Trained batch 3668 batch loss 1.16511822 epoch total loss 1.09634185
Trained batch 3669 batch loss 1.34927928 epoch total loss 1.09641075
Trained batch 3670 batch loss 1.14114666 epoch total loss 1.09642303
Trained batch 3671 batch loss 0.971438229 epoch total loss 1.09638894
Trained batch 3672 batch loss 1.01831722 epoch total loss 1.09636772
Trained batch 3673 batch loss 1.05880904 epoch total loss 1.09635746
Trained batch 3674 batch loss 1.13682699 epoch total loss 1.09636843
Trained batch 3675 batch loss 1.04389215 epoch total loss 1.09635413
Trained batch 3676 batch loss 1.012954 epoch total loss 1.09633148
Trained batch 3677 batch loss 0.828622 epoch total loss 1.09625864
Trained batch 3678 batch loss 0.77812916 epoch total loss 1.09617221
Trained batch 3679 batch loss 0.805918097 epoch total loss 1.0960933
Trained batch 3680 batch loss 1.07312012 epoch total loss 1.09608698
Trained batch 3681 batch loss 1.05343986 epoch total loss 1.09607542
Trained batch 3682 batch loss 0.909561217 epoch total loss 1.09602475
Trained batch 3683 batch loss 0.966050863 epoch total loss 1.09598947
Trained batch 3684 batch loss 0.979609489 epoch total loss 1.09595788
Trained batch 3685 batch loss 1.05541635 epoch total loss 1.09594691
Trained batch 3686 batch loss 1.15666866 epoch total loss 1.09596336
Trained batch 3687 batch loss 0.882251 epoch total loss 1.09590542
Trained batch 3688 batch loss 1.0729332 epoch total loss 1.09589922
Trained batch 3689 batch loss 1.04066193 epoch total loss 1.0958842
Trained batch 3690 batch loss 0.989570856 epoch total loss 1.09585547
Trained batch 3691 batch loss 1.10292459 epoch total loss 1.09585738
Trained batch 3692 batch loss 1.12470508 epoch total loss 1.09586525
Trained batch 3693 batch loss 1.10888195 epoch total loss 1.09586871
Trained batch 3694 batch loss 1.03055882 epoch total loss 1.09585106
Trained batch 3695 batch loss 1.30529809 epoch total loss 1.09590781
Trained batch 3696 batch loss 1.21817505 epoch total loss 1.09594083
Trained batch 3697 batch loss 1.20698965 epoch total loss 1.09597087
Trained batch 3698 batch loss 1.14878583 epoch total loss 1.09598517
Trained batch 3699 batch loss 1.05193126 epoch total loss 1.09597325
Trained batch 3700 batch loss 1.20087671 epoch total loss 1.09600163
Trained batch 3701 batch loss 1.29529786 epoch total loss 1.09605551
Trained batch 3702 batch loss 1.27889132 epoch total loss 1.09610486
Trained batch 3703 batch loss 1.07508397 epoch total loss 1.09609926
Trained batch 3704 batch loss 1.10914898 epoch total loss 1.09610271
Trained batch 3705 batch loss 1.16311 epoch total loss 1.09612083
Trained batch 3706 batch loss 1.09559596 epoch total loss 1.09612072
Trained batch 3707 batch loss 1.0631249 epoch total loss 1.09611189
Trained batch 3708 batch loss 0.978016615 epoch total loss 1.09608
Trained batch 3709 batch loss 0.901035905 epoch total loss 1.09602749
Trained batch 3710 batch loss 1.20603371 epoch total loss 1.09605706
Trained batch 3711 batch loss 1.12669063 epoch total loss 1.0960654
Trained batch 3712 batch loss 1.32064295 epoch total loss 1.09612584
Trained batch 3713 batch loss 1.06811094 epoch total loss 1.09611833
Trained batch 3714 batch loss 1.05923581 epoch total loss 1.09610844
Trained batch 3715 batch loss 1.05049503 epoch total loss 1.09609616
Trained batch 3716 batch loss 0.888692379 epoch total loss 1.09604025
Trained batch 3717 batch loss 0.955276906 epoch total loss 1.09600246
Trained batch 3718 batch loss 1.10888982 epoch total loss 1.09600592
Trained batch 3719 batch loss 1.1822871 epoch total loss 1.09602916
Trained batch 3720 batch loss 1.18277407 epoch total loss 1.09605253
Trained batch 3721 batch loss 1.06495118 epoch total loss 1.09604406
Trained batch 3722 batch loss 0.830697119 epoch total loss 1.0959729
Trained batch 3723 batch loss 1.15283895 epoch total loss 1.09598815
Trained batch 3724 batch loss 1.06310511 epoch total loss 1.09597921
Trained batch 3725 batch loss 1.15015686 epoch total loss 1.09599376
Trained batch 3726 batch loss 1.21228707 epoch total loss 1.09602499
Trained batch 3727 batch loss 1.07955647 epoch total loss 1.09602058
Trained batch 3728 batch loss 1.21601093 epoch total loss 1.09605289
Trained batch 3729 batch loss 1.2600286 epoch total loss 1.09609675
Trained batch 3730 batch loss 0.906438 epoch total loss 1.09604597
Trained batch 3731 batch loss 0.986646831 epoch total loss 1.09601665
Trained batch 3732 batch loss 0.830984712 epoch total loss 1.0959456
Trained batch 3733 batch loss 1.10137725 epoch total loss 1.09594703
Trained batch 3734 batch loss 1.03407276 epoch total loss 1.09593058
Trained batch 3735 batch loss 1.10428047 epoch total loss 1.09593272
Trained batch 3736 batch loss 1.2371366 epoch total loss 1.09597051
Trained batch 3737 batch loss 1.05036592 epoch total loss 1.09595835
Trained batch 3738 batch loss 1.33581567 epoch total loss 1.09602249
Trained batch 3739 batch loss 1.36414289 epoch total loss 1.09609425
Trained batch 3740 batch loss 1.1138773 epoch total loss 1.09609902
Trained batch 3741 batch loss 1.34379828 epoch total loss 1.09616518
Trained batch 3742 batch loss 1.26381195 epoch total loss 1.09620988
Trained batch 3743 batch loss 1.16489637 epoch total loss 1.09622836
Trained batch 3744 batch loss 1.08829165 epoch total loss 1.09622622
Trained batch 3745 batch loss 0.933751583 epoch total loss 1.09618282
Trained batch 3746 batch loss 1.00553572 epoch total loss 1.0961585
Trained batch 3747 batch loss 1.03168797 epoch total loss 1.09614134
Trained batch 3748 batch loss 1.3225553 epoch total loss 1.09620178
Trained batch 3749 batch loss 1.09928513 epoch total loss 1.09620261
Trained batch 3750 batch loss 1.40346694 epoch total loss 1.09628451
Trained batch 3751 batch loss 1.21124315 epoch total loss 1.09631515
Trained batch 3752 batch loss 1.06527591 epoch total loss 1.09630692
Trained batch 3753 batch loss 1.26802635 epoch total loss 1.0963527
Trained batch 3754 batch loss 0.985989332 epoch total loss 1.09632325
Trained batch 3755 batch loss 0.932559 epoch total loss 1.09627974
Trained batch 3756 batch loss 1.17634284 epoch total loss 1.09630096
Trained batch 3757 batch loss 1.12982702 epoch total loss 1.0963099
Trained batch 3758 batch loss 1.18698287 epoch total loss 1.0963341
Trained batch 3759 batch loss 1.00669992 epoch total loss 1.09631026
Trained batch 3760 batch loss 1.20198607 epoch total loss 1.09633839
Trained batch 3761 batch loss 1.224491 epoch total loss 1.09637249
Trained batch 3762 batch loss 1.33949888 epoch total loss 1.0964371
Trained batch 3763 batch loss 1.20240986 epoch total loss 1.09646535
Trained batch 3764 batch loss 1.18088329 epoch total loss 1.09648764
Trained batch 3765 batch loss 1.29485857 epoch total loss 1.09654045
Trained batch 3766 batch loss 1.28450799 epoch total loss 1.0965904
Trained batch 3767 batch loss 1.24053 epoch total loss 1.09662867
Trained batch 3768 batch loss 1.35363436 epoch total loss 1.09669673
Trained batch 3769 batch loss 1.26115787 epoch total loss 1.09674048
Trained batch 3770 batch loss 1.35161436 epoch total loss 1.09680808
Trained batch 3771 batch loss 1.3014462 epoch total loss 1.09686232
Trained batch 3772 batch loss 1.25548971 epoch total loss 1.09690428
Trained batch 3773 batch loss 1.09586763 epoch total loss 1.09690392
Trained batch 3774 batch loss 0.958452225 epoch total loss 1.09686732
Trained batch 3775 batch loss 0.95641923 epoch total loss 1.09683013
Trained batch 3776 batch loss 0.985859513 epoch total loss 1.09680068
Trained batch 3777 batch loss 1.0975287 epoch total loss 1.09680092
Trained batch 3778 batch loss 1.4381355 epoch total loss 1.09689128
Trained batch 3779 batch loss 1.29271829 epoch total loss 1.09694302
Trained batch 3780 batch loss 1.14166141 epoch total loss 1.09695482
Trained batch 3781 batch loss 1.18368447 epoch total loss 1.09697771
Trained batch 3782 batch loss 1.1736865 epoch total loss 1.0969981
Trained batch 3783 batch loss 1.08479297 epoch total loss 1.09699488
Trained batch 3784 batch loss 1.05105436 epoch total loss 1.09698284
Trained batch 3785 batch loss 1.02596307 epoch total loss 1.096964
Trained batch 3786 batch loss 1.18936253 epoch total loss 1.09698844
Trained batch 3787 batch loss 1.14375782 epoch total loss 1.09700072
Trained batch 3788 batch loss 1.30866098 epoch total loss 1.09705663
Trained batch 3789 batch loss 1.20858669 epoch total loss 1.09708595
Trained batch 3790 batch loss 1.10460663 epoch total loss 1.09708798
Trained batch 3791 batch loss 1.10388601 epoch total loss 1.09708977
Trained batch 3792 batch loss 1.18536019 epoch total loss 1.09711313
Trained batch 3793 batch loss 1.22021556 epoch total loss 1.09714556
Trained batch 3794 batch loss 1.10255575 epoch total loss 1.09714699
Trained batch 3795 batch loss 1.14098477 epoch total loss 1.09715855
Trained batch 3796 batch loss 1.13426709 epoch total loss 1.09716833
Trained batch 3797 batch loss 0.974295616 epoch total loss 1.0971359
Trained batch 3798 batch loss 1.12002659 epoch total loss 1.09714198
Trained batch 3799 batch loss 1.1409564 epoch total loss 1.09715354
Trained batch 3800 batch loss 1.05648065 epoch total loss 1.09714293
Trained batch 3801 batch loss 1.38840032 epoch total loss 1.09721947
Trained batch 3802 batch loss 1.17375612 epoch total loss 1.09723961
Trained batch 3803 batch loss 1.08233619 epoch total loss 1.0972358
Trained batch 3804 batch loss 0.944802642 epoch total loss 1.09719574
Trained batch 3805 batch loss 0.95298934 epoch total loss 1.09715784
Trained batch 3806 batch loss 1.05428958 epoch total loss 1.09714651
Trained batch 3807 batch loss 1.34168816 epoch total loss 1.09721076
Trained batch 3808 batch loss 1.1974318 epoch total loss 1.09723711
Trained batch 3809 batch loss 1.39544165 epoch total loss 1.09731543
Trained batch 3810 batch loss 1.07725048 epoch total loss 1.09731007
Trained batch 3811 batch loss 1.19099689 epoch total loss 1.09733462
Trained batch 3812 batch loss 0.933624506 epoch total loss 1.09729171
Trained batch 3813 batch loss 1.33692229 epoch total loss 1.09735453
Trained batch 3814 batch loss 1.16074884 epoch total loss 1.0973711
Trained batch 3815 batch loss 1.14885175 epoch total loss 1.09738469
Trained batch 3816 batch loss 1.02198696 epoch total loss 1.0973649
Trained batch 3817 batch loss 0.852967501 epoch total loss 1.09730089
Trained batch 3818 batch loss 1.21166039 epoch total loss 1.09733081
Trained batch 3819 batch loss 1.13642955 epoch total loss 1.09734094
Trained batch 3820 batch loss 1.41573489 epoch total loss 1.09742427
Trained batch 3821 batch loss 1.23876393 epoch total loss 1.09746122
Trained batch 3822 batch loss 1.15888906 epoch total loss 1.09747732
Trained batch 3823 batch loss 1.32952797 epoch total loss 1.09753799
Trained batch 3824 batch loss 1.10891223 epoch total loss 1.09754097
Trained batch 3825 batch loss 0.797976494 epoch total loss 1.09746265
Trained batch 3826 batch loss 0.929891586 epoch total loss 1.09741879
Trained batch 3827 batch loss 0.955247283 epoch total loss 1.09738159
Trained batch 3828 batch loss 1.2211864 epoch total loss 1.0974139
Trained batch 3829 batch loss 1.15651298 epoch total loss 1.09742939
Trained batch 3830 batch loss 1.0723412 epoch total loss 1.09742284
Trained batch 3831 batch loss 1.09671855 epoch total loss 1.0974226
Trained batch 3832 batch loss 0.989890099 epoch total loss 1.09739447
Trained batch 3833 batch loss 1.15672266 epoch total loss 1.09741
Trained batch 3834 batch loss 1.09212983 epoch total loss 1.09740865
Trained batch 3835 batch loss 1.12165165 epoch total loss 1.09741497
Trained batch 3836 batch loss 1.2360642 epoch total loss 1.09745109
Trained batch 3837 batch loss 1.19185901 epoch total loss 1.09747565
Trained batch 3838 batch loss 1.13844466 epoch total loss 1.09748638
Trained batch 3839 batch loss 1.01003528 epoch total loss 1.09746373
Trained batch 3840 batch loss 0.944519043 epoch total loss 1.09742379
Trained batch 3841 batch loss 1.00131869 epoch total loss 1.09739888
Trained batch 3842 batch loss 1.22285008 epoch total loss 1.09743142
Trained batch 3843 batch loss 1.03480709 epoch total loss 1.09741509
Trained batch 3844 batch loss 1.25477982 epoch total loss 1.0974561
Trained batch 3845 batch loss 1.18395662 epoch total loss 1.09747863
Trained batch 3846 batch loss 1.29253483 epoch total loss 1.09752929
Trained batch 3847 batch loss 1.00308013 epoch total loss 1.09750473
Trained batch 3848 batch loss 0.919627964 epoch total loss 1.09745848
Trained batch 3849 batch loss 0.923382878 epoch total loss 1.09741318
Trained batch 3850 batch loss 1.23460507 epoch total loss 1.09744871
Trained batch 3851 batch loss 1.33178914 epoch total loss 1.09750962
Trained batch 3852 batch loss 1.21110165 epoch total loss 1.09753907
Trained batch 3853 batch loss 1.26492155 epoch total loss 1.09758258
Trained batch 3854 batch loss 1.45312214 epoch total loss 1.09767485
Trained batch 3855 batch loss 1.12936711 epoch total loss 1.09768307
Trained batch 3856 batch loss 1.21437824 epoch total loss 1.09771335
Trained batch 3857 batch loss 1.2578727 epoch total loss 1.09775484
Trained batch 3858 batch loss 1.25518131 epoch total loss 1.09779572
Trained batch 3859 batch loss 1.41807938 epoch total loss 1.09787869
Trained batch 3860 batch loss 1.22169709 epoch total loss 1.09791076
Trained batch 3861 batch loss 1.1611414 epoch total loss 1.09792709
Trained batch 3862 batch loss 1.21502638 epoch total loss 1.09795737
Trained batch 3863 batch loss 1.18913412 epoch total loss 1.09798098
Trained batch 3864 batch loss 1.23769069 epoch total loss 1.0980171
Trained batch 3865 batch loss 1.26540744 epoch total loss 1.09806049
Trained batch 3866 batch loss 1.13863277 epoch total loss 1.09807098
Trained batch 3867 batch loss 1.16189051 epoch total loss 1.09808755
Trained batch 3868 batch loss 0.980023265 epoch total loss 1.09805703
Trained batch 3869 batch loss 1.08717513 epoch total loss 1.09805429
Trained batch 3870 batch loss 0.887645721 epoch total loss 1.09799993
Trained batch 3871 batch loss 1.02587509 epoch total loss 1.09798133
Trained batch 3872 batch loss 1.14422321 epoch total loss 1.09799325
Trained batch 3873 batch loss 1.04215837 epoch total loss 1.09797871
Trained batch 3874 batch loss 1.18147051 epoch total loss 1.09800029
Trained batch 3875 batch loss 0.99714303 epoch total loss 1.0979743
Trained batch 3876 batch loss 1.20879424 epoch total loss 1.09800291
Trained batch 3877 batch loss 1.37367535 epoch total loss 1.09807396
Trained batch 3878 batch loss 1.02088916 epoch total loss 1.09805417
Trained batch 3879 batch loss 1.1686523 epoch total loss 1.09807229
Trained batch 3880 batch loss 1.08440495 epoch total loss 1.09806871
Trained batch 3881 batch loss 1.08755493 epoch total loss 1.09806597
Trained batch 3882 batch loss 1.0904808 epoch total loss 1.09806406
Trained batch 3883 batch loss 1.19973075 epoch total loss 1.09809017
Trained batch 3884 batch loss 1.16681671 epoch total loss 1.09810793
Trained batch 3885 batch loss 1.02392733 epoch total loss 1.09808886
Trained batch 3886 batch loss 1.05255866 epoch total loss 1.09807718
Trained batch 3887 batch loss 1.14984775 epoch total loss 1.09809053
Trained batch 3888 batch loss 1.05978823 epoch total loss 1.09808064
Trained batch 3889 batch loss 1.05050731 epoch total loss 1.09806836
Trained batch 3890 batch loss 1.07300508 epoch total loss 1.09806192
Trained batch 3891 batch loss 1.17282951 epoch total loss 1.09808111
Trained batch 3892 batch loss 1.28974915 epoch total loss 1.09813035
Trained batch 3893 batch loss 1.04745317 epoch total loss 1.09811735
Trained batch 3894 batch loss 1.19280648 epoch total loss 1.09814167
Trained batch 3895 batch loss 1.09787226 epoch total loss 1.09814155
Trained batch 3896 batch loss 1.07783079 epoch total loss 1.09813631
Trained batch 3897 batch loss 1.21515977 epoch total loss 1.09816635
Trained batch 3898 batch loss 1.20972228 epoch total loss 1.09819496
Trained batch 3899 batch loss 1.16987884 epoch total loss 1.09821343
Trained batch 3900 batch loss 0.946979046 epoch total loss 1.09817457
Trained batch 3901 batch loss 1.05763614 epoch total loss 1.0981642
Trained batch 3902 batch loss 1.09277022 epoch total loss 1.09816277
Trained batch 3903 batch loss 1.14342511 epoch total loss 1.09817445
Trained batch 3904 batch loss 1.05870199 epoch total loss 1.09816432
Trained batch 3905 batch loss 1.06780219 epoch total loss 1.09815657
Trained batch 3906 batch loss 0.789077044 epoch total loss 1.09807742
Trained batch 3907 batch loss 0.962136269 epoch total loss 1.09804261
Trained batch 3908 batch loss 1.04015958 epoch total loss 1.09802771
Trained batch 3909 batch loss 0.788328826 epoch total loss 1.09794843
Trained batch 3910 batch loss 0.774254441 epoch total loss 1.0978657
Trained batch 3911 batch loss 1.1464119 epoch total loss 1.0978781
Trained batch 3912 batch loss 1.12081397 epoch total loss 1.09788394
Trained batch 3913 batch loss 1.30385947 epoch total loss 1.09793651
Trained batch 3914 batch loss 1.36700523 epoch total loss 1.09800529
Trained batch 3915 batch loss 1.37330556 epoch total loss 1.09807563
Trained batch 3916 batch loss 1.09142339 epoch total loss 1.09807396
Trained batch 3917 batch loss 1.13992441 epoch total loss 1.09808469
Trained batch 3918 batch loss 1.2907989 epoch total loss 1.09813392
Trained batch 3919 batch loss 1.14234662 epoch total loss 1.09814525
Trained batch 3920 batch loss 1.14277172 epoch total loss 1.09815657
Trained batch 3921 batch loss 1.26980925 epoch total loss 1.09820044
Trained batch 3922 batch loss 1.02459943 epoch total loss 1.09818161
Trained batch 3923 batch loss 1.18834162 epoch total loss 1.09820461
Trained batch 3924 batch loss 1.07230926 epoch total loss 1.09819806
Trained batch 3925 batch loss 1.25887799 epoch total loss 1.09823895
Trained batch 3926 batch loss 1.10971224 epoch total loss 1.09824193
Trained batch 3927 batch loss 1.18655574 epoch total loss 1.09826434
Trained batch 3928 batch loss 1.21664381 epoch total loss 1.09829462
Trained batch 3929 batch loss 1.20380569 epoch total loss 1.09832132
Trained batch 3930 batch loss 1.12498653 epoch total loss 1.09832811
Trained batch 3931 batch loss 1.13942981 epoch total loss 1.09833872
Trained batch 3932 batch loss 1.16603518 epoch total loss 1.09835589
Trained batch 3933 batch loss 1.01177931 epoch total loss 1.09833384
Trained batch 3934 batch loss 0.924048662 epoch total loss 1.09828949
Trained batch 3935 batch loss 1.0335052 epoch total loss 1.09827304
Trained batch 3936 batch loss 0.968444228 epoch total loss 1.09824
Trained batch 3937 batch loss 0.869145215 epoch total loss 1.09818184
Trained batch 3938 batch loss 0.949242711 epoch total loss 1.09814405
Trained batch 3939 batch loss 0.744637609 epoch total loss 1.09805429
Trained batch 3940 batch loss 1.02508187 epoch total loss 1.09803569
Trained batch 3941 batch loss 0.957214475 epoch total loss 1.09799993
Trained batch 3942 batch loss 1.05374074 epoch total loss 1.09798872
Trained batch 3943 batch loss 1.01527 epoch total loss 1.09796774
Trained batch 3944 batch loss 1.05048072 epoch total loss 1.09795558
Trained batch 3945 batch loss 1.17966628 epoch total loss 1.09797633
Trained batch 3946 batch loss 1.19187737 epoch total loss 1.09800017
Trained batch 3947 batch loss 1.19445777 epoch total loss 1.09802449
Trained batch 3948 batch loss 1.1155467 epoch total loss 1.09802902
Trained batch 3949 batch loss 1.11973906 epoch total loss 1.0980345
Trained batch 3950 batch loss 0.990990758 epoch total loss 1.09800744
Trained batch 3951 batch loss 0.980568409 epoch total loss 1.09797764
Trained batch 3952 batch loss 1.05930591 epoch total loss 1.09796786
Trained batch 3953 batch loss 1.10953605 epoch total loss 1.09797072
Trained batch 3954 batch loss 1.22583163 epoch total loss 1.09800315
Trained batch 3955 batch loss 1.32009721 epoch total loss 1.0980593
Trained batch 3956 batch loss 1.13296187 epoch total loss 1.09806812
Trained batch 3957 batch loss 1.20627427 epoch total loss 1.09809542
Trained batch 3958 batch loss 1.16308641 epoch total loss 1.09811187
Trained batch 3959 batch loss 1.31144929 epoch total loss 1.09816575
Trained batch 3960 batch loss 1.28522396 epoch total loss 1.09821296
Trained batch 3961 batch loss 1.03494227 epoch total loss 1.0981971
Trained batch 3962 batch loss 1.32491016 epoch total loss 1.0982542
Trained batch 3963 batch loss 1.04020131 epoch total loss 1.09823954
Trained batch 3964 batch loss 1.09196854 epoch total loss 1.09823787
Trained batch 3965 batch loss 1.10629106 epoch total loss 1.09824
Trained batch 3966 batch loss 1.23150122 epoch total loss 1.09827352
Trained batch 3967 batch loss 1.154809 epoch total loss 1.09828782
Trained batch 3968 batch loss 1.32919502 epoch total loss 1.09834599
Trained batch 3969 batch loss 1.25271189 epoch total loss 1.09838498
Trained batch 3970 batch loss 1.1089114 epoch total loss 1.0983876
Trained batch 3971 batch loss 1.16344607 epoch total loss 1.09840393
Trained batch 3972 batch loss 1.3349905 epoch total loss 1.09846354
Trained batch 3973 batch loss 1.23104215 epoch total loss 1.09849691
Trained batch 3974 batch loss 1.44685125 epoch total loss 1.09858453
Trained batch 3975 batch loss 1.25240088 epoch total loss 1.09862328
Trained batch 3976 batch loss 1.40980959 epoch total loss 1.09870148
Trained batch 3977 batch loss 1.26771569 epoch total loss 1.09874392
Trained batch 3978 batch loss 1.09626865 epoch total loss 1.09874332
Trained batch 3979 batch loss 1.14803839 epoch total loss 1.0987556
Trained batch 3980 batch loss 1.10790181 epoch total loss 1.09875798
Trained batch 3981 batch loss 1.224841 epoch total loss 1.09878957
Trained batch 3982 batch loss 1.36693251 epoch total loss 1.09885681
Trained batch 3983 batch loss 1.35514951 epoch total loss 1.09892118
Trained batch 3984 batch loss 1.3540082 epoch total loss 1.0989852
Trained batch 3985 batch loss 1.38870072 epoch total loss 1.09905791
Trained batch 3986 batch loss 1.1887002 epoch total loss 1.09908032
Trained batch 3987 batch loss 1.02688813 epoch total loss 1.0990622
Trained batch 3988 batch loss 1.24492347 epoch total loss 1.0990988
Trained batch 3989 batch loss 1.04299164 epoch total loss 1.09908473
Trained batch 3990 batch loss 1.12083304 epoch total loss 1.0990901
Trained batch 3991 batch loss 1.34542489 epoch total loss 1.09915185
Trained batch 3992 batch loss 0.897984684 epoch total loss 1.09910142
Trained batch 3993 batch loss 0.924650311 epoch total loss 1.09905779
Trained batch 3994 batch loss 1.13205862 epoch total loss 1.0990659
Trained batch 3995 batch loss 1.27737784 epoch total loss 1.0991106
Trained batch 3996 batch loss 1.02567708 epoch total loss 1.09909225
Trained batch 3997 batch loss 1.47750831 epoch total loss 1.0991869
Trained batch 3998 batch loss 1.10915065 epoch total loss 1.09918952
Trained batch 3999 batch loss 1.24470294 epoch total loss 1.09922588
Trained batch 4000 batch loss 1.02880168 epoch total loss 1.09920824
Trained batch 4001 batch loss 1.27256072 epoch total loss 1.09925151
Trained batch 4002 batch loss 0.994468689 epoch total loss 1.0992254
Trained batch 4003 batch loss 1.03174126 epoch total loss 1.09920859
Trained batch 4004 batch loss 0.864049256 epoch total loss 1.09914982
Trained batch 4005 batch loss 0.804554224 epoch total loss 1.09907639
Trained batch 4006 batch loss 1.2724911 epoch total loss 1.09911966
Trained batch 4007 batch loss 1.0558517 epoch total loss 1.09910882
Trained batch 4008 batch loss 0.939497471 epoch total loss 1.099069
Trained batch 4009 batch loss 1.06692696 epoch total loss 1.09906089
Trained batch 4010 batch loss 0.921273112 epoch total loss 1.09901667
Trained batch 4011 batch loss 1.12398982 epoch total loss 1.09902287
Trained batch 4012 batch loss 1.18147016 epoch total loss 1.09904349
Trained batch 4013 batch loss 1.03738081 epoch total loss 1.09902811
Trained batch 4014 batch loss 1.23819304 epoch total loss 1.0990628
Trained batch 4015 batch loss 1.08462656 epoch total loss 1.09905922
Trained batch 4016 batch loss 1.20337343 epoch total loss 1.09908521
Trained batch 4017 batch loss 1.15211487 epoch total loss 1.09909844
Trained batch 4018 batch loss 1.07479405 epoch total loss 1.09909236
Trained batch 4019 batch loss 1.16962934 epoch total loss 1.09910989
Trained batch 4020 batch loss 0.991957605 epoch total loss 1.0990833
Trained batch 4021 batch loss 0.974443793 epoch total loss 1.09905231
Trained batch 4022 batch loss 1.16400087 epoch total loss 1.09906852
Trained batch 4023 batch loss 1.27633929 epoch total loss 1.09911263
Trained batch 4024 batch loss 1.10000944 epoch total loss 1.09911287
Trained batch 4025 batch loss 1.00605416 epoch total loss 1.09908962
Trained batch 4026 batch loss 1.12129712 epoch total loss 1.09909511
Trained batch 4027 batch loss 1.13031173 epoch total loss 1.09910285
Trained batch 4028 batch loss 1.16719115 epoch total loss 1.09911978
Trained batch 4029 batch loss 1.19084263 epoch total loss 1.09914255
Trained batch 4030 batch loss 1.12891865 epoch total loss 1.09915
Trained batch 4031 batch loss 1.18441367 epoch total loss 1.09917116
Trained batch 4032 batch loss 1.28875744 epoch total loss 1.09921813
Trained batch 4033 batch loss 1.32421768 epoch total loss 1.09927392
Trained batch 4034 batch loss 1.24975324 epoch total loss 1.09931111
Trained batch 4035 batch loss 1.11960852 epoch total loss 1.09931612
Trained batch 4036 batch loss 1.17408299 epoch total loss 1.09933472
Trained batch 4037 batch loss 1.39917433 epoch total loss 1.0994091
Trained batch 4038 batch loss 1.14559627 epoch total loss 1.09942055
Trained batch 4039 batch loss 1.12587 epoch total loss 1.0994271
Trained batch 4040 batch loss 1.15225565 epoch total loss 1.09944022
Trained batch 4041 batch loss 1.28684533 epoch total loss 1.09948647
Trained batch 4042 batch loss 1.16860962 epoch total loss 1.09950352
Trained batch 4043 batch loss 1.37419987 epoch total loss 1.09957147
Trained batch 4044 batch loss 1.16922641 epoch total loss 1.09958875
Trained batch 4045 batch loss 1.17895103 epoch total loss 1.0996083
Trained batch 4046 batch loss 1.2220118 epoch total loss 1.09963858
Trained batch 4047 batch loss 1.29744887 epoch total loss 1.09968746
Trained batch 4048 batch loss 1.25359046 epoch total loss 1.09972537
Trained batch 4049 batch loss 1.36431658 epoch total loss 1.09979069
Trained batch 4050 batch loss 1.06177056 epoch total loss 1.09978139
Trained batch 4051 batch loss 1.04824197 epoch total loss 1.09976876
Trained batch 4052 batch loss 0.786982477 epoch total loss 1.09969151
Trained batch 4053 batch loss 1.08769846 epoch total loss 1.09968865
Trained batch 4054 batch loss 1.04042411 epoch total loss 1.09967411
Trained batch 4055 batch loss 0.962847 epoch total loss 1.09964037
Trained batch 4056 batch loss 1.01172066 epoch total loss 1.09961867
Trained batch 4057 batch loss 0.986071289 epoch total loss 1.09959066
Trained batch 4058 batch loss 1.171803 epoch total loss 1.09960842
Trained batch 4059 batch loss 1.3334446 epoch total loss 1.099666
Trained batch 4060 batch loss 1.12908518 epoch total loss 1.09967327
Trained batch 4061 batch loss 1.04751205 epoch total loss 1.0996604
Trained batch 4062 batch loss 1.11812854 epoch total loss 1.09966493
Trained batch 4063 batch loss 1.04100275 epoch total loss 1.0996505
Trained batch 4064 batch loss 0.857838 epoch total loss 1.09959102
Trained batch 4065 batch loss 0.894173145 epoch total loss 1.09954047
Trained batch 4066 batch loss 0.78786087 epoch total loss 1.09946382
Trained batch 4067 batch loss 0.949868202 epoch total loss 1.09942698
Trained batch 4068 batch loss 0.938268065 epoch total loss 1.09938741
Trained batch 4069 batch loss 1.01082397 epoch total loss 1.09936571
Trained batch 4070 batch loss 1.0761776 epoch total loss 1.09936
Trained batch 4071 batch loss 0.926732957 epoch total loss 1.09931755
Trained batch 4072 batch loss 1.18371201 epoch total loss 1.09933829
Trained batch 4073 batch loss 1.29465079 epoch total loss 1.0993861
Trained batch 4074 batch loss 1.3844074 epoch total loss 1.09945607
Trained batch 4075 batch loss 0.791472852 epoch total loss 1.09938049
Trained batch 4076 batch loss 1.0806613 epoch total loss 1.09937584
Trained batch 4077 batch loss 1.28260088 epoch total loss 1.09942091
Trained batch 4078 batch loss 1.19284844 epoch total loss 1.09944379
Trained batch 4079 batch loss 1.26201487 epoch total loss 1.09948373
Trained batch 4080 batch loss 1.37688458 epoch total loss 1.09955168
Trained batch 4081 batch loss 1.12251282 epoch total loss 1.09955728
Trained batch 4082 batch loss 1.25190616 epoch total loss 1.09959471
Trained batch 4083 batch loss 1.30208921 epoch total loss 1.0996443
Trained batch 4084 batch loss 1.31487274 epoch total loss 1.09969699
Trained batch 4085 batch loss 1.40630722 epoch total loss 1.0997721
Trained batch 4086 batch loss 1.30324578 epoch total loss 1.09982181
Trained batch 4087 batch loss 1.11756444 epoch total loss 1.09982622
Trained batch 4088 batch loss 1.07993472 epoch total loss 1.09982133
Trained batch 4089 batch loss 1.21667182 epoch total loss 1.09984994
Trained batch 4090 batch loss 1.23843265 epoch total loss 1.09988379
Trained batch 4091 batch loss 1.2324326 epoch total loss 1.09991622
Trained batch 4092 batch loss 1.23532343 epoch total loss 1.09994936
Trained batch 4093 batch loss 1.05653155 epoch total loss 1.09993875
Trained batch 4094 batch loss 1.02599084 epoch total loss 1.09992063
Trained batch 4095 batch loss 0.934356689 epoch total loss 1.09988034
Trained batch 4096 batch loss 1.32119393 epoch total loss 1.09993434
Trained batch 4097 batch loss 1.15097785 epoch total loss 1.09994674
Trained batch 4098 batch loss 1.01343155 epoch total loss 1.09992576
Trained batch 4099 batch loss 1.12262988 epoch total loss 1.09993124
Trained batch 4100 batch loss 1.08514071 epoch total loss 1.09992754
Trained batch 4101 batch loss 1.18755925 epoch total loss 1.099949
Trained batch 4102 batch loss 1.25978875 epoch total loss 1.09998786
Trained batch 4103 batch loss 0.998122752 epoch total loss 1.09996307
Trained batch 4104 batch loss 1.18321335 epoch total loss 1.09998333
Trained batch 4105 batch loss 1.23706698 epoch total loss 1.10001671
Trained batch 4106 batch loss 0.930551529 epoch total loss 1.09997559
Trained batch 4107 batch loss 1.08699203 epoch total loss 1.09997237
Trained batch 4108 batch loss 1.08256674 epoch total loss 1.09996808
Trained batch 4109 batch loss 1.15034664 epoch total loss 1.09998035
Trained batch 4110 batch loss 1.15295243 epoch total loss 1.09999323
Trained batch 4111 batch loss 1.0456686 epoch total loss 1.09998012
Trained batch 4112 batch loss 1.07652855 epoch total loss 1.09997439
Trained batch 4113 batch loss 1.11368227 epoch total loss 1.09997773
Trained batch 4114 batch loss 1.23985863 epoch total loss 1.10001171
Trained batch 4115 batch loss 1.21828461 epoch total loss 1.10004044
Trained batch 4116 batch loss 1.35745585 epoch total loss 1.10010302
Trained batch 4117 batch loss 1.30023217 epoch total loss 1.10015166
Trained batch 4118 batch loss 1.22959626 epoch total loss 1.10018301
Trained batch 4119 batch loss 1.19267607 epoch total loss 1.10020554
Trained batch 4120 batch loss 0.973500252 epoch total loss 1.10017478
Trained batch 4121 batch loss 1.06939483 epoch total loss 1.10016727
Trained batch 4122 batch loss 0.997472167 epoch total loss 1.10014248
Trained batch 4123 batch loss 1.23904431 epoch total loss 1.10017622
Trained batch 4124 batch loss 0.975384 epoch total loss 1.10014594
Trained batch 4125 batch loss 1.27829862 epoch total loss 1.10018921
Trained batch 4126 batch loss 1.09456515 epoch total loss 1.10018778
Trained batch 4127 batch loss 0.915912926 epoch total loss 1.10014319
Trained batch 4128 batch loss 1.24568152 epoch total loss 1.10017848
Trained batch 4129 batch loss 1.31895161 epoch total loss 1.10023141
Trained batch 4130 batch loss 1.13852692 epoch total loss 1.10024071
Trained batch 4131 batch loss 1.05146623 epoch total loss 1.10022891
Trained batch 4132 batch loss 1.01157427 epoch total loss 1.10020745
Trained batch 4133 batch loss 1.17986417 epoch total loss 1.10022664
Trained batch 4134 batch loss 0.812255204 epoch total loss 1.1001569
Trained batch 4135 batch loss 0.652328968 epoch total loss 1.10004866
Trained batch 4136 batch loss 0.86961472 epoch total loss 1.09999299
Trained batch 4137 batch loss 1.25639546 epoch total loss 1.10003078
Trained batch 4138 batch loss 0.878169596 epoch total loss 1.09997702
Trained batch 4139 batch loss 1.25525224 epoch total loss 1.10001457
Trained batch 4140 batch loss 1.02563953 epoch total loss 1.09999669
Trained batch 4141 batch loss 1.25952053 epoch total loss 1.10003519
Trained batch 4142 batch loss 1.08732581 epoch total loss 1.10003209
Trained batch 4143 batch loss 0.963084 epoch total loss 1.09999895
Trained batch 4144 batch loss 1.11301172 epoch total loss 1.10000205
Trained batch 4145 batch loss 0.925965786 epoch total loss 1.09996009
Trained batch 4146 batch loss 0.966357291 epoch total loss 1.09992778
Trained batch 4147 batch loss 0.899261713 epoch total loss 1.0998795
Trained batch 4148 batch loss 1.05900955 epoch total loss 1.09986961
Trained batch 4149 batch loss 0.96539706 epoch total loss 1.09983718
Trained batch 4150 batch loss 0.784667253 epoch total loss 1.09976125
Trained batch 4151 batch loss 0.9419837 epoch total loss 1.09972322
Trained batch 4152 batch loss 1.20259249 epoch total loss 1.09974802
Trained batch 4153 batch loss 0.86777842 epoch total loss 1.09969211
Trained batch 4154 batch loss 1.29973269 epoch total loss 1.09974027
Trained batch 4155 batch loss 0.839735031 epoch total loss 1.0996778
Trained batch 4156 batch loss 1.07025313 epoch total loss 1.09967065
Trained batch 4157 batch loss 1.13947415 epoch total loss 1.0996803
Trained batch 4158 batch loss 1.11369109 epoch total loss 1.09968376
Trained batch 4159 batch loss 0.864754498 epoch total loss 1.09962726
Trained batch 4160 batch loss 1.14647198 epoch total loss 1.09963846
Trained batch 4161 batch loss 1.21546149 epoch total loss 1.09966624
Trained batch 4162 batch loss 1.08579445 epoch total loss 1.09966302
Trained batch 4163 batch loss 1.23674691 epoch total loss 1.09969592
Trained batch 4164 batch loss 1.21788645 epoch total loss 1.09972429
Trained batch 4165 batch loss 1.37316537 epoch total loss 1.09978986
Trained batch 4166 batch loss 1.41649914 epoch total loss 1.09986591
Trained batch 4167 batch loss 1.09440434 epoch total loss 1.0998646
Trained batch 4168 batch loss 1.12833285 epoch total loss 1.0998714
Trained batch 4169 batch loss 1.19698441 epoch total loss 1.09989464
Trained batch 4170 batch loss 1.39999914 epoch total loss 1.09996665
Trained batch 4171 batch loss 1.12048483 epoch total loss 1.09997153
Trained batch 4172 batch loss 1.00532472 epoch total loss 1.09994888
Trained batch 4173 batch loss 1.08059955 epoch total loss 1.09994423
Trained batch 4174 batch loss 0.934116483 epoch total loss 1.09990454
Trained batch 4175 batch loss 1.02492642 epoch total loss 1.09988654
Trained batch 4176 batch loss 1.0828476 epoch total loss 1.09988248
Trained batch 4177 batch loss 1.08424878 epoch total loss 1.09987879
Trained batch 4178 batch loss 0.954135656 epoch total loss 1.09984398
Trained batch 4179 batch loss 1.12340951 epoch total loss 1.09984958
Trained batch 4180 batch loss 1.16885746 epoch total loss 1.09986615
Trained batch 4181 batch loss 1.28023887 epoch total loss 1.09990931
Trained batch 4182 batch loss 1.1846199 epoch total loss 1.09992957
Trained batch 4183 batch loss 0.971524 epoch total loss 1.09989882
Trained batch 4184 batch loss 1.19554687 epoch total loss 1.0999217
Trained batch 4185 batch loss 1.076002 epoch total loss 1.09991598
Trained batch 4186 batch loss 1.1498313 epoch total loss 1.0999279
Trained batch 4187 batch loss 0.994065762 epoch total loss 1.09990263
Trained batch 4188 batch loss 1.21210277 epoch total loss 1.09992945
Trained batch 4189 batch loss 1.21318936 epoch total loss 1.09995651
Trained batch 4190 batch loss 1.23980892 epoch total loss 1.09998989
Trained batch 4191 batch loss 1.06415248 epoch total loss 1.09998131
Trained batch 4192 batch loss 1.1391139 epoch total loss 1.09999061
Trained batch 4193 batch loss 0.786956906 epoch total loss 1.09991598
Trained batch 4194 batch loss 1.0172286 epoch total loss 1.09989619
Trained batch 4195 batch loss 1.22327232 epoch total loss 1.09992564
Trained batch 4196 batch loss 1.32540393 epoch total loss 1.09997928
Trained batch 4197 batch loss 1.28429627 epoch total loss 1.10002315
Trained batch 4198 batch loss 1.11890054 epoch total loss 1.1000278
Trained batch 4199 batch loss 1.13712883 epoch total loss 1.10003662
Trained batch 4200 batch loss 1.07798564 epoch total loss 1.10003138
Trained batch 4201 batch loss 1.0270617 epoch total loss 1.10001397
Trained batch 4202 batch loss 1.07332098 epoch total loss 1.10000765
Trained batch 4203 batch loss 1.06951785 epoch total loss 1.10000026
Trained batch 4204 batch loss 1.06485903 epoch total loss 1.09999192
Trained batch 4205 batch loss 1.02299666 epoch total loss 1.09997368
Trained batch 4206 batch loss 1.19419408 epoch total loss 1.09999609
Trained batch 4207 batch loss 0.920081 epoch total loss 1.09995329
Trained batch 4208 batch loss 1.11276388 epoch total loss 1.09995627
Trained batch 4209 batch loss 1.22001934 epoch total loss 1.09998488
Trained batch 4210 batch loss 1.16472 epoch total loss 1.10000026
Trained batch 4211 batch loss 1.01730919 epoch total loss 1.09998059
Trained batch 4212 batch loss 1.19406104 epoch total loss 1.10000288
Trained batch 4213 batch loss 1.14915752 epoch total loss 1.10001445
Trained batch 4214 batch loss 1.19685793 epoch total loss 1.10003746
Trained batch 4215 batch loss 1.24204397 epoch total loss 1.10007107
Trained batch 4216 batch loss 1.35323501 epoch total loss 1.10013115
Trained batch 4217 batch loss 1.14668953 epoch total loss 1.10014212
Trained batch 4218 batch loss 0.959208906 epoch total loss 1.10010862
Trained batch 4219 batch loss 1.12606239 epoch total loss 1.10011482
Trained batch 4220 batch loss 1.06966686 epoch total loss 1.10010755
Trained batch 4221 batch loss 0.807673812 epoch total loss 1.10003829
Trained batch 4222 batch loss 1.10991216 epoch total loss 1.10004067
Trained batch 4223 batch loss 1.08844817 epoch total loss 1.10003793
Trained batch 4224 batch loss 0.926021457 epoch total loss 1.09999657
Trained batch 4225 batch loss 0.888634562 epoch total loss 1.09994662
Trained batch 4226 batch loss 0.974715054 epoch total loss 1.09991693
Trained batch 4227 batch loss 0.828906655 epoch total loss 1.09985292
Trained batch 4228 batch loss 0.721882701 epoch total loss 1.09976339
Trained batch 4229 batch loss 0.899346948 epoch total loss 1.09971607
Trained batch 4230 batch loss 0.795569241 epoch total loss 1.09964406
Trained batch 4231 batch loss 0.991360903 epoch total loss 1.09961843
Trained batch 4232 batch loss 0.931107521 epoch total loss 1.09957874
Trained batch 4233 batch loss 1.08847761 epoch total loss 1.099576
Trained batch 4234 batch loss 0.954116821 epoch total loss 1.09954166
Trained batch 4235 batch loss 0.89791131 epoch total loss 1.0994941
Trained batch 4236 batch loss 0.98759675 epoch total loss 1.09946775
Trained batch 4237 batch loss 0.996261775 epoch total loss 1.09944332
Trained batch 4238 batch loss 1.1079005 epoch total loss 1.09944534
Trained batch 4239 batch loss 1.07008421 epoch total loss 1.09943843
Trained batch 4240 batch loss 1.12094164 epoch total loss 1.09944355
Trained batch 4241 batch loss 0.869907439 epoch total loss 1.09938943
Trained batch 4242 batch loss 1.03361499 epoch total loss 1.09937394
Trained batch 4243 batch loss 0.964746833 epoch total loss 1.09934223
Trained batch 4244 batch loss 0.964628279 epoch total loss 1.09931064
Trained batch 4245 batch loss 0.895714939 epoch total loss 1.0992626
Trained batch 4246 batch loss 0.781124711 epoch total loss 1.09918773
Trained batch 4247 batch loss 0.754853 epoch total loss 1.09910655
Trained batch 4248 batch loss 1.005867 epoch total loss 1.09908462
Trained batch 4249 batch loss 1.01860142 epoch total loss 1.09906566
Trained batch 4250 batch loss 1.04613066 epoch total loss 1.09905314
Trained batch 4251 batch loss 1.19057584 epoch total loss 1.09907472
Trained batch 4252 batch loss 1.47586584 epoch total loss 1.09916329
Trained batch 4253 batch loss 1.22186017 epoch total loss 1.09919214
Trained batch 4254 batch loss 1.32767391 epoch total loss 1.09924591
Trained batch 4255 batch loss 1.41747928 epoch total loss 1.09932065
Trained batch 4256 batch loss 1.31017792 epoch total loss 1.09937012
Trained batch 4257 batch loss 1.30731 epoch total loss 1.099419
Trained batch 4258 batch loss 1.22281325 epoch total loss 1.09944797
Trained batch 4259 batch loss 0.950304747 epoch total loss 1.09941292
Trained batch 4260 batch loss 1.00721979 epoch total loss 1.09939122
Trained batch 4261 batch loss 0.931535959 epoch total loss 1.09935188
Trained batch 4262 batch loss 0.9607656 epoch total loss 1.09931946
Trained batch 4263 batch loss 1.02818656 epoch total loss 1.09930277
Trained batch 4264 batch loss 1.0568924 epoch total loss 1.09929287
Trained batch 4265 batch loss 1.00358903 epoch total loss 1.09927034
Trained batch 4266 batch loss 0.846887946 epoch total loss 1.09921122
Trained batch 4267 batch loss 0.937875211 epoch total loss 1.09917343
Trained batch 4268 batch loss 1.00536954 epoch total loss 1.09915137
Trained batch 4269 batch loss 1.19284344 epoch total loss 1.09917331
Trained batch 4270 batch loss 1.31362379 epoch total loss 1.09922349
Trained batch 4271 batch loss 1.33492494 epoch total loss 1.09927869
Trained batch 4272 batch loss 1.14741087 epoch total loss 1.09929
Trained batch 4273 batch loss 1.34838653 epoch total loss 1.09934831
Trained batch 4274 batch loss 1.04294395 epoch total loss 1.09933507
Trained batch 4275 batch loss 1.24192119 epoch total loss 1.09936833
Trained batch 4276 batch loss 1.26027286 epoch total loss 1.099406
Trained batch 4277 batch loss 1.22433615 epoch total loss 1.09943521
Trained batch 4278 batch loss 1.12970638 epoch total loss 1.09944224
Trained batch 4279 batch loss 1.05297732 epoch total loss 1.0994314
Trained batch 4280 batch loss 1.30740976 epoch total loss 1.09948
Trained batch 4281 batch loss 1.09018862 epoch total loss 1.09947789
Trained batch 4282 batch loss 1.13213956 epoch total loss 1.09948552
Trained batch 4283 batch loss 1.18107808 epoch total loss 1.09950459
Trained batch 4284 batch loss 1.24370956 epoch total loss 1.09953821
Trained batch 4285 batch loss 1.04594159 epoch total loss 1.09952569
Trained batch 4286 batch loss 1.06930518 epoch total loss 1.09951866
Trained batch 4287 batch loss 1.13531756 epoch total loss 1.099527
Trained batch 4288 batch loss 1.22691941 epoch total loss 1.0995568
Trained batch 4289 batch loss 1.19748902 epoch total loss 1.09957957
Trained batch 4290 batch loss 1.17977309 epoch total loss 1.09959817
Trained batch 4291 batch loss 1.21961498 epoch total loss 1.09962618
Trained batch 4292 batch loss 1.17764831 epoch total loss 1.09964442
Trained batch 4293 batch loss 1.20693398 epoch total loss 1.09966946
Trained batch 4294 batch loss 1.15431356 epoch total loss 1.09968209
Trained batch 4295 batch loss 1.04692662 epoch total loss 1.09966981
Trained batch 4296 batch loss 1.01790762 epoch total loss 1.09965086
Trained batch 4297 batch loss 1.07648611 epoch total loss 1.0996455
Trained batch 4298 batch loss 1.13889563 epoch total loss 1.09965456
Trained batch 4299 batch loss 1.35552073 epoch total loss 1.09971404
Trained batch 4300 batch loss 1.09301543 epoch total loss 1.09971249
Trained batch 4301 batch loss 1.15829396 epoch total loss 1.09972608
Trained batch 4302 batch loss 1.18238866 epoch total loss 1.09974539
Trained batch 4303 batch loss 0.9586941 epoch total loss 1.09971249
Trained batch 4304 batch loss 0.996784449 epoch total loss 1.09968853
Trained batch 4305 batch loss 1.10148203 epoch total loss 1.09968901
Trained batch 4306 batch loss 1.08472848 epoch total loss 1.09968555
Trained batch 4307 batch loss 1.1002717 epoch total loss 1.09968567
Trained batch 4308 batch loss 1.23202336 epoch total loss 1.09971642
Trained batch 4309 batch loss 1.09233165 epoch total loss 1.09971464
Trained batch 4310 batch loss 0.961056471 epoch total loss 1.09968245
Trained batch 4311 batch loss 1.06661773 epoch total loss 1.0996747
Trained batch 4312 batch loss 1.15788698 epoch total loss 1.09968817
Trained batch 4313 batch loss 1.0853337 epoch total loss 1.09968483
Trained batch 4314 batch loss 1.22577643 epoch total loss 1.09971404
Trained batch 4315 batch loss 1.05407429 epoch total loss 1.09970355
Trained batch 4316 batch loss 1.14736354 epoch total loss 1.09971464
Trained batch 4317 batch loss 1.37520194 epoch total loss 1.09977841
Trained batch 4318 batch loss 1.05102205 epoch total loss 1.09976697
Trained batch 4319 batch loss 1.07912827 epoch total loss 1.0997622
Trained batch 4320 batch loss 1.03093219 epoch total loss 1.09974623
Trained batch 4321 batch loss 1.11721635 epoch total loss 1.09975028
Trained batch 4322 batch loss 1.21028531 epoch total loss 1.09977591
Trained batch 4323 batch loss 1.16616523 epoch total loss 1.09979117
Trained batch 4324 batch loss 1.16341972 epoch total loss 1.09980595
Trained batch 4325 batch loss 1.22195148 epoch total loss 1.09983432
Trained batch 4326 batch loss 1.01164007 epoch total loss 1.09981394
Trained batch 4327 batch loss 1.23238528 epoch total loss 1.09984457
Trained batch 4328 batch loss 1.25620055 epoch total loss 1.0998807
Trained batch 4329 batch loss 1.21638048 epoch total loss 1.09990764
Trained batch 4330 batch loss 1.21048105 epoch total loss 1.09993315
Trained batch 4331 batch loss 1.27705884 epoch total loss 1.09997404
Trained batch 4332 batch loss 1.20575929 epoch total loss 1.09999835
Trained batch 4333 batch loss 1.23145354 epoch total loss 1.10002863
Trained batch 4334 batch loss 1.09313822 epoch total loss 1.10002708
Trained batch 4335 batch loss 1.21526039 epoch total loss 1.10005379
Trained batch 4336 batch loss 1.17591178 epoch total loss 1.10007119
Trained batch 4337 batch loss 1.23518777 epoch total loss 1.10010242
Trained batch 4338 batch loss 0.988343 epoch total loss 1.10007656
Trained batch 4339 batch loss 0.887352586 epoch total loss 1.10002756
Trained batch 4340 batch loss 1.08281398 epoch total loss 1.10002363
Trained batch 4341 batch loss 1.0759207 epoch total loss 1.10001802
Trained batch 4342 batch loss 1.0219754 epoch total loss 1.1
Trained batch 4343 batch loss 1.06065106 epoch total loss 1.09999096
Trained batch 4344 batch loss 1.34570932 epoch total loss 1.10004747
Trained batch 4345 batch loss 1.12871194 epoch total loss 1.10005414
Trained batch 4346 batch loss 1.15302634 epoch total loss 1.1000663
Trained batch 4347 batch loss 1.23084259 epoch total loss 1.10009646
Trained batch 4348 batch loss 1.50044119 epoch total loss 1.10018849
Trained batch 4349 batch loss 1.20997977 epoch total loss 1.10021377
Trained batch 4350 batch loss 1.18475902 epoch total loss 1.1002332
Trained batch 4351 batch loss 1.29680157 epoch total loss 1.10027838
Trained batch 4352 batch loss 1.06879961 epoch total loss 1.10027111
Trained batch 4353 batch loss 1.19076812 epoch total loss 1.10029197
Trained batch 4354 batch loss 1.47352171 epoch total loss 1.10037768
Trained batch 4355 batch loss 1.27226543 epoch total loss 1.10041726
Trained batch 4356 batch loss 1.27852857 epoch total loss 1.10045803
Trained batch 4357 batch loss 1.2633363 epoch total loss 1.10049534
Trained batch 4358 batch loss 1.28020716 epoch total loss 1.10053658
Trained batch 4359 batch loss 1.26025879 epoch total loss 1.1005733
Trained batch 4360 batch loss 0.936673462 epoch total loss 1.10053563
Trained batch 4361 batch loss 0.997876108 epoch total loss 1.10051215
Trained batch 4362 batch loss 1.27718496 epoch total loss 1.10055268
Trained batch 4363 batch loss 1.17848659 epoch total loss 1.10057056
Trained batch 4364 batch loss 1.38699353 epoch total loss 1.10063624
Trained batch 4365 batch loss 1.10655 epoch total loss 1.10063767
Trained batch 4366 batch loss 1.09623098 epoch total loss 1.1006366
Trained batch 4367 batch loss 1.25056803 epoch total loss 1.10067093
Trained batch 4368 batch loss 1.0486933 epoch total loss 1.10065901
Trained batch 4369 batch loss 1.17106175 epoch total loss 1.10067511
Trained batch 4370 batch loss 1.1335969 epoch total loss 1.10068274
Trained batch 4371 batch loss 1.12094009 epoch total loss 1.10068738
Trained batch 4372 batch loss 0.995096266 epoch total loss 1.10066319
Trained batch 4373 batch loss 1.01616073 epoch total loss 1.10064387
Trained batch 4374 batch loss 0.953680873 epoch total loss 1.10061026
Trained batch 4375 batch loss 0.826591313 epoch total loss 1.10054767
Trained batch 4376 batch loss 0.786241174 epoch total loss 1.10047579
Trained batch 4377 batch loss 1.00296509 epoch total loss 1.1004535
Trained batch 4378 batch loss 0.875759363 epoch total loss 1.10040224
Trained batch 4379 batch loss 1.10404325 epoch total loss 1.10040307
Trained batch 4380 batch loss 1.15152872 epoch total loss 1.10041475
Trained batch 4381 batch loss 1.16038156 epoch total loss 1.10042834
Trained batch 4382 batch loss 1.24652171 epoch total loss 1.10046172
Trained batch 4383 batch loss 1.1054461 epoch total loss 1.10046279
Trained batch 4384 batch loss 1.13607538 epoch total loss 1.10047102
Trained batch 4385 batch loss 1.25887418 epoch total loss 1.10050714
Trained batch 4386 batch loss 1.21354401 epoch total loss 1.10053289
Trained batch 4387 batch loss 1.31529725 epoch total loss 1.10058177
Trained batch 4388 batch loss 1.15202832 epoch total loss 1.10059345
Trained batch 4389 batch loss 1.3032372 epoch total loss 1.1006397
Trained batch 4390 batch loss 0.95926 epoch total loss 1.10060751
Trained batch 4391 batch loss 0.995303154 epoch total loss 1.10058343
Trained batch 4392 batch loss 1.12706923 epoch total loss 1.10058951
Trained batch 4393 batch loss 1.02956271 epoch total loss 1.10057342
Trained batch 4394 batch loss 1.08126915 epoch total loss 1.10056889
Trained batch 4395 batch loss 1.20214021 epoch total loss 1.10059202
Trained batch 4396 batch loss 0.998206437 epoch total loss 1.10056877
Trained batch 4397 batch loss 0.890986085 epoch total loss 1.10052109
Trained batch 4398 batch loss 1.02585816 epoch total loss 1.10050416
Trained batch 4399 batch loss 0.873733044 epoch total loss 1.10045254
Trained batch 4400 batch loss 1.01277208 epoch total loss 1.10043252
Trained batch 4401 batch loss 1.02436566 epoch total loss 1.10041535
Trained batch 4402 batch loss 0.916914701 epoch total loss 1.10037363
Trained batch 4403 batch loss 0.872560441 epoch total loss 1.10032189
Trained batch 4404 batch loss 0.94310087 epoch total loss 1.10028613
Trained batch 4405 batch loss 0.892394185 epoch total loss 1.10023904
Trained batch 4406 batch loss 0.920527458 epoch total loss 1.10019815
Trained batch 4407 batch loss 0.931225061 epoch total loss 1.10015976
Trained batch 4408 batch loss 0.929160297 epoch total loss 1.10012102
Trained batch 4409 batch loss 1.05079067 epoch total loss 1.10010982
Trained batch 4410 batch loss 1.08346379 epoch total loss 1.10010612
Trained batch 4411 batch loss 0.960207582 epoch total loss 1.10007441
Trained batch 4412 batch loss 1.05762219 epoch total loss 1.10006475
Trained batch 4413 batch loss 0.996931911 epoch total loss 1.10004139
Trained batch 4414 batch loss 0.991518915 epoch total loss 1.10001695
Trained batch 4415 batch loss 1.06376529 epoch total loss 1.10000873
Trained batch 4416 batch loss 0.990285099 epoch total loss 1.09998393
Trained batch 4417 batch loss 0.8731215 epoch total loss 1.09993255
Trained batch 4418 batch loss 0.887590647 epoch total loss 1.09988451
Trained batch 4419 batch loss 0.888258874 epoch total loss 1.09983659
Trained batch 4420 batch loss 1.07641554 epoch total loss 1.09983122
Trained batch 4421 batch loss 1.12429833 epoch total loss 1.09983683
Trained batch 4422 batch loss 0.891405523 epoch total loss 1.09978974
Trained batch 4423 batch loss 1.13185883 epoch total loss 1.09979689
Trained batch 4424 batch loss 1.13562512 epoch total loss 1.09980512
Trained batch 4425 batch loss 1.40247488 epoch total loss 1.09987342
Trained batch 4426 batch loss 1.27479601 epoch total loss 1.099913
Trained batch 4427 batch loss 1.29360771 epoch total loss 1.09995675
Trained batch 4428 batch loss 1.08166015 epoch total loss 1.09995258
Trained batch 4429 batch loss 1.07966876 epoch total loss 1.09994793
Trained batch 4430 batch loss 0.859641433 epoch total loss 1.09989369
Trained batch 4431 batch loss 0.964473248 epoch total loss 1.09986317
Trained batch 4432 batch loss 1.12603807 epoch total loss 1.09986901
Trained batch 4433 batch loss 1.14815032 epoch total loss 1.09987986
Trained batch 4434 batch loss 1.15796208 epoch total loss 1.09989309
Trained batch 4435 batch loss 1.43147993 epoch total loss 1.09996784
Trained batch 4436 batch loss 1.16313767 epoch total loss 1.09998202
Trained batch 4437 batch loss 1.17370796 epoch total loss 1.09999871
Trained batch 4438 batch loss 1.03665209 epoch total loss 1.09998441
Trained batch 4439 batch loss 1.03431416 epoch total loss 1.09996963
Trained batch 4440 batch loss 1.24991798 epoch total loss 1.10000336
Trained batch 4441 batch loss 1.27835894 epoch total loss 1.10004354
Trained batch 4442 batch loss 1.36124635 epoch total loss 1.10010242
Trained batch 4443 batch loss 1.40644479 epoch total loss 1.10017133
Trained batch 4444 batch loss 1.19654143 epoch total loss 1.10019302
Trained batch 4445 batch loss 1.3507452 epoch total loss 1.10024941
Trained batch 4446 batch loss 1.42088509 epoch total loss 1.10032153
Trained batch 4447 batch loss 1.14217591 epoch total loss 1.10033083
Trained batch 4448 batch loss 1.38615298 epoch total loss 1.1003952
Trained batch 4449 batch loss 1.33022308 epoch total loss 1.10044682
Trained batch 4450 batch loss 1.47488022 epoch total loss 1.10053098
Trained batch 4451 batch loss 1.39426625 epoch total loss 1.1005969
Trained batch 4452 batch loss 1.06562722 epoch total loss 1.10058904
Trained batch 4453 batch loss 0.981772125 epoch total loss 1.10056233
Trained batch 4454 batch loss 1.07272053 epoch total loss 1.10055614
Trained batch 4455 batch loss 0.825938225 epoch total loss 1.1004945
Trained batch 4456 batch loss 1.11515784 epoch total loss 1.10049784
Trained batch 4457 batch loss 1.15752816 epoch total loss 1.10051072
Trained batch 4458 batch loss 1.30327463 epoch total loss 1.10055614
Trained batch 4459 batch loss 1.04224849 epoch total loss 1.10054314
Trained batch 4460 batch loss 1.19871807 epoch total loss 1.1005652
Trained batch 4461 batch loss 1.13607824 epoch total loss 1.10057318
Trained batch 4462 batch loss 1.07651567 epoch total loss 1.10056782
Trained batch 4463 batch loss 1.06063509 epoch total loss 1.10055876
Trained batch 4464 batch loss 1.11168742 epoch total loss 1.10056138
Trained batch 4465 batch loss 1.07312989 epoch total loss 1.10055518
Trained batch 4466 batch loss 1.28677833 epoch total loss 1.1005969
Trained batch 4467 batch loss 1.12184036 epoch total loss 1.10060167
Trained batch 4468 batch loss 1.05259204 epoch total loss 1.10059094
Trained batch 4469 batch loss 1.21333456 epoch total loss 1.10061622
Trained batch 4470 batch loss 0.953987122 epoch total loss 1.10058343
Trained batch 4471 batch loss 1.15443683 epoch total loss 1.10059547
Trained batch 4472 batch loss 1.26918316 epoch total loss 1.10063314
Trained batch 4473 batch loss 1.21441245 epoch total loss 1.10065854
Trained batch 4474 batch loss 1.18000841 epoch total loss 1.1006763
Trained batch 4475 batch loss 1.33906686 epoch total loss 1.10072958
Trained batch 4476 batch loss 1.36948025 epoch total loss 1.10078955
Trained batch 4477 batch loss 1.28541708 epoch total loss 1.10083091
Trained batch 4478 batch loss 1.24156618 epoch total loss 1.10086238
Trained batch 4479 batch loss 1.18332243 epoch total loss 1.10088074
Trained batch 4480 batch loss 1.49083328 epoch total loss 1.10096776
Trained batch 4481 batch loss 1.28682876 epoch total loss 1.10100913
Trained batch 4482 batch loss 1.3351289 epoch total loss 1.10106134
Trained batch 4483 batch loss 1.1197871 epoch total loss 1.10106552
Trained batch 4484 batch loss 1.41048765 epoch total loss 1.10113454
Trained batch 4485 batch loss 1.29751754 epoch total loss 1.10117829
Trained batch 4486 batch loss 1.14010692 epoch total loss 1.10118699
Trained batch 4487 batch loss 1.17351961 epoch total loss 1.10120308
Trained batch 4488 batch loss 1.36342072 epoch total loss 1.1012615
Trained batch 4489 batch loss 1.46112299 epoch total loss 1.10134161
Trained batch 4490 batch loss 1.27614772 epoch total loss 1.10138059
Trained batch 4491 batch loss 1.23762202 epoch total loss 1.10141098
Trained batch 4492 batch loss 1.35399437 epoch total loss 1.10146713
Trained batch 4493 batch loss 1.21357512 epoch total loss 1.10149205
Trained batch 4494 batch loss 1.43229175 epoch total loss 1.1015656
Trained batch 4495 batch loss 1.33247364 epoch total loss 1.10161698
Trained batch 4496 batch loss 1.23385239 epoch total loss 1.10164642
Trained batch 4497 batch loss 1.29165506 epoch total loss 1.10168862
Trained batch 4498 batch loss 1.29809654 epoch total loss 1.10173237
Trained batch 4499 batch loss 1.25957227 epoch total loss 1.10176754
Trained batch 4500 batch loss 1.20385826 epoch total loss 1.10179031
Trained batch 4501 batch loss 1.36540389 epoch total loss 1.10184884
Trained batch 4502 batch loss 1.05074823 epoch total loss 1.1018374
Trained batch 4503 batch loss 1.11528754 epoch total loss 1.10184038
Trained batch 4504 batch loss 1.27990448 epoch total loss 1.10188
Trained batch 4505 batch loss 1.21758807 epoch total loss 1.1019057
Trained batch 4506 batch loss 1.19847703 epoch total loss 1.10192704
Trained batch 4507 batch loss 1.24655342 epoch total loss 1.10195911
Trained batch 4508 batch loss 1.12448752 epoch total loss 1.10196412
Trained batch 4509 batch loss 1.10452747 epoch total loss 1.10196471
Trained batch 4510 batch loss 1.22488356 epoch total loss 1.10199201
Trained batch 4511 batch loss 1.27820396 epoch total loss 1.10203111
Trained batch 4512 batch loss 0.904922485 epoch total loss 1.10198736
Trained batch 4513 batch loss 0.803031266 epoch total loss 1.1019212
Trained batch 4514 batch loss 0.888227344 epoch total loss 1.10187376
Trained batch 4515 batch loss 0.81482327 epoch total loss 1.10181022
Trained batch 4516 batch loss 0.904297948 epoch total loss 1.10176659
Trained batch 4517 batch loss 0.86715436 epoch total loss 1.10171461
Trained batch 4518 batch loss 0.675032735 epoch total loss 1.10162008
Trained batch 4519 batch loss 0.818474829 epoch total loss 1.10155737
Trained batch 4520 batch loss 0.779290497 epoch total loss 1.10148609
Trained batch 4521 batch loss 0.694572449 epoch total loss 1.10139608
Trained batch 4522 batch loss 1.11711025 epoch total loss 1.10139954
Trained batch 4523 batch loss 1.14913559 epoch total loss 1.10141
Trained batch 4524 batch loss 1.25228262 epoch total loss 1.10144341
Trained batch 4525 batch loss 1.19801092 epoch total loss 1.10146487
Trained batch 4526 batch loss 1.11326659 epoch total loss 1.10146749
Trained batch 4527 batch loss 1.13412058 epoch total loss 1.10147464
Trained batch 4528 batch loss 1.2916007 epoch total loss 1.10151672
Trained batch 4529 batch loss 1.3148005 epoch total loss 1.10156381
Trained batch 4530 batch loss 1.30570483 epoch total loss 1.10160887
Trained batch 4531 batch loss 1.50386477 epoch total loss 1.10169768
Trained batch 4532 batch loss 1.5457387 epoch total loss 1.10179567
Trained batch 4533 batch loss 1.44240665 epoch total loss 1.10187078
Trained batch 4534 batch loss 1.41753411 epoch total loss 1.10194039
Trained batch 4535 batch loss 1.08524656 epoch total loss 1.10193682
Trained batch 4536 batch loss 1.1645484 epoch total loss 1.10195053
Trained batch 4537 batch loss 1.03499901 epoch total loss 1.10193586
Trained batch 4538 batch loss 0.959312677 epoch total loss 1.10190439
Trained batch 4539 batch loss 1.17094684 epoch total loss 1.10191965
Trained batch 4540 batch loss 1.07988286 epoch total loss 1.10191488
Trained batch 4541 batch loss 1.0331707 epoch total loss 1.10189974
Trained batch 4542 batch loss 0.822182775 epoch total loss 1.10183811
Trained batch 4543 batch loss 1.07510948 epoch total loss 1.10183227
Trained batch 4544 batch loss 1.29746795 epoch total loss 1.10187531
Trained batch 4545 batch loss 1.1925652 epoch total loss 1.10189521
Trained batch 4546 batch loss 1.09992206 epoch total loss 1.10189486
Trained batch 4547 batch loss 0.933747828 epoch total loss 1.10185778
Trained batch 4548 batch loss 1.12880802 epoch total loss 1.10186374
Trained batch 4549 batch loss 1.20447719 epoch total loss 1.10188639
Trained batch 4550 batch loss 1.24024165 epoch total loss 1.10191679
Trained batch 4551 batch loss 1.08374083 epoch total loss 1.10191286
Trained batch 4552 batch loss 1.18181086 epoch total loss 1.10193026
Trained batch 4553 batch loss 1.19041324 epoch total loss 1.10194981
Trained batch 4554 batch loss 1.21898067 epoch total loss 1.10197544
Trained batch 4555 batch loss 1.12919879 epoch total loss 1.1019814
Trained batch 4556 batch loss 1.10116744 epoch total loss 1.10198128
Trained batch 4557 batch loss 1.21158481 epoch total loss 1.10200524
Trained batch 4558 batch loss 1.26567745 epoch total loss 1.10204113
Trained batch 4559 batch loss 1.00397086 epoch total loss 1.10201967
Trained batch 4560 batch loss 1.13045514 epoch total loss 1.10202587
Trained batch 4561 batch loss 1.12354338 epoch total loss 1.10203052
Trained batch 4562 batch loss 1.15109 epoch total loss 1.10204124
Trained batch 4563 batch loss 1.07516372 epoch total loss 1.1020354
Trained batch 4564 batch loss 1.17005205 epoch total loss 1.1020503
Trained batch 4565 batch loss 1.23304629 epoch total loss 1.10207891
Trained batch 4566 batch loss 1.22764897 epoch total loss 1.10210633
Trained batch 4567 batch loss 1.14272594 epoch total loss 1.10211527
Trained batch 4568 batch loss 1.15206814 epoch total loss 1.10212612
Trained batch 4569 batch loss 1.21306646 epoch total loss 1.10215044
Trained batch 4570 batch loss 1.00669074 epoch total loss 1.10212958
Trained batch 4571 batch loss 0.959744155 epoch total loss 1.10209846
Trained batch 4572 batch loss 1.06631374 epoch total loss 1.1020906
Trained batch 4573 batch loss 1.20547318 epoch total loss 1.10211325
Trained batch 4574 batch loss 1.13503695 epoch total loss 1.10212052
Trained batch 4575 batch loss 1.08976102 epoch total loss 1.10211778
Trained batch 4576 batch loss 1.03117895 epoch total loss 1.10210228
Trained batch 4577 batch loss 1.03089201 epoch total loss 1.10208678
Trained batch 4578 batch loss 0.978037596 epoch total loss 1.1020596
Trained batch 4579 batch loss 0.894803047 epoch total loss 1.10201442
Trained batch 4580 batch loss 0.831155062 epoch total loss 1.10195529
Trained batch 4581 batch loss 1.14495778 epoch total loss 1.10196471
Trained batch 4582 batch loss 1.19517088 epoch total loss 1.10198498
Trained batch 4583 batch loss 0.913541257 epoch total loss 1.10194397
Trained batch 4584 batch loss 1.10640717 epoch total loss 1.10194492
Trained batch 4585 batch loss 1.0650835 epoch total loss 1.10193682
Trained batch 4586 batch loss 1.02639663 epoch total loss 1.10192037
Trained batch 4587 batch loss 1.07513535 epoch total loss 1.10191453
Trained batch 4588 batch loss 1.08191538 epoch total loss 1.10191023
Trained batch 4589 batch loss 1.45134902 epoch total loss 1.10198629
Trained batch 4590 batch loss 1.22530067 epoch total loss 1.10201311
Trained batch 4591 batch loss 1.18574429 epoch total loss 1.10203135
Trained batch 4592 batch loss 1.03254712 epoch total loss 1.10201621
Trained batch 4593 batch loss 0.885827899 epoch total loss 1.10196912
Trained batch 4594 batch loss 1.02607405 epoch total loss 1.10195255
Trained batch 4595 batch loss 0.838237882 epoch total loss 1.10189521
Trained batch 4596 batch loss 0.640348434 epoch total loss 1.10179472
Trained batch 4597 batch loss 0.702955 epoch total loss 1.10170805
Trained batch 4598 batch loss 0.95325166 epoch total loss 1.10167575
Trained batch 4599 batch loss 1.09439445 epoch total loss 1.10167408
Trained batch 4600 batch loss 1.29640782 epoch total loss 1.1017164
Trained batch 4601 batch loss 1.25921452 epoch total loss 1.10175061
Trained batch 4602 batch loss 1.01870847 epoch total loss 1.10173261
Trained batch 4603 batch loss 0.883405685 epoch total loss 1.10168517
Trained batch 4604 batch loss 1.22333169 epoch total loss 1.10171151
Trained batch 4605 batch loss 0.759227395 epoch total loss 1.10163713
Trained batch 4606 batch loss 1.05401599 epoch total loss 1.10162687
Trained batch 4607 batch loss 1.10505915 epoch total loss 1.10162759
Trained batch 4608 batch loss 1.31542134 epoch total loss 1.10167396
Trained batch 4609 batch loss 1.03755641 epoch total loss 1.10166
Trained batch 4610 batch loss 1.22369766 epoch total loss 1.10168648
Trained batch 4611 batch loss 1.09889078 epoch total loss 1.101686
Trained batch 4612 batch loss 1.11761594 epoch total loss 1.10168946
Trained batch 4613 batch loss 1.02217197 epoch total loss 1.10167217
Trained batch 4614 batch loss 1.17414355 epoch total loss 1.10168791
Trained batch 4615 batch loss 1.07757664 epoch total loss 1.10168266
Trained batch 4616 batch loss 1.27473927 epoch total loss 1.10172021
Trained batch 4617 batch loss 1.12122369 epoch total loss 1.10172439
Trained batch 4618 batch loss 1.28314173 epoch total loss 1.10176373
Trained batch 4619 batch loss 1.15395522 epoch total loss 1.10177493
Trained batch 4620 batch loss 1.05436516 epoch total loss 1.10176468
Trained batch 4621 batch loss 1.18536317 epoch total loss 1.1017828
Trained batch 4622 batch loss 1.14359081 epoch total loss 1.10179186
Trained batch 4623 batch loss 1.04937911 epoch total loss 1.10178053
Trained batch 4624 batch loss 1.11825752 epoch total loss 1.10178399
Trained batch 4625 batch loss 0.923559308 epoch total loss 1.10174549
Trained batch 4626 batch loss 0.771899581 epoch total loss 1.1016742
Trained batch 4627 batch loss 0.993436158 epoch total loss 1.10165083
Trained batch 4628 batch loss 1.13382351 epoch total loss 1.10165775
Trained batch 4629 batch loss 1.03034163 epoch total loss 1.10164237
Trained batch 4630 batch loss 0.960492432 epoch total loss 1.10161185
Trained batch 4631 batch loss 1.02523172 epoch total loss 1.1015954
Trained batch 4632 batch loss 0.778321743 epoch total loss 1.10152566
Trained batch 4633 batch loss 0.955316305 epoch total loss 1.10149395
Trained batch 4634 batch loss 0.976140499 epoch total loss 1.10146689
Trained batch 4635 batch loss 0.839235723 epoch total loss 1.10141039
Trained batch 4636 batch loss 0.934317 epoch total loss 1.10137427
Trained batch 4637 batch loss 0.96612668 epoch total loss 1.10134518
Trained batch 4638 batch loss 0.831812143 epoch total loss 1.10128713
Trained batch 4639 batch loss 0.95363915 epoch total loss 1.1012553
Trained batch 4640 batch loss 0.842623472 epoch total loss 1.10119951
Trained batch 4641 batch loss 0.924509585 epoch total loss 1.10116148
Trained batch 4642 batch loss 1.19020987 epoch total loss 1.10118067
Trained batch 4643 batch loss 0.981437922 epoch total loss 1.10115492
Trained batch 4644 batch loss 1.11167741 epoch total loss 1.10115719
Trained batch 4645 batch loss 0.925894141 epoch total loss 1.1011194
Trained batch 4646 batch loss 1.11984587 epoch total loss 1.10112345
Trained batch 4647 batch loss 1.08458281 epoch total loss 1.10111988
Trained batch 4648 batch loss 1.05520797 epoch total loss 1.10111
Trained batch 4649 batch loss 1.31461644 epoch total loss 1.10115588
Trained batch 4650 batch loss 1.25063801 epoch total loss 1.10118794
Trained batch 4651 batch loss 1.17040205 epoch total loss 1.10120285
Trained batch 4652 batch loss 1.07564926 epoch total loss 1.10119736
Trained batch 4653 batch loss 0.949198306 epoch total loss 1.1011647
Trained batch 4654 batch loss 0.844092906 epoch total loss 1.1011095
Trained batch 4655 batch loss 0.840787411 epoch total loss 1.1010536
Trained batch 4656 batch loss 1.12393045 epoch total loss 1.10105848
Trained batch 4657 batch loss 0.962913513 epoch total loss 1.1010288
Trained batch 4658 batch loss 1.00483513 epoch total loss 1.10100818
Trained batch 4659 batch loss 1.1140039 epoch total loss 1.10101092
Trained batch 4660 batch loss 0.981878042 epoch total loss 1.10098541
Trained batch 4661 batch loss 0.92776376 epoch total loss 1.10094821
Trained batch 4662 batch loss 1.18978298 epoch total loss 1.10096729
Trained batch 4663 batch loss 1.20643902 epoch total loss 1.10098994
Trained batch 4664 batch loss 0.837915301 epoch total loss 1.10093355
Trained batch 4665 batch loss 1.0586071 epoch total loss 1.10092449
Trained batch 4666 batch loss 0.962987065 epoch total loss 1.10089481
Trained batch 4667 batch loss 1.05110633 epoch total loss 1.1008842
Trained batch 4668 batch loss 0.820926785 epoch total loss 1.10082424
Trained batch 4669 batch loss 1.11223054 epoch total loss 1.10082662
Trained batch 4670 batch loss 1.29119945 epoch total loss 1.10086739
Trained batch 4671 batch loss 1.36808681 epoch total loss 1.10092461
Trained batch 4672 batch loss 1.23253298 epoch total loss 1.10095274
Trained batch 4673 batch loss 1.25017393 epoch total loss 1.10098469
Trained batch 4674 batch loss 1.08186245 epoch total loss 1.10098064
Trained batch 4675 batch loss 0.971388578 epoch total loss 1.10095286
Trained batch 4676 batch loss 1.14544916 epoch total loss 1.1009624
Trained batch 4677 batch loss 1.24415541 epoch total loss 1.10099304
Trained batch 4678 batch loss 1.25849986 epoch total loss 1.10102665
Trained batch 4679 batch loss 1.08740807 epoch total loss 1.10102367
Trained batch 4680 batch loss 1.17111433 epoch total loss 1.10103869
Trained batch 4681 batch loss 1.08789849 epoch total loss 1.10103583
Trained batch 4682 batch loss 1.18823445 epoch total loss 1.10105455
Trained batch 4683 batch loss 1.17144179 epoch total loss 1.10106957
Trained batch 4684 batch loss 1.127599 epoch total loss 1.10107517
Trained batch 4685 batch loss 0.858063221 epoch total loss 1.1010232
Trained batch 4686 batch loss 1.00276983 epoch total loss 1.10100234
Trained batch 4687 batch loss 1.11626697 epoch total loss 1.10100555
Trained batch 4688 batch loss 1.09055328 epoch total loss 1.10100329
Trained batch 4689 batch loss 1.04346681 epoch total loss 1.10099101
Trained batch 4690 batch loss 0.986431301 epoch total loss 1.10096657
Trained batch 4691 batch loss 0.82437849 epoch total loss 1.10090756
Trained batch 4692 batch loss 0.876485229 epoch total loss 1.10085976
Trained batch 4693 batch loss 1.17990255 epoch total loss 1.10087657
Trained batch 4694 batch loss 1.02504778 epoch total loss 1.10086036
Trained batch 4695 batch loss 1.07413507 epoch total loss 1.10085464
Trained batch 4696 batch loss 0.944953203 epoch total loss 1.1008215
Trained batch 4697 batch loss 1.33865595 epoch total loss 1.10087216
Trained batch 4698 batch loss 1.24682 epoch total loss 1.10090315
Trained batch 4699 batch loss 1.1592046 epoch total loss 1.10091555
Trained batch 4700 batch loss 1.0695672 epoch total loss 1.10090888
Trained batch 4701 batch loss 0.995849073 epoch total loss 1.10088646
Trained batch 4702 batch loss 1.0390898 epoch total loss 1.10087323
Trained batch 4703 batch loss 1.11273837 epoch total loss 1.10087585
Trained batch 4704 batch loss 1.02363765 epoch total loss 1.1008594
Trained batch 4705 batch loss 1.15117168 epoch total loss 1.10087013
Trained batch 4706 batch loss 1.22592568 epoch total loss 1.10089672
Trained batch 4707 batch loss 1.1531117 epoch total loss 1.1009078
Trained batch 4708 batch loss 1.18043053 epoch total loss 1.10092473
Trained batch 4709 batch loss 1.15650964 epoch total loss 1.10093665
Trained batch 4710 batch loss 1.01881099 epoch total loss 1.10091925
Trained batch 4711 batch loss 1.1463486 epoch total loss 1.1009289
Trained batch 4712 batch loss 0.970057607 epoch total loss 1.10090113
Trained batch 4713 batch loss 0.986902475 epoch total loss 1.10087693
Trained batch 4714 batch loss 0.883910775 epoch total loss 1.10083091
Trained batch 4715 batch loss 1.06788826 epoch total loss 1.10082388
Trained batch 4716 batch loss 1.12119722 epoch total loss 1.10082817
Trained batch 4717 batch loss 1.10361326 epoch total loss 1.10082877
Trained batch 4718 batch loss 1.01977563 epoch total loss 1.1008116
Trained batch 4719 batch loss 1.18142867 epoch total loss 1.10082877
Trained batch 4720 batch loss 1.04747868 epoch total loss 1.10081744
Trained batch 4721 batch loss 1.21705723 epoch total loss 1.10084212
Trained batch 4722 batch loss 1.0396595 epoch total loss 1.10082912
Trained batch 4723 batch loss 1.08811307 epoch total loss 1.10082638
Trained batch 4724 batch loss 1.21710908 epoch total loss 1.10085106
Trained batch 4725 batch loss 1.04450417 epoch total loss 1.10083914
Trained batch 4726 batch loss 1.05642819 epoch total loss 1.10082972
Trained batch 4727 batch loss 0.886277258 epoch total loss 1.10078442
Trained batch 4728 batch loss 1.012079 epoch total loss 1.10076559
Trained batch 4729 batch loss 1.09199858 epoch total loss 1.1007638
Trained batch 4730 batch loss 0.899307609 epoch total loss 1.10072112
Trained batch 4731 batch loss 1.01607823 epoch total loss 1.10070324
Trained batch 4732 batch loss 0.916435659 epoch total loss 1.10066438
Trained batch 4733 batch loss 0.857957244 epoch total loss 1.10061312
Trained batch 4734 batch loss 0.881947517 epoch total loss 1.10056686
Trained batch 4735 batch loss 0.813515604 epoch total loss 1.10050619
Trained batch 4736 batch loss 1.12307525 epoch total loss 1.10051095
Trained batch 4737 batch loss 1.15295589 epoch total loss 1.10052204
Trained batch 4738 batch loss 1.16455984 epoch total loss 1.10053551
Trained batch 4739 batch loss 1.25974917 epoch total loss 1.10056913
Trained batch 4740 batch loss 0.694773674 epoch total loss 1.10048354
Trained batch 4741 batch loss 1.51254523 epoch total loss 1.10057044
Trained batch 4742 batch loss 1.31135154 epoch total loss 1.10061502
Trained batch 4743 batch loss 0.900604188 epoch total loss 1.10057271
Trained batch 4744 batch loss 1.06824303 epoch total loss 1.10056591
Trained batch 4745 batch loss 1.03623319 epoch total loss 1.10055244
Trained batch 4746 batch loss 1.19064617 epoch total loss 1.10057127
Trained batch 4747 batch loss 1.08260155 epoch total loss 1.10056758
Trained batch 4748 batch loss 1.16970372 epoch total loss 1.10058212
Trained batch 4749 batch loss 0.930992 epoch total loss 1.10054648
Trained batch 4750 batch loss 1.03920555 epoch total loss 1.10053349
Trained batch 4751 batch loss 1.0262692 epoch total loss 1.10051787
Trained batch 4752 batch loss 0.987529278 epoch total loss 1.10049403
Trained batch 4753 batch loss 1.04067266 epoch total loss 1.10048151
Trained batch 4754 batch loss 0.820774078 epoch total loss 1.10042262
Trained batch 4755 batch loss 0.858155966 epoch total loss 1.10037172
Trained batch 4756 batch loss 0.877585649 epoch total loss 1.10032487
Trained batch 4757 batch loss 1.04375792 epoch total loss 1.10031295
Trained batch 4758 batch loss 0.768741786 epoch total loss 1.10024333
Trained batch 4759 batch loss 0.789152 epoch total loss 1.10017788
Trained batch 4760 batch loss 0.823081076 epoch total loss 1.10011971
Trained batch 4761 batch loss 0.682300329 epoch total loss 1.10003197
Trained batch 4762 batch loss 0.733992934 epoch total loss 1.09995508
Trained batch 4763 batch loss 0.802683294 epoch total loss 1.09989262
Trained batch 4764 batch loss 0.808169246 epoch total loss 1.09983134
Trained batch 4765 batch loss 0.78985548 epoch total loss 1.09976637
Trained batch 4766 batch loss 0.748180032 epoch total loss 1.09969258
Trained batch 4767 batch loss 1.04062974 epoch total loss 1.09968019
Trained batch 4768 batch loss 0.995896339 epoch total loss 1.09965837
Trained batch 4769 batch loss 0.950303793 epoch total loss 1.09962714
Trained batch 4770 batch loss 0.835006297 epoch total loss 1.09957159
Trained batch 4771 batch loss 0.952003479 epoch total loss 1.09954071
Trained batch 4772 batch loss 1.12734139 epoch total loss 1.09954655
Trained batch 4773 batch loss 1.34152365 epoch total loss 1.09959722
Trained batch 4774 batch loss 1.11890209 epoch total loss 1.09960127
Trained batch 4775 batch loss 1.03289139 epoch total loss 1.09958732
Trained batch 4776 batch loss 1.04865205 epoch total loss 1.09957671
Trained batch 4777 batch loss 1.02296376 epoch total loss 1.09956062
Trained batch 4778 batch loss 0.917404711 epoch total loss 1.09952247
Trained batch 4779 batch loss 1.00835228 epoch total loss 1.0995034
Trained batch 4780 batch loss 1.08730817 epoch total loss 1.09950089
Trained batch 4781 batch loss 1.10385561 epoch total loss 1.09950185
Trained batch 4782 batch loss 1.03165185 epoch total loss 1.09948766
Trained batch 4783 batch loss 1.19738066 epoch total loss 1.09950805
Trained batch 4784 batch loss 1.13869202 epoch total loss 1.09951627
Trained batch 4785 batch loss 1.25917089 epoch total loss 1.09954965
Trained batch 4786 batch loss 1.37017727 epoch total loss 1.09960616
Trained batch 4787 batch loss 1.22339916 epoch total loss 1.09963214
Trained batch 4788 batch loss 1.10398936 epoch total loss 1.09963298
Trained batch 4789 batch loss 0.912694335 epoch total loss 1.099594
Trained batch 4790 batch loss 0.871788085 epoch total loss 1.09954643
Trained batch 4791 batch loss 1.00010312 epoch total loss 1.09952557
Trained batch 4792 batch loss 1.07687712 epoch total loss 1.0995208
Trained batch 4793 batch loss 1.12087739 epoch total loss 1.09952533
Trained batch 4794 batch loss 0.906491756 epoch total loss 1.09948504
Trained batch 4795 batch loss 1.02427149 epoch total loss 1.0994693
Trained batch 4796 batch loss 1.09923756 epoch total loss 1.0994693
Trained batch 4797 batch loss 1.16557741 epoch total loss 1.09948301
Trained batch 4798 batch loss 0.931533337 epoch total loss 1.09944808
Trained batch 4799 batch loss 1.19329929 epoch total loss 1.09946764
Trained batch 4800 batch loss 1.07912612 epoch total loss 1.09946334
Trained batch 4801 batch loss 1.0535289 epoch total loss 1.09945393
Trained batch 4802 batch loss 1.0405798 epoch total loss 1.09944165
Trained batch 4803 batch loss 0.978375375 epoch total loss 1.09941638
Trained batch 4804 batch loss 0.970428228 epoch total loss 1.09938955
Trained batch 4805 batch loss 0.955577374 epoch total loss 1.09935963
Trained batch 4806 batch loss 0.802653372 epoch total loss 1.09929788
Trained batch 4807 batch loss 0.97574234 epoch total loss 1.09927213
Trained batch 4808 batch loss 0.868595481 epoch total loss 1.09922421
Trained batch 4809 batch loss 0.887225866 epoch total loss 1.0991801
Trained batch 4810 batch loss 0.85279417 epoch total loss 1.09912896
Trained batch 4811 batch loss 0.852701187 epoch total loss 1.0990777
Trained batch 4812 batch loss 0.779435635 epoch total loss 1.09901118
Trained batch 4813 batch loss 0.834312081 epoch total loss 1.09895623
Trained batch 4814 batch loss 0.873058856 epoch total loss 1.09890926
Trained batch 4815 batch loss 1.00244951 epoch total loss 1.09888923
Trained batch 4816 batch loss 0.924530506 epoch total loss 1.09885299
Trained batch 4817 batch loss 0.853865147 epoch total loss 1.09880221
Trained batch 4818 batch loss 0.979578912 epoch total loss 1.09877741
Trained batch 4819 batch loss 1.09571254 epoch total loss 1.09877682
Trained batch 4820 batch loss 1.17869747 epoch total loss 1.09879339
Trained batch 4821 batch loss 0.936314 epoch total loss 1.09875977
Trained batch 4822 batch loss 0.990889788 epoch total loss 1.09873736
Trained batch 4823 batch loss 0.932383895 epoch total loss 1.09870291
Trained batch 4824 batch loss 0.880906105 epoch total loss 1.09865773
Trained batch 4825 batch loss 1.04608274 epoch total loss 1.09864676
Trained batch 4826 batch loss 0.924066067 epoch total loss 1.09861052
Trained batch 4827 batch loss 0.902336478 epoch total loss 1.09856987
Trained batch 4828 batch loss 1.08620346 epoch total loss 1.09856737
Trained batch 4829 batch loss 0.995288253 epoch total loss 1.09854591
Trained batch 4830 batch loss 0.985046387 epoch total loss 1.09852242
Trained batch 4831 batch loss 0.727404237 epoch total loss 1.09844565
Trained batch 4832 batch loss 1.08658838 epoch total loss 1.09844315
Trained batch 4833 batch loss 1.05525708 epoch total loss 1.09843421
Trained batch 4834 batch loss 1.12739229 epoch total loss 1.09844017
Trained batch 4835 batch loss 1.14131474 epoch total loss 1.09844899
Trained batch 4836 batch loss 0.94454807 epoch total loss 1.09841716
Trained batch 4837 batch loss 0.904010534 epoch total loss 1.09837687
Trained batch 4838 batch loss 0.953853965 epoch total loss 1.09834695
Trained batch 4839 batch loss 0.884476542 epoch total loss 1.09830272
Trained batch 4840 batch loss 1.07304358 epoch total loss 1.0982976
Trained batch 4841 batch loss 1.16153717 epoch total loss 1.09831071
Trained batch 4842 batch loss 1.19033396 epoch total loss 1.09832966
Trained batch 4843 batch loss 1.31307626 epoch total loss 1.09837401
Trained batch 4844 batch loss 1.09491611 epoch total loss 1.09837329
Trained batch 4845 batch loss 1.23026121 epoch total loss 1.09840047
Trained batch 4846 batch loss 1.1758008 epoch total loss 1.09841645
Trained batch 4847 batch loss 1.13950253 epoch total loss 1.09842503
Trained batch 4848 batch loss 1.14103341 epoch total loss 1.09843385
Trained batch 4849 batch loss 1.32854438 epoch total loss 1.0984813
Trained batch 4850 batch loss 1.06617963 epoch total loss 1.09847462
Trained batch 4851 batch loss 1.12562108 epoch total loss 1.09848022
Trained batch 4852 batch loss 0.99354583 epoch total loss 1.09845865
Trained batch 4853 batch loss 1.24593258 epoch total loss 1.09848905
Trained batch 4854 batch loss 1.08251143 epoch total loss 1.09848571
Trained batch 4855 batch loss 1.21540976 epoch total loss 1.09850979
Trained batch 4856 batch loss 1.23769867 epoch total loss 1.09853852
Trained batch 4857 batch loss 1.18014383 epoch total loss 1.09855533
Trained batch 4858 batch loss 0.951624751 epoch total loss 1.09852505
Trained batch 4859 batch loss 0.902652383 epoch total loss 1.09848475
Trained batch 4860 batch loss 1.09338188 epoch total loss 1.09848368
Trained batch 4861 batch loss 1.1549325 epoch total loss 1.09849524
Trained batch 4862 batch loss 1.23517847 epoch total loss 1.0985235
Trained batch 4863 batch loss 1.20323324 epoch total loss 1.09854496
Trained batch 4864 batch loss 1.05105209 epoch total loss 1.09853518
Trained batch 4865 batch loss 1.09554315 epoch total loss 1.0985347
Trained batch 4866 batch loss 1.10557771 epoch total loss 1.09853613
Trained batch 4867 batch loss 1.26285863 epoch total loss 1.09856975
Trained batch 4868 batch loss 1.29288793 epoch total loss 1.09860969
Trained batch 4869 batch loss 1.23503494 epoch total loss 1.0986377
Trained batch 4870 batch loss 1.14080167 epoch total loss 1.0986464
Trained batch 4871 batch loss 1.19248438 epoch total loss 1.0986656
Trained batch 4872 batch loss 1.2294693 epoch total loss 1.09869242
Trained batch 4873 batch loss 1.04847312 epoch total loss 1.09868217
Trained batch 4874 batch loss 0.923026204 epoch total loss 1.09864604
Trained batch 4875 batch loss 1.14301062 epoch total loss 1.0986551
Trained batch 4876 batch loss 1.03130412 epoch total loss 1.09864128
Trained batch 4877 batch loss 1.00438 epoch total loss 1.09862196
Trained batch 4878 batch loss 0.987628043 epoch total loss 1.09859931
Trained batch 4879 batch loss 1.11499429 epoch total loss 1.09860265
Trained batch 4880 batch loss 1.12162089 epoch total loss 1.09860742
Trained batch 4881 batch loss 1.3183527 epoch total loss 1.09865236
Trained batch 4882 batch loss 1.21684146 epoch total loss 1.09867656
Trained batch 4883 batch loss 0.989997387 epoch total loss 1.09865439
Trained batch 4884 batch loss 1.00752759 epoch total loss 1.09863567
Trained batch 4885 batch loss 1.00033057 epoch total loss 1.09861565
Trained batch 4886 batch loss 0.927155793 epoch total loss 1.0985806
Trained batch 4887 batch loss 1.09765434 epoch total loss 1.09858036
Trained batch 4888 batch loss 0.879654884 epoch total loss 1.09853566
Trained batch 4889 batch loss 1.05635357 epoch total loss 1.09852695
Trained batch 4890 batch loss 1.2640121 epoch total loss 1.09856081
Trained batch 4891 batch loss 1.05782962 epoch total loss 1.09855247
Trained batch 4892 batch loss 1.1111877 epoch total loss 1.09855509
Trained batch 4893 batch loss 1.08108521 epoch total loss 1.09855151
Trained batch 4894 batch loss 1.08189416 epoch total loss 1.09854805
Trained batch 4895 batch loss 1.17164278 epoch total loss 1.09856308
Trained batch 4896 batch loss 1.03004837 epoch total loss 1.09854913
Trained batch 4897 batch loss 1.01802886 epoch total loss 1.09853268
Trained batch 4898 batch loss 1.13536298 epoch total loss 1.09854019
Trained batch 4899 batch loss 0.770367861 epoch total loss 1.09847319
Trained batch 4900 batch loss 0.976308942 epoch total loss 1.09844828
Trained batch 4901 batch loss 0.934465349 epoch total loss 1.09841478
Trained batch 4902 batch loss 1.34194779 epoch total loss 1.09846449
Trained batch 4903 batch loss 1.19267178 epoch total loss 1.09848368
Trained batch 4904 batch loss 1.0160203 epoch total loss 1.09846687
Trained batch 4905 batch loss 1.09430528 epoch total loss 1.09846604
Trained batch 4906 batch loss 0.9940449 epoch total loss 1.09844482
Trained batch 4907 batch loss 1.06470287 epoch total loss 1.09843802
Trained batch 4908 batch loss 1.04836416 epoch total loss 1.09842777
Trained batch 4909 batch loss 1.11103201 epoch total loss 1.09843028
Trained batch 4910 batch loss 0.940917 epoch total loss 1.09839821
Trained batch 4911 batch loss 1.06573343 epoch total loss 1.09839165
Trained batch 4912 batch loss 1.01997769 epoch total loss 1.09837568
Trained batch 4913 batch loss 0.865402818 epoch total loss 1.09832823
Trained batch 4914 batch loss 0.926181436 epoch total loss 1.09829319
Trained batch 4915 batch loss 1.2641716 epoch total loss 1.09832692
Trained batch 4916 batch loss 1.08554161 epoch total loss 1.0983243
Trained batch 4917 batch loss 1.00855863 epoch total loss 1.09830606
Trained batch 4918 batch loss 1.0794754 epoch total loss 1.09830225
Trained batch 4919 batch loss 1.29980338 epoch total loss 1.09834325
Trained batch 4920 batch loss 1.1771524 epoch total loss 1.09835935
Trained batch 4921 batch loss 1.01283431 epoch total loss 1.09834194
Trained batch 4922 batch loss 0.9552598 epoch total loss 1.09831274
Trained batch 4923 batch loss 1.03925467 epoch total loss 1.0983007
Trained batch 4924 batch loss 1.22034645 epoch total loss 1.09832549
Trained batch 4925 batch loss 1.01784682 epoch total loss 1.09830916
Trained batch 4926 batch loss 0.911555052 epoch total loss 1.09827125
Trained batch 4927 batch loss 0.911354 epoch total loss 1.09823334
Trained batch 4928 batch loss 0.962521195 epoch total loss 1.0982058
Trained batch 4929 batch loss 1.18597126 epoch total loss 1.09822357
Trained batch 4930 batch loss 1.08978248 epoch total loss 1.0982219
Trained batch 4931 batch loss 0.989665747 epoch total loss 1.09819984
Trained batch 4932 batch loss 0.999381781 epoch total loss 1.09817982
Trained batch 4933 batch loss 1.30752087 epoch total loss 1.09822237
Trained batch 4934 batch loss 1.16152716 epoch total loss 1.09823513
Trained batch 4935 batch loss 1.0053488 epoch total loss 1.09821641
Trained batch 4936 batch loss 0.975390613 epoch total loss 1.0981915
Trained batch 4937 batch loss 0.931547582 epoch total loss 1.09815776
Trained batch 4938 batch loss 1.13166583 epoch total loss 1.09816456
Trained batch 4939 batch loss 1.08976007 epoch total loss 1.09816289
Trained batch 4940 batch loss 1.12970448 epoch total loss 1.09816933
Trained batch 4941 batch loss 1.30729103 epoch total loss 1.09821165
Trained batch 4942 batch loss 1.18220663 epoch total loss 1.09822857
Trained batch 4943 batch loss 1.33744764 epoch total loss 1.09827697
Trained batch 4944 batch loss 1.14938498 epoch total loss 1.09828734
Trained batch 4945 batch loss 1.14177108 epoch total loss 1.09829605
Trained batch 4946 batch loss 0.964918375 epoch total loss 1.0982691
Trained batch 4947 batch loss 1.01405239 epoch total loss 1.09825206
Trained batch 4948 batch loss 1.47432542 epoch total loss 1.09832811
Trained batch 4949 batch loss 1.22030103 epoch total loss 1.09835267
Trained batch 4950 batch loss 1.21613753 epoch total loss 1.09837651
Trained batch 4951 batch loss 1.22121263 epoch total loss 1.09840131
Trained batch 4952 batch loss 1.00739098 epoch total loss 1.09838295
Trained batch 4953 batch loss 1.04553676 epoch total loss 1.09837222
Trained batch 4954 batch loss 0.748823941 epoch total loss 1.09830177
Trained batch 4955 batch loss 1.23929071 epoch total loss 1.09833014
Trained batch 4956 batch loss 1.00488472 epoch total loss 1.09831131
Trained batch 4957 batch loss 1.1487422 epoch total loss 1.09832156
Trained batch 4958 batch loss 1.0856967 epoch total loss 1.09831905
Trained batch 4959 batch loss 1.16722941 epoch total loss 1.09833288
Trained batch 4960 batch loss 1.18890047 epoch total loss 1.09835112
Trained batch 4961 batch loss 1.16316032 epoch total loss 1.09836423
Trained batch 4962 batch loss 1.38183045 epoch total loss 1.09842134
Trained batch 4963 batch loss 1.2808466 epoch total loss 1.09845805
Trained batch 4964 batch loss 1.27812099 epoch total loss 1.09849429
Trained batch 4965 batch loss 0.994531751 epoch total loss 1.09847343
Trained batch 4966 batch loss 0.917772532 epoch total loss 1.09843707
Trained batch 4967 batch loss 0.748291671 epoch total loss 1.09836662
Trained batch 4968 batch loss 0.824475288 epoch total loss 1.09831154
Trained batch 4969 batch loss 0.840845108 epoch total loss 1.09825969
Trained batch 4970 batch loss 0.969146132 epoch total loss 1.0982337
Trained batch 4971 batch loss 1.33275771 epoch total loss 1.09828091
Trained batch 4972 batch loss 1.18389058 epoch total loss 1.09829807
Trained batch 4973 batch loss 1.28636527 epoch total loss 1.09833586
Trained batch 4974 batch loss 1.4341495 epoch total loss 1.09840345
Trained batch 4975 batch loss 1.24869633 epoch total loss 1.09843361
Trained batch 4976 batch loss 1.411309 epoch total loss 1.09849644
Trained batch 4977 batch loss 1.31902766 epoch total loss 1.09854066
Trained batch 4978 batch loss 1.3170712 epoch total loss 1.09858453
Trained batch 4979 batch loss 1.31771 epoch total loss 1.09862864
Trained batch 4980 batch loss 1.32045579 epoch total loss 1.09867311
Trained batch 4981 batch loss 0.999323785 epoch total loss 1.0986532
Trained batch 4982 batch loss 0.949354172 epoch total loss 1.09862316
Trained batch 4983 batch loss 0.869973838 epoch total loss 1.09857738
Trained batch 4984 batch loss 0.898428142 epoch total loss 1.09853721
Trained batch 4985 batch loss 0.729066908 epoch total loss 1.09846306
Trained batch 4986 batch loss 0.883771956 epoch total loss 1.09842
Trained batch 4987 batch loss 0.983048558 epoch total loss 1.0983969
Trained batch 4988 batch loss 0.822942376 epoch total loss 1.09834158
Trained batch 4989 batch loss 0.820806384 epoch total loss 1.09828591
Trained batch 4990 batch loss 0.922730327 epoch total loss 1.09825075
Trained batch 4991 batch loss 0.921050251 epoch total loss 1.09821522
Trained batch 4992 batch loss 1.02194202 epoch total loss 1.0982
Trained batch 4993 batch loss 0.973346114 epoch total loss 1.09817493
Trained batch 4994 batch loss 1.13953304 epoch total loss 1.09818327
Trained batch 4995 batch loss 0.893145084 epoch total loss 1.09814215
Trained batch 4996 batch loss 0.871326685 epoch total loss 1.09809673
Trained batch 4997 batch loss 0.9223575 epoch total loss 1.09806156
Trained batch 4998 batch loss 0.798960686 epoch total loss 1.09800172
Trained batch 4999 batch loss 0.98489213 epoch total loss 1.09797907
Trained batch 5000 batch loss 0.868054867 epoch total loss 1.09793305
Trained batch 5001 batch loss 0.995399475 epoch total loss 1.09791267
Trained batch 5002 batch loss 0.987028837 epoch total loss 1.09789038
Trained batch 5003 batch loss 1.06014061 epoch total loss 1.09788287
Trained batch 5004 batch loss 1.02533782 epoch total loss 1.09786844
Trained batch 5005 batch loss 0.803179324 epoch total loss 1.09780955
Trained batch 5006 batch loss 1.13179719 epoch total loss 1.09781635
Trained batch 5007 batch loss 0.899969816 epoch total loss 1.09777677
Trained batch 5008 batch loss 1.02086103 epoch total loss 1.09776151
Trained batch 5009 batch loss 1.08086157 epoch total loss 1.09775817
Trained batch 5010 batch loss 0.847749591 epoch total loss 1.09770823
Trained batch 5011 batch loss 1.08387876 epoch total loss 1.09770548
Trained batch 5012 batch loss 1.04371476 epoch total loss 1.09769475
Trained batch 5013 batch loss 1.06417477 epoch total loss 1.09768796
Trained batch 5014 batch loss 1.12282968 epoch total loss 1.09769309
Trained batch 5015 batch loss 1.03229046 epoch total loss 1.09768
Trained batch 5016 batch loss 1.03002679 epoch total loss 1.0976665
Trained batch 5017 batch loss 0.980940163 epoch total loss 1.09764326
Trained batch 5018 batch loss 0.990034103 epoch total loss 1.0976218
Trained batch 5019 batch loss 1.0853864 epoch total loss 1.09761941
Trained batch 5020 batch loss 1.15980244 epoch total loss 1.09763169
Trained batch 5021 batch loss 1.29270053 epoch total loss 1.09767056
Trained batch 5022 batch loss 1.25570941 epoch total loss 1.09770203
Trained batch 5023 batch loss 1.04409015 epoch total loss 1.0976913
Trained batch 5024 batch loss 0.886050642 epoch total loss 1.09764922
Trained batch 5025 batch loss 1.14048719 epoch total loss 1.0976578
Trained batch 5026 batch loss 1.07347441 epoch total loss 1.09765291
Trained batch 5027 batch loss 1.1940186 epoch total loss 1.0976721
Trained batch 5028 batch loss 1.07452106 epoch total loss 1.09766746
Trained batch 5029 batch loss 1.20162165 epoch total loss 1.0976882
Trained batch 5030 batch loss 1.11782205 epoch total loss 1.09769213
Trained batch 5031 batch loss 0.999785066 epoch total loss 1.0976727
Trained batch 5032 batch loss 0.923061371 epoch total loss 1.09763801
Trained batch 5033 batch loss 0.895353794 epoch total loss 1.09759784
Trained batch 5034 batch loss 1.08328819 epoch total loss 1.0975951
Trained batch 5035 batch loss 0.947948933 epoch total loss 1.09756529
Trained batch 5036 batch loss 0.843589067 epoch total loss 1.09751487
Trained batch 5037 batch loss 0.809238315 epoch total loss 1.09745765
Trained batch 5038 batch loss 0.925361753 epoch total loss 1.09742343
Trained batch 5039 batch loss 1.1192174 epoch total loss 1.09742773
Trained batch 5040 batch loss 0.8782444 epoch total loss 1.09738433
Trained batch 5041 batch loss 0.961913049 epoch total loss 1.09735739
Trained batch 5042 batch loss 1.14186096 epoch total loss 1.09736633
Trained batch 5043 batch loss 1.04895866 epoch total loss 1.09735668
Trained batch 5044 batch loss 1.12022352 epoch total loss 1.09736121
Trained batch 5045 batch loss 0.83458662 epoch total loss 1.09730911
Trained batch 5046 batch loss 0.966620505 epoch total loss 1.09728324
Trained batch 5047 batch loss 1.04008579 epoch total loss 1.09727192
Trained batch 5048 batch loss 1.1260066 epoch total loss 1.09727752
Trained batch 5049 batch loss 1.14763296 epoch total loss 1.09728754
Trained batch 5050 batch loss 1.12734544 epoch total loss 1.0972935
Trained batch 5051 batch loss 1.0532589 epoch total loss 1.09728479
Trained batch 5052 batch loss 1.36668146 epoch total loss 1.09733808
Trained batch 5053 batch loss 1.1871897 epoch total loss 1.09735584
Trained batch 5054 batch loss 1.12370539 epoch total loss 1.09736097
Trained batch 5055 batch loss 0.974071205 epoch total loss 1.09733665
Trained batch 5056 batch loss 1.05074489 epoch total loss 1.09732747
Trained batch 5057 batch loss 1.3490212 epoch total loss 1.09737718
Trained batch 5058 batch loss 1.20984578 epoch total loss 1.09739947
Trained batch 5059 batch loss 1.18682599 epoch total loss 1.09741724
Trained batch 5060 batch loss 1.15507436 epoch total loss 1.09742856
Trained batch 5061 batch loss 1.18149126 epoch total loss 1.09744525
Trained batch 5062 batch loss 1.18372953 epoch total loss 1.0974623
Trained batch 5063 batch loss 1.11165977 epoch total loss 1.09746516
Trained batch 5064 batch loss 1.30682504 epoch total loss 1.0975064
Trained batch 5065 batch loss 1.38933551 epoch total loss 1.09756398
Trained batch 5066 batch loss 1.05800271 epoch total loss 1.09755623
Trained batch 5067 batch loss 1.0253036 epoch total loss 1.09754193
Trained batch 5068 batch loss 0.737013817 epoch total loss 1.09747076
Trained batch 5069 batch loss 1.18681479 epoch total loss 1.0974884
Trained batch 5070 batch loss 1.10997844 epoch total loss 1.09749091
Trained batch 5071 batch loss 1.34430051 epoch total loss 1.09753954
Trained batch 5072 batch loss 1.2997849 epoch total loss 1.09757948
Trained batch 5073 batch loss 1.21601903 epoch total loss 1.09760273
Trained batch 5074 batch loss 0.964809179 epoch total loss 1.09757662
Trained batch 5075 batch loss 1.17787969 epoch total loss 1.09759235
Trained batch 5076 batch loss 0.95266223 epoch total loss 1.09756386
Trained batch 5077 batch loss 1.13164842 epoch total loss 1.09757054
Trained batch 5078 batch loss 1.15304971 epoch total loss 1.09758139
Trained batch 5079 batch loss 1.07737565 epoch total loss 1.09757745
Trained batch 5080 batch loss 1.1110239 epoch total loss 1.09758008
Trained batch 5081 batch loss 0.916321039 epoch total loss 1.09754443
Trained batch 5082 batch loss 1.08277655 epoch total loss 1.09754157
Trained batch 5083 batch loss 1.21839666 epoch total loss 1.09756529
Trained batch 5084 batch loss 1.07444429 epoch total loss 1.09756064
Trained batch 5085 batch loss 1.25479543 epoch total loss 1.09759164
Trained batch 5086 batch loss 1.12272763 epoch total loss 1.09759653
Trained batch 5087 batch loss 1.24635601 epoch total loss 1.09762585
Trained batch 5088 batch loss 1.19796979 epoch total loss 1.09764552
Trained batch 5089 batch loss 1.2251116 epoch total loss 1.09767056
Trained batch 5090 batch loss 1.26315904 epoch total loss 1.0977031
Trained batch 5091 batch loss 1.17222452 epoch total loss 1.09771776
Trained batch 5092 batch loss 1.07385027 epoch total loss 1.09771299
Trained batch 5093 batch loss 1.30932212 epoch total loss 1.09775448
Trained batch 5094 batch loss 1.14992154 epoch total loss 1.09776473
Trained batch 5095 batch loss 1.09093738 epoch total loss 1.09776342
Trained batch 5096 batch loss 0.958990455 epoch total loss 1.09773612
Trained batch 5097 batch loss 0.834021568 epoch total loss 1.09768438
Trained batch 5098 batch loss 1.03812158 epoch total loss 1.0976727
Trained batch 5099 batch loss 1.16145039 epoch total loss 1.09768522
Trained batch 5100 batch loss 1.08532143 epoch total loss 1.09768283
Trained batch 5101 batch loss 1.31640971 epoch total loss 1.09772575
Trained batch 5102 batch loss 1.32824063 epoch total loss 1.09777093
Trained batch 5103 batch loss 1.24353814 epoch total loss 1.09779954
Trained batch 5104 batch loss 1.14286709 epoch total loss 1.09780836
Trained batch 5105 batch loss 1.17683434 epoch total loss 1.09782386
Trained batch 5106 batch loss 1.20064187 epoch total loss 1.097844
Trained batch 5107 batch loss 1.39575768 epoch total loss 1.0979023
Trained batch 5108 batch loss 1.36022162 epoch total loss 1.09795368
Trained batch 5109 batch loss 1.37448704 epoch total loss 1.09800792
Trained batch 5110 batch loss 1.03273106 epoch total loss 1.09799504
Trained batch 5111 batch loss 1.00616562 epoch total loss 1.09797716
Trained batch 5112 batch loss 1.10505295 epoch total loss 1.09797847
Trained batch 5113 batch loss 0.757943034 epoch total loss 1.09791195
Trained batch 5114 batch loss 1.01968765 epoch total loss 1.0978967
Trained batch 5115 batch loss 1.11038876 epoch total loss 1.09789908
Trained batch 5116 batch loss 0.851879656 epoch total loss 1.09785104
Trained batch 5117 batch loss 1.0567838 epoch total loss 1.09784305
Trained batch 5118 batch loss 1.21579218 epoch total loss 1.09786606
Trained batch 5119 batch loss 1.26939964 epoch total loss 1.09789956
Trained batch 5120 batch loss 1.00440788 epoch total loss 1.09788132
Trained batch 5121 batch loss 1.09441924 epoch total loss 1.0978806
Trained batch 5122 batch loss 0.945731401 epoch total loss 1.09785092
Trained batch 5123 batch loss 1.16310215 epoch total loss 1.09786367
Trained batch 5124 batch loss 1.13275266 epoch total loss 1.09787047
Trained batch 5125 batch loss 0.848920166 epoch total loss 1.09782195
Trained batch 5126 batch loss 0.874739408 epoch total loss 1.09777832
Trained batch 5127 batch loss 0.932872772 epoch total loss 1.09774625
Trained batch 5128 batch loss 1.13361716 epoch total loss 1.09775329
Trained batch 5129 batch loss 1.10605693 epoch total loss 1.09775484
Trained batch 5130 batch loss 0.980840087 epoch total loss 1.09773207
Trained batch 5131 batch loss 0.908623934 epoch total loss 1.09769523
Trained batch 5132 batch loss 0.85665071 epoch total loss 1.09764826
Trained batch 5133 batch loss 1.10811472 epoch total loss 1.09765029
Trained batch 5134 batch loss 1.14322305 epoch total loss 1.09765911
Trained batch 5135 batch loss 0.981071413 epoch total loss 1.09763634
Trained batch 5136 batch loss 0.994320869 epoch total loss 1.0976162
Trained batch 5137 batch loss 1.07582593 epoch total loss 1.0976119
Trained batch 5138 batch loss 0.990842342 epoch total loss 1.09759116
Trained batch 5139 batch loss 1.07701373 epoch total loss 1.09758723
Trained batch 5140 batch loss 0.822171688 epoch total loss 1.09753358
Trained batch 5141 batch loss 1.03019881 epoch total loss 1.09752047
Trained batch 5142 batch loss 1.11318302 epoch total loss 1.09752357
Trained batch 5143 batch loss 0.958236814 epoch total loss 1.09749651
Trained batch 5144 batch loss 1.38305187 epoch total loss 1.09755194
Trained batch 5145 batch loss 1.12705874 epoch total loss 1.09755766
Trained batch 5146 batch loss 1.07066584 epoch total loss 1.09755242
Trained batch 5147 batch loss 0.986576319 epoch total loss 1.09753096
Trained batch 5148 batch loss 0.968676686 epoch total loss 1.09750593
Trained batch 5149 batch loss 1.0048511 epoch total loss 1.09748793
Trained batch 5150 batch loss 0.997968733 epoch total loss 1.09746861
Trained batch 5151 batch loss 0.925608397 epoch total loss 1.09743524
Trained batch 5152 batch loss 0.911536932 epoch total loss 1.09739923
Trained batch 5153 batch loss 1.09084082 epoch total loss 1.09739792
Trained batch 5154 batch loss 1.0170176 epoch total loss 1.09738231
Trained batch 5155 batch loss 0.861336708 epoch total loss 1.09733653
Trained batch 5156 batch loss 0.911838233 epoch total loss 1.09730053
Trained batch 5157 batch loss 0.662142456 epoch total loss 1.09721613
Trained batch 5158 batch loss 0.585891604 epoch total loss 1.09711707
Trained batch 5159 batch loss 0.711263776 epoch total loss 1.09704232
Trained batch 5160 batch loss 0.752375841 epoch total loss 1.09697545
Trained batch 5161 batch loss 0.815359831 epoch total loss 1.09692097
Trained batch 5162 batch loss 1.09644651 epoch total loss 1.09692085
Trained batch 5163 batch loss 1.25068235 epoch total loss 1.09695065
Trained batch 5164 batch loss 1.18603265 epoch total loss 1.09696794
Trained batch 5165 batch loss 1.24803066 epoch total loss 1.09699714
Trained batch 5166 batch loss 1.35137045 epoch total loss 1.09704638
Trained batch 5167 batch loss 1.22084272 epoch total loss 1.09707034
Trained batch 5168 batch loss 1.22777009 epoch total loss 1.09709561
Trained batch 5169 batch loss 1.07187438 epoch total loss 1.09709072
Trained batch 5170 batch loss 0.961573958 epoch total loss 1.0970645
Trained batch 5171 batch loss 1.004022 epoch total loss 1.09704649
Trained batch 5172 batch loss 1.11414933 epoch total loss 1.09704971
Trained batch 5173 batch loss 1.14218795 epoch total loss 1.09705853
Trained batch 5174 batch loss 0.933218241 epoch total loss 1.09702682
Trained batch 5175 batch loss 1.16076887 epoch total loss 1.0970391
Trained batch 5176 batch loss 1.035936 epoch total loss 1.0970273
Trained batch 5177 batch loss 1.21651435 epoch total loss 1.09705031
Trained batch 5178 batch loss 1.0505439 epoch total loss 1.09704137
Trained batch 5179 batch loss 1.02143526 epoch total loss 1.09702682
Trained batch 5180 batch loss 1.05522561 epoch total loss 1.09701872
Trained batch 5181 batch loss 1.05057073 epoch total loss 1.09700978
Trained batch 5182 batch loss 0.898557961 epoch total loss 1.09697151
Trained batch 5183 batch loss 1.03940225 epoch total loss 1.09696043
Trained batch 5184 batch loss 0.81356132 epoch total loss 1.09690571
Trained batch 5185 batch loss 1.01938367 epoch total loss 1.09689081
Trained batch 5186 batch loss 0.873230457 epoch total loss 1.09684765
Trained batch 5187 batch loss 1.05339813 epoch total loss 1.09683919
Trained batch 5188 batch loss 0.785751164 epoch total loss 1.09677923
Trained batch 5189 batch loss 0.961308718 epoch total loss 1.09675312
Trained batch 5190 batch loss 0.990353823 epoch total loss 1.09673262
Trained batch 5191 batch loss 1.11000586 epoch total loss 1.09673524
Trained batch 5192 batch loss 0.966446459 epoch total loss 1.09671009
Trained batch 5193 batch loss 1.12380612 epoch total loss 1.09671533
Trained batch 5194 batch loss 0.833459079 epoch total loss 1.09666467
Trained batch 5195 batch loss 1.18375278 epoch total loss 1.09668136
Trained batch 5196 batch loss 0.857668519 epoch total loss 1.09663546
Trained batch 5197 batch loss 1.18729651 epoch total loss 1.09665287
Trained batch 5198 batch loss 0.987719893 epoch total loss 1.096632
Trained batch 5199 batch loss 0.974844456 epoch total loss 1.09660852
Trained batch 5200 batch loss 1.18036151 epoch total loss 1.09662461
Trained batch 5201 batch loss 1.09383547 epoch total loss 1.09662402
Trained batch 5202 batch loss 1.413342 epoch total loss 1.09668493
Trained batch 5203 batch loss 0.94721067 epoch total loss 1.0966562
Trained batch 5204 batch loss 1.25248 epoch total loss 1.09668612
Trained batch 5205 batch loss 1.05454302 epoch total loss 1.09667814
Trained batch 5206 batch loss 1.11228848 epoch total loss 1.09668112
Trained batch 5207 batch loss 1.21442294 epoch total loss 1.09670365
Trained batch 5208 batch loss 1.12997186 epoch total loss 1.09671009
Trained batch 5209 batch loss 1.08595538 epoch total loss 1.09670794
Trained batch 5210 batch loss 1.17042959 epoch total loss 1.09672213
Trained batch 5211 batch loss 1.21931183 epoch total loss 1.09674561
Trained batch 5212 batch loss 1.25991404 epoch total loss 1.09677696
Trained batch 5213 batch loss 1.24324453 epoch total loss 1.09680498
Trained batch 5214 batch loss 1.25712 epoch total loss 1.09683585
Trained batch 5215 batch loss 1.08501852 epoch total loss 1.09683347
Trained batch 5216 batch loss 1.00317764 epoch total loss 1.09681559
Trained batch 5217 batch loss 1.18666971 epoch total loss 1.09683275
Trained batch 5218 batch loss 1.03101301 epoch total loss 1.09682024
Trained batch 5219 batch loss 1.10347784 epoch total loss 1.09682155
Trained batch 5220 batch loss 1.01326263 epoch total loss 1.09680545
Trained batch 5221 batch loss 1.1254611 epoch total loss 1.09681094
Trained batch 5222 batch loss 1.29488754 epoch total loss 1.09684896
Trained batch 5223 batch loss 1.05270314 epoch total loss 1.0968405
Trained batch 5224 batch loss 1.26215863 epoch total loss 1.09687209
Trained batch 5225 batch loss 1.24919081 epoch total loss 1.0969013
Trained batch 5226 batch loss 1.22375679 epoch total loss 1.0969255
Trained batch 5227 batch loss 1.07482648 epoch total loss 1.09692121
Trained batch 5228 batch loss 1.07473147 epoch total loss 1.09691703
Trained batch 5229 batch loss 0.830615222 epoch total loss 1.09686613
Trained batch 5230 batch loss 1.07471657 epoch total loss 1.09686184
Trained batch 5231 batch loss 1.157547 epoch total loss 1.09687352
Trained batch 5232 batch loss 0.975498319 epoch total loss 1.09685028
Trained batch 5233 batch loss 1.16735065 epoch total loss 1.09686375
Trained batch 5234 batch loss 1.03485799 epoch total loss 1.09685194
Trained batch 5235 batch loss 1.1111939 epoch total loss 1.09685469
Trained batch 5236 batch loss 1.10519552 epoch total loss 1.09685624
Trained batch 5237 batch loss 1.02314568 epoch total loss 1.09684205
Trained batch 5238 batch loss 1.18499804 epoch total loss 1.09685898
Trained batch 5239 batch loss 0.80256772 epoch total loss 1.09680283
Trained batch 5240 batch loss 1.13935018 epoch total loss 1.09681094
Trained batch 5241 batch loss 1.16676521 epoch total loss 1.09682429
Trained batch 5242 batch loss 0.944172 epoch total loss 1.0967952
Trained batch 5243 batch loss 1.19962811 epoch total loss 1.09681487
Trained batch 5244 batch loss 1.14337385 epoch total loss 1.09682369
Trained batch 5245 batch loss 0.93214 epoch total loss 1.09679234
Trained batch 5246 batch loss 0.893449962 epoch total loss 1.0967536
Trained batch 5247 batch loss 0.855122685 epoch total loss 1.09670746
Trained batch 5248 batch loss 1.01289797 epoch total loss 1.09669149
Trained batch 5249 batch loss 1.03949749 epoch total loss 1.09668064
Trained batch 5250 batch loss 1.03122497 epoch total loss 1.09666812
Trained batch 5251 batch loss 1.03119421 epoch total loss 1.09665573
Trained batch 5252 batch loss 1.10835838 epoch total loss 1.09665799
Trained batch 5253 batch loss 1.0327251 epoch total loss 1.09664571
Trained batch 5254 batch loss 1.1795963 epoch total loss 1.09666157
Trained batch 5255 batch loss 1.28015 epoch total loss 1.0966965
Trained batch 5256 batch loss 1.38689125 epoch total loss 1.09675169
Trained batch 5257 batch loss 1.2014991 epoch total loss 1.0967716
Trained batch 5258 batch loss 1.08320022 epoch total loss 1.09676898
Trained batch 5259 batch loss 1.32830191 epoch total loss 1.09681296
Trained batch 5260 batch loss 1.26098764 epoch total loss 1.09684432
Trained batch 5261 batch loss 1.28942907 epoch total loss 1.09688091
Trained batch 5262 batch loss 1.16816592 epoch total loss 1.09689438
Trained batch 5263 batch loss 1.40554035 epoch total loss 1.09695315
Trained batch 5264 batch loss 1.29002726 epoch total loss 1.09698975
Trained batch 5265 batch loss 1.15930951 epoch total loss 1.09700155
Trained batch 5266 batch loss 1.3756566 epoch total loss 1.09705448
Trained batch 5267 batch loss 1.26262081 epoch total loss 1.09708595
Trained batch 5268 batch loss 1.20616066 epoch total loss 1.09710658
Trained batch 5269 batch loss 1.277 epoch total loss 1.09714067
Trained batch 5270 batch loss 1.30405641 epoch total loss 1.09718
Trained batch 5271 batch loss 1.20879722 epoch total loss 1.09720123
Trained batch 5272 batch loss 1.18631256 epoch total loss 1.09721816
Trained batch 5273 batch loss 1.34690595 epoch total loss 1.09726548
Trained batch 5274 batch loss 0.985406041 epoch total loss 1.09724426
Trained batch 5275 batch loss 0.99172914 epoch total loss 1.09722424
Trained batch 5276 batch loss 1.03964806 epoch total loss 1.09721327
Trained batch 5277 batch loss 0.990492046 epoch total loss 1.09719312
Trained batch 5278 batch loss 1.02237391 epoch total loss 1.09717894
Trained batch 5279 batch loss 0.871675789 epoch total loss 1.09713626
Trained batch 5280 batch loss 0.864744186 epoch total loss 1.09709227
Trained batch 5281 batch loss 1.00594902 epoch total loss 1.09707499
Trained batch 5282 batch loss 0.839205265 epoch total loss 1.09702611
Trained batch 5283 batch loss 0.806912899 epoch total loss 1.09697127
Trained batch 5284 batch loss 0.782016277 epoch total loss 1.09691167
Trained batch 5285 batch loss 0.800752878 epoch total loss 1.09685564
Trained batch 5286 batch loss 0.820206165 epoch total loss 1.09680343
Trained batch 5287 batch loss 0.74387 epoch total loss 1.09673655
Trained batch 5288 batch loss 0.87948221 epoch total loss 1.09669542
Trained batch 5289 batch loss 0.920502663 epoch total loss 1.09666216
Trained batch 5290 batch loss 0.76366061 epoch total loss 1.09659922
Trained batch 5291 batch loss 0.934555411 epoch total loss 1.09656858
Trained batch 5292 batch loss 1.04951894 epoch total loss 1.09655964
Trained batch 5293 batch loss 0.963099897 epoch total loss 1.09653437
Trained batch 5294 batch loss 1.03207469 epoch total loss 1.09652221
Trained batch 5295 batch loss 1.22108305 epoch total loss 1.09654582
Trained batch 5296 batch loss 1.07868171 epoch total loss 1.09654236
Trained batch 5297 batch loss 1.1143868 epoch total loss 1.0965457
Trained batch 5298 batch loss 1.07640648 epoch total loss 1.09654188
Trained batch 5299 batch loss 1.23170376 epoch total loss 1.09656751
Trained batch 5300 batch loss 0.975978732 epoch total loss 1.09654474
Trained batch 5301 batch loss 1.08053303 epoch total loss 1.09654176
Trained batch 5302 batch loss 1.05696023 epoch total loss 1.09653425
Trained batch 5303 batch loss 1.23446715 epoch total loss 1.09656024
Trained batch 5304 batch loss 1.13959575 epoch total loss 1.09656835
Trained batch 5305 batch loss 0.865796328 epoch total loss 1.09652483
Trained batch 5306 batch loss 1.01563811 epoch total loss 1.09650958
Trained batch 5307 batch loss 1.00625587 epoch total loss 1.09649265
Trained batch 5308 batch loss 0.835738301 epoch total loss 1.09644353
Trained batch 5309 batch loss 0.756644607 epoch total loss 1.09637964
Trained batch 5310 batch loss 1.00226831 epoch total loss 1.09636188
Trained batch 5311 batch loss 0.933237314 epoch total loss 1.09633112
Trained batch 5312 batch loss 0.99527061 epoch total loss 1.09631205
Trained batch 5313 batch loss 1.01396036 epoch total loss 1.09629667
Trained batch 5314 batch loss 1.2473011 epoch total loss 1.09632504
Trained batch 5315 batch loss 1.06434536 epoch total loss 1.09631896
Trained batch 5316 batch loss 1.09838331 epoch total loss 1.09631932
Trained batch 5317 batch loss 1.17870402 epoch total loss 1.09633482
Trained batch 5318 batch loss 1.0013814 epoch total loss 1.09631705
Trained batch 5319 batch loss 0.936289728 epoch total loss 1.09628701
Trained batch 5320 batch loss 1.34202969 epoch total loss 1.09633315
Trained batch 5321 batch loss 1.1943388 epoch total loss 1.0963515
Trained batch 5322 batch loss 1.31307256 epoch total loss 1.09639227
Trained batch 5323 batch loss 1.18214691 epoch total loss 1.09640837
Trained batch 5324 batch loss 1.23100948 epoch total loss 1.09643364
Trained batch 5325 batch loss 1.13080132 epoch total loss 1.09644008
Trained batch 5326 batch loss 0.951876402 epoch total loss 1.0964129
Trained batch 5327 batch loss 1.10143471 epoch total loss 1.09641385
Trained batch 5328 batch loss 1.02429819 epoch total loss 1.09640038
Trained batch 5329 batch loss 1.22096086 epoch total loss 1.09642375
Trained batch 5330 batch loss 1.31536722 epoch total loss 1.09646487
Trained batch 5331 batch loss 1.09769821 epoch total loss 1.09646511
Trained batch 5332 batch loss 1.04135633 epoch total loss 1.09645474
Trained batch 5333 batch loss 0.850909829 epoch total loss 1.09640872
Trained batch 5334 batch loss 0.998190701 epoch total loss 1.09639037
Trained batch 5335 batch loss 0.976310551 epoch total loss 1.09636772
Trained batch 5336 batch loss 1.07555199 epoch total loss 1.0963639
Trained batch 5337 batch loss 1.19400549 epoch total loss 1.09638214
Trained batch 5338 batch loss 1.29230177 epoch total loss 1.09641886
Trained batch 5339 batch loss 1.2359941 epoch total loss 1.09644496
Trained batch 5340 batch loss 1.298208 epoch total loss 1.09648287
Trained batch 5341 batch loss 1.22050095 epoch total loss 1.09650612
Trained batch 5342 batch loss 1.12126255 epoch total loss 1.09651065
Trained batch 5343 batch loss 1.12046218 epoch total loss 1.09651518
Trained batch 5344 batch loss 1.14750779 epoch total loss 1.09652472
Trained batch 5345 batch loss 1.25325572 epoch total loss 1.09655404
Trained batch 5346 batch loss 1.11819267 epoch total loss 1.09655809
Trained batch 5347 batch loss 1.04246485 epoch total loss 1.09654796
Trained batch 5348 batch loss 1.25982094 epoch total loss 1.09657848
Trained batch 5349 batch loss 1.12335825 epoch total loss 1.0965836
Trained batch 5350 batch loss 1.16791415 epoch total loss 1.09659696
Trained batch 5351 batch loss 1.16524506 epoch total loss 1.09660971
Trained batch 5352 batch loss 1.19642901 epoch total loss 1.09662831
Trained batch 5353 batch loss 1.19376051 epoch total loss 1.09664643
Trained batch 5354 batch loss 1.13737583 epoch total loss 1.09665406
Trained batch 5355 batch loss 1.15118146 epoch total loss 1.09666431
Trained batch 5356 batch loss 1.06577873 epoch total loss 1.09665859
Trained batch 5357 batch loss 0.838543773 epoch total loss 1.09661031
Trained batch 5358 batch loss 0.98216486 epoch total loss 1.09658897
Trained batch 5359 batch loss 1.25878263 epoch total loss 1.09661913
Trained batch 5360 batch loss 1.11008048 epoch total loss 1.09662163
Trained batch 5361 batch loss 0.963959217 epoch total loss 1.09659684
Trained batch 5362 batch loss 0.920340478 epoch total loss 1.09656405
Trained batch 5363 batch loss 0.889778495 epoch total loss 1.09652543
Trained batch 5364 batch loss 0.914441705 epoch total loss 1.09649158
Trained batch 5365 batch loss 1.08440828 epoch total loss 1.09648931
Trained batch 5366 batch loss 1.06045437 epoch total loss 1.09648263
Trained batch 5367 batch loss 1.03235078 epoch total loss 1.09647059
Trained batch 5368 batch loss 1.16086829 epoch total loss 1.09648252
Trained batch 5369 batch loss 1.40100193 epoch total loss 1.09653926
Trained batch 5370 batch loss 1.2556988 epoch total loss 1.09656894
Trained batch 5371 batch loss 1.32903302 epoch total loss 1.09661222
Trained batch 5372 batch loss 1.0019176 epoch total loss 1.09659457
Trained batch 5373 batch loss 1.03505015 epoch total loss 1.09658313
Trained batch 5374 batch loss 1.07283056 epoch total loss 1.09657872
Trained batch 5375 batch loss 1.11277485 epoch total loss 1.09658182
Trained batch 5376 batch loss 1.17911029 epoch total loss 1.09659708
Trained batch 5377 batch loss 1.08442152 epoch total loss 1.09659493
Trained batch 5378 batch loss 1.04279852 epoch total loss 1.09658492
Trained batch 5379 batch loss 1.09994972 epoch total loss 1.09658551
Trained batch 5380 batch loss 1.23064041 epoch total loss 1.09661043
Trained batch 5381 batch loss 1.10610819 epoch total loss 1.09661222
Trained batch 5382 batch loss 1.23153973 epoch total loss 1.09663725
Trained batch 5383 batch loss 1.20627415 epoch total loss 1.09665751
Trained batch 5384 batch loss 1.1473217 epoch total loss 1.09666693
Trained batch 5385 batch loss 1.27206969 epoch total loss 1.0966996
Trained batch 5386 batch loss 1.00292766 epoch total loss 1.09668219
Trained batch 5387 batch loss 1.12686181 epoch total loss 1.09668779
Trained batch 5388 batch loss 1.08018327 epoch total loss 1.09668469
Trained batch 5389 batch loss 1.12185073 epoch total loss 1.09668934
Trained batch 5390 batch loss 1.22434282 epoch total loss 1.09671307
Trained batch 5391 batch loss 1.0879488 epoch total loss 1.0967114
Trained batch 5392 batch loss 1.20639491 epoch total loss 1.09673178
Trained batch 5393 batch loss 1.13599467 epoch total loss 1.09673905
Trained batch 5394 batch loss 1.09792984 epoch total loss 1.09673929
Trained batch 5395 batch loss 1.12323081 epoch total loss 1.09674418
Trained batch 5396 batch loss 1.31810236 epoch total loss 1.09678519
Trained batch 5397 batch loss 0.940676093 epoch total loss 1.09675634
Trained batch 5398 batch loss 1.36058748 epoch total loss 1.0968051
Trained batch 5399 batch loss 1.07126427 epoch total loss 1.09680045
Trained batch 5400 batch loss 1.03846788 epoch total loss 1.0967896
Trained batch 5401 batch loss 1.15864491 epoch total loss 1.09680116
Trained batch 5402 batch loss 1.18712926 epoch total loss 1.09681785
Trained batch 5403 batch loss 1.25940084 epoch total loss 1.09684789
Trained batch 5404 batch loss 1.02165771 epoch total loss 1.09683394
Trained batch 5405 batch loss 1.02970839 epoch total loss 1.09682155
Trained batch 5406 batch loss 1.21658576 epoch total loss 1.09684372
Trained batch 5407 batch loss 1.1132282 epoch total loss 1.0968467
Trained batch 5408 batch loss 1.13980222 epoch total loss 1.09685469
Trained batch 5409 batch loss 1.14102578 epoch total loss 1.09686279
Trained batch 5410 batch loss 1.25847447 epoch total loss 1.09689271
Trained batch 5411 batch loss 0.807229757 epoch total loss 1.09683919
Trained batch 5412 batch loss 1.0485431 epoch total loss 1.09683013
Trained batch 5413 batch loss 1.2427485 epoch total loss 1.09685707
Trained batch 5414 batch loss 0.962055326 epoch total loss 1.09683216
Trained batch 5415 batch loss 0.972899437 epoch total loss 1.09680927
Trained batch 5416 batch loss 1.1417079 epoch total loss 1.09681749
Trained batch 5417 batch loss 1.02158034 epoch total loss 1.09680367
Trained batch 5418 batch loss 1.06263137 epoch total loss 1.09679735
Trained batch 5419 batch loss 1.01300275 epoch total loss 1.09678185
Trained batch 5420 batch loss 1.04490733 epoch total loss 1.09677231
Trained batch 5421 batch loss 1.05744696 epoch total loss 1.09676504
Trained batch 5422 batch loss 1.05941534 epoch total loss 1.09675825
Trained batch 5423 batch loss 0.930106163 epoch total loss 1.09672749
Trained batch 5424 batch loss 1.16152954 epoch total loss 1.09673941
Trained batch 5425 batch loss 1.15842652 epoch total loss 1.09675074
Trained batch 5426 batch loss 0.914458156 epoch total loss 1.09671724
Trained batch 5427 batch loss 1.09265137 epoch total loss 1.09671652
Trained batch 5428 batch loss 1.06852674 epoch total loss 1.09671128
Trained batch 5429 batch loss 1.03996146 epoch total loss 1.09670079
Trained batch 5430 batch loss 1.24654245 epoch total loss 1.09672844
Trained batch 5431 batch loss 1.04708767 epoch total loss 1.09671926
Trained batch 5432 batch loss 0.98623 epoch total loss 1.09669888
Trained batch 5433 batch loss 0.904751539 epoch total loss 1.09666359
Trained batch 5434 batch loss 0.982562065 epoch total loss 1.09664261
Trained batch 5435 batch loss 0.911292195 epoch total loss 1.0966084
Trained batch 5436 batch loss 1.18843555 epoch total loss 1.09662533
Trained batch 5437 batch loss 0.869026899 epoch total loss 1.09658349
Trained batch 5438 batch loss 0.936899543 epoch total loss 1.09655416
Trained batch 5439 batch loss 0.892392159 epoch total loss 1.09651661
Trained batch 5440 batch loss 1.07818985 epoch total loss 1.09651327
Trained batch 5441 batch loss 0.831170917 epoch total loss 1.09646451
Trained batch 5442 batch loss 0.913605332 epoch total loss 1.0964309
Trained batch 5443 batch loss 0.868388236 epoch total loss 1.09638894
Trained batch 5444 batch loss 0.991832137 epoch total loss 1.09636974
Trained batch 5445 batch loss 0.997476697 epoch total loss 1.09635162
Trained batch 5446 batch loss 0.991489291 epoch total loss 1.09633231
Trained batch 5447 batch loss 1.14709544 epoch total loss 1.09634161
Trained batch 5448 batch loss 0.999729 epoch total loss 1.09632385
Trained batch 5449 batch loss 1.03730464 epoch total loss 1.096313
Trained batch 5450 batch loss 1.1604116 epoch total loss 1.0963248
Trained batch 5451 batch loss 1.04072 epoch total loss 1.09631455
Trained batch 5452 batch loss 1.00794148 epoch total loss 1.09629834
Trained batch 5453 batch loss 1.27723122 epoch total loss 1.0963316
Trained batch 5454 batch loss 1.22891295 epoch total loss 1.09635592
Trained batch 5455 batch loss 1.1040051 epoch total loss 1.09635723
Trained batch 5456 batch loss 1.02874672 epoch total loss 1.09634495
Trained batch 5457 batch loss 1.02108669 epoch total loss 1.09633112
Trained batch 5458 batch loss 1.25794017 epoch total loss 1.09636068
Trained batch 5459 batch loss 1.00031221 epoch total loss 1.09634316
Trained batch 5460 batch loss 1.23978662 epoch total loss 1.09636939
Trained batch 5461 batch loss 1.05846262 epoch total loss 1.09636247
Trained batch 5462 batch loss 1.09445381 epoch total loss 1.09636211
Trained batch 5463 batch loss 1.4149946 epoch total loss 1.09642041
Trained batch 5464 batch loss 1.01149249 epoch total loss 1.09640491
Trained batch 5465 batch loss 1.3117094 epoch total loss 1.09644425
Trained batch 5466 batch loss 1.28398085 epoch total loss 1.09647858
Trained batch 5467 batch loss 1.21511149 epoch total loss 1.0965004
Trained batch 5468 batch loss 1.39634347 epoch total loss 1.09655523
Trained batch 5469 batch loss 1.34420466 epoch total loss 1.09660053
Trained batch 5470 batch loss 1.28180933 epoch total loss 1.09663439
Trained batch 5471 batch loss 1.26625717 epoch total loss 1.09666526
Trained batch 5472 batch loss 1.0314312 epoch total loss 1.09665334
Trained batch 5473 batch loss 0.981659055 epoch total loss 1.09663236
Trained batch 5474 batch loss 1.17703986 epoch total loss 1.09664702
Trained batch 5475 batch loss 1.07519758 epoch total loss 1.09664309
Trained batch 5476 batch loss 1.35810423 epoch total loss 1.09669077
Trained batch 5477 batch loss 1.12609851 epoch total loss 1.09669614
Trained batch 5478 batch loss 1.02605593 epoch total loss 1.09668326
Trained batch 5479 batch loss 1.12700987 epoch total loss 1.09668875
Trained batch 5480 batch loss 1.1668756 epoch total loss 1.09670162
Trained batch 5481 batch loss 1.25790429 epoch total loss 1.09673095
Trained batch 5482 batch loss 1.20959675 epoch total loss 1.09675157
Trained batch 5483 batch loss 1.10028148 epoch total loss 1.09675217
Trained batch 5484 batch loss 1.13239646 epoch total loss 1.09675872
Trained batch 5485 batch loss 1.18707037 epoch total loss 1.09677517
Trained batch 5486 batch loss 1.31026506 epoch total loss 1.09681404
Trained batch 5487 batch loss 1.17886817 epoch total loss 1.09682894
Trained batch 5488 batch loss 1.36868453 epoch total loss 1.09687841
Trained batch 5489 batch loss 1.2437098 epoch total loss 1.09690523
Trained batch 5490 batch loss 0.868719637 epoch total loss 1.09686363
Trained batch 5491 batch loss 0.991384387 epoch total loss 1.09684432
Trained batch 5492 batch loss 0.885183513 epoch total loss 1.09680581
Trained batch 5493 batch loss 0.824523151 epoch total loss 1.09675634
Trained batch 5494 batch loss 0.971440315 epoch total loss 1.09673357
Trained batch 5495 batch loss 1.12403905 epoch total loss 1.09673846
Trained batch 5496 batch loss 0.997933924 epoch total loss 1.09672058
Trained batch 5497 batch loss 1.02817225 epoch total loss 1.09670806
Trained batch 5498 batch loss 1.28734422 epoch total loss 1.09674275
Trained batch 5499 batch loss 0.877264738 epoch total loss 1.09670281
Trained batch 5500 batch loss 0.912329 epoch total loss 1.09666932
Trained batch 5501 batch loss 0.893530369 epoch total loss 1.09663236
Trained batch 5502 batch loss 0.853019834 epoch total loss 1.09658813
Trained batch 5503 batch loss 0.854340434 epoch total loss 1.09654415
Trained batch 5504 batch loss 0.849420369 epoch total loss 1.0964992
Trained batch 5505 batch loss 0.800291657 epoch total loss 1.09644544
Trained batch 5506 batch loss 1.02156556 epoch total loss 1.09643185
Trained batch 5507 batch loss 0.991747439 epoch total loss 1.09641278
Trained batch 5508 batch loss 0.743642926 epoch total loss 1.09634876
Trained batch 5509 batch loss 0.94738549 epoch total loss 1.0963217
Trained batch 5510 batch loss 0.975486636 epoch total loss 1.09629977
Trained batch 5511 batch loss 1.04551649 epoch total loss 1.09629059
Trained batch 5512 batch loss 1.14141679 epoch total loss 1.09629881
Trained batch 5513 batch loss 0.985937476 epoch total loss 1.09627879
Trained batch 5514 batch loss 1.151999 epoch total loss 1.0962888
Trained batch 5515 batch loss 0.853403926 epoch total loss 1.09624481
Trained batch 5516 batch loss 0.863185525 epoch total loss 1.09620261
Trained batch 5517 batch loss 0.898190439 epoch total loss 1.09616661
Trained batch 5518 batch loss 0.822834969 epoch total loss 1.09611702
Trained batch 5519 batch loss 0.689819038 epoch total loss 1.09604347
Trained batch 5520 batch loss 0.729712486 epoch total loss 1.09597707
Trained batch 5521 batch loss 0.664587438 epoch total loss 1.09589899
Trained batch 5522 batch loss 0.701640129 epoch total loss 1.09582758
Trained batch 5523 batch loss 0.854222596 epoch total loss 1.09578371
Trained batch 5524 batch loss 0.798392773 epoch total loss 1.09573
Trained batch 5525 batch loss 0.849097252 epoch total loss 1.09568524
Trained batch 5526 batch loss 0.913461804 epoch total loss 1.09565234
Trained batch 5527 batch loss 0.704562902 epoch total loss 1.09558153
Trained batch 5528 batch loss 0.654046357 epoch total loss 1.09550166
Trained batch 5529 batch loss 0.641102731 epoch total loss 1.09541941
Trained batch 5530 batch loss 0.792522311 epoch total loss 1.09536469
Trained batch 5531 batch loss 0.762760818 epoch total loss 1.09530449
Trained batch 5532 batch loss 1.04713273 epoch total loss 1.09529591
Trained batch 5533 batch loss 1.0631671 epoch total loss 1.09529006
Trained batch 5534 batch loss 0.937714756 epoch total loss 1.09526157
Trained batch 5535 batch loss 1.08899069 epoch total loss 1.09526038
Trained batch 5536 batch loss 1.09820807 epoch total loss 1.09526086
Trained batch 5537 batch loss 1.08454955 epoch total loss 1.09525895
Trained batch 5538 batch loss 1.00854874 epoch total loss 1.09524333
Trained batch 5539 batch loss 0.975283 epoch total loss 1.09522164
Trained batch 5540 batch loss 1.05070603 epoch total loss 1.09521365
Trained batch 5541 batch loss 1.07381523 epoch total loss 1.09520972
Trained batch 5542 batch loss 1.0068717 epoch total loss 1.09519374
Trained batch 5543 batch loss 1.14806581 epoch total loss 1.09520328
Trained batch 5544 batch loss 1.03637457 epoch total loss 1.09519267
Trained batch 5545 batch loss 1.21052122 epoch total loss 1.09521341
Trained batch 5546 batch loss 1.19209969 epoch total loss 1.09523082
Trained batch 5547 batch loss 1.03847909 epoch total loss 1.09522069
Trained batch 5548 batch loss 1.03420389 epoch total loss 1.0952096
Trained batch 5549 batch loss 0.950045228 epoch total loss 1.09518349
Trained batch 5550 batch loss 0.926211536 epoch total loss 1.09515309
Trained batch 5551 batch loss 1.34556 epoch total loss 1.09519827
Trained batch 5552 batch loss 1.13473082 epoch total loss 1.09520531
Epoch 5 train loss 1.095205307006836
Validated batch 1 batch loss 1.13964307
Validated batch 2 batch loss 1.18312371
Validated batch 3 batch loss 1.1845777
Validated batch 4 batch loss 1.25333047
Validated batch 5 batch loss 1.12270212
Validated batch 6 batch loss 1.04916787
Validated batch 7 batch loss 1.27017641
Validated batch 8 batch loss 1.24095356
Validated batch 9 batch loss 1.25342
Validated batch 10 batch loss 1.00018692
Validated batch 11 batch loss 1.23566842
Validated batch 12 batch loss 1.14484048
Validated batch 13 batch loss 1.21904182
Validated batch 14 batch loss 0.982379079
Validated batch 15 batch loss 1.31179082
Validated batch 16 batch loss 1.01864195
Validated batch 17 batch loss 1.39459598
Validated batch 18 batch loss 1.05483568
Validated batch 19 batch loss 1.40298474
Validated batch 20 batch loss 1.3588624
Validated batch 21 batch loss 1.64354861
Validated batch 22 batch loss 1.43630612
Validated batch 23 batch loss 1.25260293
Validated batch 24 batch loss 1.08824551
Validated batch 25 batch loss 0.975975394
Validated batch 26 batch loss 1.13933086
Validated batch 27 batch loss 1.29468966
Validated batch 28 batch loss 1.17107129
Validated batch 29 batch loss 1.05786133
Validated batch 30 batch loss 1.3505919
Validated batch 31 batch loss 1.3083868
Validated batch 32 batch loss 1.10097098
Validated batch 33 batch loss 1.24081814
Validated batch 34 batch loss 1.03482676
Validated batch 35 batch loss 1.19931054
Validated batch 36 batch loss 1.41320121
Validated batch 37 batch loss 1.27304673
Validated batch 38 batch loss 1.20283794
Validated batch 39 batch loss 1.20236492
Validated batch 40 batch loss 1.18527579
Validated batch 41 batch loss 1.28590262
Validated batch 42 batch loss 1.1029551
Validated batch 43 batch loss 1.19893289
Validated batch 44 batch loss 1.25970042
Validated batch 45 batch loss 1.01199639
Validated batch 46 batch loss 1.22841
Validated batch 47 batch loss 0.913603663
Validated batch 48 batch loss 1.10084689
Validated batch 49 batch loss 1.22546268
Validated batch 50 batch loss 1.3986814
Validated batch 51 batch loss 1.42411542
Validated batch 52 batch loss 1.48158717
Validated batch 53 batch loss 1.17871571
Validated batch 54 batch loss 1.03143668
Validated batch 55 batch loss 1.08532488
Validated batch 56 batch loss 1.0331645
Validated batch 57 batch loss 1.36901736
Validated batch 58 batch loss 1.29477572
Validated batch 59 batch loss 1.43458962
Validated batch 60 batch loss 1.07027984
Validated batch 61 batch loss 1.2475611
Validated batch 62 batch loss 1.29133248
Validated batch 63 batch loss 1.28666031
Validated batch 64 batch loss 1.13311946
Validated batch 65 batch loss 1.15065753
Validated batch 66 batch loss 1.2821281
Validated batch 67 batch loss 1.3310672
Validated batch 68 batch loss 1.31745374
Validated batch 69 batch loss 1.24897218
Validated batch 70 batch loss 0.900106132
Validated batch 71 batch loss 0.847210705
Validated batch 72 batch loss 1.04886258
Validated batch 73 batch loss 1.18912363
Validated batch 74 batch loss 1.28941131
Validated batch 75 batch loss 1.22176421
Validated batch 76 batch loss 1.2845118
Validated batch 77 batch loss 1.24400222
Validated batch 78 batch loss 1.18017
Validated batch 79 batch loss 1.04244065
Validated batch 80 batch loss 0.976471305
Validated batch 81 batch loss 1.15995169
Validated batch 82 batch loss 1.32652044
Validated batch 83 batch loss 1.0573523
Validated batch 84 batch loss 1.54338193
Validated batch 85 batch loss 1.12314045
Validated batch 86 batch loss 1.07233727
Validated batch 87 batch loss 1.23445678
Validated batch 88 batch loss 1.26353276
Validated batch 89 batch loss 1.0631485
Validated batch 90 batch loss 1.16423929
Validated batch 91 batch loss 1.15415609
Validated batch 92 batch loss 1.38811612
Validated batch 93 batch loss 1.01483893
Validated batch 94 batch loss 1.046121
Validated batch 95 batch loss 1.25902748
Validated batch 96 batch loss 1.13848126
Validated batch 97 batch loss 1.25015807
Validated batch 98 batch loss 1.29150558
Validated batch 99 batch loss 0.965839684
Validated batch 100 batch loss 0.850412846
Validated batch 101 batch loss 1.27309239
Validated batch 102 batch loss 1.26502454
Validated batch 103 batch loss 1.03488398
Validated batch 104 batch loss 0.871904433
Validated batch 105 batch loss 1.06536341
Validated batch 106 batch loss 1.03498769
Validated batch 107 batch loss 1.31597924
Validated batch 108 batch loss 1.16699696
Validated batch 109 batch loss 1.19666052
Validated batch 110 batch loss 1.20354772
Validated batch 111 batch loss 0.837623954
Validated batch 112 batch loss 1.1513958
Validated batch 113 batch loss 1.27699268
Validated batch 114 batch loss 1.70532167
Validated batch 115 batch loss 1.16041434
Validated batch 116 batch loss 0.964438915
Validated batch 117 batch loss 1.2901125
Validated batch 118 batch loss 0.90957129
Validated batch 119 batch loss 1.00583935
Validated batch 120 batch loss 1.34368622
Validated batch 121 batch loss 1.19027638
Validated batch 122 batch loss 0.783780932
Validated batch 123 batch loss 0.844700873
Validated batch 124 batch loss 1.16003537
Validated batch 125 batch loss 1.00626183
Validated batch 126 batch loss 1.03701806
Validated batch 127 batch loss 1.34147632
Validated batch 128 batch loss 1.05248237
Validated batch 129 batch loss 1.14869332
Validated batch 130 batch loss 1.28653038
Validated batch 131 batch loss 1.03626275
Validated batch 132 batch loss 0.970175922
Validated batch 133 batch loss 1.07977796
Validated batch 134 batch loss 0.99373436
Validated batch 135 batch loss 1.03404117
Validated batch 136 batch loss 1.0785346
Validated batch 137 batch loss 1.22809958
Validated batch 138 batch loss 1.12984705
Validated batch 139 batch loss 0.981959879
Validated batch 140 batch loss 0.880416512
Validated batch 141 batch loss 1.11715329
Validated batch 142 batch loss 0.920569062
Validated batch 143 batch loss 1.3208313
Validated batch 144 batch loss 0.937578261
Validated batch 145 batch loss 1.15908623
Validated batch 146 batch loss 1.00487566
Validated batch 147 batch loss 1.11155009
Validated batch 148 batch loss 1.26889658
Validated batch 149 batch loss 1.26458395
Validated batch 150 batch loss 1.33878088
Validated batch 151 batch loss 1.19766736
Validated batch 152 batch loss 1.33872843
Validated batch 153 batch loss 1.33793604
Validated batch 154 batch loss 1.23889947
Validated batch 155 batch loss 1.25890481
Validated batch 156 batch loss 1.06600368
Validated batch 157 batch loss 1.15641212
Validated batch 158 batch loss 1.14786887
Validated batch 159 batch loss 0.914227605
Validated batch 160 batch loss 1.3699894
Validated batch 161 batch loss 1.24999
Validated batch 162 batch loss 1.32887983
Validated batch 163 batch loss 1.21400738
Validated batch 164 batch loss 1.14233398
Validated batch 165 batch loss 0.910094678
Validated batch 166 batch loss 0.982294798
Validated batch 167 batch loss 0.84893775
Validated batch 168 batch loss 1.2072258
Validated batch 169 batch loss 1.01557207
Validated batch 170 batch loss 0.868991792
Validated batch 171 batch loss 1.25719249
Validated batch 172 batch loss 1.23281074
Validated batch 173 batch loss 1.28911519
Validated batch 174 batch loss 0.98421824
Validated batch 175 batch loss 0.921773314
Validated batch 176 batch loss 1.025594
Validated batch 177 batch loss 1.06694031
Validated batch 178 batch loss 1.20563245
Validated batch 179 batch loss 1.24097228
Validated batch 180 batch loss 1.07519507
Validated batch 181 batch loss 1.29161572
Validated batch 182 batch loss 1.34191823
Validated batch 183 batch loss 1.10604978
Validated batch 184 batch loss 1.29077828
Validated batch 185 batch loss 1.26643324
Validated batch 186 batch loss 1.16670442
Validated batch 187 batch loss 1.35904074
Validated batch 188 batch loss 1.34905291
Validated batch 189 batch loss 1.05696869
Validated batch 190 batch loss 1.10756063
Validated batch 191 batch loss 1.1611073
Validated batch 192 batch loss 1.34541929
Validated batch 193 batch loss 1.12880349
Validated batch 194 batch loss 1.29703283
Validated batch 195 batch loss 0.887160182
Validated batch 196 batch loss 1.18502069
Validated batch 197 batch loss 1.16302288
Validated batch 198 batch loss 1.00966787
Validated batch 199 batch loss 1.34769511
Validated batch 200 batch loss 1.21251285
Validated batch 201 batch loss 1.06661987
Validated batch 202 batch loss 1.06893253
Validated batch 203 batch loss 1.0342958
Validated batch 204 batch loss 1.24160647
Validated batch 205 batch loss 1.29542494
Validated batch 206 batch loss 1.2425729
Validated batch 207 batch loss 1.04486394
Validated batch 208 batch loss 1.20391273
Validated batch 209 batch loss 1.1321516
Validated batch 210 batch loss 1.35742402
Validated batch 211 batch loss 1.07907248
Validated batch 212 batch loss 1.29718447
Validated batch 213 batch loss 1.11116529
Validated batch 214 batch loss 1.07902288
Validated batch 215 batch loss 0.847858965
Validated batch 216 batch loss 1.04069448
Validated batch 217 batch loss 1.0716083
Validated batch 218 batch loss 1.13727832
Validated batch 219 batch loss 1.2288909
Validated batch 220 batch loss 1.31565499
Validated batch 221 batch loss 1.2187171
Validated batch 222 batch loss 1.41804349
Validated batch 223 batch loss 0.955788493
Validated batch 224 batch loss 1.16896427
Validated batch 225 batch loss 1.25882709
Validated batch 226 batch loss 1.24966562
Validated batch 227 batch loss 1.2775563
Validated batch 228 batch loss 1.26958334
Validated batch 229 batch loss 1.39665723
Validated batch 230 batch loss 1.3501389
Validated batch 231 batch loss 1.08473372
Validated batch 232 batch loss 1.13370681
Validated batch 233 batch loss 1.13336444
Validated batch 234 batch loss 1.35088754
Validated batch 235 batch loss 1.18605709
Validated batch 236 batch loss 0.989758253
Validated batch 237 batch loss 0.972844362
Validated batch 238 batch loss 1.03420281
Validated batch 239 batch loss 1.15753949
Validated batch 240 batch loss 1.13488913
Validated batch 241 batch loss 1.34819388
Validated batch 242 batch loss 1.08014524
Validated batch 243 batch loss 0.873841584
Validated batch 244 batch loss 1.06292713
Validated batch 245 batch loss 1.24846292
Validated batch 246 batch loss 1.12626743
Validated batch 247 batch loss 1.11691952
Validated batch 248 batch loss 1.07623434
Validated batch 249 batch loss 1.0085485
Validated batch 250 batch loss 1.31205392
Validated batch 251 batch loss 1.14570022
Validated batch 252 batch loss 1.07404327
Validated batch 253 batch loss 1.16875923
Validated batch 254 batch loss 1.23452902
Validated batch 255 batch loss 1.28871918
Validated batch 256 batch loss 1.02560449
Validated batch 257 batch loss 1.19155622
Validated batch 258 batch loss 1.1863085
Validated batch 259 batch loss 1.15522122
Validated batch 260 batch loss 1.17047811
Validated batch 261 batch loss 1.49928832
Validated batch 262 batch loss 1.23570836
Validated batch 263 batch loss 1.5392921
Validated batch 264 batch loss 1.48692918
Validated batch 265 batch loss 1.30960584
Validated batch 266 batch loss 1.32201266
Validated batch 267 batch loss 1.01758242
Validated batch 268 batch loss 1.05629385
Validated batch 269 batch loss 1.05984616
Validated batch 270 batch loss 1.23867536
Validated batch 271 batch loss 1.19662237
Validated batch 272 batch loss 1.04922962
Validated batch 273 batch loss 1.08005536
Validated batch 274 batch loss 1.04493308
Validated batch 275 batch loss 0.924647927
Validated batch 276 batch loss 1.09670472
Validated batch 277 batch loss 0.85669446
Validated batch 278 batch loss 1.1813302
Validated batch 279 batch loss 1.14993834
Validated batch 280 batch loss 1.12508142
Validated batch 281 batch loss 1.25404644
Validated batch 282 batch loss 0.863355279
Validated batch 283 batch loss 1.01036882
Validated batch 284 batch loss 1.11291575
Validated batch 285 batch loss 1.04609513
Validated batch 286 batch loss 1.07550216
Validated batch 287 batch loss 1.28290009
Validated batch 288 batch loss 1.22564042
Validated batch 289 batch loss 1.15507901
Validated batch 290 batch loss 0.956588387
Validated batch 291 batch loss 0.959834695
Validated batch 292 batch loss 1.07484746
Validated batch 293 batch loss 1.16454077
Validated batch 294 batch loss 1.16751528
Validated batch 295 batch loss 0.969649851
Validated batch 296 batch loss 1.19547153
Validated batch 297 batch loss 1.07341981
Validated batch 298 batch loss 1.06760883
Validated batch 299 batch loss 1.35689
Validated batch 300 batch loss 1.2639358
Validated batch 301 batch loss 1.06957281
Validated batch 302 batch loss 1.03834391
Validated batch 303 batch loss 1.24449325
Validated batch 304 batch loss 1.14600241
Validated batch 305 batch loss 1.23794293
Validated batch 306 batch loss 1.20050418
Validated batch 307 batch loss 1.27011895
Validated batch 308 batch loss 1.42294192
Validated batch 309 batch loss 1.18660402
Validated batch 310 batch loss 1.20661306
Validated batch 311 batch loss 1.08829272
Validated batch 312 batch loss 1.20171607
Validated batch 313 batch loss 1.3147862
Validated batch 314 batch loss 1.17764974
Validated batch 315 batch loss 1.16647625
Validated batch 316 batch loss 1.05665469
Validated batch 317 batch loss 1.28874433
Validated batch 318 batch loss 1.08434463
Validated batch 319 batch loss 1.29165339
Validated batch 320 batch loss 1.14922309
Validated batch 321 batch loss 1.41976023
Validated batch 322 batch loss 1.28461981
Validated batch 323 batch loss 1.46779954
Validated batch 324 batch loss 1.19665337
Validated batch 325 batch loss 1.27569675
Validated batch 326 batch loss 1.38932085
Validated batch 327 batch loss 1.29380655
Validated batch 328 batch loss 1.15260267
Validated batch 329 batch loss 1.43656325
Validated batch 330 batch loss 1.20460725
Validated batch 331 batch loss 1.26436067
Validated batch 332 batch loss 1.34993505
Validated batch 333 batch loss 1.25357461
Validated batch 334 batch loss 1.29283834
Validated batch 335 batch loss 1.1882298
Validated batch 336 batch loss 1.27605009
Validated batch 337 batch loss 1.29372358
Validated batch 338 batch loss 1.26539922
Validated batch 339 batch loss 1.36336255
Validated batch 340 batch loss 1.11484194
Validated batch 341 batch loss 1.28200519
Validated batch 342 batch loss 1.40427041
Validated batch 343 batch loss 1.16006207
Validated batch 344 batch loss 1.12491059
Validated batch 345 batch loss 1.24196863
Validated batch 346 batch loss 1.18061
Validated batch 347 batch loss 0.868069768
Validated batch 348 batch loss 1.12633014
Validated batch 349 batch loss 1.09556842
Validated batch 350 batch loss 1.0884707
Validated batch 351 batch loss 1.13215911
Validated batch 352 batch loss 1.18537688
Validated batch 353 batch loss 1.23683071
Validated batch 354 batch loss 1.33180118
Validated batch 355 batch loss 1.14976513
Validated batch 356 batch loss 1.2605772
Validated batch 357 batch loss 1.29055285
Validated batch 358 batch loss 1.33169675
Validated batch 359 batch loss 1.28928161
Validated batch 360 batch loss 1.06565487
Validated batch 361 batch loss 1.11268687
Validated batch 362 batch loss 0.969008803
Validated batch 363 batch loss 1.31165457
Validated batch 364 batch loss 1.17543292
Validated batch 365 batch loss 1.30125165
Validated batch 366 batch loss 1.28233719
Validated batch 367 batch loss 1.15499878
Validated batch 368 batch loss 1.04659855
Validated batch 369 batch loss 1.2704432
Validated batch 370 batch loss 1.04844284
Validated batch 371 batch loss 1.33763659
Validated batch 372 batch loss 1.26456356
Validated batch 373 batch loss 0.973688602
Validated batch 374 batch loss 1.13482547
Validated batch 375 batch loss 1.02099478
Validated batch 376 batch loss 1.00227606
Validated batch 377 batch loss 1.18761098
Validated batch 378 batch loss 1.13617802
Validated batch 379 batch loss 1.04774404
Validated batch 380 batch loss 1.10532498
Validated batch 381 batch loss 1.03970504
Validated batch 382 batch loss 1.23223209
Validated batch 383 batch loss 1.1207509
Validated batch 384 batch loss 0.840358913
Validated batch 385 batch loss 0.990479529
Validated batch 386 batch loss 1.15697181
Validated batch 387 batch loss 0.941364646
Validated batch 388 batch loss 1.23443413
Validated batch 389 batch loss 1.16909385
Validated batch 390 batch loss 1.29159415
Validated batch 391 batch loss 1.11454856
Validated batch 392 batch loss 1.24421
Validated batch 393 batch loss 1.22919083
Validated batch 394 batch loss 1.16915464
Validated batch 395 batch loss 1.00783634
Validated batch 396 batch loss 1.3654108
Validated batch 397 batch loss 1.24119937
Validated batch 398 batch loss 1.16609979
Validated batch 399 batch loss 1.10827804
Validated batch 400 batch loss 1.19910824
Validated batch 401 batch loss 1.21901023
Validated batch 402 batch loss 1.17971945
Validated batch 403 batch loss 1.16849923
Validated batch 404 batch loss 0.946307182
Validated batch 405 batch loss 1.12755084
Validated batch 406 batch loss 1.07594371
Validated batch 407 batch loss 0.906479
Validated batch 408 batch loss 1.20942187
Validated batch 409 batch loss 1.49197721
Validated batch 410 batch loss 1.26082778
Validated batch 411 batch loss 1.03501189
Validated batch 412 batch loss 0.945778668
Validated batch 413 batch loss 1.20483589
Validated batch 414 batch loss 1.4453795
Validated batch 415 batch loss 1.05024993
Validated batch 416 batch loss 0.934164464
Validated batch 417 batch loss 0.984506667
Validated batch 418 batch loss 0.963492155
Validated batch 419 batch loss 1.22120011
Validated batch 420 batch loss 1.20523846
Validated batch 421 batch loss 1.23093629
Validated batch 422 batch loss 1.10971856
Validated batch 423 batch loss 1.13450325
Validated batch 424 batch loss 0.977749228
Validated batch 425 batch loss 1.23187482
Validated batch 426 batch loss 1.28663933
Validated batch 427 batch loss 1.10857129
Validated batch 428 batch loss 1.20542192
Validated batch 429 batch loss 0.967329681
Validated batch 430 batch loss 0.985922754
Validated batch 431 batch loss 1.15769207
Validated batch 432 batch loss 1.25786436
Validated batch 433 batch loss 1.21421242
Validated batch 434 batch loss 1.4017539
Validated batch 435 batch loss 1.1771338
Validated batch 436 batch loss 1.35288978
Validated batch 437 batch loss 1.18262863
Validated batch 438 batch loss 0.863066912
Validated batch 439 batch loss 1.24209046
Validated batch 440 batch loss 1.43247581
Validated batch 441 batch loss 1.32789302
Validated batch 442 batch loss 1.27516222
Validated batch 443 batch loss 1.09293342
Validated batch 444 batch loss 0.820868552
Validated batch 445 batch loss 0.882044435
Validated batch 446 batch loss 1.24060881
Validated batch 447 batch loss 1.05750644
Validated batch 448 batch loss 1.52843225
Validated batch 449 batch loss 1.21073878
Validated batch 450 batch loss 1.0397799
Validated batch 451 batch loss 1.27927339
Validated batch 452 batch loss 1.11513376
Validated batch 453 batch loss 1.04960907
Validated batch 454 batch loss 1.37047529
Validated batch 455 batch loss 1.00552392
Validated batch 456 batch loss 0.911997676
Validated batch 457 batch loss 1.10372722
Validated batch 458 batch loss 1.0908277
Validated batch 459 batch loss 1.15050888
Validated batch 460 batch loss 1.19748139
Validated batch 461 batch loss 1.19251633
Validated batch 462 batch loss 1.0609901
Validated batch 463 batch loss 1.22851276
Validated batch 464 batch loss 1.09073734
Validated batch 465 batch loss 1.21236897
Validated batch 466 batch loss 1.28949285
Validated batch 467 batch loss 1.10636711
Validated batch 468 batch loss 1.29853272
Validated batch 469 batch loss 1.17117071
Validated batch 470 batch loss 1.06236613
Validated batch 471 batch loss 1.35255051
Validated batch 472 batch loss 1.06792498
Validated batch 473 batch loss 1.11969173
Validated batch 474 batch loss 0.885627031
Validated batch 475 batch loss 1.37312555
Validated batch 476 batch loss 1.01642323
Validated batch 477 batch loss 1.32234848
Validated batch 478 batch loss 1.16328847
Validated batch 479 batch loss 1.13453579
Validated batch 480 batch loss 1.22807729
Validated batch 481 batch loss 1.30649328
Validated batch 482 batch loss 1.09599197
Validated batch 483 batch loss 1.26624703
Validated batch 484 batch loss 1.35219252
Validated batch 485 batch loss 1.19718277
Validated batch 486 batch loss 1.35750735
Validated batch 487 batch loss 1.24051726
Validated batch 488 batch loss 1.26271915
Validated batch 489 batch loss 1.30412984
Validated batch 490 batch loss 1.11302471
Validated batch 491 batch loss 1.35146785
Validated batch 492 batch loss 1.26417184
Validated batch 493 batch loss 1.23394823
Validated batch 494 batch loss 1.2983067
Validated batch 495 batch loss 1.31085432
Validated batch 496 batch loss 1.21496916
Validated batch 497 batch loss 1.05742812
Validated batch 498 batch loss 1.09316468
Validated batch 499 batch loss 1.0602169
Validated batch 500 batch loss 1.08049369
Validated batch 501 batch loss 1.25076222
Validated batch 502 batch loss 1.15784192
Validated batch 503 batch loss 1.15186989
Validated batch 504 batch loss 1.26395047
Validated batch 505 batch loss 1.26459312
Validated batch 506 batch loss 1.13198698
Validated batch 507 batch loss 1.1093998
Validated batch 508 batch loss 1.14434481
Validated batch 509 batch loss 1.1675849
Validated batch 510 batch loss 0.886506796
Validated batch 511 batch loss 1.23467469
Validated batch 512 batch loss 1.23529291
Validated batch 513 batch loss 1.22568059
Validated batch 514 batch loss 1.393628
Validated batch 515 batch loss 1.12967753
Validated batch 516 batch loss 1.37663603
Validated batch 517 batch loss 1.2366637
Validated batch 518 batch loss 1.5461719
Validated batch 519 batch loss 1.29218364
Validated batch 520 batch loss 1.03517711
Validated batch 521 batch loss 1.35840774
Validated batch 522 batch loss 1.09120822
Validated batch 523 batch loss 1.22175288
Validated batch 524 batch loss 1.25404656
Validated batch 525 batch loss 1.04262054
Validated batch 526 batch loss 1.17129278
Validated batch 527 batch loss 1.32428503
Validated batch 528 batch loss 1.56009352
Validated batch 529 batch loss 1.3491689
Validated batch 530 batch loss 1.02737558
Validated batch 531 batch loss 1.04119372
Validated batch 532 batch loss 1.18957686
Validated batch 533 batch loss 0.931058109
Validated batch 534 batch loss 1.43962359
Validated batch 535 batch loss 0.855127335
Validated batch 536 batch loss 1.24827421
Validated batch 537 batch loss 1.52720332
Validated batch 538 batch loss 0.96930778
Validated batch 539 batch loss 0.958563805
Validated batch 540 batch loss 0.999774158
Validated batch 541 batch loss 0.900740921
Validated batch 542 batch loss 1.00716519
Validated batch 543 batch loss 0.913691044
Validated batch 544 batch loss 1.232512
Validated batch 545 batch loss 1.34395266
Validated batch 546 batch loss 1.275388
Validated batch 547 batch loss 1.07029462
Validated batch 548 batch loss 1.14915013
Validated batch 549 batch loss 1.29543948
Validated batch 550 batch loss 0.984211087
Validated batch 551 batch loss 1.02799237
Validated batch 552 batch loss 1.03657055
Validated batch 553 batch loss 1.22721291
Validated batch 554 batch loss 1.154387
Validated batch 555 batch loss 1.12087059
Validated batch 556 batch loss 0.879659951
Validated batch 557 batch loss 0.925859451
Validated batch 558 batch loss 1.15060711
Validated batch 559 batch loss 0.900426745
Validated batch 560 batch loss 1.27580476
Validated batch 561 batch loss 1.04452896
Validated batch 562 batch loss 1.27798522
Validated batch 563 batch loss 1.26705992
Validated batch 564 batch loss 1.14506519
Validated batch 565 batch loss 1.18811226
Validated batch 566 batch loss 1.12187457
Validated batch 567 batch loss 1.20918798
Validated batch 568 batch loss 0.827171445
Validated batch 569 batch loss 1.09508014
Validated batch 570 batch loss 1.28017294
Validated batch 571 batch loss 1.08128548
Validated batch 572 batch loss 1.32304466
Validated batch 573 batch loss 1.22090411
Validated batch 574 batch loss 1.50635672
Validated batch 575 batch loss 1.37621629
Validated batch 576 batch loss 1.30681574
Validated batch 577 batch loss 1.2221024
Validated batch 578 batch loss 1.07041287
Validated batch 579 batch loss 0.895540953
Validated batch 580 batch loss 0.971249163
Validated batch 581 batch loss 0.983097613
Validated batch 582 batch loss 1.24694026
Validated batch 583 batch loss 1.18407357
Validated batch 584 batch loss 1.24504137
Validated batch 585 batch loss 1.04097974
Validated batch 586 batch loss 1.2286917
Validated batch 587 batch loss 1.24442828
Validated batch 588 batch loss 0.832589149
Validated batch 589 batch loss 1.16274977
Validated batch 590 batch loss 1.13267696
Validated batch 591 batch loss 1.32621717
Validated batch 592 batch loss 1.12498105
Validated batch 593 batch loss 1.33883929
Validated batch 594 batch loss 1.07835412
Validated batch 595 batch loss 1.18090796
Validated batch 596 batch loss 1.08424687
Validated batch 597 batch loss 1.20836151
Validated batch 598 batch loss 0.87550813
Validated batch 599 batch loss 1.06716263
Validated batch 600 batch loss 1.02472329
Validated batch 601 batch loss 0.755588174
Validated batch 602 batch loss 0.665949821
Validated batch 603 batch loss 0.745787501
Validated batch 604 batch loss 1.12642789
Validated batch 605 batch loss 1.2136898
Validated batch 606 batch loss 1.15242147
Validated batch 607 batch loss 1.13698578
Validated batch 608 batch loss 0.892348289
Validated batch 609 batch loss 1.03295302
Validated batch 610 batch loss 1.12227595
Validated batch 611 batch loss 1.11100721
Validated batch 612 batch loss 0.925857425
Validated batch 613 batch loss 1.29366493
Validated batch 614 batch loss 0.91744566
Validated batch 615 batch loss 1.18201661
Validated batch 616 batch loss 1.15520537
Validated batch 617 batch loss 1.07589221
Validated batch 618 batch loss 1.36922932
Validated batch 619 batch loss 1.19212079
Validated batch 620 batch loss 1.07124186
Validated batch 621 batch loss 1.05054045
Validated batch 622 batch loss 1.14292145
Validated batch 623 batch loss 0.997682631
Validated batch 624 batch loss 0.862873
Validated batch 625 batch loss 1.00835133
Validated batch 626 batch loss 1.29116583
Validated batch 627 batch loss 1.16537261
Validated batch 628 batch loss 1.01509619
Validated batch 629 batch loss 1.25309467
Validated batch 630 batch loss 1.33238494
Validated batch 631 batch loss 1.32594538
Validated batch 632 batch loss 1.301579
Validated batch 633 batch loss 1.08152664
Validated batch 634 batch loss 1.23583102
Validated batch 635 batch loss 1.33563685
Validated batch 636 batch loss 1.28173304
Validated batch 637 batch loss 1.12106407
Validated batch 638 batch loss 1.28332782
Validated batch 639 batch loss 1.28200078
Validated batch 640 batch loss 0.994489908
Validated batch 641 batch loss 1.14809585
Validated batch 642 batch loss 0.975358
Validated batch 643 batch loss 1.03046572
Validated batch 644 batch loss 0.974185288
Validated batch 645 batch loss 1.18163836
Validated batch 646 batch loss 1.12966883
Validated batch 647 batch loss 1.0263567
Validated batch 648 batch loss 1.12955499
Validated batch 649 batch loss 1.31350529
Validated batch 650 batch loss 1.45769215
Validated batch 651 batch loss 1.20332265
Validated batch 652 batch loss 0.857017219
Validated batch 653 batch loss 1.27940714
Validated batch 654 batch loss 1.00485682
Validated batch 655 batch loss 1.00467944
Validated batch 656 batch loss 1.20303941
Validated batch 657 batch loss 1.19651246
Validated batch 658 batch loss 1.30962276
Validated batch 659 batch loss 1.18078017
Validated batch 660 batch loss 0.915407777
Validated batch 661 batch loss 1.17999971
Validated batch 662 batch loss 1.16284275
Validated batch 663 batch loss 1.16826475
Validated batch 664 batch loss 1.24318457
Validated batch 665 batch loss 1.16457915
Validated batch 666 batch loss 0.88852036
Validated batch 667 batch loss 1.28884327
Validated batch 668 batch loss 1.31658161
Validated batch 669 batch loss 1.13168764
Validated batch 670 batch loss 1.06561351
Validated batch 671 batch loss 1.32203043
Validated batch 672 batch loss 1.21840668
Validated batch 673 batch loss 1.07035494
Validated batch 674 batch loss 1.04655886
Validated batch 675 batch loss 0.968177199
Validated batch 676 batch loss 1.39412212
Validated batch 677 batch loss 1.10792804
Validated batch 678 batch loss 0.861998081
Validated batch 679 batch loss 1.01872563
Validated batch 680 batch loss 1.29006493
Validated batch 681 batch loss 1.35169053
Validated batch 682 batch loss 1.61163402
Validated batch 683 batch loss 1.01198661
Validated batch 684 batch loss 1.23591805
Validated batch 685 batch loss 1.15173078
Validated batch 686 batch loss 1.17777205
Validated batch 687 batch loss 1.03541481
Validated batch 688 batch loss 1.0638026
Validated batch 689 batch loss 0.868929863
Validated batch 690 batch loss 1.10079265
Validated batch 691 batch loss 0.995082378
Validated batch 692 batch loss 0.942228377
Validated batch 693 batch loss 1.00618911
Validated batch 694 batch loss 1.26698637
Validated batch 695 batch loss 1.20004106
Validated batch 696 batch loss 1.09368348
Validated batch 697 batch loss 1.25474644
Validated batch 698 batch loss 1.34060264
Validated batch 699 batch loss 1.27205682
Validated batch 700 batch loss 1.4955399
Validated batch 701 batch loss 1.18903434
Validated batch 702 batch loss 1.04023635
Validated batch 703 batch loss 1.36577857
Validated batch 704 batch loss 1.43984747
Validated batch 705 batch loss 1.40359855
Validated batch 706 batch loss 1.3103174
Validated batch 707 batch loss 1.50058842
Validated batch 708 batch loss 1.26152706
Validated batch 709 batch loss 1.36817622
Validated batch 710 batch loss 1.05069757
Validated batch 711 batch loss 1.06897855
Validated batch 712 batch loss 1.10829258
Validated batch 713 batch loss 1.46562362
Validated batch 714 batch loss 1.38649917
Validated batch 715 batch loss 1.42496502
Validated batch 716 batch loss 1.22651577
Validated batch 717 batch loss 1.30680144
Validated batch 718 batch loss 1.1316309
Validated batch 719 batch loss 1.09191525
Validated batch 720 batch loss 1.14686155
Validated batch 721 batch loss 1.2383852
Validated batch 722 batch loss 1.54205298
Validated batch 723 batch loss 1.3567723
Validated batch 724 batch loss 0.806885481
Validated batch 725 batch loss 1.05276585
Validated batch 726 batch loss 1.08828211
Validated batch 727 batch loss 1.32726705
Validated batch 728 batch loss 1.26458478
Validated batch 729 batch loss 1.07855523
Validated batch 730 batch loss 0.938086689
Validated batch 731 batch loss 0.962149799
Validated batch 732 batch loss 0.706255674
Validated batch 733 batch loss 0.907003522
Validated batch 734 batch loss 1.05717969
Validated batch 735 batch loss 0.954876423
Validated batch 736 batch loss 1.12904978
Validated batch 737 batch loss 1.30803478
Validated batch 738 batch loss 1.12831831
Epoch 5 val loss 1.1636605262756348